Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Smola2007,
abstract = {We describe a technique for comparing distributions without the need for density estimation as an intermediate step. Our approach relies on mapping the distributions into a reproducing kernel Hilbert space. Applications of this technique can be found in two-sample tests, which are used for determining whether two sets of observations arise from the same distribution, covariate shift correction, local learning, measures of independence, and density estimation.},
author = {Smola, Alex and Gretton, Arthur and Song, Le and Sch{\"{o}}lkopf, Bernhard},
doi = {10.1007/978-3-540-75225-7_5},
file = {:home/kaslu/Documents/Mendeley/2007 - Smola et al. - A Hilbert Space Embedding for Distributions.pdf:pdf},
isbn = {978-3-540-75224-0},
issn = {0302-9743},
pages = {13--31},
title = {{A Hilbert Space Embedding for Distributions}},
url = {http://link.springer.com/10.1007/978-3-540-75225-7{\_}5},
year = {2007}
}
@article{Hoel2013,
abstract = {Causal interactions within complex systems can be analyzed at multiple spatial and temporal scales. For example, the brain can be analyzed at the level of neurons, neuronal groups, and areas, over tens, hundreds, or thousands of milliseconds. It is widely assumed that, once a micro level is fixed, macro levels are fixed too, a relation called supervenience. It is also assumed that, although macro descriptions may be convenient, only the micro level is causally complete, because it includes every detail, thus leaving no room for causation at the macro level. However, this assumption can only be evaluated under a proper measure of causation. Here, we use a measure [effective information (EI)] that depends on both the effectiveness of a system's mechanisms and the size of its state space: EI is higher the more the mechanisms constrain the system's possible past and future states. By measuring EI at micro and macro levels in simple systems whose micro mechanisms are fixed, we show that for certain causal architectures EI can peak at a macro level in space and/or time. This happens when coarse-grained macro mechanisms are more effective (more deterministic and/or less degenerate) than the underlying micro mechanisms, to an extent that overcomes the smaller state space. Thus, although the macro level supervenes upon the micro, it can supersede it causally, leading to genuine causal emergence--the gain in EI when moving from a micro to a macro level of analysis.},
author = {Hoel, Erik P and Albantakis, Larissa and Tononi, Giulio},
doi = {10.1073/pnas.1314922110},
file = {:home/kaslu/Documents/Mendeley/2013 - Hoel, Albantakis, Tononi - Quantifying causal emergence shows that macro can beat micro.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Computer Simulation,Information Theory,Models, Theoretical,Systems Biology,Systems Biology: methods},
month = {dec},
number = {49},
pages = {19790--5},
pmid = {24248356},
title = {{Quantifying causal emergence shows that macro can beat micro.}},
url = {http://www.pnas.org/cgi/content/long/110/49/19790},
volume = {110},
year = {2013}
}
@article{Akrami2018,
abstract = {Many models of cognition and of neural computations posit the use and estimation of prior stimulus statistics: it has long been known that working memory and perception are strongly impacted by previous sensory experience, even when that sensory history is irrelevant for the current task at hand. Nevertheless, the neural mechanisms and brain regions necessary for computing and using such priors are unknown. Here we report that the posterior parietal cortex (PPC) is a critical locus for the representation and use of prior stimulus information. We trained rats in an auditory Parametric Working Memory (PWM) task, and found that rats displayed substantial and readily quantifiable behavioral effects of sensory stimulus history, similar to those observed in humans and monkeys. Earlier proposals that PPC supports working memory predict that optogenetic silencing of this region would impair behavior in our working memory task. Contrary to this prediction, silencing PPC significantly improved performance. Quantitative analyses of behavior revealed that this improvement was due to the selective reduction of the effects of prior sensory stimuli. Electrophysiological recordings showed that PPC neurons carried far more information about sensory stimuli of previous trials than about stimuli of the current trial. Furthermore, the more information about previous trial sensory history in the neural firing rates of a given rat's PPC, the greater the behavioral effect of sensory history in that rat, suggesting a tight link between behavior and PPC representations of stimulus history. Our results indicate that the PPC is a central component in the processing of sensory stimulus history, and open a window for neurobiological investigation of long-standing questions regarding how perception and working memory are affected by prior sensory information.},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1101/182246},
author = {Akrami, Athena and Kopec, Charles D. and Diamond, Mathew E. and Brody, Carlos D.},
doi = {10.1038/nature25510},
eprint = {/dx.doi.org/10.1101/182246},
isbn = {1476-4687},
issn = {14764687},
journal = {Nature},
month = {feb},
number = {7692},
pages = {368--372},
pmid = {29414944},
primaryClass = {http:},
title = {{Posterior parietal cortex represents sensory history and mediates its effects on behaviour}},
url = {http://www.nature.com/doifinder/10.1038/nature25510},
volume = {554},
year = {2018}
}
@article{Kass,
abstract = {We use our experience in neuroscience as a source of defining issues for the discipline of statistics. We argue that to remain vibrant, the field must open up by taking a less restrictive view of what constitutes statistical training.},
author = {Brown, Emery N. and Kass, Robert E.},
doi = {10.1198/tast.2009.0019},
file = {:home/kaslu/Documents/Mendeley/2009 - Brown, Kass - What Is Statistics.pdf{\_}(case{\_}:pdf{\_}(case{\_}},
isbn = {0003-1305$\backslash$r1537-2731},
issn = {0003-1305},
journal = {The American Statistician},
month = {may},
number = {2},
pages = {105--110},
title = {{What Is Statistics?}},
url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2009.0019},
volume = {63},
year = {2009}
}
@article{Manuscript2008,
author = {Wark, Barry and Lundstrom, Brian Nils and Fairhall, Adrienne L.},
doi = {10.1016/j.conb.2007.07.001},
file = {:home/kaslu/Documents/Mendeley/2007 - Wark, Lundstrom, Fairhall - Sensory adaptation.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {aug},
number = {4},
pages = {423--429},
pmid = {1000000221},
title = {{Sensory adaptation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022202X15370834 http://linkinghub.elsevier.com/retrieve/pii/S0959438807000840},
volume = {17},
year = {2007}
}
@article{Amelunxen2013,
abstract = {Recent research indicates that many convex optimization problems with random constraints exhibit a phase transition as the number of constraints increases. For example, this phenomenon emerges in the {\$}\backslashell{\_}1{\$} minimization method for identifying a sparse vector from random linear measurements. Indeed, the {\$}\backslashell{\_}1{\$} approach succeeds with high probability when the number of measurements exceeds a threshold that depends on the sparsity level; otherwise, it fails with high probability. This paper provides the first rigorous analysis that explains why phase transitions are ubiquitous in random convex optimization problems. It also describes tools for making reliable predictions about the quantitative aspects of the transition, including the location and the width of the transition region. These techniques apply to regularized linear inverse problems with random measurements, to demixing problems under a random incoherence model, and also to cone programs with random affine constraints. The applied results depend on foundational research in conic geometry. This paper introduces a summary parameter, called the statistical dimension, that canonically extends the dimension of a linear subspace to the class of convex cones. The main technical result demonstrates that the sequence of intrinsic volumes of a convex cone concentrates sharply around the statistical dimension. This fact leads to accurate bounds on the probability that a randomly rotated cone shares a ray with a fixed cone.},
archivePrefix = {arXiv},
arxivId = {1303.6672},
author = {Amelunxen, Dennis and Lotz, Martin and McCoy, Michael B. and Tropp, Joel A.},
doi = {10.1093/imaiai/iau005},
eprint = {1303.6672},
file = {:home/kaslu/Documents/Mendeley/2013 - Amelunxen et al. - Living on the edge Phase transitions in convex programs with random data.pdf:pdf},
issn = {2049-8764},
keywords = {1 minimization,compressed sens-,conic geometry,convex optimization,ing,integral geometry,morphological component analysis,nuclear norm minimization,phase transitions,rank-sparsity},
number = {December},
pages = {224--294},
title = {{Living on the edge: Phase transitions in convex programs with random data}},
url = {http://arxiv.org/abs/1303.6672},
year = {2013}
}
@article{Okun2015,
abstract = {A large population of neurons can, in principle, produce an astro- nomical number of distinct firing patterns. In cortex, however, these patterns lie in a space of lower dimension1–4 , as if individual neuronswere ‘‘obedientmembersof ahuge orchestra''5 recordings from the visual cortex of mouse ( monkey ( Maca ca mul atta ) to investigate the relationship between Mus mus .Herewe use cul us ) and individual neurons and the population, and to establish the under- lying circuit mechanisms.Weshow that neighbouring neurons can differ in their coupling to the overall firing of the population, rang- ing from strongly coupled ‘choristers' to weakly coupled ‘soloists'. Population coupling is largely independent of sensory preferences, and it is a fixed cellular attribute, invariant to stimulus conditions. Neurons with high population coupling are more strongly affected by non-sensory behavioural variables such asmotor intention. Pop- ulation coupling reflects a causal relationship, predicting the res- ponseof aneurontooptogeneticallydrivenincreases inlocalactivity. Moreover, population coupling indicates synaptic connectivity; the population coupling of a neuron, measured in vitro in sequent estimates of the number of synapses received from vivo , predicted sub- itsneighbours.Finally,populationcouplingprovides a compact sum- maryof population activity;knowledge of the population couplings of n neurons predicts a substantial portion of their n 2 pairwise cor- relations. Population coupling therefore represents a novel, simple measure that characterizes the relationship of each neuron to a largerpopulation, explainingseemingly complexnetworkfiringpat- terns},
author = {Okun, Michael and Steinmetz, Nicholas A. and Cossell, Lee and Iacaruso, M. Florencia and Ko, Ho and Barth{\'{o}}, P{\'{e}}ter and Moore, Tirin and Hofer, Sonja B. and Mrsic-Flogel, Thomas D. and Carandini, Matteo and Harris, Kenneth D.},
doi = {10.1038/nature14273},
isbn = {doi:10.1038/nature14273},
issn = {14764687},
journal = {Nature},
month = {may},
number = {7553},
pages = {511--515},
pmid = {25849776},
title = {{Diverse coupling of neurons to populations in sensory cortex}},
url = {http://www.nature.com/articles/nature14273},
volume = {521},
year = {2015}
}
@article{Crockett2017,
abstract = {Despite the diversity of human moral values, there is a universal prohibition on harming others for personal gain 1,2 . Humans avoid harming others to a remarkable degree compared with other species 3 and are even willing to incur significant personal costs to alleviate others' suffering 4,5 . Why and how people forgo self-interest for the sake of others' welfare remains an enduring puzzle. Recent work has implicated specific brain regions in moral decision-making 6–9 and probed how moral behavior relates to social cognitive processes such as empathy and mentalizing 10–14 . However, little is known about the neural computations supporting moral decisions to avoid harming others for personal gain and whether individual differences in these computations predict variation in actual moral behavior. We measured moral behavior in a task where participants could trade personal profit against pain experienced by either themselves or an anonymous other person (Fig. 1a). Most people required more financial compensation to increase others' pain compared with their own 15,16 . In other words, profiting from another's pain had lower subjective value than profiting from one's own pain. One possible explanation for this moral preference is that another's pain is more aversive than one's own pain. Alternatively, profit gained from harming another may engender less pleasure than the very same profit gained from harming oneself 17 . Because the moral behavior we are interested in here reflects a tradeoff between profit and pain, these competing explanations are not easily resolved from behavioral observation alone. However, using neuroimaging, we can ask whether individual differences in moral preferences are better explained by differential neural repre-sentations of pain or profit in the context of harming others versus oneself. Previous neuroimaging studies of moral decision-making have attributed activity in several brain regions to a range of cognitive processes. Activity in insula, anterior cingulate cortex (ACC) and tempo-roparietal junction (TPJ) is linked to empathy and mentalizing 7,8,10–14 ; activity in striatum and ventromedial prefrontal cortex (vmPFC) is associated with value computation 8,12,13 ; and lateral prefrontal cortex (LPFC) activity is considered to reflect cognitive control 6–9 . However, decomposing the cognitive mechanisms supporting moral decisions is difficult without resorting to reverse inference. Here we addressed this challenge by independently manipulating the amounts of profit and pain resulting from participants' decisions (Fig. 1b). This in turn allowed us to extract neural representations of profit and pain and to ask whether the former was suppressed or the lat-ter boosted as a function of the behavioral expression of a moral aversion to harming others for profit. We avoided reverse inference by asking whether, in line with moral behavior, any brain region showed a greater response to others' pain compared to one's own pain or showed a weaker response to profit gained from harming others relative to profit gained from harming oneself. Our predic-tion, based on prior literature, was that moral decisions involving a tradeoff between pain and profit would engage regions implicated in pain processing or in value-based decision-making, respectively, with pain encoded in insula, ACC and TPJ 18,19 and profit encoded in the striatum and vmPFC 20,21 . Higher-order goals represented in regions such as LPFC are known to modulate value computations in striatum and vmPFC 22 . In particu-lar, LPFC is implicated in orchestrating the influence of moral norms on behavior 23–29 . This region shows increased activation to the extent that people choose to comply with fairness norms 24 , reciprocate trust 26 and avoid harming others for personal gain 8 . Disrupting LPFC activ-ity impairs the integration of moral blame assessments into punish-ment decisions 28 . However, notwithstanding these observations, the},
author = {Crockett, Molly J. and Siegel, Jenifer Z. and Kurth-Nelson, Zeb and Dayan, Peter and Dolan, Raymond J.},
doi = {10.1038/nn.4557},
file = {:home/kaslu/Documents/Mendeley/2017 - Crockett et al. - Moral transgressions corrupt neural representations of value.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {may},
number = {6},
pages = {879--885},
pmid = {28459442},
publisher = {Nature Publishing Group},
title = {{Moral transgressions corrupt neural representations of value}},
url = {http://www.nature.com/doifinder/10.1038/nn.4557},
volume = {20},
year = {2017}
}
@article{Grangier1986,
abstract = {We report on two experiments using an atomic cascade as a light source, and a triggered detection scheme for the second photon of the cascade. The first experiment shows a strong anticorrelation between the triggered detections on both sides of a beam splitter. This result is in contradiction with any classical wave model of light, but in agreement with a quantum description involving single-photon states. The same source and detection scheme were used in a second experiment, where we have observed interferences with a visibility over 98{\%}.},
author = {Grangier, P. and Roger, G. and Aspect, A.},
doi = {10.1209/0295-5075/1/4/004},
file = {:home/kaslu/Documents/Mendeley/1986 - Grangier, Roger, Aspect - Experimental-Evidence for a Photon Anticorrelation Effect on a Beam Splitter - a New Light on Single-Ph.pdf:pdf},
isbn = {0295-5075},
issn = {0295-5075},
journal = {Europhysics Letters (EPL)},
number = {4},
pages = {173--179},
title = {{Experimental-Evidence for a Photon Anticorrelation Effect on a Beam Splitter - a New Light on Single-Photon Interferences}},
volume = {1},
year = {1986}
}
@article{Lak2017,
abstract = {Highlights d Reinforcement learning model with belief state to cope with perceptual uncertainty d Model provides unified account of dopamine in perceptual and reward-guided choices d Dopamine can act as a teaching signal during perceptual decision making as well d Dopamine signals decision confidence prior to behavioral manifestation of choice In Brief Lak et al. show that dopamine neuron responses during a visual decision task comply with predictions of a reinforcement learning model with a belief state signaling confidence. The results reveal that dopamine neurons encode teaching signals appropriate for learning perceptual decisions and respond early enough to impact impending decisions. Lak et al., 2017, Current Biology 27, 821–832 March 20, 2017 {\textordfeminine} 2017 Elsevier Ltd. SUMMARY Central to the organization of behavior is the ability to predict the values of outcomes to guide choices. The accuracy of such predictions is honed by a teaching signal that indicates how incorrect a prediction was (''reward prediction error,'' RPE). In several reinforce-ment learning contexts, such as Pavlovian condition-ing and decisions guided by reward history, this RPE signal is provided by midbrain dopamine neurons. In many situations, however, the stimuli predictive of outcomes are perceptually ambiguous. Perceptual uncertainty is known to influence choices, but it has been unclear whether or how dopamine neurons fac-tor it into their teaching signal. To cope with uncer-tainty, we extended a reinforcement learning model with a belief state about the perceptually ambiguous stimulus; this model generates an estimate of the probability of choice correctness, termed decision confidence. We show that dopamine responses in monkeys performing a perceptually ambiguous deci-sion task comply with the model's predictions. Consequently, dopamine responses did not simply reflect a stimulus' average expected reward value but were predictive of the trial-to-trial fluctuations in perceptual accuracy. These confidence-dependent dopamine responses emerged prior to monkeys' choice initiation, raising the possibility that dopamine impacts impending decisions, in addition to encoding a post-decision teaching signal. Finally, by manipu-lating reward size, we found that dopamine neurons reflect both the upcoming reward size and the confi-dence in achieving it. Together, our results show that dopamine responses convey teaching signals that are also appropriate for perceptual decisions.},
author = {Lak, Armin and Nomoto, Kensaku and Keramati, Mehdi and Sakagami, Masamichi and Correspondence, Adam Kepecs and Kepecs, Adam},
doi = {10.1016/j.cub.2017.02.026},
file = {:home/kaslu/Documents/Mendeley/2017 - Lak et al. - Midbrain Dopamine Neurons Signal Belief in Choice Accuracy during a Perceptual Decision.pdf:pdf},
title = {{Midbrain Dopamine Neurons Signal Belief in Choice Accuracy during a Perceptual Decision}},
year = {2017}
}
@article{Cockayne2016,
abstract = {This paper develops a class of meshless methods that are well-suited to statistical inverse problems involving partial differential equations (PDEs). The methods discussed in this paper view the forcing term in the PDE as a random field that induces a probability distribution over the residual error of a symmetric collocation method. This construction enables the solution of challenging inverse problems while accounting, in a rigorous way, for the impact of the discretisation of the forward problem. In particular, this confers robustness to failure of meshless methods, with statistical inferences driven to be more conservative in the presence of significant solver error. In addition, (i) a principled learning-theoretic approach to minimise the impact of solver error is developed, and (ii) the challenging setting of inverse problems with a non-linear forward model is considered. The method is applied to parameter inference problems in which non-negligible solver error must be accounted for in order to draw valid statistical conclusions.},
archivePrefix = {arXiv},
arxivId = {1605.07811},
author = {Cockayne, Jon and Oates, Chris and Sullivan, Tim and Girolami, Mark},
eprint = {1605.07811},
file = {:home/kaslu/Documents/Mendeley/2016 - Cockayne et al. - Probabilistic Meshless Methods for Partial Differential Equations and Bayesian Inverse Problems.pdf:pdf},
month = {may},
title = {{Probabilistic Meshless Methods for Partial Differential Equations and Bayesian Inverse Problems}},
url = {http://arxiv.org/abs/1605.07811},
year = {2016}
}
@article{Franks2008,
abstract = {One aspect of opinion change that has been of academic interest is the impact of people with extreme opinions (extremists) on opinion dynamics. An agent-based model has been used to study the role of small-world social network topologies on general opinion change in the presence of extremists. It has been found that opinion convergence to a single extreme occurs only when the average number of network connections for each individual is extremely high. Here, we extend the model to examine the effect of positively skewed degree distributions, in addition to small-world structures, on the types of opinion convergence that occur in the presence of extremists. We also examine what happens when extremist opinions are located on the well-connected nodes (hubs) created by the positively skewed distribution. We find that a positively skewed network topology encourages opinion convergence on a single extreme under a wider range of conditions than topologies whose degree distributions were not skewed. The importance of social position for social influence is highlighted by the result that, when positive extremists are placed on hubs, all population convergence is to the positive extreme even when there are twice as many negative extremists. Thus, our results have shown the importance of considering a positively skewed degree distribution, and in particular network hubs and social position, when examining extremist transmission.},
author = {Franks, Daniel W. and Noble, Jason and Kaufmann, Peter and Stagl, Sigrid},
doi = {10.1177/1059712308090536},
isbn = {1059-7123},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {extremism,opinion change,scale free,small world,social networks},
number = {4},
pages = {264--274},
title = {{Extremism Propagation in Social Networks with Hubs}},
url = {http://journals.sagepub.com/doi/10.1177/1059712308090536},
volume = {16},
year = {2008}
}
@article{Aitchison2017,
abstract = {Two theoretical ideas have emerged recently with the ambition to provide a unifying functional explanation of neural population coding and dynamics: predictive coding and Bayesian inference. Here, we describe the two theories and their combination into a single framework: Bayesian predictive coding. We clarify how the two theories can be distinguished, despite sharing core computational concepts and addressing an overlapping set of empirical phenomena. We argue that predictive coding is an algorithmic/representational motif that can serve several different computational goals of which Bayesian inference is but one. Conversely, while Bayesian inference can utilize predictive coding, it can also be realized by a variety of other representations. We critically evaluate the experimental evidence supporting Bayesian predictive coding and discuss how to test it more directly.},
author = {Aitchison, Laurence and Lengyel, M{\'{a}}t{\'{e}}},
doi = {10.1016/j.conb.2017.08.010},
file = {:home/kaslu/Documents/Mendeley/2017 - Aitchison, Lengyel - With or without you predictive coding and Bayesian inference in the brain.pdf:pdf},
isbn = {0959-4388},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {219--227},
pmid = {28942084},
title = {{With or without you: predictive coding and Bayesian inference in the brain}},
volume = {46},
year = {2017}
}
@article{Friston2006,
abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure. ?? 2006.},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.4122v2},
author = {Friston, Karl and Kilner, James and Harrison, Lee},
doi = {10.1016/j.jphysparis.2006.10.001},
eprint = {arXiv:1401.4122v2},
file = {:home/kaslu/Documents/Mendeley/2006 - Friston, Kilner, Harrison - A free energy principle for the brain.pdf:pdf},
isbn = {0928-4257},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes},
month = {jul},
number = {1-3},
pages = {70--87},
pmid = {17097864},
title = {{A free energy principle for the brain}},
url = {http://www.sciencedirect.com/science/article/pii/S092842570600060X http://linkinghub.elsevier.com/retrieve/pii/S092842570600060X},
volume = {100},
year = {2006}
}
@article{Bollimunta2012,
abstract = {Previous neurophysiological studies of perceptual decision-making have focused on single-unit activity, providing insufficient information about how individual decisions are accomplished. For the first time, we recorded simultaneously from multiple decision-related neurons in parietal cortex of monkeys performing a perceptual decision task and used these recordings to analyze the neural dynamics during single trials. We demonstrate that decision-related lateral intraparietal area neurons typically undergo gradual changes in firing rate during individual decisions, as predicted by mechanisms based on continuous integration of sensory evidence. Furthermore, we identify individual decisions that can be described as a change of mind: the decision circuitry was transiently in a state associated with a different choice before transitioning into a state associated with the final choice. These changes of mind reflected in monkey neural activity share similarities with previously reported changes of mind reflected in human behavior.},
author = {Bollimunta, Anil and Totten, Douglas and Ditterich, Jochen},
doi = {10.1523/JNEUROSCI.5752-11.2012},
file = {:home/kaslu/Documents/Mendeley/2012 - Bollimunta, Totten, Ditterich - Neural Dynamics of Choice Single-Trial Analysis of Decision-Related Activity in Parietal Cortex.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {37},
pages = {12684--12701},
pmid = {22972993},
title = {{Neural Dynamics of Choice: Single-Trial Analysis of Decision-Related Activity in Parietal Cortex}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5752-11.2012},
volume = {32},
year = {2012}
}
@article{Churchland2010,
author = {Churchland, Mark M. and Yu, Byron M. and Cunningham, John P. and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew a and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V.},
doi = {10.1038/nn.2501},
file = {:home/kaslu/Documents/Mendeley/2010 - Churchland et al. - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {mar},
number = {3},
pages = {369--378},
title = {{Stimulus onset quenches neural variability: a widespread cortical phenomenon}},
url = {http://www.nature.com/doifinder/10.1038/nn.2501},
volume = {13},
year = {2010}
}
@article{Mehta2014,
abstract = {Deep learning is a broad set of techniques that uses multiple layers of representation to automatically learn relevant features directly from structured data. Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing. Despite the enormous success of deep learning, relatively little is understood theoretically about why these techniques are so successful at feature learning and compression. Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales. We construct an exact mapping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs). We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions. Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data.},
archivePrefix = {arXiv},
arxivId = {1410.3831},
author = {Mehta, Pankaj and Schwab, David J.},
eprint = {1410.3831},
file = {:home/kaslu/Documents/Mendeley/2014 - Mehta, Schwab - An exact mapping between the Variational Renormalization Group and Deep Learning.pdf:pdf},
month = {oct},
pages = {8},
title = {{An exact mapping between the Variational Renormalization Group and Deep Learning}},
url = {http://arxiv.org/abs/1410.3831},
year = {2014}
}
@article{Skene2017,
abstract = {{\textless}p{\textgreater}The genetic mechanisms regulating the brain and behaviour across the lifespan are poorly understood. We found that lifespan transcriptome trajectories describe a calendar of gene regulatory events in the brain of humans and mice. Transcriptome trajectories defined a sequence of gene expression changes in neuronal, glial and endothelial cell-types, which enabled prediction of age from tissue samples. A major lifespan landmark was the peak change in trajectories occurring in humans at 26 years and in mice at 5 months of age. This species-conserved peak was delayed in females and marked a reorganization of expression of synaptic and schizophrenia-susceptibility genes. The lifespan calendar predicted the characteristic age of onset in young adults and sex differences in schizophrenia. We propose a genomic program generates a lifespan calendar of gene regulation that times age-dependent molecular organization of the brain and mutations that interrupt the program in young adults cause schizophrenia.{\textless}/p{\textgreater}},
author = {Skene, Nathan G. and Roy, Marcia and Grant, Seth G.N.},
doi = {10.7554/eLife.17915.001},
file = {:home/kaslu/Documents/Mendeley/2017 - Skene, Roy, Grant - A genomic lifespan program that reorganises the young adult brain is targeted in schizophrenia.pdf:pdf},
issn = {2050084X},
journal = {eLife},
keywords = {Evolutionary biology,Genomics,Human,Mouse,Neuroscience,Post-mortem,Schizophrenia,Transcriptomics},
pages = {1--30},
pmid = {28893375},
title = {{A genomic lifespan program that reorganises the young adult brain is targeted in schizophrenia}},
volume = {6},
year = {2017}
}
@article{Eldar2016,
abstract = {When perceiving rich sensory information, some people may integrate its various aspects, whereas other people may selectively focus on its most salient aspects. We propose that neural gain modulates the trade-off between breadth and selectivity, such that high gain focuses perception on those aspects of the information that have the strongest, most immediate influence, whereas low gain allows broader integration of different aspects. We illustrate our hypothesis using a neural-network model of ambiguous-letter perception. We then report an experiment demonstrating that, as predicted by the model, pupil-diameter indices of higher gain are associated with letter perception that is more selectively focused on the letter's shape or, if primed, its semantic content. Finally, we report a recognition-memory experiment showing that the relationship between gain and selective processing also applies when the influence of different stimulus features is voluntarily modulated by task demands.},
author = {Eldar, Eran and Niv, Yael and Cohen, Jonathan D.},
doi = {10.1177/0956797616665578},
file = {:home/kaslu/Documents/Mendeley/2016 - Eldar, Niv, Cohen - Do You See the Forest or the Tree Neural Gain and Breadth Versus Focus in Perceptual Processing.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {attention,memory,neural gain,neural network,perception,pupillometry},
number = {12},
pages = {1632--1643},
pmid = {28195019},
title = {{Do You See the Forest or the Tree? Neural Gain and Breadth Versus Focus in Perceptual Processing}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797616665578},
volume = {27},
year = {2016}
}
@article{Gomez2016a,
author = {G{\'{o}}mez, Jos{\'{e}} Mar{\'{i}}a and Verd{\'{u}}, Miguel and Gonz{\'{a}}lez-Meg{\'{i}}as, Adela and M{\'{e}}ndez, Marcos},
doi = {10.1038/nature19758},
file = {:home/kaslu/Documents/Mendeley/2016 - G{\'{o}}mez et al. - The phylogenetic roots of human lethal violence.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {sep},
number = {7624},
pages = {233--237},
publisher = {Nature Research},
title = {{The phylogenetic roots of human lethal violence}},
url = {http://www.nature.com/doifinder/10.1038/nature19758},
volume = {538},
year = {2016}
}
@article{Lee2013,
abstract = {We build simple models for the distribution of voting patterns in a group, using the Supreme Court of the United States as an example. The least structured, or maximum entropy, model that is consistent with the observed pairwise correlations among justices' votes is equivalent to an Ising spin glass. While all correlations (perhaps surprisingly) are positive, the effective pairwise interactions in the spin glass model have both signs, recovering some of our intuition that justices on opposite sides of the ideological spectrum should have a negative influence on one another. Despite the competing interactions, a strong tendency toward unanimity emerges from the model, and this agrees quantitatively with the data. The model shows that voting patterns are organized in a relatively simple "energy landscape," correctly predicts the extent to which each justice is correlated with the majority, and gives us a measure of the influence that justices exert on one another. These results suggest that simple models, grounded in statistical physics, can capture essential features of collective decision making quantitatively, even in a complex political context.},
archivePrefix = {arXiv},
arxivId = {1306.5004},
author = {Lee, Edward D. and Broedersz, Chase P. and Bialek, William},
eprint = {1306.5004},
file = {:home/kaslu/Documents/Mendeley/2013 - Lee, Broedersz, Bialek - Statistical mechanics of the US Supreme Court.pdf:pdf},
month = {jun},
title = {{Statistical mechanics of the US Supreme Court}},
url = {http://arxiv.org/abs/1306.5004},
year = {2013}
}
@article{Cohen2007,
abstract = {Many large and small decisions we make in our daily lives-which ice cream to choose, what research projects to pursue, which partner to marry-require an exploration of alternatives before committing to and exploiting the benefits of a particular choice. Furthermore, many decisions require re-evaluation, and further exploration of alternatives, in the face of changing needs or circumstances. That is, often our decisions depend on a higher level choice: whether to exploit well known but possibly suboptimal alternatives or to explore risky but potentially more profitable ones. How adaptive agents choose between exploitation and exploration remains an important and open question that has received relatively limited attention in the behavioural and brain sciences. The choice could depend on a number of factors, including the familiarity of the environment, how quickly the environment is likely to change and the relative value of exploiting known sources of reward versus the cost of reducing uncertainty through exploration. There is no known generally optimal solution to the exploration versus exploitation problem, and a solution to the general case may indeed not be possible. However, there have been formal analyses of the optimal policy under constrained circumstances. There have also been specific suggestions of how humans and animals may respond to this problem under particular experimental conditions as well as proposals about the brain mechanisms involved. Here, we provide a brief review of this work, discuss how exploration and exploitation may be mediated in the brain and highlight some promising future directions for research.},
author = {Cohen, Jonathan D. and McClure, Samuel and Yu, Angela J.},
doi = {10.1098/rstb.2007.2098},
file = {:home/kaslu/Documents/Mendeley/2007 - Cohen, McClure, Yu - Should I stay or should I go How the human brain manages the trade-off between exploitation and exploration.pdf:pdf},
isbn = {0962-8436 (Print) 0962-8436},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
month = {may},
number = {1481},
pages = {933--942},
pmid = {17395573},
title = {{Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration}},
url = {http://rstb.royalsocietypublishing.org/content/362/1481/933.short http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2007.2098},
volume = {362},
year = {2007}
}
@article{Haidt2004a,
abstract = {Strangeness is fascinating. Medieval maps embellished with fantastical beasts, sixteenth-century wonder chambers filled with natural and technological marvels, even late-twentieth-century supermarket tabloids–all attest to the human fascination with things that violate our basic ideas about reality. The study of morality and culture is therefore an intrinsically fascinating topic. People have created moralities as divergent as those of Nazis and Quakers, headhunters and Jains. And yet, when we look closely at the daily lives of people in divergent cultures, we can find elements that arise in nearly all of them– for example, reciprocity, loyalty, respect for (some) authority, limits on physical harm, and regulation of eating and sexuality. What are we to make of this pattern of similarity within profound difference? Social scientists have traditionally taken two approaches.},
author = {Haidt, Jonathan and Joseph, Craig},
doi = {10.1162/0011526042365555},
file = {:home/kaslu/Documents/Mendeley/2004 - Haidt, Joseph - Intuitive ethics how innately prepared intuitions generate culturally variable virtues(2).pdf:pdf},
isbn = {00115266},
issn = {0011-5266},
journal = {Daedalus},
number = {4},
pages = {55--66},
pmid = {19412522},
title = {{Intuitive ethics: how innately prepared intuitions generate culturally variable virtues}},
url = {http://www.mitpressjournals.org/doi/10.1162/0011526042365555},
volume = {133},
year = {2004}
}
@article{Yu2005,
abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain's implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic. Copyright ??2005 by Elsevier Inc.},
author = {Yu, Angela J. and Dayan, Peter},
doi = {10.1016/j.neuron.2005.04.026},
file = {:home/kaslu/Documents/Mendeley/2005 - Yu, Dayan - Uncertainty, Neuromodulation, and Attention.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
month = {may},
number = {4},
pages = {681--692},
pmid = {15944135},
publisher = {Cell Press},
title = {{Uncertainty, Neuromodulation, and Attention}},
url = {http://www.sciencedirect.com/science/article/pii/S0896627305003624 http://linkinghub.elsevier.com/retrieve/pii/S0896627305003624},
volume = {46},
year = {2005}
}
@article{Fairhall2001,
abstract = {We examine the dynamics of a neural code in the context of stimuli whose statistical properties are themselves evolving dynamically. Adaptation to these statistics occurs over a wide range of timescales-from tens of milliseconds to minutes. Rapid components of adaptation serve to optimize the information that action potentials carry about rapid stimulus variations within the local statistical ensemble, while changes in the rate and statistics of action-potential firing encode information about the ensemble itself, thus resolving potential ambiguities. The speed with which information is optimized and ambiguities are resolved approaches the physical limit imposed by statistical sampling and noise.},
author = {Fairhall, Adrienne L. and Lewen, Geoffrey D. and Bialek, William and {de Ruyter Van Steveninck}, Robert R.},
doi = {10.1038/35090500},
file = {:home/kaslu/Documents/Mendeley/2001 - Fairhall et al. - Efficiency and ambiguity in an adaptive neural code.pdf:pdf},
isbn = {0028-0836 (Print)},
issn = {0028-0836},
journal = {Nature},
month = {aug},
number = {6849},
pages = {787--792},
pmid = {11518957},
title = {{Efficiency and ambiguity in an adaptive neural code}},
url = {http://www.nature.com/doifinder/10.1038/35090500},
volume = {412},
year = {2001}
}
@article{Balasubramanian1996,
abstract = {I define a natural measure of the complexity of a parametric distribution relative to a given true distribution called the {\{}$\backslash$it razor{\}} of a model family. The Minimum Description Length principle (MDL) and Bayesian inference are shown to give empirical approximations of the razor via an analysis that significantly extends existing results on the asymptotics of Bayesian model selection. I treat parametric families as manifolds embedded in the space of distributions and derive a canonical metric and a measure on the parameter manifold by appealing to the classical theory of hypothesis testing. I find that the Fisher information is the natural measure of distance, and give a novel justification for a choice of Jeffreys prior for Bayesian inference. The results of this paper suggest corrections to MDL that can be important for model selection with a small amount of data. These corrections are interpreted as natural measures of the simplicity of a model family. I show that in a certain sense the logarithm of the Bayesian posterior converges to the logarithm of the {\{}$\backslash$it razor{\}} of a model family as defined here. Close connections with known results on density estimation and ``information geometry'' are discussed as they arise.},
archivePrefix = {arXiv},
arxivId = {adap-org/9601001},
author = {Balasubramanian, Vijay},
eprint = {9601001},
file = {:home/kaslu/Documents/Mendeley/1996 - Balasubramanian - A Geometric Formulation of Occam's Razor for Inference of Parametric Distributions.pdf:pdf},
month = {jan},
pages = {35},
primaryClass = {adap-org},
title = {{A Geometric Formulation of Occam's Razor for Inference of Parametric Distributions}},
url = {http://arxiv.org/abs/adap-org/9601001},
year = {1996}
}
@article{Colombo2012,
abstract = {According to agrowing trend in theoretical neuroscience, thehumanperceptual system is akin to a Bayesian machine. The aim of this article is to clearly articulate the claims that perception can be considered Bayesian inference and that the brain can be considered a Bayesian machine, some of the epistemological challenges to these claims; and some of the implications of these claims.Weaddress two questions: (i)Howare Bayesian models used in theoretical neuroscience? (ii) From the use of Bayesian models in theoretical neuroscience, have we learned or can we hope to learn that perception is Bayesian infer- ence or that the brain is a Bayesian machine? From actual practice in theoretical neuro- science, we argue for three claims. First, currently Bayesian models do not provide mechanistic explanations; instead they are useful devices for predictingandsystematizing observational statements about peoples performances in a variety of perceptual tasks. That is, currentlyweshould have an instrumentalist attitude towards Bayesian models in neuroscience. Second, the inference typicallydrawnfrom Bayesian behavioural perform- ance in a variety of perceptual tasks to underlying Bayesian mechanisms should be understood within the three-level framework laid out by David Marr (1982). Third, we can hope to learn that perception is Bayesian inference or that the brain is a Bayesian machine to the extent that Bayesian models will prove successful in yielding secure and informative predictions of both subjects perceptual performance and features of the underlying neural mechanisms.},
author = {Colombo, Matteo and Seri{\`{e}}s, Peggy},
doi = {10.1093/bjps/axr043},
file = {:home/kaslu/Documents/Mendeley/2012 - Colombo, Seri{\`{e}}s - Bayes in the brain - On Bayesian modelling in neuroscience.pdf:pdf},
isbn = {0007-0882$\backslash$r1464-3537},
issn = {00070882},
journal = {British Journal for the Philosophy of Science},
number = {3},
pages = {697--723},
title = {{Bayes in the brain - On Bayesian modelling in neuroscience}},
volume = {63},
year = {2012}
}
@article{Farries2007,
abstract = {Spike timing-dependent synaptic plasticity (STDP) has emerged as the preferred framework linking patterns of pre- and postsynaptic activity to changes in synaptic strength. Although synaptic plasticity is widely believed to be a major component of learning, it is unclear how STDP itself could serve as a mechanism for general purpose learning. On the other hand, algorithms for reinforcement learning work on a wide variety of problems, but lack an experimentally established neural implementation. Here, we combine these paradigms in a novel model in which a modified version of STDP achieves reinforcement learning. We build this model in stages, identifying a minimal set of conditions needed to make it work. Using a performance-modulated modification of STDP in a two-layer feedforward network, we can train output neurons to generate arbitrarily selected spike trains or population responses. Furthermore, a given network can learn distinct responses to several different input patterns. We also describe in detail how this model might be implemented biologically. Thus our model offers a novel and biologically plausible implementation of reinforcement learning that is capable of training a neural population to produce a very wide range of possible mappings between synaptic input and spiking output.},
author = {Farries, M. A. and Fairhall, Adrienne L.},
doi = {10.1152/jn.00364.2007},
file = {:home/kaslu/Documents/Mendeley/2007 - Farries, Fairhall - Reinforcement Learning With Modulated Spike Timing Dependent Synaptic Plasticity.pdf:pdf},
isbn = {0022-3077 (Print)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {6},
pages = {3648--3665},
pmid = {17928565},
title = {{Reinforcement Learning With Modulated Spike Timing Dependent Synaptic Plasticity}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00364.2007},
volume = {98},
year = {2007}
}
@article{Ghavamzadeh2016,
abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
archivePrefix = {arXiv},
arxivId = {1609.04436},
author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
doi = {10.1561/2200000049},
eprint = {1609.04436},
file = {:home/kaslu/Documents/Mendeley/2015 - Ghavamzadeh et al. - Convex Optimization Algorithms and Complexity.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
month = {sep},
number = {5-6},
pages = {359--483},
title = {{Convex Optimization: Algorithms and Complexity}},
url = {http://arxiv.org/abs/1609.04436 http://dx.doi.org/10.1561/2200000049 http://www.nowpublishers.com/article/Details/MAL-049},
volume = {8},
year = {2015}
}
@article{Graves2014,
abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
archivePrefix = {arXiv},
arxivId = {1410.5401},
author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
eprint = {1410.5401},
month = {oct},
title = {{Neural Turing Machines}},
url = {http://arxiv.org/abs/1410.5401},
year = {2014}
}
@article{Haidt2004,
author = {Haidt, Jonathan and Joseph, Craig},
doi = {10.1162/0011526042365555},
file = {:home/kaslu/Documents/Mendeley/2004 - Haidt, Joseph - Intuitive ethics how innately prepared intuitions generate culturally variable virtues.pdf:pdf},
issn = {0011-5266},
journal = {Daedalus},
month = {sep},
number = {4},
pages = {55--66},
title = {{Intuitive ethics: how innately prepared intuitions generate culturally variable virtues}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/0011526042365555},
volume = {133},
year = {2004}
}
@article{Jenkinson2014,
abstract = {Author SummaryNetworks of noisy interacting components arise in diverse scientific disciplines. Here, we develop a mathematical framework to study the underlying causes of a bursting phenomenon in network activity known as avalanching. As prototypical examples, we study a model of disease spreading in a population of individuals and a model of brain activity in a neural network. Although avalanching is well-documented in neural networks, thought to be crucial for learning, information processing, and memory, it has not been studied before in disease spreading. We employ tools originally used to analyze thermodynamic systems to argue that randomness in the actions of individual network components plays a fundamental role in avalanche formation. We show that avalanching is a spontaneous behavior, brought about by a phenomenon reminiscent to a phase transition in statistical mechanics, caused by increasing randomness as the network size decreases. Our work demonstrates that a previously suggested balanced feed-forward network structure is not necessary for neuronal avalanching. Instead, we attribute avalanching to a reallocation of the global minima of the network's stationary potential energy landscape, caused by a noise-induced deformation of its topographic surface.},
author = {Jenkinson, Garrett and Goutsias, John},
doi = {10.1371/journal.pcbi.1003411},
file = {:home/kaslu/Documents/Mendeley/2014 - Jenkinson, Goutsias - Intrinsic Noise Induces Critical Behavior in Leaky Markovian Networks Leading to Avalanching.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {1},
pmid = {24415927},
title = {{Intrinsic Noise Induces Critical Behavior in Leaky Markovian Networks Leading to Avalanching}},
volume = {10},
year = {2014}
}
@article{Glaze2018,
author = {Glaze, Christopher M. and Filipowicz, Alexandre L. S. and Kable, Joseph W. and Balasubramanian, Vijay and Gold, Joshua I.},
doi = {10.1038/s41562-018-0297-4},
file = {:home/kaslu/Documents/Mendeley/2018 - Glaze et al. - A bias–variance trade-off governs individual differences in on-line learning in an unpredictable environment.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
month = {feb},
publisher = {Springer US},
title = {{A bias–variance trade-off governs individual differences in on-line learning in an unpredictable environment}},
url = {http://www.nature.com/articles/s41562-018-0297-4},
year = {2018}
}
@article{Kramer2016,
author = {Kramer, Jos and Meunier, Jo{\"{e}}l},
doi = {10.12688/f1000research.8018.1},
issn = {2046-1402},
journal = {F1000Research},
month = {apr},
pages = {776},
title = {{Kin and multilevel selection in social evolution: a never-ending controversy?}},
url = {http://f1000research.com/articles/5-776/v1},
volume = {5},
year = {2016}
}
@article{Gilbert2015,
author = {Gilbert, Scott F. and Bosch, Thomas C. G. and Led{\'{o}}n-Rettig, Cristina},
doi = {10.1038/nrg3982},
file = {:home/kaslu/Documents/Mendeley/2015 - Gilbert, Bosch, Led{\'{o}}n-Rettig - Eco-Evo-Devo developmental symbiosis and developmental plasticity as evolutionary agents.pdf:pdf},
issn = {1471-0056},
journal = {Nature Reviews Genetics},
month = {sep},
number = {10},
pages = {611--622},
title = {{Eco-Evo-Devo: developmental symbiosis and developmental plasticity as evolutionary agents}},
url = {http://www.nature.com/doifinder/10.1038/nrg3982},
volume = {16},
year = {2015}
}
@article{Metzler2000,
author = {Metzler, R. and Kinzel, W. and Kanter, I.},
doi = {10.1103/PhysRevE.62.2555},
issn = {1063-651X},
journal = {Physical Review E},
month = {aug},
number = {2},
pages = {2555--2565},
publisher = {American Physical Society},
title = {{Interacting neural networks}},
url = {http://journals.aps.org/pre/abstract/10.1103/PhysRevE.62.2555 http://link.aps.org/doi/10.1103/PhysRevE.62.2555},
volume = {62},
year = {2000}
}
@article{Vespignani1998,
abstract = {We present a unified mean-field theory, based on the single site approximation to the master-equation, for stochastic self-organized critical models. In particular, we analyze in detail the properties of sandpile and forest-fire (FF) models. In analogy with other non-equilibrium critical phenomena, we identify the order parameter with the density of ``active'' sites and the control parameters with the driving rates. Depending on the values of the control parameters, the system is shown to reach a subcritical (absorbing) or super-critical (active) stationary state. Criticality is analyzed in terms of the singularities of the zero-field susceptibility. In the limit of vanishing control parameters, the stationary state displays scaling characteristic of self-organized criticality (SOC). We show that this limit corresponds to the breakdown of space-time locality in the dynamical rules of the models. We define a complete set of critical exponents, describing the scaling of order parameter, response functions, susceptibility and correlation length in the subcritical and supercritical states. In the subcritical state, the response of the system to small perturbations takes place in avalanches. We analyze their scaling behavior in relation with branching processes. In sandpile models because of conservation laws, a critical exponents subset displays mean-field values ({\$}\backslashnu=1/2{\$} and {\$}\backslashgamma = 1{\$}) in any dimensions. We treat bulk and boundary dissipation and introduce a new critical exponent relating dissipation and finite size effects. We present numerical simulations that confirm our results. In the case of the forest-fire model, our approach can distinguish between different regimes (SOC-FF and deterministic FF) studied in the literature and determine the full spectrum of critical exponents.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9709192},
author = {Vespignani, Alessandro and Zapperi, Stefano},
doi = {10.1103/PhysRevE.57.6345},
eprint = {9709192},
file = {:home/kaslu/Documents/Mendeley/1998 - Vespignani, Zapperi - How self-organized criticality works A unified mean-field picture.pdf:pdf},
issn = {1063-651X},
journal = {Physical Review E},
month = {jun},
number = {6},
pages = {6345--6362},
primaryClass = {cond-mat},
title = {{How self-organized criticality works: A unified mean-field picture}},
url = {http://arxiv.org/abs/cond-mat/9709192 https://link.aps.org/doi/10.1103/PhysRevE.57.6345},
volume = {57},
year = {1998}
}
@article{Bengio2017,
abstract = {A new prior is proposed for representation learning, which can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by the phenomenon of consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant. This provides a powerful constraint on the representation in that such low-dimensional thought vectors can correspond to statements about reality which are true, highly probable, or very useful for taking decisions. The fact that a few elements of the current state can be combined into such a predictive or useful statement is a strong constraint and deviates considerably from the maximum likelihood approaches to modelling data and how states unfold in the future based on an agent's actions. Instead of making predictions in the sensory (e.g. pixel) space, the consciousness prior allows the agent to make predictions in the abstract space, with only a few dimensions of that space being involved in each of these predictions. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in the form of facts and rules, although the conscious states may be richer than what can be expressed easily in the form of a sentence, a fact or a rule.},
archivePrefix = {arXiv},
arxivId = {1709.08568},
author = {Bengio, Yoshua},
eprint = {1709.08568},
file = {:home/kaslu/Documents/Mendeley/2017 - Bengio - The Consciousness Prior.pdf:pdf},
month = {sep},
title = {{The Consciousness Prior}},
url = {http://arxiv.org/abs/1709.08568},
year = {2017}
}
@article{Mechanisms2013,
author = {McClelland, James and Ditterich, Jochen and Newsome, William and Holmes, Philip},
file = {:home/kaslu/Documents/Mendeley/2013 - McClelland et al. - Dynamic Decision Making in Complex Task Environments Principles and Neural Mechanisms.pdf:pdf},
number = {March},
title = {{Dynamic Decision Making in Complex Task Environments: Principles and Neural Mechanisms}},
url = {http://www.dtic.mil/docs/citations/ADA581230},
year = {2013}
}
@article{Nirenberg2003,
abstract = {It has been known for {\textgreater}30 years that neuronal spike trains exhibit correlations, that is, the occurrence of a spike at one time is not independent of the occurrence of spikes at other times, both within spike trains from single neurons and across spike trains from multiple neurons. The presence of these correlations has led to the proposal that they might form a key element of the neural code. Specifically, they might act as an extra channel for information, carrying messages about events in the outside world that are not carried by other aspects of the spike trains, such as firing rate. Currently, there is no general consensus about whether this proposal applies to real spike trains in the nervous system. This is largely because it has been hard to separate information carried in correlations from that not carried in correlations. Here we propose a framework for performing this separation. Specifically, we derive an information-theoretic cost function that measures how much harder it is to decode neuronal responses when correlations are ignored than when they are taken into account. This cost function can be readily applied to real neuronal data.},
author = {Nirenberg, Sheila and Latham, Peter E.},
doi = {10.1073/pnas.1131895100},
file = {:home/kaslu/Documents/Mendeley/2003 - Nirenberg, Latham - Decoding neuronal spike trains how important are correlations.pdf:pdf},
isbn = {0027-8424 (Print)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Electric Stimulation,Electrophysiology,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology},
month = {jun},
number = {12},
pages = {7348--53},
pmid = {12775756},
publisher = {National Academy of Sciences},
title = {{Decoding neuronal spike trains: how important are correlations?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12775756 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC165878 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=165878{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {100},
year = {2003}
}
@article{Kanitscheider2015,
abstract = {The ability to discriminate between similar sensory stimuli relies on the amount of information encoded in sensory neuronal populations. Such information can be substantially reduced by correlated trial-to-trial variability. Noise correlations have been measured across a wide range of areas in the brain, but their origin is still far from clear. Here we show analytically and with simulations that optimal computation on inputs with limited information creates patterns of noise correlations that account for a broad range of experimental observations while at same time causing information to saturate in large neural populations. With the example of a network of V1 neurons extracting orientation from a noisy image, we illustrate to our knowledge the first generative model of noise correlations that is consistent both with neurophysiology and with behavioral thresholds, without invoking suboptimal encoding or decoding or internal sources of variability such as stochastic network dynamics or cortical state fluctuations. We further show that when information is limited at the input, both suboptimal connectivity and internal fluctuations could similarly reduce the asymptotic information, but they have qualitatively different effects on correlations leading to specific experimental predictions. Our study indicates that noise at the sensory periphery could have a major effect on cortical representations in widely studied discrimination tasks. It also provides an analytical framework to understand the functional relevance of different sources of experimentally measured correlations.},
author = {Kanitscheider, Ingmar and Coen-Cagli, Ruben and Pouget, Alexandre},
doi = {10.1073/pnas.1508738112},
file = {:home/kaslu/Documents/Mendeley/2015 - Kanitscheider, Coen-Cagli, Pouget - Origin of information-limiting noise correlations.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {efficient coding,information theory,neural computation,neuronal variability,noise correlations},
month = {dec},
number = {50},
pages = {E6973--E6982},
pmid = {26621747},
title = {{Origin of information-limiting noise correlations}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1508738112},
volume = {112},
year = {2015}
}
@article{Cowley2016,
abstract = {Dimensionality reduction has been applied in various brain areas to study the activity of populations of neurons. To interpret the outputs of dimensionality reduction, it is important to first understand its outputs for brain areas for which the relationship between the stimulus and neural response is well characterized. Here, we applied principal component analysis (PCA) to trial-averaged neural responses in macaque primary visual cortex (V1) to study two fundamental, population-level questions. First, we characterized how neural complexity relates to stimulus complexity, where complexity is measured using relative comparisons of dimensionality. Second, we assessed the extent to which responses to different stimuli occupy similar dimensions of the population activity space using a novel statistical method. For comparison, we performed the same dimensionality reduction analyses on the activity of a recently-proposed V1 receptive field model and a deep convolutional neural network. Our results show that the dimensionality of the population response changes systematically with alterations in the properties and complexity of the visual stimulus.},
author = {Cowley, Benjamin R. and Smith, Matthew A. and Kohn, Adam and Yu, Byron M.},
doi = {10.1371/journal.pcbi.1005185},
file = {:home/kaslu/Documents/Mendeley/2016 - Cowley et al. - Stimulus-Driven Population Activity Patterns in Macaque Primary Visual Cortex.pdf:pdf},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {12},
pages = {1--31},
pmid = {27935935},
title = {{Stimulus-Driven Population Activity Patterns in Macaque Primary Visual Cortex}},
volume = {12},
year = {2016}
}
@article{Leike2016,
abstract = {Signal inference problems with non-Gaussian posteriors can be hard to tackle. Through using the concept of Gibbs free energy these posteriors are rephrased as Gaussian posteriors for the price of computing various expectation values with respect to a Gaussian distribution. We present a new way of translating these expectation values to a language of operators which is similar to that in quantum mechanics. This simplifies many calculations, for instance such involving log-normal priors. The operator calculus is illustrated by deriving a novel self-calibrating algorithm which is tested with mock data.},
archivePrefix = {arXiv},
arxivId = {1605.00660},
author = {Leike, Reimar H. and En{\ss}lin, Torsten A.},
doi = {10.1103/PhysRevE.94.053306},
eprint = {1605.00660},
file = {:home/kaslu/Documents/Mendeley/2016 - Leike, En{\ss}lin - Operator calculus for information field theory.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {nov},
number = {5},
pages = {053306},
title = {{Operator calculus for information field theory}},
url = {http://arxiv.org/abs/1605.00660 http://dx.doi.org/10.1103/PhysRevE.94.053306 http://link.aps.org/doi/10.1103/PhysRevE.94.053306},
volume = {94},
year = {2016}
}
@article{Rau1998,
abstract = {I give a concise introduction to some essential concepts of statistical mechanics:  1. Probability theory (constrained distributions, concentration theorem, frequency estimation, hypothesis testing);  2. Macroscopic systems in equilibrium (macrostate, thermodynamic variables, entropy, first law, thermodynamic potentials, correlations);  3. Linear response (Kubo formula).},
archivePrefix = {arXiv},
arxivId = {physics/9805024},
author = {Rau, Jochen},
eprint = {9805024},
file = {:home/kaslu/Documents/Mendeley/1998 - Rau - Statistical Mechanics in a Nutshell.pdf:pdf},
month = {may},
pages = {23},
primaryClass = {physics},
title = {{Statistical Mechanics in a Nutshell}},
url = {http://arxiv.org/abs/physics/9805024},
year = {1998}
}
@article{Ipek2018,
abstract = {In the Entropic Dynamics framework quantum theory is derived as an application of the method of maximum entropy. In previous work the entropic dynamics of relativistic quantum scalar fields was formulated in the Schr{\"{o}}dinger functional representation in which the Lorentz symmetry is not manifest. Here the formalism is extended to curved spacetimes. We develop a manifestly covariant approach inspired by the Hamiltonian methods of Dirac, Kuchař, and Teitelboim. The key ingredient is the adoption of a local notion of entropic time in which instants are defined on curved three-dimensional surfaces and time evolution consists of the accumulation of changes induced by local deformations of these surfaces.},
archivePrefix = {arXiv},
arxivId = {arXiv:1803.07493v1},
author = {Ipek, Selman and Abedi, Mohammad and Caticha, Ariel},
eprint = {arXiv:1803.07493v1},
file = {:home/kaslu/Documents/Mendeley/2018 - Ipek, Abedi, Caticha - Entropic Dynamics of Quantum Scalar Fields in Curved Spacetime.pdf:pdf},
pages = {1--22},
title = {{Entropic Dynamics of Quantum Scalar Fields in Curved Spacetime}},
year = {2018}
}
@article{Hutcherson2015,
abstract = {Moral judgment often requires making difficult tradeoffs (e.g., is it appropriate to torture to save the lives of innocents at risk?). Previous research suggests that both emotional appraisals and more deliberative utilitarian appraisals influence such judgments and that these appraisals often conflict. However, it is unclear how these different types of appraisals are represented in the brain, or how they are integrated into an overall moral judgment. We addressed these questions using an fMRI paradigm in which human subjects provide separate emotional and utilitarian appraisals for different potential actions, and then make difficult moral judgments constructed from combinations of these actions. We found that anterior cingulate, insula, and superior temporal gyrus correlated with emotional appraisals, whereas temporoparietal junction and dorsomedial prefrontal cortex correlated with utilitarian appraisals. Overall moral value judgments were represented in an anterior portion of the ventromedial prefrontal cortex. Critically, the pattern of responses and functional interactions between these three sets of regions are consistent with a model in which emotional and utilitarian appraisals are computed independently and in parallel, and passed to the ventromedial prefrontal cortex where they are integrated into an overall moral value judgment. Significance statement: Popular accounts of moral judgment often describe it as a battle for control between two systems, one intuitive and emotional, the other rational and utilitarian, engaged in winner-take-all inhibitory competition. Using a novel fMRI paradigm, we identified distinct neural signatures of emotional and utilitarian appraisals and used them to test different models of how they compete for the control of moral behavior. Importantly, we find little support for competitive inhibition accounts. Instead, moral judgments resembled the architecture of simple economic choices: distinct regions represented emotional and utilitarian appraisals independently and passed this information to the ventromedial prefrontal cortex for integration into an overall moral value signal.},
author = {Hutcherson, Cendri A and Montaser-Kouhsari, Leila and Woodward, James and Rangel, Antonio},
doi = {10.1523/JNEUROSCI.3402-14.2015},
file = {:home/kaslu/Documents/Mendeley/2015 - Hutcherson et al. - Emotional and Utilitarian Appraisals of Moral Dilemmas Are Encoded in Separate Areas and Integrated in Ventro.pdf:pdf},
isbn = {0270-6474},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {decision-making,emotion and cognition,medial prefrontal cortex,moral judgment,temporoparietal junction},
number = {36},
pages = {12593--605},
pmid = {26354924},
title = {{Emotional and Utilitarian Appraisals of Moral Dilemmas Are Encoded in Separate Areas and Integrated in Ventromedial Prefrontal Cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26354924{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4563040},
volume = {35},
year = {2015}
}
@article{Sparrow2011,
abstract = {The advent of the Internet, with sophisticated algorithmic search engines, has made accessing information as easy as lifting a finger. No longer do we have to make costly efforts to find the things we want. We can “Google” the old classmate, find articles online, or look up the actor who was on the tip of our tongue. The results of four studies suggest that when faced with difficult questions, people are primed to think about computers and that when people expect to have future access to information, they have lower rates of recall of the information itself and enhanced recall instead for where to access it. The Internet has become a primary form of external or transactive memory, where information is stored collectively outside ourselves. I},
author = {Sparrow, Betsy and Liu, Jenny and Wegner, Daniel M},
doi = {10.1126/science.1207745},
issn = {0036-8075, 1095-9203},
journal = {Science},
number = {August},
pages = {776--779},
title = {{Google Effects on Memory: Information at Our Fingertips}},
volume = {333},
year = {2011}
}
@article{Shlens2014a,
abstract = {Independent component analysis (ICA) has become a standard data analysis technique applied to an array of problems in signal processing and machine learning. This tutorial provides an introduction to ICA based on linear algebra formulating an intuition for ICA from first principles. The goal of this tutorial is to provide a solid foundation on this advanced topic so that one might learn the motivation behind ICA, learn why and when to apply this technique and in the process gain an introduction to this exciting field of active research.},
archivePrefix = {arXiv},
arxivId = {1404.2986},
author = {Shlens, Jonathon},
eprint = {1404.2986},
file = {:home/kaslu/Documents/Mendeley/2014 - Shlens - A Tutorial on Independent Component Analysis.pdf:pdf},
month = {apr},
pages = {1--13},
title = {{A Tutorial on Independent Component Analysis}},
url = {http://arxiv.org/abs/1404.2986},
year = {2014}
}
@article{Cafaro2016,
archivePrefix = {arXiv},
arxivId = {1612.06356},
author = {Cafaro, Carlo and Ali, Sean Alan},
doi = {10.1103/PhysRevE.94.052145},
eprint = {1612.06356},
file = {:home/kaslu/Documents/Mendeley/2016 - Cafaro, Ali - Maximum caliber inference and the stochastic Ising model.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--10},
title = {{Maximum caliber inference and the stochastic Ising model}},
volume = {94},
year = {2016}
}
@article{Caticha1993,
author = {Caticha, Nestor and Kuva, Silvia},
journal = {IFUSP Publica{\c{c}}{\~{o}}es},
title = {{Dreaming in Analog Attractor Neural Nets}},
year = {1993}
}
@article{Panzeri2017,
abstract = {The two basic processes underlying perceptual decisions—how neural responses encode stimuli, and how they inform behavioral choices—have mainly been studied separately. Thus, although many spatiotemporal features of neural population activity, or “neural codes,” have been shown to carry sensory information, it is often unknown whether the brain uses these features for perception. To address this issue, we propose a new framework centered on redefining the neural code as the neural features that carry sensory information used by the animal to drive appropriate behavior; that is, the features that have an intersection between sensory and choice information. We show how this framework leads to a new statistical analysis of neural activity recorded during behavior that can identify such neural codes, and we discuss how to combine intersection-based analysis of neural recordings with intervention on neural activity to determine definitively whether specific neural activity features are involved in a task.},
author = {Panzeri, Stefano and Harvey, Christopher D. and Piasini, Eugenio and Latham, Peter E. and Fellin, Tommaso},
doi = {10.1016/j.neuron.2016.12.036},
file = {:home/kaslu/Documents/Mendeley/2017 - Panzeri et al. - Cracking the Neural Code for Sensory Perception by Combining Statistics, Intervention, and Behavior.pdf:pdf},
isbn = {2012203566},
issn = {10974199},
journal = {Neuron},
keywords = {behavior,choice,information,neural coding,optogenetics,population coding},
number = {3},
pages = {491--507},
pmid = {28182905},
publisher = {Elsevier Inc.},
title = {{Cracking the Neural Code for Sensory Perception by Combining Statistics, Intervention, and Behavior}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.036},
volume = {93},
year = {2017}
}
@article{Solway2012,
abstract = {Recent work has given rise to the view that reward-based decision making is governed by two key controllers: a habit system, which stores stimulus-response associations shaped by past reward, and a goal-oriented system that selects actions based on their anticipated outcomes. The current literature provides a rich body of computational theory addressing habit formation, centering on temporal-difference learning mechanisms. Less progress has been made toward formalizing the processes involved in goal-directed decision making. We draw on recent work in cognitive neuroscience, animal conditioning, cognitive and developmental psychology, and machine learning to outline a new theory of goal-directed decision making. Our basic proposal is that the brain, within an identifiable network of cortical and subcortical structures, implements a probabilistic generative model of reward, and that goal-directed decision making is effected through Bayesian inversion of this model. We present a set of simulations implementing the account, which address benchmark behavioral and neuroscientific findings, and give rise to a set of testable predictions. We also discuss the relationship between the proposed framework and other models of decision making, including recent models of perceptual choice, to which our theory bears a direct connection.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Solway, Alec and Botvinick, Matthew M.},
doi = {10.1037/a0026435},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2012 - Solway, Botvinick - Goal-directed decision making as probabilistic inference A computational framework and potential neural corre.pdf:pdf},
isbn = {1939-1471(Electronic);0033-295X(Print)},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {10,1037,a0026435,decision making,doi,dx,http,neuroeconomics,org,planning,probabilistic inference,reward,supp,supplemental materials},
number = {1},
pages = {120--154},
pmid = {22229491},
title = {{Goal-directed decision making as probabilistic inference: A computational framework and potential neural correlates.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0026435},
volume = {119},
year = {2012}
}
@article{Fleming2014,
author = {Fleming, N. C.},
doi = {10.1111/1478-9302.12030},
issn = {14789302},
journal = {Political Studies Review},
keywords = {British national party,Extremism,Islamism,Liberal democracy},
number = {3},
pages = {395--401},
title = {{Political extremes and extremist politics}},
volume = {12},
year = {2014}
}
@article{Zia2008,
abstract = {The Legendre transform is an important tool in theoretical physics, playing a critical role in classical mechanics, statistical mechanics, and thermodynamics. Yet, in typical undergraduate or graduate courses, the power of motivation and elegance of the method are often missing, unlike the treatments frequently enjoyed by Fourier transforms. We review and modify the presentation of Legendre transforms in a way that explicates the formal mathematics, resulting in manifestly symmetric equations, thereby clarifying the structure of the transform algebraically and geometrically. Then we bring in the physics to motivate the transform as a way of choosing independent variables that are more easily controlled. We demonstrate how the Legendre transform arises naturally from statistical mechanics and show how the use of dimensionless thermodynamic potentials leads to more natural and symmetric relations.},
archivePrefix = {arXiv},
arxivId = {0806.1147},
author = {Zia, R. K. P. and Redish, Edward F. and McKay, Susan R.},
doi = {10.1119/1.3119512},
eprint = {0806.1147},
file = {:home/kaslu/Documents/Mendeley/2008 - Zia, Redish, McKay - Making Sense of the Legendre Transform.pdf:pdf},
issn = {00029505},
journal = {American Journal of Physics},
number = {7},
pages = {11},
title = {{Making Sense of the Legendre Transform}},
url = {http://arxiv.org/abs/0806.1147 http://link.aip.org/link/AJPIAS/v77/i7/p614/s1{\&}Agg=doi},
volume = {77},
year = {2008}
}
@article{Hesse2014,
abstract = {The neural criticality hypothesis states that the brain may be poised in a critical state at a boundary between different types of dynamics. Theoretical and experimental studies show that critical systems often exhibit optimal computational properties, suggesting the possibility that criticality has been evolutionarily selected as a useful trait for our nervous system. Evidence for criticality has been found in cell cultures, brain slices, and anesthetized animals. Yet, inconsistent results were reported for recordings in awake animals and humans, and current results point to open questions about the exact nature and mechanism of criticality, as well as its functional role. Therefore, the criticality hypothesis has remained a controversial proposition. Here, we provide an account of the mathematical and physical foundations of criticality. In the light of this conceptual framework, we then review and discuss recent experimental studies with the aim of identifying important next steps to be taken and connections to other fields that should be explored.},
author = {Hesse, Janina and Gross, Thilo},
doi = {10.3389/fnsys.2014.00166},
file = {:home/kaslu/Documents/Mendeley/2014 - Hesse, Gross - Self-organized criticality as a fundamental property of neural systems.pdf:pdf},
isbn = {1662-5137 (Electronic)$\backslash$r1662-5137 (Linking)},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
month = {sep},
number = {September},
pmid = {25294989},
title = {{Self-organized criticality as a fundamental property of neural systems}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2014.00166/abstract},
volume = {8},
year = {2014}
}
@article{Daniels2017,
abstract = {A central question in cognitive neuroscience is how unitary, coherent decisions at the whole organism level can arise from the distributed behavior of a large population of neurons with only partially overlapping information. We address this issue by studying neural spiking behavior recorded from a multielectrode array with 169 channels during a visual motion direction discrimination task. It is well known that in this task there are two distinct phases in neural spiking behavior. Here we show Phase I is a distributed or incompressible phase in which uncertainty about the decision is substantially reduced by pooling information from many cells. Phase II is a redundant or compressible phase in which numerous single cells contain all the information present at the population level in Phase I, such that the firing behavior of a single cell is enough to predict the subject's decision. Using an empirically grounded dynamical modeling framework, we show that in Phase I large cell populations with low redundancy produce a slow timescale of information aggregation through critical slowing down near a symmetry-breaking transition. Our model indicates that increasing collective amplification in Phase II leads naturally to a faster timescale of information pooling and consensus formation. Based on our results and others in the literature, we propose that a general feature of collective computation is a `coding duality' in which there are accumulation and consensus formation processes distinguished by different timescales.},
author = {Daniels, Bryan C. and Flack, Jessica C. and Krakauer, David C.},
doi = {10.3389/fnins.2017.00313},
file = {:home/kaslu/Documents/Mendeley/2017 - Daniels, Flack, Krakauer - Dual coding theory explains biphasic collective computation in neural decision-making.pdf:pdf},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Collective computation,Critical slowing down,Decision tasks},
month = {jun},
number = {JUN},
pages = {313},
pmid = {28634436},
publisher = {Frontiers},
title = {{Dual coding theory explains biphasic collective computation in neural decision-making}},
url = {http://journal.frontiersin.org/article/10.3389/fnins.2017.00313/full},
volume = {11},
year = {2017}
}
@inproceedings{Tishby2015,
abstract = {Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.},
archivePrefix = {arXiv},
arxivId = {1503.02406},
author = {Tishby, Naftali and Zaslavsky, Noga},
booktitle = {2015 IEEE Information Theory Workshop (ITW)},
doi = {10.1109/ITW.2015.7133169},
eprint = {1503.02406},
file = {:home/kaslu/Documents/Mendeley/2015 - Tishby, Zaslavsky - Deep learning and the information bottleneck principle.pdf:pdf},
isbn = {978-1-4799-5524-4},
month = {apr},
number = {November},
pages = {1--5},
publisher = {IEEE},
title = {{Deep learning and the information bottleneck principle}},
url = {http://ieeexplore.ieee.org/document/7133169/},
year = {2015}
}
@article{Ioffe2015,
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9{\%} top-5 validation error (and 4.8{\%} test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1502.03167},
isbn = {9780874216561},
issn = {0717-6163},
month = {feb},
pmid = {15003161},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {http://arxiv.org/abs/1502.03167},
year = {2015}
}
@article{Summerfield2014,
abstract = {Nature Reviews Neuroscience, (2014). doi:10.1038/nrn3838},
author = {Summerfield, Christopher and de Lange, Floris P.},
doi = {10.1038/nrn3838},
file = {:home/kaslu/Documents/Mendeley/2014 - Summerfield, de Lange - Expectation in perceptual decision making neural and computational mechanisms.pdf:pdf},
journal = {Nature Reviews Neuroscience},
month = {oct},
number = {11},
pages = {745--756},
title = {{Expectation in perceptual decision making: neural and computational mechanisms}},
url = {http://www.nature.com/doifinder/10.1038/nrn3838},
volume = {15},
year = {2014}
}
@article{Opper1998,
abstract = {Online learning is discussed from the viewpoint of Bayesian statistical inference. By replacing the true posterior distribution with a simpler parametric distribution, one can define an online algorithm by a repetition of two steps: An update of the approximate posterior, when a new example arrives, and an optimal projection into the parametric family. Choosing this family to be Gaussian, we show that the algorithm achieves asymptotic efficiency. An application to learning in single layer neural networks is given.},
author = {Opper, Manfred and Winther, Ole},
file = {:home/kaslu/Documents/Mendeley/1998 - Opper, Winther - A Bayesian approach to on-line learning.pdf:pdf},
journal = {Learning},
keywords = {mathematical computing sciences not elsewhere clas},
pages = {363--378},
title = {{A Bayesian approach to on-line learning}},
url = {http://eprints.aston.ac.uk/1444/},
year = {1998}
}
@article{Barral2016,
abstract = {The balance between excitation and inhibition (E–I balance) is maintained across brain regions though the network size, strength and number of synaptic connections, and connection architecture may vary substantially. We use a culture preparation to examine the homeostatic synaptic scaling rules that produce E–I balance and in vivo-like activity. We show that synaptic strength scales with the number of connections K as {\~{}} 1/ K, close to the ideal theoretical value. Using optogenetic techniques, we delivered spatiotemporally patterned stimuli to neurons and confirmed key theoretical predictions: E–I balance is maintained, active decorrelation occurs and the spiking correlation increases with firing rate. Moreover, the trial-to-trial response variability decreased during stimulation, as observed in vivo. These results—obtained in generic cultures, predicted by theory and observed in the intact brain—suggest that the synaptic scaling rule and resultant dynamics are emergent properties of networks in general.},
author = {Barral, J{\'{e}}r{\'{e}}mie and {D Reyes}, Alex},
doi = {10.1038/nn.4415},
file = {:home/kaslu/Documents/Mendeley/2016 - Barral, D Reyes - Synaptic scaling rule preserves excitatory–inhibitory balance and salient neuronal network dynamics.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {12},
pages = {1690--1696},
pmid = {27749827},
title = {{Synaptic scaling rule preserves excitatory–inhibitory balance and salient neuronal network dynamics}},
url = {http://www.nature.com/doifinder/10.1038/nn.4415},
volume = {19},
year = {2016}
}
@article{Mante2013,
abstract = {Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
doi = {10.1038/nature12742},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2013 - Mante et al. - Context-dependent computation by recurrent dynamics in prefrontal cortex.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {1476-4687},
journal = {Nature},
keywords = {Animals,Choice Behavior,Choice Behavior: physiology,Discrimination Learning,Macaca mulatta,Macaca mulatta: physiology,Male,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology},
number = {7474},
pages = {78--84},
pmid = {24201281},
publisher = {Nature Publishing Group},
title = {{Context-dependent computation by recurrent dynamics in prefrontal cortex.}},
url = {http://dx.doi.org/10.1038/nature12742},
volume = {503},
year = {2013}
}
@article{Archer2009,
abstract = {Human aggression is viewed from four explanatory perspectives, derived from the ethological tradition. The first consists of its adaptive value, which can be seen throughout the animal kingdom, involving resource competition and protection of the self and offspring, which has been viewed from a cost-benefit perspective. The second concerns the phylogenetic origin of aggression, which in humans involves brain mechanisms that are associated with anger and inhibition, the emotional expression of anger, and how aggressive actions are manifest. The third concerns the origin of aggression in development and its subsequent modification through experience. An evolutionary approach to development yields conclusions that are contrary to the influential social learning perspective, notably that physical aggression occurs early in life, and its subsequent development is characterized by learned inhibition. The fourth explanation concerns the motivational mechanisms controlling aggression: approached from an evolutionary background, these mechanisms range from the inflexible reflex-like responses to those incorporating rational decision-making.},
author = {Archer, John},
doi = {10.1016/j.ijlp.2009.04.001},
issn = {01602527},
journal = {International Journal of Law and Psychiatry},
month = {jul},
number = {4},
pages = {202--208},
pmid = {19411108},
title = {{The nature of human aggression}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19411108 http://linkinghub.elsevier.com/retrieve/pii/S0160252709000442},
volume = {32},
year = {2009}
}
@article{Vicente2014,
abstract = {The moral foundations theory supports that people, across cultures, tend to consider a small number of dimensions when classifying issues on a moral basis. The data also show that the statistics of weights attributed to each moral dimension is related to self-declared political affiliation, which in turn has been connected to cognitive learning styles by the recent literature in neuroscience and psychology. Inspired by these data, we propose a simple statistical mechanics model with interacting neural networks classifying vectors and learning from members of their social neighbourhood about their average opinion on a large set of issues. The purpose of learning is to reduce dissension among agents when disagreeing. We consider a family of learning algorithms parametrized by ??, that represents the importance given to corroborating (same sign) opinions. We define an order parameter that quantifies the diversity of opinions in a group with homogeneous learning style. Using Monte Carlo simulations and a mean field approximation we find the relation between the order parameter and the learning parameter ?? at a temperature we associate with the importance of social influence in a given group. In concordance with data, groups that rely more strongly on corroborating evidence sustain less opinion diversity. We discuss predictions of the model and propose possible experimental tests. ?? 2014 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1307.3203},
author = {Vicente, Renato and Susemihl, Alex and Jeric{\'{o}}, Jo{\~{a}}o Pedro and Caticha, Nestor},
doi = {10.1016/j.physa.2014.01.013},
eprint = {1307.3203},
file = {:home/kaslu/Documents/Mendeley/2014 - Vicente et al. - Moral foundations in an interacting neural networks society A statistical mechanics analysis.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Moral foundations theory,Neural networks,Opinion dynamics,Social interactions,Sociophysics,caticha,rv,social},
mendeley-tags = {caticha,rv,social},
month = {apr},
number = {c},
pages = {124--138},
title = {{Moral foundations in an interacting neural networks society: A statistical mechanics analysis}},
url = {http://arxiv.org/abs/1307.3203 http://linkinghub.elsevier.com/retrieve/pii/S037843711400017X},
volume = {400},
year = {2014}
}
@article{Alamino2016,
abstract = {This work introduces a model in which agents of a network act upon one another according to three different kinds of moral decisions. These decisions are based on an increasing level of sophistication in the empathy capacity of the agent, a hierarchy which we name Piaget's Ladder. The decision strategy of the agents is non-rational, in the sense that it does not minimize model's Hamiltonian, and the model presents quenched disorder given by the distribution of its defining parameters. We obtain an analytical solution for this model in the thermodynamic limit and also a leading order correction for finite sized systems. Using these results, we show that typical realizations develop a rich phase structure with discontinuous non-thermal transitions.},
archivePrefix = {arXiv},
arxivId = {1601.02808},
author = {Alamino, Roberto},
doi = {10.1088/1751-8113/49/33/335001},
eprint = {1601.02808},
file = {:home/kaslu/Documents/Mendeley/2016 - Alamino - Non-thermal transitions in a model inspired by moral decisions.pdf:pdf},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and Theoretical},
month = {aug},
number = {33},
pages = {335001},
title = {{Non-thermal transitions in a model inspired by moral decisions}},
url = {http://arxiv.org/abs/1601.02808 http://stacks.iop.org/1751-8121/49/i=33/a=335001?key=crossref.a63cf9a6a97cf2141b03806567e97c85},
volume = {49},
year = {2016}
}
@article{Luzzi2006a,
abstract = {A general overview on the construction of a non-equilibrium sta- tistical mechanics ensemble formalism is presented. Such construction has been approached along the recently past twentieth century by a pleiad of distinguished scientists, their work being subsumed in a large systematization in the form of a physically sound, general and useful, theoretical framework. It includes their con- tributions and also incorporates some extensions and generalizations. The present contribution has been organized in sixteen items and five appendices where the main questions associated to such construction are considered and discussed. Among them are the relevant ones of choice of the basic variables, the questions of his- toricity and irreversibility and the approach to equilibrium. The derivation of a non-equilibrium grand-canonical statistical operator is presented. In terms of it a statistical irreversible thermodynamics can be built, which provides microscopic (mechano-statistical) foundations to phenomenological extended irreversible ther- modynamics. It also provides a statistical non-linear higher-order hydrodynamics, including fluctuations, thus providing a unification of the kinetics and hydrody- namic approaches. Moreover, a brief description of an all-important accompany- ing non-linear quantum kinetic theory of relaxation processes is presented, as well as a response function theory and a fluctuation-dissipation theorem for far-from- equilibrium systems. The aspect of validation of the theory (comparison of theory and experiment) is reviewed in compact form. Furthermore, the derivation of the formalism is briefly discussed within the scope of a variational principle in an ap- proach associated to information theory. Considerations on the question of the use of the formalism for dealing with systems with complex structure, small systems, and other particular situations, are presented.},
author = {Luzzi, R. and Vasconcellos, {\'{A}} R. and Ramos, J. G.},
doi = {10.1393/ncr/i2006-10009-1},
file = {:home/kaslu/Documents/Mendeley/2006 - Luzzi, Vasconcellos, Ramos - The theory of irreversible processes Foundations of a non-equilibrium statistical ensemble formalism.pdf:pdf},
issn = {0393697X},
journal = {Rivista del Nuovo Cimento},
number = {2},
pages = {1--82},
title = {{The theory of irreversible processes: Foundations of a non-equilibrium statistical ensemble formalism}},
volume = {29},
year = {2006}
}
@article{Miller2017a,
abstract = {Planning can be defined as a process of action selection that leverages an internal model of the environment. Such models provide information about the likely outcomes that will follow each selected action, and their use is a key function underlying complex adaptive behavior. However, the neural mechanisms supporting this ability remain poorly understood. In the present work, we adapt for rodents recent advances from work on human planning, presenting for the first time a task for animals which produces many trials of planned behavior per session, allowing the experimental toolkit available for use in trial-by-trial tasks for rodents to be applied to the study of planning. We take advantage of one part of this toolkit to address a perennially controversial issue in planning research: the role of the dorsal hippocampus. Although prospective representations in the hippocampus have been proposed to support model-based planning, intact planning in hippocampally damaged animals has been observed in a number of assays. Combining formal algorithmic behavioral analysis with muscimol inactivation, we provide the first causal evidence directly linking dorsal hippocampus with planning behavior. The results reported, and the methods introduced, open the door to new and more detailed investigations of the neural mechanisms of planning, in the hippocampus and throughout the brain.},
author = {Miller, Kevin J. and Botvinick, Matthew M. and Brody, Carlos D.},
doi = {10.1038/nn.4613},
file = {:home/kaslu/Documents/Mendeley/2017 - Miller, Botvinick, Brody - Dorsal hippocampus contributes to model-based planning.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
pmid = {28758995},
title = {{Dorsal hippocampus contributes to model-based planning}},
url = {http://www.nature.com/doifinder/10.1038/nn.4613},
year = {2017}
}
@article{VanDenBerg2016,
abstract = {Decisions are accompanied by a degree of confidence that a selected option is correct. A sequential sampling framework explains the speed and accuracy of decisions and extends naturally to the confidence that the decision rendered is likely to be correct. However, discrepancies between confidence and accuracy suggest that confidence might be supported by mechanisms dissociated from the decision process. Here we show that this discrepancy can arise naturally because of simple processing delays. When participants were asked to report choice and confidence simultaneously, their confidence, reaction time and a perceptual decision about motion were explained by bounded evidence accumulation. However, we also observed revisions of the initial choice and/or confidence. These changes of mind were explained by a continuation of the mechanism that led to the initial choice. Our findings extend the sequential sampling framework to vacillation about confidence and invites caution in interpreting dissociations between confidence and accuracy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Van Den Berg}, Ronald and Anandalingam, Kavitha and Zylberberg, Ariel and Kiani, Roozbeh and Shadlen, Michael N. and Wolpert, Daniel M.},
doi = {10.7554/eLife.12192},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2016 - Van Den Berg et al. - A common mechanism underlies changes of mind about decisions and confidence.pdf:pdf},
isbn = {9788578110796},
issn = {2050084X},
journal = {eLife},
number = {FEBRUARY2016},
pages = {1--21},
pmid = {25246403},
title = {{A common mechanism underlies changes of mind about decisions and confidence}},
volume = {5},
year = {2016}
}
@article{Fusi2016,
abstract = {Neurons often respond to diverse combinations of task-relevant variables. This form of mixed selectivity plays an important computational role which is related to the dimensionality of the neural representations: high-dimensional representations with mixed selectivity allow a simple linear readout to generate a huge number of different potential responses. In contrast, neural representations based on highly specialized neurons are low dimensional and they preclude a linear readout from generating several responses that depend on multiple task-relevant variables. Here we review the conceptual and theoretical framework that explains the importance of mixed selectivity and the experimental evidence that recorded neural representations are high-dimensional. We end by discussing the implications for the design of future experiments.},
author = {Fusi, Stefano and Miller, Earl K. and Rigotti, Mattia},
doi = {10.1016/j.conb.2016.01.010},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {apr},
pages = {66--74},
pmid = {26851755},
title = {{Why neurons mix: high dimensionality for higher cognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438816000118},
volume = {37},
year = {2016}
}
@article{Pouget2002,
abstract = {We argue that current theories of multisensory representations are inconsistent with the existence of a large proportion of multimodal neurons with gain fields and partially shifting receptive fields. Moreover, these theories do not fully resolve the recoding and statistical issues involved in multisensory integration. An alternative theory, which we have recently developed and review here, has important implications for the idea of 'frame of reference' in neural spatial representations. This theory is based on a neural architecture that combines basis functions and attractor dynamics. Basis function units are used to solve the recoding problem, whereas attractor dynamics are used for optimal statistical inferences. This architecture accounts for gain fields and partially shifting receptive fields, which emerge naturally as a result of the network connectivity and dynamics.},
author = {Pouget, Alexandre and Den{\`{e}}ve, Sophie and Duhamel, Jean-Ren{\'{e}}},
doi = {10.1038/nrn914},
file = {:home/kaslu/Documents/Mendeley/2002 - Pouget, Den{\`{e}}ve, Duhamel - A computational perspective on the neural basis of multisensory spatial representations.pdf:pdf},
isbn = {1471-003X (Print)},
issn = {1471003X},
journal = {Nature reviews. Neuroscience},
number = {9},
pages = {741--747},
pmid = {12209122},
title = {{A computational perspective on the neural basis of multisensory spatial representations.}},
volume = {3},
year = {2002}
}
@article{Buzsaki2014,
abstract = {We often assume that the variables of functional and structural brain parameters - such as synaptic weights, the firing rates of individual neurons, the synchronous discharge of neural populations, the number of synaptic contacts between neurons and the size of dendritic boutons - have a bell-shaped distribution. However, at many physiological and anatomical levels in the brain, the distribution of numerous parameters is in fact strongly skewed with a heavy tail, suggesting that skewed (typically lognormal) distributions are fundamental to structural and functional brain organization. This insight not only has implications for how we should collect and analyse data, it may also help us to understand how the different levels of skewed distributions - from synapses to cognition - are related to each other.},
annote = {NULL},
author = {Buzs{\'{a}}ki, Gy{\"{o}}rgy and Mizuseki, Kenji},
doi = {10.1038/nrn3687},
file = {:home/kaslu/Documents/Mendeley/2014 - Buzs{\'{a}}ki, Mizuseki - The log-dynamic brain how skewed distributions affect network operations.pdf:pdf},
isbn = {1471220214},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neurological},
month = {apr},
number = {4},
pages = {264--278},
pmid = {24569488},
publisher = {Nature Publishing Group},
title = {{The log-dynamic brain: how skewed distributions affect network operations}},
url = {http://www.nature.com/articles/nrn3687},
volume = {15},
year = {2014}
}
@article{Klibaite2016,
abstract = {Social behaviors involving the interaction of multiple individuals are complex and frequently crucial for an animal's survival. These interactions, ranging across sensory modalities, length scales, and time scales, are often subtle and difficult to quantify. Contextual effects on the frequency of behaviors become even more difficult to quantify when physical interaction between animals interferes with conventional data analysis, e.g. due to visual occlusion. We introduce a method for quantifying behavior in courting fruit flies that combines high-throughput video acquisition and tracking of individuals with recent unsupervised methods for capturing an animal's entire behavioral repertoire. We find behavioral differences in paired and solitary flies of both sexes, identifying specific behaviors that are affected by social and spatial context. Our pipeline allows for a comprehensive description of the interaction between multiple individuals using unsupervised machine learning methods, and will be used to answer questions about the depth of complexity and variance in fruit fly courtship.},
archivePrefix = {arXiv},
arxivId = {1609.09345},
author = {Klibaite, Ugne and Berman, Gordon J. and Cande, Jessica and Stern, David L. and Shaevitz, Joshua W.},
eprint = {1609.09345},
file = {:home/kaslu/Documents/Mendeley/2016 - Klibaite et al. - An Unsupervised Method for Quantifying the Behavior of Interacting Individuals.pdf:pdf},
month = {sep},
pages = {16},
title = {{An Unsupervised Method for Quantifying the Behavior of Interacting Individuals}},
url = {http://arxiv.org/abs/1609.09345},
year = {2016}
}
@article{Xu2016,
abstract = {Many studies have investigated how exclusion affects cognitive control and have reported inconsistent results. However, these studies usually treated cognitive control as a unitary concept, whereas it actually involved two main sub-processes: conflict detection and response implementation. Furthermore, existing studies have focused primarily on exclusion's effects on conscious cognitive control, while recent studies have shown the existence of unconscious cognitive control. Therefore, the present study investigated whether and how exclusion affects the sub-processes underlying conscious and unconscious cognitive control differently. The Cyberball game was used to manipulate social exclusion and participants subsequently performed a masked Go/No-Go task during which event-related potentials were measured. For conscious cognitive control, excluded participants showed a larger N2 but smaller P3 effects than included participants, suggesting that excluded people invest more attention in conscious conflict detection, but less in conscious inhibition of impulsive responses. However, for unconscious cognitive control, excluded participants showed a smaller N2 but larger P3 effects than included participants, suggesting that excluded people invest less attention in unconscious conflict detection, but more in unconscious inhibition of impulsive responses. Together, these results suggest that exclusion causes people to rebalance attention allocation priorities for cognitive control according to a more flexible and adaptive strategy.},
author = {Xu, Mengsi and Li, Zhiai and Diao, Liuting and Zhang, Lijie and Yuan, Jiajin and Ding, Cody and Yang, Dong},
doi = {10.1038/srep31282},
file = {:home/kaslu/Documents/Mendeley/2016 - Xu et al. - Social exclusion modulates priorities of attention allocation in cognitive control.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {August},
pages = {31282},
publisher = {Nature Publishing Group},
title = {{Social exclusion modulates priorities of attention allocation in cognitive control}},
url = {http://www.nature.com/articles/srep31282},
volume = {6},
year = {2016}
}
@article{Alvares2016,
abstract = {Aiming to critically review key research on populism, extremism and media, this article examines some definition aspects of populism as a concept, its relation to 'the people' and points to future directions for research in mainstream – and social media – the terrain where so much of the political is played out. An individualisation of civic cultures has emerged in tandem with the growth of mediated populism through the use of new technologies, with a tendency towards personalisation in the public domain. While the new technological affordances exemplified by Web 2.0 may have contributed to intensified forms of popular engagement, they have been less successful in promoting democratic values, as shown by the results of the May 2014 European Parliamentary elections. Thus, the question as to the type of publics that are 'possible and desirable in present circumstances' (Nolan, 2008: 747) remains valid, for publics can espouse anti-democratic values while nevertheless remaining 'publics'. The fact that the link between the new media and right-wing extremism has been comparatively explored at greater length than that of a religious bend indicates the need to invest in the latter, especially due to home-bred Islamic terrorism increasingly seen as threatening the multiculturalism of various European societies. Several avenues for research are presented to this effect, with a final reflection on the challenge posed by new media to the concept of media populism, both in terms of the Net's market logics and the specificity of its architecture.},
author = {Alvares, Claudia and Dahlgren, Peter},
doi = {10.1177/0267323115614485},
isbn = {0267323115},
issn = {0267-3231},
journal = {European Journal of Communication},
number = {1},
pages = {46--57},
title = {{Populism, extremism and media: Mapping an uncertain terrain}},
url = {http://journals.sagepub.com/doi/10.1177/0267323115614485},
volume = {31},
year = {2016}
}
@article{Gelfand2006,
abstract = {Cross-cultural research is dominated by the use of values despite their mixed empirical support and their limited theoretical scope. This article expands the dominant paradigm in cross-cultural research by developing a theory of cultural tightness-looseness (the strength of social norms and the degree of sanctioning within societies) and by advancing a multilevel research agenda for future research. Through an exploration of the top-down, bottom-up, and moderating impact that cultural tightness-looseness has on individuals and organizations, as well as on variance at multiple levels of analysis, the theory provides a new and complementary perspective to the values approach.},
author = {Gelfand, Michele J. and Nishii, Lisa H and Raver, Jana L},
doi = {10.1037/0021-9010.91.6.1225},
isbn = {0021-9010 U6 - ctx{\_}ver=Z39.88-2004{\&}ctx{\_}enc=info{\%}3Aofi{\%}2Fenc{\%}3AUTF-8{\&}rfr{\_}id=info:sid/summon.serialssolutions.com{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:journal{\&}rft.genre=article{\&}rft.atitle=On+the+nature+and+importance+of+cultural+tightness-looseness{\&}rft.jtitle=Journal+of+Applied+Psychology{\&}rft.au=Gelfand{\%}2C+Michele+J{\&}rft.au=Nishii{\%}2C+Lisa+H{\&}rft.au=Raver{\%}2C+Jana+L{\&}rft.date=2006{\&}rft.issn=0021-9010{\&}rft.eissn=1939-1854{\&}rft.volume=91{\&}rft.issue=6{\&}rft.spage=1225{\&}rft.epage=1244{\&}rft{\_}id=info:doi/10.1037{\%}2F0021-9},
issn = {1939-1854},
journal = {Journal of Applied Psychology},
keywords = {Cross-Cultural Comparison,Culture,Humans,Motivation,Organizational Culture,Psychological Theory},
number = {6},
pages = {1225--1244},
pmid = {17100480},
title = {{On the nature and importance of cultural tightness-looseness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17100480 http://doi.apa.org/getdoi.cfm?doi=10.1037/0021-9010.91.6.1225},
volume = {91},
year = {2006}
}
@article{Shafto2012,
abstract = {From early childhood, human beings learn not only from collections of facts about the world, but also in social contexts: from observation of other people, from communication, and from explicit teaching. In these contexts, the data are the result of human actions—actions that come about because of people's goals and intentions. To interpret the implications of others' actions correctly, learners must understand the people generating the data. Most models of learning, however, assume that data are randomly collected facts about the world, and cannot explain how social contexts influence learning. We provide a Bayesian analysis of learning from knowledgeable others, which formalizes how a learner may reason from a person's actions and goals to infer the actor's knowledge about the world. We illustrate this framework using two examples from causal learning and conclude by discussing the implications for cognition, social reasoning, and cognitive development.},
author = {Shafto, P. and Goodman, N. D. and Frank, M. C.},
doi = {10.1177/1745691612448481},
isbn = {1745-6916$\backslash$r1745-6924},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {bayesian model,but even a perfect,children are often compared,learning,reasoning,scientist,social cognition,to scientists,using experiments alone,would struggle to redis-},
number = {4},
pages = {341--351},
title = {{Learning From Others: The Consequences of Psychological Reasoning for Human Learning}},
volume = {7},
year = {2012}
}
@article{MCKAY2012,
abstract = {Does the formation of delusions involve abnormal reasoning? According to the prominent 'two-factor' theory of delusions (e.g. Coltheart, 2007), the answer is yes. The second factor in this theory is supposed to affect a deluded individual's ability to evaluate candidates for belief. However, most published accounts of the two-factor theory have not said much about the nature of this second factor. In an effort to remedy this shortcoming, Coltheart, Menzies and Sutton (2010) recently put forward a Bayesian account of inference in delusions. I outline some criticisms of this important account, and sketch an alternative account of delusional inference that, I argue, avoids these criticisms. Specifically, I argue that the second factor in delusion formation involves a systematic deviation from Bayesian updating, a deviation that may be characterized as a bias towards 'explanatory adequacy'. I present a numerical model of this idea and show that my alternative account is broadly consistent with prominent prediction error models of delusion formation (e.g. Corlett, Murray et al., 2007).},
author = {MCKAY, RYAN},
doi = {10.1111/j.1468-0017.2012.01447.x},
isbn = {0268-1064},
issn = {02681064},
journal = {Mind {\&} Language},
month = {jun},
number = {3},
pages = {330--355},
title = {{Delusional Inference}},
url = {http://doi.wiley.com/10.1111/j.1468-0017.2012.01447.x},
volume = {27},
year = {2012}
}
@article{Churchland1998,
abstract = {Recent neural-network models of cognition--first used to illuminate perceptual, linguistic, motor, and scientific cognition--also throw light on the nature of moral cognition. The primary impact is on metaethics, specifically, on moral epistemology, and moral psychology (as opposed to substantive moral doctrine). However, the picture of moral knowledge that emerges from this neurobiological reconstruction is one moral philosophers will recognize. It is the picture defended by Aristotle and by contemporary proponents of "virtue ethics." I provide an introductory explanation of the relevant neurocomputational ideas and trace their consequences for a dozen notion central to moral philosophy.},
author = {Churchland, Paul M},
doi = {10.1023/A:1017186710699},
file = {:home/kaslu/Documents/Mendeley/1998 - Churchland - Toward a Cognitive Neurobiology of the Moral Virtues.pdf:pdf},
isbn = {0167-7411},
issn = {0167-7411},
journal = {Topoi: An International Review of Philosophy},
keywords = {Cognitive,Ethics,Moral Theory,Neurobiology,Vir},
number = {2},
pages = {83},
title = {{Toward a Cognitive Neurobiology of the Moral Virtues}},
volume = {17},
year = {1998}
}
@article{Ruff2014,
abstract = {How does our brain choose the best course of action? Choices between material goods are thought to be steered by neural value signals that encode the rewarding properties of the choice options. Social decisions, by contrast, are traditionally thought to rely on neural representations of the self and others. However, recent studies show that many types of social decisions may also involve neural value computations. This suggests a unified mechanism for motivational control of behaviour that may incorporate both social and non-social factors. In this Review, we outline a theoretical framework that may help to identify possible overlaps and differences between the neural processes that guide social and non-social decision making.},
author = {Ruff, Christian C and Fehr, Ernst},
doi = {10.1038/nrn3776},
file = {:home/kaslu/Documents/Mendeley/2014 - Ruff, Fehr - The neurobiology of rewards and values in social decision making.pdf:pdf;:home/kaslu/Documents/Mendeley/2014 - Ruff, Fehr - The neurobiology of rewards and values in social decision making(2).pdf:pdf},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
month = {jul},
number = {July},
pmid = {24986556},
publisher = {Nature Publishing Group},
title = {{The neurobiology of rewards and values in social decision making.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24986556},
year = {2014}
}
@article{Jacobs2013,
abstract = {Grid cells in the entorhinal cortex appear to represent spatial location via a triangular coordinate system. Such cells, which have been identified in rats, bats and monkeys, are believed to support a wide range of spatial behaviors. Recording neuronal activity from neurosurgical patients performing a virtual-navigation task, we identified cells exhibiting grid-like spiking patterns in the human brain, suggesting that humans and simpler animals rely on homologous spatial-coding schemes.},
author = {Jacobs, Joshua and Weidemann, Christoph T and Miller, Jonathan F and Solway, Alec and Burke, John F and Wei, Xue-Xin and Suthana, Nanthia and Sperling, Michael R and Sharan, Ashwini D and Fried, Itzhak and Kahana, Michael J},
doi = {10.1038/nn.3466},
file = {:home/kaslu/Documents/Mendeley/2013 - Jacobs et al. - Direct recordings of grid-like neuronal activity in human spatial navigation.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {9},
pages = {1188--1190},
pmid = {23912946},
title = {{Direct recordings of grid-like neuronal activity in human spatial navigation}},
url = {http://www.nature.com/doifinder/10.1038/nn.3466},
volume = {16},
year = {2013}
}
@article{Schapiro2016,
author = {Schapiro, Anna C. and Turk-browne, Nicholas B. and Norman, Kenneth A. and Botvinick, Matthew M.},
doi = {10.1002/hipo.22523.Statistical},
file = {:home/kaslu/Documents/Mendeley/2016 - Schapiro et al. - Statistical learning of temporal community structure in the hippocampus.pdf:pdf},
journal = {Hippocampus},
number = {1},
pages = {3--8},
title = {{Statistical learning of temporal community structure in the hippocampus}},
volume = {26},
year = {2016}
}
@article{Traulsen2010,
abstract = {Evolutionary game theory is a general mathematical framework that describes the evolution of social traits. This framework forms the basis of many multilevel selection models and is also frequently used to model evolutionary dynamics on networks. Kin selection, which was initially restricted to describe social interactions between relatives, has also led to a broader mathematical approach, inclusive fitness, that can not only describe social evolution among relatives, but also in group structured populations or on social networks. It turns out that the underlying mathematics of game theory is fundamentally different from the approach of inclusive fitness. Thus, both approaches-evolutionary game theory and inclusive fitness-can be helpful to understand the evolution of social traits in group structured or spatially extended populations.},
author = {Traulsen, Arne},
doi = {10.1111/j.1558-5646.2009.00899.x},
isbn = {1558-5646},
issn = {00143820},
journal = {Evolution},
keywords = {Evolutionary game theory,Inclusive fitness,Mathematical biology,Multilevel selection},
number = {2},
pages = {316--323},
pmid = {19929970},
title = {{Mathematics of kin- and group-selection: Formally equivalent?}},
volume = {64},
year = {2010}
}
@article{Roudi2009,
abstract = {Biological systems are exceedingly complicated: They consist of a large number of elements, those elements interact in nonlinear and highly unpredictable ways, and collective interactions typically play a critical role. It would seem surprising, then, that one could build a quantitative description of biological systems based only on knowledge of how pairs of elements interact. Yet, that is what a number of studies have found. Those studies, however, focused on relatively small systems. Here, we ask the question: Do their conclusions extend to large systems? We show that the answer depends on the size of the system relative to a crossover point: Below the crossover point the results on the small system have no predictive power for large systems; above the crossover point the results on the small system may have predictive power. Moreover, the crossover point can be computed analytically. This work thus provides a general framework for determining the extent to which pairwise models can be used to predict the behavior of large biological systems. It also provides a useful heuristic for designing experiments: If one is interested in understanding truly large systems via pairwise interactions, then make sure that the system one studies is above the crossover point.},
archivePrefix = {arXiv},
arxivId = {arXiv:0811.0903v1},
author = {Roudi, Yasser and Nirenberg, Sheila and Latham, Peter E.},
doi = {10.1371/journal.pcbi.1000380},
eprint = {arXiv:0811.0903v1},
file = {:home/kaslu/Documents/Mendeley/2009 - Roudi, Nirenberg, Latham - Pairwise maximum entropy models for studying large biological systems When they can work and when they.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {5},
pmid = {19424487},
title = {{Pairwise maximum entropy models for studying large biological systems: When they can work and when they can't}},
volume = {5},
year = {2009}
}
@article{Sardi2017a,
abstract = {Neurons are the computational elements that compose the brain and their fundamental principles of activity are known for decades. According to the long-lasting computational scheme, each neuron sums the incoming electrical signals via its dendrites and when the membrane potential reaches a certain threshold the neuron typically generates a spike to its axon. Here we present three types of experiments, using neuronal cultures, indicating that each neuron functions as a collection of independent threshold units. The neuron is anisotropically activated following the original of the arriving signals to the membrane, via its dendritic trees. The first type of experiments demonstrates that a single neuron's spike waveform typically varies as a function of the stimulation location. The second type reveals that spatial summation is absent for extracellular stimulations from different directions. The third type indicates that spatial summation and subtraction are not achieved when combining intra- and extra- cellular stimulations, as well as for nonlocal time interference, where the precise timings of the stimulations are irrelevant. Results call to re-examine neuronal functionalities beyond the traditional framework, and the advanced computational capabilities and dynamical properties of such complex systems.},
author = {Sardi, Shira and Vardi, Roni and Sheinin, Anton and Goldental, Amir and Kanter, Ido},
doi = {10.1038/s41598-017-18363-1},
isbn = {20452322 (ISSN)},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {18036},
pmid = {29269849},
title = {{New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units}},
url = {http://www.nature.com/articles/s41598-017-18363-1 https://www.nature.com/articles/s41598-017-18363-1},
volume = {7},
year = {2017}
}
@article{Tkacik2014a,
abstract = {The activity of a neural network is defined by patterns of spiking and silence from the individual neurons. Because spikes are (relatively) sparse, patterns of activity with increasing numbers of spikes are less probable, but with more spikes the number of possible patterns increases. This tradeoff between probability and numerosity is mathematically equivalent to the relationship between entropy and energy in statistical physics. We construct this relationship for populations of up to N=160 neurons in a small patch of the vertebrate retina, using a combination of direct and model-based analyses of experiments on the response of this network to naturalistic movies. We see signs of a thermodynamic limit, where the entropy per neuron approaches a smooth function of the energy per neuron as N increases. The form of this function corresponds to the distribution of activity being poised near an unusual kind of critical point. Networks with more or less correlation among neurons would not reach this critical state. We suggest further tests of criticality, and give a brief discussion of its functional significance.},
archivePrefix = {arXiv},
arxivId = {1407.5946},
author = {Tkacik, Gasper and Mora, Thierry and Marre, Olivier and Amodei, Dario and Berry, Michael J. and Bialek, William},
doi = {10.1073/pnas.1514188112},
eprint = {1407.5946},
file = {:home/kaslu/Documents/Mendeley/2014 - Tkacik et al. - Thermodynamics for a network of neurons Signatures of criticality.pdf:pdf},
isbn = {1514188112},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jul},
number = {37},
pages = {11508--11513},
pmid = {26330611},
title = {{Thermodynamics for a network of neurons: Signatures of criticality}},
url = {http://arxiv.org/abs/physics/0004057 http://www.pnas.org/lookup/doi/10.1073/pnas.1514188112},
volume = {112},
year = {2014}
}
@article{Carrasquilla2016,
abstract = {Neural networks can be used to identify phases and phase transitions in condensed matter systems via supervised machine learning. Readily programmable through modern software libraries, we show that a standard feed-forward neural network can be trained to detect multiple types of order parameter directly from raw state configurations sampled with Monte Carlo. In addition, they can detect highly non-trivial states such as Coulomb phases, and if modified to a convolutional neural network, topological phases with no conventional order parameter. We show that this classification occurs within the neural network without knowledge of the Hamiltonian or even the general locality of interactions. These results demonstrate the power of machine learning as a basic research tool in the field of condensed matter and statistical physics.},
archivePrefix = {arXiv},
arxivId = {1605.01735},
author = {Carrasquilla, Juan and Melko, Roger G.},
doi = {10.1038/nphys4035},
eprint = {1605.01735},
file = {:home/kaslu/Documents/Mendeley/2016 - Carrasquilla, Melko - Machine learning phases of matter.pdf:pdf},
isbn = {1745-2473, 1745-2481},
issn = {1745-2473},
journal = {Nature Physics},
month = {feb},
number = {5},
pages = {431--434},
title = {{Machine learning phases of matter}},
url = {http://arxiv.org/abs/1605.01735{\%}0Ahttp://dx.doi.org/10.1038/nphys4035 http://www.nature.com/doifinder/10.1038/nphys4035},
volume = {13},
year = {2017}
}
@article{Schwemmer2014,
abstract = {While spike timing has been shown to carry detailed stimulus information at the sensory periphery, its possible role in network computation is less clear. Most models of computation by neural networks are based on population firing rates. In equivalent spiking implementations, firing is assumed to be random such that averaging across populations of neurons recovers the rate-based approach. Recently, however, Den$\backslash$'eve and colleagues have suggested that the spiking behavior of neurons may be fundamental to how neuronal networks compute, with precise spike timing determined by each neuron's contribution to producing the desired output. By postulating that each neuron fires in order to reduce the error in the network's output, it was demonstrated that linear computations can be carried out by networks of integrate-and-fire neurons that communicate through instantaneous synapses. This left open, however, the possibility that realistic networks, with conductance-based neurons with subthreshold nonlinearity and the slower timescales of biophysical synapses, may not fit into this framework. Here, we show how the spike-based approach can be extended to biophysically plausible networks. We then show that our network reproduces a number of key features of cortical networks including irregular and Poisson-like spike times and a tight balance between excitation and inhibition. Lastly, we discuss how the behavior of our model scales with network size, or with the number of neurons "recorded" from a larger computing network. These results significantly increase the biological plausibility of the spike-based approach to network computation.},
archivePrefix = {arXiv},
arxivId = {1411.3191},
author = {Schwemmer, Michael A. and Fairhall, Adrienne and Den{\`{e}}ve, Sophie and Shea-Brown, Eric},
doi = {10.1523/JNEUROSCI.4951-14.2015},
eprint = {1411.3191},
file = {:home/kaslu/Documents/Mendeley/2014 - Schwemmer et al. - Constructing precisely computing networks with biophysical spiking neurons.pdf:pdf;:home/kaslu/Documents/Mendeley/2014 - Schwemmer et al. - Constructing precisely computing networks with biophysical spiking neurons(2).pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {nov},
number = {28},
pages = {10112--10134},
pmid = {26180189},
title = {{Constructing precisely computing networks with biophysical spiking neurons}},
url = {http://arxiv.org/abs/1411.3191 http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4951-14.2015},
volume = {35},
year = {2014}
}
@article{Daw2006,
abstract = {Following the suggestion that midbrain dopaminergic neurons encode a signal, known as a 'reward prediction error', used by artificial intelligence algorithms for learning to choose advantageous actions, the study of the neural substrates for reward-based learning has been strongly influenced by computational theories. In recent work, such theories have been increasingly integrated into experimental design and analysis. Such hybrid approaches have offered detailed new insights into the function of a number of brain areas, especially the cortex and basal ganglia. In part this is because these approaches enable the study of neural correlates of subjective factors (such as a participant's beliefs about the reward to be received for performing some action) that the computational theories purport to quantify. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Daw, Nathaniel D. and Doya, Kenji},
doi = {10.1016/j.conb.2006.03.006},
file = {:home/kaslu/Documents/Mendeley/2006 - Daw, Doya - The computational neurobiology of learning and reward.pdf:pdf},
isbn = {0959-4388 (Print)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {apr},
number = {2},
pages = {199--204},
pmid = {16563737},
title = {{The computational neurobiology of learning and reward}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438806000316},
volume = {16},
year = {2006}
}
@article{Beck2008,
abstract = {When making a decision, one must first accumulate evidence, often over time, and then select the appropriate action. Here, we present a neural model of decision making that can perform both evidence accumulation and action selection optimally. More specifically, we show that, given a Poisson-like distribution of spike counts, biological neural networks can accumulate evidence without loss of information through linear integration of neural activity and can select the most likely action through attractor dynamics. This holds for arbitrary correlations, any tuning curves, continuous and discrete variables, and sensory evidence whose reliability varies over time. Our model predicts that the neurons in the lateral intraparietal cortex involved in evidence accumulation encode, on every trial, a probability distribution which predicts the animal's performance. We present experimental evidence consistent with this prediction and discuss other predictions applicable to more general settings. ?? 2008 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1507.01561},
author = {Beck, Jeffrey M. and Ma, Wei Ji and Kiani, Roozbeh and Hanks, Timothy D. and Churchland, Anne K. and Roitman, Jamie and Shadlen, Michael N. and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1016/j.neuron.2008.09.021},
eprint = {1507.01561},
file = {:home/kaslu/Documents/Mendeley/2008 - Beck et al. - Probabilistic Population Codes for Bayesian Decision Making.pdf:pdf;:home/kaslu/Documents/Mendeley/2008 - Beck et al. - Probabilistic Population Codes for Bayesian Decision Making(2).pdf:pdf},
isbn = {1097-4199},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
month = {dec},
number = {6},
pages = {1142--1152},
pmid = {19109917},
publisher = {Wiley, New York},
title = {{Probabilistic Population Codes for Bayesian Decision Making}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19109917 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2742921 http://linkinghub.elsevier.com/retrieve/pii/S0896627308008039},
volume = {60},
year = {2008}
}
@incollection{Bialek1997,
author = {Bialek, William},
booktitle = {Physics of Biological Systems},
doi = {10.1007/978-3-540-49733-2_12},
file = {:home/kaslu/Documents/Mendeley/1997 - Bialek - Statistical Mechanics and Sensory Signal Processing.pdf:pdf},
number = {1969},
pages = {252--280},
title = {{Statistical Mechanics and Sensory Signal Processing}},
url = {http://link.springer.com/10.1007/978-3-540-49733-2{\_}12},
year = {1997}
}
@article{Lake2009,
abstract = {During the learning of speech sounds and other perceptual categories, category labels are not provided, the number of categories is unknown, and the stimuli are encountered sequentially. These constraints provide a challenge for models, but they have been recently addressed in the online mixture estimation model of unsupervised vowel category learning (see Vallabha in the reference section). The model treats categories as Gaussian distributions, proposing both the number and the parameters of the categories. While the model has been shown to successfully learn vowel categories, it has not been evaluated as a model of the learning process. We account for several results: acquired distinctiveness between categories and acquired similarity within categories, a faster increase in discrimination for more acoustically dissimilar vowels, and gradual unsupervised learning of category structure in simple visual stimuli.},
author = {Lake, Brenden M. and Vallabha, Gautam K. and McClelland, James L.},
doi = {10.1109/TAMD.2009.2021703},
file = {:home/kaslu/Documents/Mendeley/2009 - Lake, Vallabha, McClelland - Modeling unsupervised perceptual category learning.pdf:pdf},
isbn = {9781424426621},
issn = {19430604},
journal = {IEEE Transactions on Autonomous Mental Development},
keywords = {Human learning,Mixture of Gaussians,Online learning,Unsupervised learning},
number = {1},
pages = {35--43},
title = {{Modeling unsupervised perceptual category learning}},
volume = {1},
year = {2009}
}
@article{Campbell2016,
abstract = {In 2014 Comparative Sociology published our analysis of microaggression complaints – a comparative and theoretical piece addressing microaggres-sion complaints as a form of social control indicative of a distinct moral culture. The article attracted a surprising amount of attention in popular media, and with this attention came confusion and controversy. Here we respond to popular accounts of our work, addressing common criticisms and confusions as well as the sociological question of why the article produced such strong reactions. We conclude by clarifying the sociology of morality's role in moral debates and suggesting ways that sociological knowledge can inform debate and guide reform.},
author = {Campbell, Bradley and Manning, Jason},
doi = {10.1163/15691330-12341382},
issn = {1569-1322},
journal = {Comparative Sociology},
keywords = {dignity,honor,microaggression,moral cultures,sociology of knowledge,sociology of morality,victimhood},
number = {323},
pages = {147--178},
title = {{Campus Culture Wars and the Sociology of Morality}},
volume = {15},
year = {2016}
}
@article{Kohn2016,
abstract = {Brain function involves the activity of neuronal populations. Much recent effort has been devoted to measuring the activity of neuronal populations in different parts of the brain under various experimental conditions. Population activity patterns contain rich structure, yet many studies have focused on measuring pairwise relationships between members of a larger population-termed noise correlations. Here we review recent progress in understanding how these correlations affect population information, how information should be quantified, and what mechanisms may give rise to correlations. As population coding theory has improved, it has made clear that some forms of correlation are more important for information than others. We argue that this is a critical lesson for those interested in neuronal population responses more generally: Descriptions of population responses should be motivated by and linked to well-specified function. Within this context, we offer suggestions of where current theoretical frameworks fall short. Expected final online publication date for the Annual Review of Neuroscience Volume 39 is July 08, 2016. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.},
author = {Kohn, Adam and Coen-cagli, Ruben and Kanitscheider, Ingmar and Pouget, Alexandre},
doi = {10.1146/annurev-neuro-070815-013851},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
number = {April},
pages = {237--256},
pmid = {27145916},
title = {{Correlations and Neuronal Population Information}},
volume = {39},
year = {2016}
}
@article{Galv,
abstract = {In science, the most widespread statistical quantities are perhaps {\$}p{\$}-values. A typical advice is to reject the null hypothesis {\$}H{\_}0{\$} if the corresponding p-value is sufficiently small (usually smaller than 0.05). Many criticisms regarding p-values have arisen in the scientific literature. The main issue is that in general optimal p-values (based on likelihood ratio statistics) are not measures of evidence over the parameter space {\$}\backslashTheta{\$}. Here, we propose an $\backslash$emph{\{}objective{\}} measure of evidence for very general null hypotheses that satisfies logical requirements (i.e., operations on the subsets of {\$}\backslashTheta{\$}) that are not met by p-values (e.g., it is a possibility measure). We study the proposed measure in the light of the abstract belief calculus formalism and we conclude that it can be used to establish objective states of belief on the subsets of {\$}\backslashTheta{\$}. Based on its properties, we strongly recommend this measure as an additional summary of significance tests. At the end of the paper we give a short listing of possible open problems.},
archivePrefix = {arXiv},
arxivId = {1201.0400},
author = {Patriota, Alexandre Galv{\~{a}}o},
doi = {10.1016/j.fss.2013.03.007},
eprint = {1201.0400},
file = {:home/kaslu/Documents/Mendeley/2013 - Patriota - A classical measure of evidence for general null hypotheses.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {abstract belief calculus,evidence measure,fidence,likelihood-based con-,nested hypothesis,p-value,possibilistic measure,significance test},
month = {dec},
pages = {74--88},
title = {{A classical measure of evidence for general null hypotheses}},
url = {http://arxiv.org/abs/1201.0400},
volume = {233},
year = {2013}
}
@article{Gachter2016,
author = {G{\"{a}}chter, Simon and Schulz, Jonathan F},
doi = {10.1038/nature17160},
file = {:home/kaslu/Documents/Mendeley/2016 - G{\"{a}}chter, Schulz - Intrinsic honesty and the prevalence of rule violations across societies.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {mar},
pages = {1--11},
pmid = {26958830},
publisher = {Nature Publishing Group},
title = {{Intrinsic honesty and the prevalence of rule violations across societies}},
url = {http://dx.doi.org/10.1038/nature17160 http://www.nature.com/doifinder/10.1038/nature17160},
year = {2016}
}
@article{Hosoya2017,
abstract = {Experimental studies have revealed evidence of both parts-based and holistic representations of objects and faces in the primate visual system. However, it is still a mystery how such seemingly contradictory types of processing can coexist within a single system. Here, we propose a novel theory called mixture of sparse coding models, inspired by the formation of category-specific subregions in the inferotemporal (IT) cortex. We developed a hierarchical network that constructed a mixture of two sparse coding submodels on top of a simple Gabor analysis. The submodels were each trained with face or non-face object images, which resulted in separate representations of facial parts and object parts. Importantly, evoked neural activities were modeled by Bayesian inference, which had a top-down explaining-away effect that enabled recognition of an individual part to depend strongly on the category of the whole input. We show that this explaining-away effect was indeed crucial for the units in the face submodel to exhibit significant selectivity to face images over object images in a similar way to actual face-selective neurons in the macaque IT cortex. Furthermore, the model explained, qualitatively and quantitatively, several tuning properties to facial features found in the middle patch of face processing in IT as documented by Freiwald, Tsao, and Livingstone (2009). These included, in particular, tuning to only a small number of facial features that were often related to geometrically large parts like face outline and hair, preference and anti-preference of extreme facial features (e.g., very large/small inter-eye distance), and reduction of the gain of feature tuning for partial face stimuli compared to whole face stimuli.},
author = {Hosoya, Haruo and Hyv{\"{a}}rinen, Aapo},
doi = {10.1371/journal.pcbi.1005667},
file = {:home/kaslu/Documents/Mendeley/2017 - Hosoya, Hyv{\"{a}}rinen - A mixture of sparse coding models explaining properties of face neurons related to holistic and parts-based.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {7},
pages = {1--27},
title = {{A mixture of sparse coding models explaining properties of face neurons related to holistic and parts-based processing}},
volume = {13},
year = {2017}
}
@misc{Hassabis2017,
abstract = {The fields of neuroscience and artificial intelligence (AI) have a long and intertwined history. In more recent times, however, communication and collaboration between the two fields has become less commonplace. In this article, we argue that better understanding biological brains could play a vital role in building intelligent machines. We survey historical interactions between the AI and neuroscience fields and emphasize current advances in AI that have been inspired by the study of neural computation in humans and other animals. We conclude by highlighting shared themes that may be key for advancing future research in both fields. Hassabis et al. review how neuroscience has informed research in artificial intelligence. They argue that a better understanding of biological brains will play a vital role in building intelligent machines.},
archivePrefix = {arXiv},
arxivId = {1404.7282},
author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew M.},
booktitle = {Neuron},
doi = {10.1016/j.neuron.2017.06.011},
eprint = {1404.7282},
file = {:home/kaslu/Documents/Mendeley/2017 - Hassabis et al. - Neuroscience-Inspired Artificial Intelligence.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
keywords = {artificial intelligence,brain,cognition,learning,neural network},
month = {jul},
number = {2},
pages = {245--258},
pmid = {28728020},
publisher = {Elsevier},
title = {{Neuroscience-Inspired Artificial Intelligence}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28728020},
volume = {95},
year = {2017}
}
@article{Cerf1998,
abstract = {We present a quantum information theory that allows for a consistent description of entanglement. It parallels classical (Shannon) information theory but is based entirely on density matrices rather than probability distributions for the description of quantum ensembles. We find that quantum (von Neumann) conditional entropies can be negative for entangled systems, which leads to a violation of entropic Bell inequalities. Quantum inseparability can be related, in this theory, to the appearance of “unclassical” eigenvalues in the spectrum of a conditional “amplitude” matrix that underlies the quantum conditional entropy. Such a unified information-theoretic description of classical correlation and quantum entanglement clarifies the link between them: the latter can be viewed as “super-correlation” which can induce classical correlation when considering a tripartite or larger system. Furthermore, the characterization of entanglment with negative conditional entropies paves the way to a natural information-theoretic description of the measurement process. This model, while unitary and causal, implies the well-known probabilistic results of conventional quantum mechanics. It also results in a simple interpretation of the Levitin-Kholevo theorem limiting the accessible information in a quantum measurement.},
author = {Cerf, Nicolas J. and Adami, Christoph},
doi = {10.1016/S0167-2789(98)00045-1},
file = {:home/kaslu/Documents/Mendeley/1998 - Cerf, Adami - Information theory of quantum entanglement and measurement.pdf:pdf},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {entanglement,quantum information theory,quantum measurement,quantum non-locality},
number = {November 1996},
pages = {62--81},
title = {{Information theory of quantum entanglement and measurement}},
volume = {120},
year = {1998}
}
@article{Molleman2014,
abstract = {Social learning has allowed humans to build up extensive cultural repertoires, enabling them to adapt to a wide variety of environmental and social conditions. However, it is unclear which social learning strategies people use, especially in social contexts where their payoffs depend on the behaviour of others. Here we show experimentally that individuals differ in their social learning strategies and that they tend to employ the same learning strategy irrespective of the interaction context. Payoff-based learners focus on their peers' success, while decision-based learners disregard payoffs and exclusively focus on their peers' past behaviour. These individual differences may be of considerable importance for cultural evolution. By means of a simple model, we demonstrate that groups harbouring individuals with different learning strategies may be faster in adopting technological innovations and can be more efficient through successful role differentiation. Our study highlights the importance of individual variation for human interactions and sheds new light on the dynamics of cultural evolution.},
author = {Molleman, Lucas and van den Berg, Pieter and Weissing, Franz J},
doi = {10.1038/ncomms4570},
file = {:home/kaslu/Documents/Mendeley/2014 - Molleman, van den Berg, Weissing - Consistent individual differences in human social learning strategies.pdf:pdf},
isbn = {info:doi/10.1038/ncomms4570},
issn = {2041-1723},
journal = {Nature communications},
pages = {3570},
pmid = {24705692},
publisher = {Nature Publishing Group},
title = {{Consistent individual differences in human social learning strategies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24705692},
volume = {5},
year = {2014}
}
@article{Investment2015,
author = {Arrow, Kenneth J.},
doi = {10.1086/256963},
issn = {0022-3808},
journal = {Journal of Political Economy},
month = {aug},
number = {4},
pages = {328--346},
title = {{A Difficulty in the Concept of Social Welfare}},
url = {http://www.journals.uchicago.edu/doi/10.1086/256963 http://www.journals.uchicago.edu/doi/abs/10.1086/256963},
volume = {58},
year = {1950}
}
@article{Rescorla1972,
abstract = {Transposable elements (TEs) are a tremendous source of genome instability and genetic variation. Of particular interest to investigators of human biology and human evolution are retrotransposon insertions that are recent and/or polymorphic in the human population. As a consequence, the ability to assay large numbers of polymorphic TEs in a given genome is valuable. Five recent manuscripts each propose methods to scan whole human genomes to identify, map, and, in some cases, genotype polymorphic retrotransposon insertions in multiple human genomes simultaneously. These technologies promise to revolutionize our ability to analyze human genomes for TE-based variation important to studies of human variability and human disease. Furthermore, the approaches hold promise for researchers interested in nonhuman genomic variability. Herein, we explore the methods reported in the manuscripts and discuss their applications to aspects of human biology and the biology of other organisms.},
author = {Rescorla, Robert A and Wagner, Allan R},
doi = {10.1101/gr.110528.110},
file = {:home/kaslu/Documents/Mendeley/1972 - Rescorla, Wagner - A theory of Pavlovian conditioning Variations in the effectiveness of reinforcement and nonreinforcement.pdf:pdf},
isbn = {0390718017},
issn = {19416016},
journal = {Classical Conditioning II Current Research and Theory},
number = {6},
pages = {64--99},
pmid = {21632748},
title = {{A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement}},
url = {http://homepage.mac.com/sanagnos/rescorlawagner1972.pdf},
volume = {21},
year = {1972}
}
@article{Rangel2008,
abstract = {Neuroeconomics is the study of the neurobiological and computational basis of value-based decision making. Its goal is to provide a biologically based account of human behaviour that can be applied in both the natural and the social sciences. This Review proposes a framework to investigate different aspects of the neurobiology of decision making. The framework allows us to bring together recent findings in the field, highlight some of the most important outstanding problems, define a common lexicon that bridges the different disciplines that inform neuroeconomics, and point the way to future applications.},
author = {Rangel, Antonio and Camerer, Colin and Montague, P. Read},
doi = {10.1038/nrn2357},
file = {:home/kaslu/Documents/Mendeley/2008 - Rangel, Camerer, Montague - A framework for studying the neurobiology of value-based decision making.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {7},
pages = {545--556},
pmid = {18545266},
title = {{A framework for studying the neurobiology of value-based decision making}},
url = {http://www.nature.com/doifinder/10.1038/nrn2357},
volume = {9},
year = {2008}
}
@article{Wasserman1996,
author = {Wasserman, Larry and Kass, Robert E.},
file = {:home/kaslu/Documents/Mendeley/1996 - Wasserman, Kass - The Selection of Prior Distributions by Formal Rules.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {bayes factors,entropy,haar measure,improper priors,jeffreys,marginalization paradoxes,mative priors,noninfor-,reference priors,s prior},
number = {435},
pages = {1343--1370},
title = {{The Selection of Prior Distributions by Formal Rules}},
url = {http://mathfaculty.fullerton.edu/sbehseta/KassWasserman-JASA-1996.pdf},
volume = {91},
year = {1996}
}
@article{Caticha2014,
abstract = {We review the derivation of quantum theory as an application of entropic methods of inference. The new contribution in this paper is a streamlined derivation of the Schr$\backslash$"odinger equation based on a different choice of microstates and constraints.},
archivePrefix = {arXiv},
arxivId = {1403.3822},
author = {Caticha, Ariel},
doi = {10.1088/1742-6596/504/1/012009},
eprint = {1403.3822},
file = {:home/kaslu/Documents/Mendeley/2014 - Caticha - Entropic Dynamics an inference approach to quantum theory, time and measurement.pdf:pdf},
issn = {1742-6588},
journal = {Journal of Physics: Conference Series},
month = {apr},
pages = {012009},
title = {{Entropic Dynamics: an inference approach to quantum theory, time and measurement}},
url = {http://arxiv.org/abs/1403.3822 http://stacks.iop.org/1742-6596/504/i=1/a=012009?key=crossref.4471c0e6d280e858c4ebe9e1e5218e3d},
volume = {504},
year = {2014}
}
@article{Danks2003,
abstract = {The Rescorla-Wagner model has been a leading theory of animal causal induction for nearly 30 years, and human causal induction for the past 15 years. Recent theories (especially Psychol. Rev. 104 (1997) 367) have provided alternative explanations of how people draw causal conclusions from covariational data. However, theoretical attempts to compare the Rescorla-Wagner model with more recent models have been hampered by the fact that the Rescorla-Wagner model is an algorithmic theory, while the more recent theories are all computational. This paper provides a detailed derivation of the long-run behavior of the Rescorla-Wagner model under a wide range of parameters and experimental setups, so that the model can be compared with computational theories. It also shows that the model agrees with competing theories on a wider range of cases than had previously been thought. The paper concludes by showing how recently suggested modifications of the Rescorla-Wagner model impact the long-run behavior of the model. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Danks, David},
doi = {10.1016/S0022-2496(02)00016-0},
file = {:home/kaslu/Documents/Mendeley/2003 - Danks - Equilibria of the Rescorla - Wagner model.pdf:pdf},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
keywords = {Causal learning,Rescorla-Wagner model},
number = {2},
pages = {109--121},
title = {{Equilibria of the Rescorla - Wagner model}},
volume = {47},
year = {2003}
}
@article{Metropolis1953,
archivePrefix = {arXiv},
arxivId = {5744249209},
author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
doi = {10.1063/1.1699114},
eprint = {5744249209},
file = {:home/kaslu/Documents/Mendeley/1953 - Metropolis et al. - Equation of State Calculations by Fast Computing Machines.pdf:pdf},
isbn = {doi:10.1063/1.1699114},
issn = {00219606},
journal = {The Journal of Chemical Physics},
number = {6},
pages = {1087},
pmid = {2797},
title = {{Equation of State Calculations by Fast Computing Machines}},
url = {http://scitation.aip.org.proxy.library.nd.edu/getabs/servlet/GetabsServlet?prog=normal{\&}id=JCPSA6000021000006001087000001{\&}idtype=cvips{\&}gifs=yes{\%}5Cnpapers2://publication/doi/10.1063/1.1699114 http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.169},
volume = {21},
year = {1953}
}
@article{Huang2011,
abstract = {Predictive coding is a unifying framework for understanding redundancy reduction and efficient coding in the nervous system. By transmitting only the unpredicted portions of an incoming sensory signal, predictive coding allows the nervous system to reduce redundancy and make full use of the limited dynamic range of neurons. Starting with the hypothesis of efficient coding as a design principle in the sensory system, predictive coding provides a functional explanation for a range of neural responses and many aspects of brain organization. The lateral and temporal antagonism in receptive fields in the retina and lateral geniculate nucleus occur naturally as a consequence of predictive coding of natural images. In the higher visual system, predictive coding provides an explanation for oriented receptive fields and contextual effects as well as the hierarchical reciprocally connected organization of the cortex. Predictive coding has also been found to be consistent with a variety of neurophysiological and psychophysical data obtained from different areas of the brain.},
archivePrefix = {arXiv},
arxivId = {Huang, Y., {\&} Rao, R. P. N. (2011). Predictive Coding. Cognitive Science, 2, 580–593. http://doi.org/10.1002/wcs.142},
author = {Huang, Yanping and Rao, Rajesh P. N.},
doi = {10.1002/wcs.142},
eprint = {/doi.org/10.1002/wcs.142},
file = {:home/kaslu/Documents/Mendeley/2011 - Huang, Rao - Predictive coding.pdf:pdf},
isbn = {19395078},
issn = {19395078},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
number = {5},
pages = {580--593},
pmid = {1000185202},
primaryClass = {Huang, Y., {\&} Rao, R. P. N. (2011). Predictive Coding. Cognitive Science, 2, 580–593. http:},
title = {{Predictive coding}},
volume = {2},
year = {2011}
}
@article{Crockett2014,
abstract = {Concern for the suffering of others is central to moral decision making. How humans evaluate others' suffering, relative to their own suffering, is unknown. We investigated this question by inviting subjects to trade off profits for themselves against pain experienced either by themselves or an anonymous other person. Subjects made choices between different amounts of money and different numbers of painful electric shocks. We independently varied the recipient of the shocks (self vs. other) and whether the choice involved paying to decrease pain or profiting by increasing pain. We built computational models to quantify the relative values subjects ascribed to pain for themselves and others in this setting. In two studies we show that most people valued others' pain more than their own pain. This was evident in a willingness to pay more to reduce others' pain than their own and a requirement for more compensation to increase others' pain relative to their own. This "hyperaltruistic" valuation of others' pain was linked to slower responding when making decisions that affected others, consistent with an engagement of deliberative processes in moral decision making. Subclinical psychopathic traits correlated negatively with aversion to pain for both self and others, in line with reports of aversive processing deficits in psychopathy. Our results provide evidence for a circumstance in which people care more for others than themselves. Determining the precise boundaries of this surprisingly prosocial disposition has implications for understanding human moral decision making and its disturbance in antisocial behavior.},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Crockett, Molly J. and Kurth-Nelson, Zeb and Siegel, Jenifer Z. and Dayan, Peter and Dolan, Raymond J.},
doi = {10.1073/pnas.1408988111},
eprint = {arXiv:1408.1149},
file = {:home/kaslu/Documents/Mendeley/2014 - Crockett et al. - Harm to others outweighs harm to self in moral decision making.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {48},
pages = {17320--17325},
pmid = {25404350},
title = {{Harm to others outweighs harm to self in moral decision making}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408988111},
volume = {111},
year = {2014}
}
@article{Yoder2015,
abstract = {Psychopathy, characterized by symptoms of emotional detachment, reduced guilt and empathy and a callous disregard for the rights and welfare of others, is a strong risk factor for immoral behavior. Psychopathy is also marked by abnormal attention with downstream consequences on emotional processing. To examine the influence of task demands on moral evaluation in psychopathy, functional magnetic resonance imaging was used to measure neural response and functional connectivity in 88 incarcerated male subjects (28 with Psychopathy Checklist Revised (PCL-R) scores ⩾ 30) while they viewed dynamic visual stimuli depicting interpersonal harm and interpersonal assistance in two contexts, implicit and explicit. During the implicit task, high psychopathy was associated with reduced activity in the dorsolateral prefrontal cortex and caudate when viewing harmful compared with helpful social interactions. Functional connectivity seeded in the right amygdala and right temporoparietal junction revealed decreased coupling with the anterior cingulate cortex (ACC), anterior insula, striatum and ventromedial prefrontal cortex. In the explicit task, higher trait psychopathy predicted reduced signal change in ACC and amygdala, accompanied by decreased functional connectivity to temporal pole, insula and striatum, but increased connectivity with dorsal ACC. Psychopathy did not influence behavioral performance in either task, despite differences in neural activity and functional connectivity. These findings provide the first direct evidence that hemodynamic activity and neural coupling within the salience network are disrupted in psychopathy, and that the effects of psychopathy on moral evaluation are influenced by attentional demands.},
author = {Yoder, K J and Harenski, C and Kiehl, K A and Decety, J},
doi = {10.1038/tp.2015.117},
file = {:home/kaslu/Documents/Mendeley/2015 - Yoder et al. - Neural networks underlying implicit and explicit moral evaluations in psychopathy.pdf:pdf},
isbn = {2158-3188},
issn = {2158-3188},
journal = {Translational Psychiatry},
number = {8},
pages = {e625},
pmid = {26305476},
publisher = {Nature Publishing Group},
title = {{Neural networks underlying implicit and explicit moral evaluations in psychopathy}},
url = {http://www.nature.com/doifinder/10.1038/tp.2015.117},
volume = {5},
year = {2015}
}
@article{Wang2008,
abstract = {Decision making has recently emerged as a central theme in neurophysiological studies of cognition, and experimental and computational work has led to the proposal of a cortical circuit mechanism of elemental decision computations. This mechanism depends on slow recurrent synaptic excitation balanced by fast feedback inhibition, which not only instantiates attractor states for forming categorical choices but also long transients for gradually accumulating evidence in favor of or against alternative options. Such a circuit endowed with reward-dependent synaptic plasticity is able to produce adaptive choice behavior. While decision threshold is a core concept for reaction time tasks, it can be dissociated from a general decision rule. Moreover, perceptual decisions and value-based economic choices are described within a unified framework in which probabilistic choices result from irregular neuronal activity as well as iterative interactions of a decision maker with an uncertain environment or other unpredictable decision makers in a social group. ?? 2008 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Wang, Xiao Jing},
doi = {10.1016/j.neuron.2008.09.034},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2008 - Wang - Decision Making in Recurrent Neuronal Circuits.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {215--234},
pmid = {18957215},
publisher = {Elsevier Inc.},
title = {{Decision Making in Recurrent Neuronal Circuits}},
url = {http://dx.doi.org/10.1016/j.neuron.2008.09.034},
volume = {60},
year = {2008}
}
@article{Macke2013,
abstract = {Maximum entropy models have become popular statistical models in neuroscience and other areas in biology and can be useful tools for obtaining estimates of mutual information in biological systems. However, maximum entropy models fit to small data sets can be subject to sampling bias; i.e., the true entropy of the data can be severely underestimated. Here, we study the sampling properties of estimates of the entropy obtained from maximum entropy models. We focus on pairwise binary models, which are used extensively to model neural population activity. We show that if the data is well described by a pairwise model, the bias is equal to the number of parameters divided by twice the number of observations. If, however, the higher order correlations in the data deviate from those predicted by the model, the bias can be larger. Using a phenomenological model of neural population recordings, we find that this additional bias is highest for small firing probabilities, strong correlations and large population sizes—for the parameters we tested, a factor of about four higher. We derive guidelines for how long a neurophysiological experiment needs to be in order to ensure that the bias is less than a specified criterion. Finally, we show how a modified plug-in estimate of the entropy can be used for bias correction.},
author = {Macke, Jakob H. and Murray, Iain and Latham, Peter E.},
doi = {10.3390/e15083209},
file = {:home/kaslu/Documents/Mendeley/2013 - Macke, Murray, Latham - Estimation bias in maximum entropy models.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {Asymptotic bias,Dichotomized gaussian,Ising model,Maximum entropy,Model-misspecification,Neural population coding,Neurophysiology,Sampling bias},
number = {8},
pages = {3109--3129},
title = {{Estimation bias in maximum entropy models}},
volume = {15},
year = {2013}
}
@article{Neirotti2003,
abstract = {We study the evolution of artificial learning systems by means of selection. Genetic programming is used to generate populations of programs that implement algorithms used by neural network classifiers to learn a rule in a supervised learning scenario. In contrast to concentrating on final results, which would be the natural aim while designing good learning algorithms, we study the evolution process. Phenotypic and genotypic entropies, which describe the distribution of fitness and of symbols, respectively, are used to monitor the dynamics. We identify significant functional structures responsible for the improvements in the learning process. In particular, some combinations of variables and operators are useful in assessing performance in rule extraction and can thus implement annealing of the learning schedule. We also find combinations that can signal surprise, measured on a single example, by the difference between predicted and correct classification. When such favorable structures appear, they are disseminated on very short time scales throughout the population. Due to such abruptness they can be thought of as dynamical transitions. But foremost, we find a strict temporal order of such discoveries. Structures that measure performance are never useful before those for measuring surprise. Invasions of the population by such structures in the reverse order were never observed. Asymptotically, the generalization ability approaches Bayesian results.},
author = {Neirotti, Juan Pablo and Caticha, Nestor},
doi = {10.1103/PhysRevE.67.041912},
file = {:home/kaslu/Documents/Mendeley/2003 - Neirotti, Caticha - Dynamics of the evolution of learning algorithms by selection.pdf:pdf},
issn = {1539-3755 (Print)},
journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},
keywords = {Algorithms,Humans,Learning,Models, Genetic,Models, Statistical,Neural Networks (Computer),Time Factors},
number = {4 Pt 1},
pages = {41912},
pmid = {12786401},
title = {{Dynamics of the evolution of learning algorithms by selection.}},
volume = {67},
year = {2003}
}
@inproceedings{Johnson2012,
abstract = {We explore the measurement problem in the entropic dynamics approach to quantum theory. The dual modes of quantum evolution---either continuous unitary evolution or abrupt wave function collapse during measurement---are unified by virtue of both being special instances of entropic updating of probabilities. In entropic dynamics particles have definite but unknown positions; their values are not created by the act of measurement. Other types of observables are introduced as a convenient way to describe more complex position measurements; they are not attributes of the particles but of the probability distributions; their values are effectively created by the act of measurement. We discuss the Born statistical rule for position, which is trivially built into the formalism, and also for generic observables.},
archivePrefix = {arXiv},
arxivId = {1108.2550},
author = {Johnson, David T. and Caticha, Ariel},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.3703626},
eprint = {1108.2550},
file = {:home/kaslu/Documents/Mendeley/2012 - Johnson, Caticha - Entropic dynamics and the quantum measurement problem.pdf:pdf},
isbn = {9780735410398},
issn = {0094243X},
keywords = {Bayesian Inference,Entropic Dynamics,Maximum Entropy,Quantum Theory},
month = {aug},
pages = {104--111},
title = {{Entropic dynamics and the quantum measurement problem}},
url = {http://arxiv.org/abs/1108.2550 http://dx.doi.org/10.1063/1.3703626 http://aip.scitation.org/doi/abs/10.1063/1.3703626},
volume = {1443},
year = {2012}
}
@article{Chwialkowski2016,
abstract = {We propose a nonparametric statistical test for goodness-of-fit: given a set of samples, the test determines how likely it is that these were generated from a target density function. The measure of goodness-of-fit is a divergence constructed via Stein's method using functions from a Reproducing Kernel Hilbert Space. Our test statistic is based on an empirical estimate of this divergence, taking the form of a V-statistic in terms of the log gradients of the target density and the kernel. We derive a statistical test, both for i.i.d. and non-i.i.d. samples, where we estimate the null distribution quantiles using a wild bootstrap procedure. We apply our test to quantifying convergence of approximate Markov Chain Monte Carlo methods, statistical model criticism, and evaluating quality of fit vs model complexity in nonparametric density estimation.},
archivePrefix = {arXiv},
arxivId = {1602.02964},
author = {Chwialkowski, Kacper and Strathmann, Heiko and Gretton, Arthur},
doi = {10.1080/01621459.1954.10501232},
eprint = {1602.02964},
file = {:home/kaslu/Documents/Mendeley/2016 - Chwialkowski, Strathmann, Gretton - A Kernel Test of Goodness of Fit.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
pmid = {25246403},
title = {{A Kernel Test of Goodness of Fit}},
url = {http://arxiv.org/abs/1602.02964},
volume = {48},
year = {2016}
}
@article{Kass2018,
abstract = {Extensive experimental investigations of the magnetic structures and excitations in the XY pyrochlores have been carried out over the last decade. Three families of XY pyrochlores have emerged: Yb{\$}{\_}2B{\_}2{\$}O{\$}{\_}7{\$}, Er{\$}{\_}2B{\_}2{\$}O{\$}{\_}7{\$}, and, most recently, {\$}AA'{\$}Co{\$}{\_}2{\$}F{\$}{\_}7{\$}. In each case, the magnetic cation (either Yb, Er, or Co) exhibits XY anisotropy within the local pyrochlore coordinates, a consequence of crystal field effects. Materials in these families display rich phase behavior and are candidates for exotic ground states, such as quantum spin ice, and exotic ground state selection via order-by-disorder mechanisms. In this review, we present an experimental summary of the ground state properties of the XY pyrochlores, including evidence that they are strongly influenced by phase competition. We empirically demonstrate the signatures for phase competition in a frustrated magnet: multiple heat capacity anomalies, suppressed {\$}T{\_}N{\$} or {\$}T{\_}C{\$}, sample and pressure dependent ground states, and unconventional spin dynamics.},
author = {Kass, Robert E and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N. and Diekman, Casey O. and Diesmann, Markus and Doiron, Brent and Eden, Uri T. and Fairhall, Adrienne L. and Fiddyment, Grant M. and Fukai, Tomoki and Gr{\"{u}}n, Sonja and Harrison, Matthew T. and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J. and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G. and Shea-Brown, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M. and Kramer, Mark A.},
doi = {10.1146/annurev-statistics-041715-033733},
file = {:home/kaslu/Documents/Mendeley/2018 - Kass et al. - Computational Neuroscience Mathematical and Statistical Perspectives(2).pdf:pdf},
isbn = {1545-1593 (Electronic)$\backslash$r0066-426X (Linking)},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
month = {mar},
number = {1},
pages = {annurev--statistics--041715--033733},
pmid = {26980309},
title = {{Computational Neuroscience: Mathematical and Statistical Perspectives}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-statistics-041715-033733},
volume = {5},
year = {2018}
}
@article{Caticha2014b,
abstract = {I discuss the design of the method of entropic inference as a general framework for reasoning under conditions of uncertainty. The main contribution of this discussion is to emphasize the pragmatic elements in the derivation. More specifically: (1) Probability theory is designed as the uniquely natural tool for representing states of incomplete information. (2) An epistemic notion of information is defined in terms of its relation to the Bayesian beliefs of ideally rational agents. (3) The method of updating from a prior to a posterior probability distribution is designed through an eliminative induction process that singles out the logarithmic relative entropy as the unique tool for inference. The resulting framework includes as special cases both MaxEnt and Bayes' rule. It therefore unifies entropic and Bayesian methods into a single general inference scheme. I find that similar pragmatic elements are an integral part of Putnam's internal realism, of Floridi's informational structural realism, and also of van Fraasen's empiricist structuralism. I conclude with the conjecture that their valuable insights can be incorporated into a single coherent doctrine - an informational pragmatic realism.},
archivePrefix = {arXiv},
arxivId = {1412.5644},
author = {Caticha, Ariel},
doi = {10.1007/s11023-013-9322-6},
eprint = {1412.5644},
file = {:home/kaslu/Documents/Mendeley/2014 - Caticha - Towards an informational pragmatic realism.pdf:pdf;:home/kaslu/Documents/Mendeley/2014 - Caticha - Towards an informational pragmatic realism(2).pdf:pdf},
issn = {09246495},
journal = {Minds and Machines},
keywords = {Entropic inference,Entropy,Information,Pragmatic realism},
month = {feb},
number = {1},
pages = {37--70},
title = {{Towards an informational pragmatic realism}},
url = {http://arxiv.org/abs/1412.5644 http://link.springer.com/10.1007/s11023-013-9322-6},
volume = {24},
year = {2014}
}
@article{Makhzani2015,
abstract = {In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.},
archivePrefix = {arXiv},
arxivId = {1511.05644},
author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
eprint = {1511.05644},
file = {:home/kaslu/Documents/Mendeley/2015 - Makhzani et al. - Adversarial Autoencoders.pdf:pdf},
month = {nov},
title = {{Adversarial Autoencoders}},
url = {http://arxiv.org/abs/1511.05644},
year = {2015}
}
@article{Agnelli2012,
abstract = {A mathematical model of the evacuation of a crowd from bounded domains is derived by a hybrid approach with kinetic and macro-features. Interactions at the micro-scale, which modify the velocity direction, are modeled by using tools of game theory and are transferred to the dynamics of collective behaviors. The velocity modulus is assumed to depend on the local density. The modeling approach considers dynamics caused by interactions of pedestrians not only with all the other pedestrians, but also with the geometry of the domain, such as walls and exits. Interactions with the boundary of the domain are non-local and described by games. Numerical simulations are developed to study evacuation time depending on the size of the exit zone, on the initial distribution of the crowd and on a parameter which weighs the unconscious attraction of the stream and the search for less crowded walking directions.},
author = {Agnelli, J. P. and Colasuonno, F. and Knopoff, D.},
doi = {10.1142/S0218202515500049},
issn = {0218-2025},
journal = {Mathematical Models and Methods in Applied Sciences},
keywords = {Crowd dynamics,complex systems,hybrid model,nonlinear interactions,stochastic games},
month = {jan},
number = {01},
pages = {109--129},
publisher = {World Scientific Publishing Company},
title = {{A kinetic theory approach to the dynamics of crowd evacuation from bounded domains}},
url = {http://dx.doi.org/10.1142/S0218202515500049 http://www.worldscientific.com/doi/abs/10.1142/S0218202515500049},
volume = {25},
year = {2015}
}
@article{Raposo2014,
abstract = {The posterior parietal cortex (PPC) receives diverse inputs and is involved in a dizzying array of behaviors. These many behaviors could rely on distinct categories of neurons specialized to represent particular variables or could rely on a single population of PPC neurons that is leveraged in different ways. To distinguish these possibilities, we evaluated rat PPC neurons recorded during multisensory decisions. Newly designed tests revealed that task parameters and temporal response features were distributed randomly across neurons, without evidence of categories. This suggests that PPC neurons constitute a dynamic network that is decoded according to the animal's present needs. To test for an additional signature of a dynamic network, we compared moments when behavioral demands differed: decision and movement. Our new state-space analysis revealed that the network explored different dimensions during decision and movement. These observations suggest that a single network of neurons can support the evolving behavioral demands of decision-making.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Raposo, David and Kaufman, Matthew T and Churchland, Anne K},
doi = {10.1038/nn.3865},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2014 - Raposo, Kaufman, Churchland - A category-free neural population supports evolving demands during decision-making.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {nov},
number = {12},
pages = {1784--1792},
pmid = {25383902},
title = {{A category-free neural population supports evolving demands during decision-making}},
url = {http://www.nature.com/doifinder/10.1038/nn.3865},
volume = {17},
year = {2014}
}
@article{Cantor2015,
abstract = {Multilevel societies, containing hierarchically nested social levels, are remarkable social structures whose origins are unclear. The social relationships of sperm whales are organized in a multilevel society with an upper level composed of clans of individuals communicating using similar patterns of clicks (codas). Using agent-based models informed by an 18-year empirical study, we show that clans are unlikely products of stochastic processes (genetic or cultural drift) but likely originate from cultural transmission via biased social learning of codas. Distinct clusters of individuals with similar acoustic repertoires, mirroring the empirical clans, emerge when whales learn preferentially the most common codas (conformism) from behaviourally similar individuals (homophily). Cultural transmission seems key in the partitioning of sperm whales into sympatric clans. These findings suggest that processes similar to those that generate complex human cultures could not only be at play in non-human societies but also create multilevel social structures in the wild.},
author = {Cantor, Maur{\'{i}}cio and Shoemaker, Lauren G. and Cabral, Reniel B. and Flores, C{\'{e}}sar O. and Varga, Melinda and Whitehead, Hal},
doi = {10.1038/ncomms9091},
isbn = {2041-1723},
issn = {2041-1723},
journal = {Nature Communications},
month = {sep},
pages = {8091},
title = {{Multilevel animal societies can emerge from cultural transmission}},
url = {http://www.nature.com/doifinder/10.1038/ncomms9091{\%}5Cnpapers3://publication/doi/10.1038/ncomms9091 http://www.nature.com/doifinder/10.1038/ncomms9091},
volume = {6},
year = {2015}
}
@article{Zhang2017,
abstract = {Representations of probability measures in reproducing kernel Hilbert spaces provide a flexible framework for fully nonparametric hypothesis tests of independence, which can capture any type of departure from independence, including nonlinear associations and multivariate interactions. However, these approaches come with an at least quadratic computational cost in the number of observations, which can be prohibitive in many applications. Arguably, it is exactly in such large-scale datasets that capturing any type of dependence is of interest, so striking a favourable tradeoff between computational efficiency and test performance for kernel independence tests would have a direct impact on their applicability in practice. In this contribution, we provide an extensive study of the use of large-scale kernel approximations in the context of independence testing, contrasting block-based, Nystrom and random Fourier feature approaches. Through a variety of synthetic data experiments, it is demonstrated that our novel large scale methods give comparable performance with existing methods whilst using significantly less computation time and memory.},
archivePrefix = {arXiv},
arxivId = {1606.07892},
author = {Zhang, Qinyi and Filippi, Sarah and Gretton, Arthur and Sejdinovic, Dino},
doi = {10.1007/s11222-016-9721-7},
eprint = {1606.07892},
file = {:home/kaslu/Documents/Mendeley/2017 - Zhang et al. - Large-scale kernel methods for independence testing.pdf:pdf},
issn = {15731375},
journal = {Statistics and Computing},
keywords = {Hilbert???Schmidt independence criteria,Independence testing,Large-scale kernel method,Nystr??m method,Random Fourier features},
number = {1},
pages = {1--18},
publisher = {Springer US},
title = {{Large-scale kernel methods for independence testing}},
volume = {28},
year = {2017}
}
@article{Newman2015,
abstract = {A substantial volume of research has been devoted to studies of community structure in networks, but communities are not the only possible form of large-scale network structure. Here we describe a broad extension of community structure that encompasses traditional communities but includes a wide range of generalized structural patterns as well. We describe a principled method for detecting this generalized structure in empirical network data and demonstrate with real-world examples how it can be used to learn new things about the shape and meaning of networks.},
archivePrefix = {arXiv},
arxivId = {1505.07478},
author = {Newman, M. E. J. and Peixoto, Tiago P.},
doi = {10.1103/PhysRevLett.115.088701},
eprint = {1505.07478},
file = {:home/kaslu/Documents/Mendeley/2015 - Newman, Peixoto - Generalized communities in networks.pdf:pdf},
issn = {10797114},
journal = {Physical Review Letters},
month = {may},
number = {8},
pages = {088701},
pmid = {26340218},
title = {{Generalized communities in networks}},
url = {http://arxiv.org/abs/1505.07478 http://dx.doi.org/10.1103/PhysRevLett.115.088701 http://link.aps.org/doi/10.1103/PhysRevLett.115.088701},
volume = {115},
year = {2015}
}
@article{Mann2017,
abstract = {Collective intelligence is the ability of a group to perform more effectively than any individual alone. Diversity among group members is a key condition for the emergence of collective intel-ligence, but maintaining diversity is challenging in the face of social pressure to imitate one's peers. Through an evolutionary game-theoretic model of collective prediction, we investigate the role that incentives may play in maintaining useful diversity. We show that market-based incentive systems produce herding effects, reduce information available to the group, and restrain collective intelligence. Therefore, we propose an incentive scheme that rewards accurate minority predictions and show that this produces optimal diversity and collective predictive accuracy. We conclude that real world systems should reward those who have shown accuracy when the majority opinion has been in error.},
author = {Mann, Richard P and Helbing, Dirk},
doi = {10.1073/pnas.1618722114},
file = {:home/kaslu/Documents/Mendeley/2017 - Mann, Helbing - Optimal incentives for collective intelligence.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {may},
number = {20},
pages = {5077--5082},
title = {{Optimal incentives for collective intelligence}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1618722114},
volume = {114},
year = {2017}
}
@article{Perunov2014,
abstract = {All living things exhibit adaptations that enable them to survive and reproduce in the natural environment that they inhabit. From a biological standpoint, it has long been understood that adaptation comes from natural selection, whereby maladapted individuals do not pass their traits effectively to future generations. However, we may also consider the phenomenon of adaptation from the standpoint of physics, and ask whether it is possible to delineate what the difference is in terms of physical properties between something that is well-adapted to its surrounding environment, and something that is not. In this work, we undertake to address this question from a theoretical standpoint. Building on past fundamental results in far-from-equilibrium statistical mechanics, we demonstrate a generalization of the Helmholtz free energy for the finite-time stochastic evolution of driven Newtonian matter. By analyzing this expression term by term, we are able to argue for a general tendency in driven many-particle systems towards self-organization into states formed through exceptionally reliable absorption and dissipation of work energy from the surrounding environment. Subsequently, we illustrate the mechanism of this general tendency towards physical adaptation by analyzing the process of random hopping in driven energy landscapes.},
archivePrefix = {arXiv},
arxivId = {1412.1875},
author = {Perunov, Nikolai and Marsland, Robert and England, Jeremy},
eprint = {1412.1875},
file = {:home/kaslu/Documents/Mendeley/2014 - Perunov, Marsland, England - Statistical Physics of Adaptation.pdf:pdf},
month = {dec},
title = {{Statistical Physics of Adaptation}},
url = {http://arxiv.org/abs/1412.1875},
year = {2014}
}
@article{Leong2017,
abstract = {Little is known about the relationship between attention and learning during decision making. Using eye tracking and multivariate pattern analysis of??fMRI data, we measured participants??? dimensional attention as they performed a trial-and-error learning task in which only one of three stimulus dimensions was relevant for reward at any given time. Analysis of participants??? choices revealed that attention biased both value computation during choice and value update during learning. Value signals in the ventromedial prefrontal cortex and prediction errors in the striatum were similarly biased by attention. In turn, participants??? focus of attention was dynamically modulated by ongoing learning. Attentional switches across dimensions correlated with activity in a frontoparietal attention network, which showed enhanced connectivity with the ventromedial prefrontal cortex between switches. Our results suggest a bidirectional interaction between attention and learning: attention constrains learning to relevant dimensions of the environment, while we learn what to attend to via trial and error.},
author = {Leong, Yuan Chang and Radulescu, Angela and Daniel, Reka and DeWoskin, Vivian and Niv, Yael},
doi = {10.1016/j.neuron.2016.12.040},
file = {:home/kaslu/Documents/Mendeley/2017 - Leong et al. - Dynamic Interaction between Reinforcement Learning and Attention in Multidimensional Environments.pdf:pdf},
issn = {10974199},
journal = {Neuron},
keywords = {MVPA,attention,computational modeling,decision making,fMRI,prediction error,reinforcement learning,striatum,value,vmPFC},
number = {2},
pages = {451--463},
pmid = {28103483},
publisher = {Elsevier Inc.},
title = {{Dynamic Interaction between Reinforcement Learning and Attention in Multidimensional Environments}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.040},
volume = {93},
year = {2017}
}
@article{Rigato2014,
abstract = {Spontaneous actions are preceded by brain signals that may sometimes be detected hundreds of milliseconds in advance of a subject's conscious intention to act. These signals have been claimed to reflect prior unconscious decisions, raising doubts about the causal role of conscious will. Murakami et al. (2014. Nat Neurosci 17: 1574–1582) have recently argued for a different interpretation. During a task in which rats spontaneously decided when to abortwaiting, the authors recorded neurons in the secondary motor cortex. The neural activity and relationship to action timing was parsimoniously explained using an integration-to-bound model, similar to those widely used to account for evidence-based decisions. In this model, the brain accumulates spontaneously occurring inputs voting for or against an action, but only commits to act once a certain threshold is crossed. The model explains howspontaneous decisions can be forecast (partially predicted) by neurons that reflect either the input or output of the integrator. It therefore presents an explicit hypothesis capable of rejecting the claim that such predictive signals imply unconscious decisions. We suggest that these results can inform the current debate on free will but must be considered with caution.},
author = {Rigato, Joana and Murakami, Masayoshi and Mainen, Zachary},
doi = {10.1101/sqb.2014.79.024810},
file = {:home/kaslu/Documents/Mendeley/2014 - Rigato, Murakami, Mainen - Spontaneous Decisions and Free Will Empirical Results and Philosophical Considerations.pdf:pdf},
issn = {0091-7451},
journal = {Cold Spring Harbor Symposia on Quantitative Biology},
pages = {177--184},
pmid = {25746063},
title = {{Spontaneous Decisions and Free Will: Empirical Results and Philosophical Considerations}},
url = {http://symposium.cshlp.org/lookup/doi/10.1101/sqb.2014.79.024810},
volume = {79},
year = {2014}
}
@article{Bowles2009,
abstract = {Since Darwin, intergroup hostilities have figured prominently in explanations of the evolution of human social behavior. Yet whether ancestral humans were largely "peaceful" or "warlike" remains controversial. I ask a more precise question: If more cooperative groups were more likely to prevail in conflicts with other groups, was the level of intergroup violence sufficient to influence the evolution of human social behavior? Using a model of the evolutionary impact of between-group competition and a new data set that combines archaeological evidence on causes of death during the Late Pleistocene and early Holocene with ethnographic and historical reports on hunter-gatherer populations, I find that the estimated level of mortality in intergroup conflicts would have had substantial effects, allowing the proliferation of group-beneficial behaviors that were quite costly to the individual altruist.},
author = {Bowles, Samuel},
doi = {10.1126/science.1168112},
issn = {0036-8075},
journal = {Science},
month = {jun},
number = {5932},
pages = {1293--1298},
pmid = {19498163},
title = {{Did Warfare Among Ancestral Hunter-Gatherers Affect the Evolution of Human Social Behaviors?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19498163 http://www.sciencemag.org/cgi/doi/10.1126/science.1168112},
volume = {324},
year = {2009}
}
@article{Ay2015,
abstract = {Interdependencies of stochastically interacting units are usually quantified by the Kullback-Leibler divergence of a stationary joint probability distribution on the set of all configurations from the corresponding factorized distribution. This is a spatial approach which does not describe the intrinsically temporal aspects of interaction. In the present paper, the setting is extended to a dynamical version where temporal interdependencies are also captured by using information geometry of Markov chain manifolds.},
author = {Ay, Nihat},
doi = {10.3390/e17042432},
issn = {10994300},
journal = {Entropy},
keywords = {Complexity,Information geometry,Kullback-leibler divergence,Markov chains,Random fields,Separability,Stochastic interaction},
month = {apr},
number = {4},
pages = {2432--2458},
title = {{Information geometry on complexity and stochastic interaction}},
url = {http://www.mdpi.com/1099-4300/17/4/2432/},
volume = {17},
year = {2015}
}
@article{Hanks2015,
author = {Hanks, Timothy D. and Kopec, Charles D. and Brunton, Bingni W. and Duan, Chunyu A. and Erlich, Jeffrey C. and Brody, Carlos D.},
doi = {10.1038/nature14066},
file = {:home/kaslu/Documents/Mendeley/2015 - Hanks et al. - Distinct relationships of parietal and prefrontal cortices to evidence accumulation(2).pdf:pdf},
isbn = {9780123860439},
issn = {0028-0836},
journal = {Nature},
keywords = {cadherins,cell adhesion,cell migration and actin,force generation,integrins,vinculin},
month = {jan},
number = {7546},
pages = {220--223},
title = {{Distinct relationships of parietal and prefrontal cortices to evidence accumulation}},
url = {http://www.nature.com/doifinder/10.1038/nature14066},
volume = {520},
year = {2015}
}
@article{Evans2002,
abstract = {The question of how reversible microscopic equations of motion can lead to irreversible macroscopic behaviour has been one of the central issues in statistical mechanics for more than a century. The basic issues were known to Gibbs. Boltzmann conducted a very public debate with Loschmidt and others without a satisfactory resolution. In recent decades there has been no real change in the situation. In 1993 we discovered a relation, subsequently known as the Fluctuation Theorem (FT), which gives an analytical expression for the probability of observing Second Law violating dynamical ¯uctuations in thermostatted dissipa- tive non-equilibriumsystems. The relation was derived heuristically and applied to the special case of dissipative non-equilibrium systems subject to constant energy `thermostatting'. These restrictionsmeant that the full importance of the Theorem was not immediately apparent. Within a few years, derivations of the Theorem were improved but it has only been in the last few of years that the generality of the Theorem has been appreciated. We now know that the Second Law of Thermo- dynamics can be derived assuming ergodicity at equilibrium, and causality. We take the assumption of causality to be axiomatic. It is causality which ultimately is responsible for breaking time reversal symmetry and which leads to the possibility of irreversible macroscopic behaviour. The Fluctuation Theorem does much more than merely prove that in large systems observed for long periods of time, the Second Law is overwhelmingly likely to be valid. The Fluctuation Theorem quanti{\textregistered}es the probability of observing Second Law violations in small systems observed for a short time. Unlike the Boltzmann equation, the FT is completely consistent with Loschmidt's observa- tion that for time reversible dynamics, every dynamical phase space trajectory and its conjugate time reversed `anti-trajectory', are both solutions of the underlying equations of motion. Indeed the standard proofs of the FT explicitly consider conjugate pairs of phase space trajectories. Quantitative predictions made by the Fluctuation Theorem regarding the probability of Second Law violations have been con{\textregistered}rmed experimentally, both using molecular dynamics computer simula- tion and very recently in laboratory experiments.},
author = {Evans, Denis J and Searles, Debra J},
doi = {10.1080/00018730210155133},
file = {:home/kaslu/Documents/Mendeley/2002 - Evans, Searles - The Fluctuation Theorem.pdf:pdf},
isbn = {0001-8732},
issn = {0001-8732},
journal = {Advances in Physics},
month = {nov},
number = {7},
pages = {1529--1585},
pmid = {18190201},
title = {{The Fluctuation Theorem}},
url = {http://dx.doi.org/10.1080/00018730210155133 http://www.tandfonline.com/doi/abs/10.1080/00018730210155133},
volume = {51},
year = {2002}
}
@article{Vinkers2015,
abstract = {Objective To investigate whether language used in science abstracts can skew towards the use of strikingly positive and negative words over time. Design Retrospective analysis of all scientific abstracts in PubMed between 1974 and 2014. Methods The yearly frequencies of positive, negative, and neutral words (25 preselected words in each category), plus 100 randomly selected words were normalised for the total number of abstracts. Subanalyses included pattern quantification of individual words, specificity for selected high impact journals, and comparison between author affiliations within or outside countries with English as the official majority language. Frequency patterns were compared with 4{\%} of all books ever printed and digitised by use of Google Books Ngram Viewer. Main outcome measures Frequencies of positive and negative words in abstracts compared with frequencies of words with a neutral and random connotation, expressed as relative change since 1980. Results The absolute frequency of positive words increased from 2.0{\%} (1974-80) to 17.5{\%} (2014), a relative increase of 880{\%} over four decades. All 25 individual positive words contributed to the increase, particularly the words "robust," "novel," "innovative," and "unprecedented," which increased in relative frequency up to 15 000{\%}. Comparable but less pronounced results were obtained when restricting the analysis to selected journals with high impact factors. Authors affiliated to an institute in a non-English speaking country used significantly more positive words. Negative word frequencies increased from 1.3{\%} (1974-80) to 3.2{\%} (2014), a relative increase of 257{\%}. Over the same time period, no apparent increase was found in neutral or random word use, or in the frequency of positive word use in published books. Conclusions Our lexicographic analysis indicates that scientific abstracts are currently written with more positive and negative words, and provides an insight into the evolution of scientific writing. Apparently scientists look on the bright side of research results. But whether this perception fits reality should be questioned.},
author = {Vinkers, Christiaan H and Tijdink, Joeri K and Otte, Willem M},
doi = {10.1136/bmj.h6467},
issn = {1756-1833},
journal = {Bmj},
number = {dec14{\_}13},
pages = {h6467},
pmid = {26668206},
title = {{Use of positive and negative words in scientific PubMed abstracts between 1974 and 2014: retrospective analysis}},
url = {http://www.bmj.com/content/351/bmj.h6467},
volume = {351},
year = {2015}
}
@article{Eisenberger2003,
author = {Eisenberger, Naomi and Lieberman, Matthew and Williams, Kipling},
doi = {10.1126/science.1089134},
file = {:home/kaslu/Documents/Mendeley/2003 - Eisenberger, Lieberman, Williams - Does Rejection Hurt An fMRI Study of Social Exclusion.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {oct},
number = {5643},
pages = {290--292},
title = {{Does Rejection Hurt? An fMRI Study of Social Exclusion}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1089134},
volume = {302},
year = {2003}
}
@article{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard to compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories form taking much computation time.},
archivePrefix = {arXiv},
arxivId = {1206.1901},
author = {Neal, Radford M.},
doi = {doi:10.1201/b10905-6},
eprint = {1206.1901},
file = {:home/kaslu/Documents/Mendeley/2011 - Neal - MCMC using Hamiltonian dynamics.pdf:pdf},
isbn = {9781420079418},
issn = {{\textless}null{\textgreater}},
journal = {Handbook of Markov Chain Monte Carlo},
keywords = {hamiltonian dynamics,mcmc},
pages = {113--162},
pmid = {25246403},
title = {{MCMC using Hamiltonian dynamics}},
year = {2011}
}
@article{Kelly2005,
abstract = {Recent findings and analyses in evolutionary biology, archaeology, and ethnology provide a favorable conjuncture for examining the evolution of lethal intergroup violence among hominids during the 2.9-million-year Paleolithic time span. Here, I seek to identify and investigate the main turning points in this evolutionary trajectory and to delineate the periodization that follows from this inquiry.},
author = {Kelly, Raymond C},
doi = {10.1073/pnas.0505955102},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {43},
pages = {15294--15298},
pmid = {16129826},
title = {{The evolution of lethal intergroup violence}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16129826 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1266108 http://www.pnas.org/cgi/doi/10.1073/pnas.0505955102},
volume = {102},
year = {2005}
}
@article{Guimera2011,
abstract = {Next-generation sequencing (NGS) technologies provide a revolutionary tool with numerous applications in transcriptome studies. The power of NGS technologies to address diverse biological questions has already been proved in many studies. One of the most important applications of NGS is the sequencing and characterization of transcriptome of a non-model species using RNA-seq. This application of NGS technologies can be used to dissect the complete expressed gene content of an organism. In this article, I illustrate the use of NGS technologies in transcriptome characterization of a non-model species taking example of chickpea from our recent studies.},
author = {Guimer{\`{a}}, Roger and Sales-Pardo, Marta},
doi = {10.1371/journal.pone.0027188},
editor = {Moreno, Yamir},
file = {:home/kaslu/Documents/Mendeley/2011 - Guimer{\`{a}}, Sales-Pardo - Justice Blocks and Predictability of U.S. Supreme Court Votes.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
keywords = {Expressed sequence tags,Next-generation sequencing technologies,Non-model species,Transcriptome},
month = {nov},
number = {11},
pages = {e27188},
title = {{Justice Blocks and Predictability of U.S. Supreme Court Votes}},
url = {http://dx.plos.org/10.1371/journal.pone.0027188},
volume = {6},
year = {2011}
}
@inproceedings{Caticha2001,
abstract = {The method of maximum entropy (ME) is extended to address the following problem: Once one accepts that the ME distribution is to be preferred over all others, the question is to what extent are distributions with lower entropy supposed to be ruled out. Two applications are given. The first is to the theory of thermodynamic fluctuations. The formulation is exact, covariant under changes of coordinates, and allows fluctuations of both the extensive and the conjugate intensive variables. The second application is to the construction of an objective prior for Bayesian inference. The prior obtained by following the ME method to its inevitable conclusion turns out to be a special case of what are currently known under the name of entropic priors.},
archivePrefix = {arXiv},
arxivId = {math-ph/0008017},
author = {Caticha, Ariel},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.1381874},
eprint = {0008017},
file = {:home/kaslu/Documents/Mendeley/2001 - Caticha - Maximum entropy, fluctuations and priors.pdf:pdf},
isbn = {0735400040},
issn = {0094243X},
pages = {94--105},
primaryClass = {math-ph},
publisher = {AIP},
title = {{Maximum entropy, fluctuations and priors}},
url = {http://aip.scitation.org/doi/abs/10.1063/1.1381874},
volume = {568},
year = {2001}
}
@article{Salimans2017,
abstract = {We explore the use of Evolution Strategies, a class of black box optimization algorithms, as an alternative to popular RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using hundreds to thousands of parallel workers, ES can solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training time. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.},
archivePrefix = {arXiv},
arxivId = {1703.03864},
author = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sutskever, Ilya},
eprint = {1703.03864},
file = {:home/kaslu/Documents/Mendeley/2017 - Salimans et al. - Evolution Strategies as a Scalable Alternative to Reinforcement Learning.pdf:pdf},
month = {mar},
title = {{Evolution Strategies as a Scalable Alternative to Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.03864},
year = {2017}
}
@article{Deutsch1955,
abstract = {Several modifications of the Asch experiment in which the S judges the length of lines in the company of a group of "stooges" who carry out the experimenter's instructions are described. These include a face-to-face situation, an anonymous situation, and a group situation, with self-commitment, public commitment and Magic Pad commitment variations. The results indicate that, even when normative social influence in the direction of an incorrect judgment is largely removed (as in the anonymous situation), more errors are made by Ss in experimental groups than by Ss making their judgments when alone. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Deutsch, Morton and Gerard, Harold B.},
doi = {10.1037/h0046408},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/1955 - Deutsch, Gerard - A study of normative and informational social influences upon individual judgment.pdf:pdf},
isbn = {0096-851X(Print)},
issn = {0096-851X},
journal = {The Journal of Abnormal and Social Psychology},
number = {3},
pages = {629--636},
pmid = {13286010},
title = {{A study of normative and informational social influences upon individual judgment.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0046408},
volume = {51},
year = {1955}
}
@article{Jordan2013,
abstract = {Systematic studies of phenotypic diversity--required for understanding evolution--lag behind investigations of genetic diversity. Here we develop a quantitative approach to studying behavioral diversity, which we apply to swimming of the ciliate Tetrahymena. We measure the full-lifetime behavior of hundreds of individual organisms at high temporal resolution, over several generations and in diverse nutrient conditions. To characterize population diversity and temporal variability we introduce a unique statistical framework grounded in the notion of a phenotypic space of behaviors. We show that this space is effectively low dimensional with dimensions that correlate with a two-state "roaming and dwelling" model of swimming behavior. Temporal variability over the lifetime of an individual is correlated with the fraction of time spent roaming whereas diversity between individuals is correlated with the speed of roaming. Quantifying the dynamics of behavioral variation shows that behavior over the lifetime of an individual is strongly nonstationary. Analysis of behavioral dynamics between generations reveals complex patterns of behavioral heritability that point to the importance of considering correlations beyond mothers and daughters. Our description of a low-dimensional behavioral space should enable the systematic study of the evolutionary and ecological bases of phenotypic constraints. Future experimental and theoretical studies of behavioral diversity will have to account for the possibility of nonstationary and environmentally dependent behavioral dynamics that we observe.},
author = {Jordan, David and Kuehn, Seppe and Katifori, Eleni and Leibler, Stanislas},
doi = {10.1073/pnas.1308282110},
file = {:home/kaslu/Documents/Mendeley/2013 - Jordan et al. - Behavioral diversity in microbes and low-dimensional phenotypic spaces.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Biological Evolution,Inheritance Patterns,Inheritance Patterns: genetics,Models, Biological,Models, Statistical,Movement,Movement: physiology,Phenotype,Systems Biology,Systems Biology: methods,Tetrahymena,Tetrahymena: genetics,Tetrahymena: physiology},
month = {aug},
number = {34},
pages = {14018--23},
pmid = {23898201},
title = {{Behavioral diversity in microbes and low-dimensional phenotypic spaces.}},
url = {http://www.pnas.org/cgi/content/long/110/34/14018},
volume = {110},
year = {2013}
}
@article{Kaufman2014,
abstract = {Neural circuits must perform computations and then selectively output the results to other circuits. Yet synapses do not change radically at millisecond timescales. A key question then is: how is communication between neural circuits controlled? In motor control, brain areas directly involved in driving movement are active well before movement begins. Muscle activity is some readout of neural activity, yet it remains largely unchanged during preparation. Here we find that during preparation, while the monkey holds still, changes in motor cortical activity cancel out at the level of these population readouts. Motor cortex can thereby prepare the movement without prematurely causing it. Further, we found evidence that this mechanism also operates in dorsal premotor cortex, largely accounting for how preparatory activity is attenuated in primary motor cortex. Selective use of 'output-null' vs. 'output-potent' patterns of activity may thus help control communication to the muscles and between these brain areas.},
author = {Kaufman, Matthew T. and Churchland, Mark M. and Ryu, Stephen I. and Shenoy, Krishna V.},
doi = {10.1038/nn.3643},
file = {:home/kaslu/Documents/Mendeley/2014 - Kaufman et al. - Cortical activity in the null space permitting preparation without movement.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {440--448},
pmid = {24487233},
title = {{Cortical activity in the null space: permitting preparation without movement}},
url = {http://www.nature.com/doifinder/10.1038/nn.3643},
volume = {17},
year = {2014}
}
@article{Mazzucato2016,
abstract = {The activity of ensembles of simultaneously recorded neurons can be represented as a set of points in the space of firing rates. Even though the dimension of this space is equal to the ensemble size, neural activity can be effectively localized on smaller subspaces. The dimensionality of the neural space is an important determinant of the computational tasks supported by the neural activity. Here, we investigate the dimensionality of neural ensembles from the sensory cortex of alert rats during periods of ongoing (inter-trial) and stimulus-evoked activity. We find that dimensionality grows linearly with ensemble size, and grows significantly faster during ongoing activity compared to evoked activity. We explain these results using a spiking network model based on a clustered architecture. The model captures the difference in growth rate between ongoing and evoked activity and predicts a characteristic scaling with ensemble size that could be tested in high-density multi-electrode recordings. Moreover, we present a simple theory that predicts the existence of an upper bound on dimensionality. This upper bound is inversely proportional to the amount of pair-wise correlations and, compared to a homogeneous network without clusters, it is larger by a factor equal to the number of clusters. The empirical estimation of such bounds depends on the number and duration of trials and is well predicted by the theory. Together, these results provide a framework to analyze neural dimensionality in alert animals, its behavior under stimulus presentation, and its theoretical dependence on ensemble size, number of clusters, and correlations in spiking network models.},
archivePrefix = {arXiv},
arxivId = {1509.03621},
author = {Mazzucato, Luca and Fontanini, Alfredo and {La Camera}, Giancarlo},
doi = {10.3389/fnsys.2016.00011},
eprint = {1509.03621},
file = {:home/kaslu/Documents/Mendeley/2016 - Mazzucato, Fontanini, La Camera - Stimuli reduce the dimensionality of cortical activity.pdf:pdf},
isbn = {doi:10.3389/fnsys.2016.00011},
issn = {1662-5137},
journal = {Front Syst Neurosci},
keywords = {dimensionality,gustatory cortex,gustatory cortex, dimensionality, hidden markov mo,hidden markov models,mean field theory,metastable dynamics,network model,ongoing activity,spiking},
number = {February},
pages = {11},
pmid = {26924968},
title = {{Stimuli reduce the dimensionality of cortical activity}},
url = {http://arxiv.org/abs/1509.03621},
volume = {10},
year = {2016}
}
@article{Spekkens2007a,
abstract = {We present a toy theory that is based on a simple principle: the number of questions about the physical state of a system that are answered must always be equal to the number that are unanswered in a state of maximal knowledge. A wide variety of quantum phenomena are found to have analogues within this toy theory. Such phenomena include: the noncommutativity of measurements, interference, the multiplicity of convex decompositions of a mixed state, the impossibility of discriminating nonorthogonal states, the impossibility of a universal state inverter, the distinction between bi-partite and tri-partite entanglement, the monogamy of pure entanglement, no cloning, no broadcasting, remote steering, teleportation, dense coding, mutually unbiased bases, and many others. The diversity and quality of these analogies is taken as evidence for the view that quantum states are states of incomplete knowledge rather than states of reality. A consideration of the phenomena that the toy theory fails to reproduce, notably, violations of Bell inequalities and the existence of a Kochen-Specker theorem, provides clues for how to proceed with this research program.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0401052},
author = {Spekkens, Robert W.},
doi = {10.1103/PhysRevA.75.032110},
eprint = {0401052},
file = {:home/kaslu/Documents/Mendeley/2007 - Spekkens - Evidence for the epistemic view of quantum states A toy theory.pdf:pdf},
issn = {1050-2947},
journal = {Physical Review A},
month = {mar},
number = {3},
pages = {032110},
primaryClass = {quant-ph},
title = {{Evidence for the epistemic view of quantum states: A toy theory}},
url = {http://arxiv.org/abs/quant-ph/0401052},
volume = {75},
year = {2007}
}
@article{Graham2009,
abstract = {How and why do moral judgments vary across the political spectrum? To test moral foundations theory (J. Haidt {\&} J. Graham, 2007; J. Haidt {\&} C. Joseph, 2004), the authors developed several ways to measure people's use of 5 sets of moral intuitions: Harm/care, Fairness/reciprocity, Ingroup/loyalty, Authority/respect, and Purity/sanctity. Across 4 studies using multiple methods, liberals consistently showed greater endorsement and use of the Harm/care and Fairness/reciprocity foundations compared to the other 3 foundations, whereas conservatives endorsed and used the 5 foundations more equally. This difference was observed in abstract assessments of the moral relevance of foundation-related concerns such as violence or loyalty (Study 1), moral judgments of statements and scenarios (Study 2), "sacredness" reactions to taboo trade-offs (Study 3), and use of foundation-related words in the moral texts of religious sermons (Study 4). These findings help to illuminate the nature and intractability of moral disagreements in the American "culture war."},
author = {Graham, Jesse and Haidt, Jonathan and Nosek, Brian A.},
doi = {10.1037/a0015141},
file = {:home/kaslu/Documents/Mendeley/2009 - Graham, Haidt, Nosek - Liberals and conservatives rely on different sets of moral foundations.pdf:pdf},
isbn = {0022-3514$\backslash$r1939-1315},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
keywords = {conservative,ideology,liberal,morality},
number = {5},
pages = {1029--1046},
pmid = {19379034},
title = {{Liberals and conservatives rely on different sets of moral foundations}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19379034},
volume = {96},
year = {2009}
}
@article{Mrazek2013,
abstract = {This research provides novel insights into the evolutionary basis of cultural norm development and maintenance. We yield evidence for a unique culture-gene coevolutionary model between ecological threat, allelic frequency of the serotonin transporter polymorphism (5-HTTLPR), cultural tightness-looseness-the strength of norms and tolerance for deviance from norms-and moral justifiability. As hypothesized, the results across 21 nations show that: (a) propensity for ecological threat correlates with short (S) allele frequency in the 5-HTTLPR, (b) allelic frequency in the 5-HTTLPR and vulnerability to ecological threat both correlate with cultural tightness-looseness, (c) susceptibility to ecological threat predicts tightness-looseness via the mediation of S allele carriers, and (d) frequency of S allele carriers predicts justifiability of morally relevant behavior via tightness-looseness. This research highlights the importance of studying the interplay between environmental, genetic, and cultural factors underlying contemporary differences in social behavior and presents an empirical framework for future research.},
author = {Mrazek, Alissa J. and Chiao, Joan Y. and Blizinsky, Katherine D. and Lun, Janetta and Gelfand, Michele J.},
doi = {10.1007/s40167-013-0009-x},
isbn = {2193-8652 (Print)$\backslash$r2193-8652 (Linking)},
issn = {2193-8652},
journal = {Culture and Brain},
keywords = {5-httlpr moral justifiability,culture,gene coevolution tightness,looseness serotonin transporter gene},
month = {nov},
number = {2-4},
pages = {100--117},
pmid = {24404439},
title = {{The role of culture–gene coevolution in morality judgment: examining the interplay between tightness–looseness and allelic variation of the serotonin transporter gene}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3880222{\&}tool=pmcentrez{\&}rendertype=abstract http://link.springer.com/10.1007/s40167-013-0009-x},
volume = {1},
year = {2013}
}
@article{Freedman2016,
abstract = {Categorization is our ability to flexibly assign sensory stimuli into discrete, behaviorally relevant groupings. Categorical decisions can be used to study decision making more generally by dissociating category identity of stimuli from the actions subjects use to signal their decisions. Here we discuss the evidence for such abstract categorical encoding in the primate brain and consider the relationship with other perceptual decision paradigms. Recent work on visual categorization has examined neuronal activity across a hierarchically organized network of cortical areas in monkeys trained to group visual stimuli into arbitrary categories. This has revealed a transformation of visual-feature encoding in early visual cortical areas into more flexible categorical representations in downstream parietal and prefrontal areas. These neuronal category representations are encoded as abstract internal cognitive states because they are not rigidly linked with either specific sensory stimuli or the actions that the monkeys use to signal their categorical choices.},
author = {Freedman, David J. and Assad, John A.},
doi = {10.1146/annurev-neuro-071714-033919},
file = {:home/kaslu/Documents/Mendeley/2016 - Freedman, Assad - Neuronal Mechanisms of Visual Categorization An Abstract View on Decision Making.pdf:pdf},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {categorization,decision making,learning and memory,parietal cortex,perception,prefrontal cortex,recognition,vision},
number = {1},
pages = {129--147},
pmid = {27070552},
title = {{Neuronal Mechanisms of Visual Categorization: An Abstract View on Decision Making}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-071714-033919},
volume = {39},
year = {2016}
}
@article{Chan2016,
abstract = {UNLABELLED The orbitofrontal cortex (OFC) has been implicated in both the representation of "state," in studies of reinforcement learning and decision making, and also in the representation of "schemas," in studies of episodic memory. Both of these cognitive constructs require a similar inference about the underlying situation or "latent cause" that generates our observations at any given time. The statistically optimal solution to this inference problem is to use Bayes' rule to compute a posterior probability distribution over latent causes. To test whether such a posterior probability distribution is represented in the OFC, we tasked human participants with inferring a probability distribution over four possible latent causes, based on their observations. Using fMRI pattern similarity analyses, we found that BOLD activity in the OFC is best explained as representing the (log-transformed) posterior distribution over latent causes. Furthermore, this pattern explained OFC activity better than other task-relevant alternatives, such as the most probable latent cause, the most recent observation, or the uncertainty over latent causes. SIGNIFICANCE STATEMENT Our world is governed by hidden (latent) causes that we cannot observe, but which generate the observations we see. A range of high-level cognitive processes require inference of a probability distribution (or "belief distribution") over the possible latent causes that might be generating our current observations. This is true for reinforcement learning and decision making (where the latent cause comprises the true "state" of the task), and for episodic memory (where memories are believed to be organized by the inferred situation or "schema"). Using fMRI, we show that this belief distribution over latent causes is encoded in patterns of brain activity in the orbitofrontal cortex, an area that has been separately implicated in the representations of both states and schemas.},
author = {Chan, Stephanie C. Y. and Niv, Yael and Norman, Kenneth A.},
doi = {10.1523/JNEUROSCI.0659-16.2016},
file = {:home/kaslu/Documents/Mendeley/2016 - Chan, Niv, Norman - A Probability Distribution over Latent Causes, in the Orbitofrontal Cortex.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {a range of,bayes,belief distribution,but which generate the,by hidden,causes that we cannot,context,distribution,high-level cognitive processes require,inference of a probability,latent,observations we see,observe,or,our world is governed,over the possible latent,posterior distribution,rule,schemas,significance statement,state representation,ventromedial prefrontal cortex},
number = {30},
pages = {7817--7828},
pmid = {27466328},
title = {{A Probability Distribution over Latent Causes, in the Orbitofrontal Cortex}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0659-16.2016},
volume = {36},
year = {2016}
}
@article{Lisman2015,
abstract = {Starting with the work of Cajal more than 100 years ago, neuroscience has sought to understand how the cells of the brain give rise to cognitive functions. How far has neuroscience progressed in this endeavor? This Perspective assesses progress in elucidating five basic brain processes: visual recognition, long-term memory, short-term memory, action selection, and motor control. Each of these processes entails several levels of analysis: the behavioral properties, the underlying computational algorithm, and the cellular/network mechanisms that implement that algorithm. At this juncture, while many questions remain unanswered, achievements in several areas of research have made it possible to relate specific properties of brain networks to cognitive functions. What has been learned reveals, at least in rough outline, how cognitive processes can be an emergent property of neurons and their connections.},
author = {Lisman, John},
doi = {10.1016/j.neuron.2015.03.032},
file = {:home/kaslu/Documents/Mendeley/2015 - Lisman - The Challenge of Understanding the Brain Where We Stand in 2015.pdf:pdf},
isbn = {doi:10.1016/j.neuron.2015.03.032},
issn = {10974199},
journal = {Neuron},
number = {4},
pages = {864--882},
pmid = {25996132},
publisher = {Elsevier Inc.},
title = {{The Challenge of Understanding the Brain: Where We Stand in 2015}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.03.032},
volume = {86},
year = {2015}
}
@article{Parrondo2015,
abstract = {By its very nature, the second law of thermodynamics is probabilistic, in that its formulation requires a probabilistic description of the state of a system. This raises questions about the objectivity of the second law: does it depend, for example, on what we know about the system? For over a century, much effort has been devoted to incorporating information into thermodynamics and assessing the entropic and energetic costs of manipulating information. More recently, this historically theoretical pursuit has become relevant in practical situations where information is manipulated at small scales, such as in molecular and cell biology, artificial nano-devices or quantum computation. Here we give an introduction to a novel theoretical framework for the thermodynamics of information based on stochastic thermodynamics and fluctuation theorems, review some recent experimental results, and present an overview of the state of the art in the field.},
author = {Parrondo, Juan M. R. and Horowitz, Jordan M. and Sagawa, Takahiro},
doi = {10.1038/nphys3230},
file = {:home/kaslu/Documents/Mendeley/2015 - Parrondo, Horowitz, Sagawa - Thermodynamics of information.pdf:pdf},
isbn = {1745-2473},
issn = {1745-2473},
journal = {Nature Physics},
keywords = {Statistical physics,thermodynamics and nonlinear dynamics},
month = {mar},
number = {2},
pages = {131--139},
title = {{Thermodynamics of information}},
url = {http://www.nature.com/doifinder/10.1038/nphys3230},
volume = {11},
year = {2015}
}
@inproceedings{Alves2016,
author = {Alves, Felippe and Caticha, Nestor},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.4959064},
file = {:home/kaslu/Documents/Mendeley/2016 - Alves, Caticha - Sympatric multiculturalism in opinion models.pdf:pdf},
isbn = {9780735414150},
pages = {060005},
title = {{Sympatric multiculturalism in opinion models}},
url = {http://aip.scitation.org/doi/abs/10.1063/1.4959064},
volume = {1757},
year = {2016}
}
@article{Williams-Garcia2016,
abstract = {We introduce a novel tool for analyzing complex network dynamics, allowing for cascades of causally-related events, which we call causal webs (c-webs), to be separated from other non-causally-related events. This tool shows that traditionally-conceived avalanches may contain mixtures of spatially-distinct but temporally-overlapping cascades of events, and dynamical disorder or noise. In contrast, c-webs separate these components, unveiling previously hidden features of the network and dynamics. We apply our method to mouse cortical data with resulting statistics which demonstrate for the first time that neuronal avalanches are not merely composed of causally-related events.},
archivePrefix = {arXiv},
arxivId = {1603.05659},
author = {Williams-Garcia, Rashid V. and Beggs, John M. and Ortiz, Gerardo},
eprint = {1603.05659},
file = {:home/kaslu/Documents/Mendeley/2016 - Williams-Garcia, Beggs, Ortiz - Unveiling causal activity of complex networks.pdf:pdf},
pages = {1--7},
title = {{Unveiling causal activity of complex networks}},
url = {http://arxiv.org/abs/1603.05659},
year = {2016}
}
@article{Whalley2017,
abstract = {ORIGINAL ARTICLE Thura, D. {\&} Cisek, P. The basal ganglia do not select reach targets but control the urgency of commitment. Neuron 30, 1160–1170 (2017)},
author = {Whalley, Katherine},
doi = {10.1038/nrn.2017.116},
file = {:home/kaslu/Documents/Mendeley/2017 - Whalley - Decision making Making hasty decisions.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {10},
pages = {569--569},
publisher = {Nature Publishing Group},
title = {{Decision making: Making hasty decisions}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2017.116},
volume = {18},
year = {2017}
}
@article{Deneve2008a,
abstract = {We show that the dynamics of spiking neurons can be interpreted as a form of Bayesian inference in time. Neurons that optimally integrate evidence about events in the external world exhibit properties similar to leaky integrate-and-fire neurons with spike-dependent adaptation and maximally respond to fluctuations of their input. Spikes signal the occurrence of new information-what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic representation of probabilities.},
author = {Den{\`{e}}ve, Sophie},
doi = {10.1162/neco.2008.20.1.91},
file = {:home/kaslu/Documents/Mendeley/2008 - Den{\`{e}}ve - Bayesian spiking neurons I inference.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Algorithms,Animals,Bayes Theorem,Central Nervous System,Central Nervous System: physiology,Computer Simulation,Humans,Markov Chains,Models,Movement,Movement: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Perception,Perception: physiology,Physiological,Physiological: physiology,Statistical,Synaptic Transmission,Synaptic Transmission: physiology},
number = {1},
pages = {91--117},
pmid = {18045002},
title = {{Bayesian spiking neurons I: inference.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18045002},
volume = {20},
year = {2008}
}
@article{Whitesides2004,
abstract = {Insights into conducting research and the writing of scientific papers are given by Prof. Whitesides in this short essay. The manuscript and its guidelines has been circulated within the Whitesides' research group since 1989.},
archivePrefix = {arXiv},
arxivId = {1003.3921v1},
author = {Whitesides, G. M.},
doi = {10.1002/adma.200400767},
eprint = {1003.3921v1},
file = {:home/kaslu/Documents/Mendeley/2004 - Whitesides - Whitesides' Group Writing a Paper.pdf:pdf},
isbn = {3825208028},
issn = {0935-9648},
journal = {Advanced Materials},
month = {aug},
number = {15},
pages = {1375--1377},
pmid = {19782018},
title = {{Whitesides' Group: Writing a Paper}},
url = {http://doi.wiley.com/10.1002/adma.200400767},
volume = {16},
year = {2004}
}
@article{Gray2007,
abstract = {We examine the nature of the stationary character of the Hamilton action S for a space-time trajectory (worldline) x(t) of a single particle moving in one dimension with a general time-dependent potential energy function U(x,t). We show that the action is a local minimum for sufficiently short worldlines for all potentials and for worldlines of any length in some potentials. For long enough worldlines in most time-independent potentials U(x), the action is a saddle point, that is, a minimum with respect to some nearby alternative curves and a maximum with respect to others. The action is never a true maximum, that is, it is never greater along the actual worldline than along every nearby alternative curve. We illustrate these results for the harmonic oscillator, two different nonlinear oscillators, and a scattering system. We also briefly discuss two-dimensional examples, the Maupertuis action, and newer action principles.},
author = {Gray, C. G. and Taylor, Edwin F.},
doi = {10.1119/1.2710480},
issn = {00029505},
journal = {American Journal of Physics},
number = {5},
pages = {434},
title = {{When action is not least}},
volume = {75},
year = {2007}
}
@article{Ide2013,
author = {Ide, Jaime S. and Shenoy, Pradeep and Yu, Angela J. and Li, C.-s. R.},
doi = {10.1523/JNEUROSCI.2201-12.2013},
file = {:home/kaslu/Documents/Mendeley/2013 - Ide et al. - Bayesian Prediction and Evaluation in the Anterior Cingulate Cortex.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = {jan},
number = {5},
pages = {2039--2047},
pmid = {23365241},
title = {{Bayesian Prediction and Evaluation in the Anterior Cingulate Cortex}},
url = {http://www.jneurosci.org/content/33/5/2039.short http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2201-12.2013},
volume = {33},
year = {2013}
}
@article{Zhou2003,
abstract = {The Google search engine has enjoyed huge success with its web page ranking algorithm, which exploits global, rather than local, hyperlink structure of the web using random walks. Here we propose a simple universal ranking algorithm for data lying in the Euclidean space, such as text or image data. The core idea of our method is to rank the data with respect to the intrinsic manifold structure collectively revealed by a great amount of data. Encouraging experimental results from synthetic,...},
author = {Zhou, Dengyong and Weston, Jason and Gretton, Arthur and Bousquet, Olivier and Sch{\"{o}}lkopf, Bernhard},
file = {:home/kaslu/Documents/Mendeley/2003 - Zhou et al. - Ranking on Data Manifolds.pdf:pdf},
isbn = {0-262-20152-6},
issn = {1049-5258},
journal = {Advances in Neural Information Processing Systems},
number = {c},
pages = {177--186},
title = {{Ranking on Data Manifolds}},
url = {http://www.kyb.mpg.de/publications/pdfs/pdf2334.pdf},
volume = {16},
year = {2003}
}
@article{Charman2017,
abstract = {The Constitutionally mandated task of assigning Congressional seats to the various U.S. States proportional to their represented populations ("according to their numbers") has engendered much contention, but rather less consensus. Using the same principles of entropic inference that underlie the foundations of information theory and statistical thermodynamics, and also enjoy fruitful application in image processing, spectral analysis, machine learning, econometrics, bioinformatics, and a growing number of other fields, we motivate and explore a method for Congressional apportionment based on minimizing relative entropy (also known as Kullback-Leibler divergence), or, equivalently, maximizing Shannon entropy. In terms of communication theory, we might say that the entropic apportionment gives each constituent as equal a voice as possible. If we view representational weight as a finite resource to be distributed amongst the represented population, the entropic measure is identical with the Theil index long employed in economics to measure inequality in the distribution of wealth or income, or in ecology to measure the distribution of biomass or reproductive fitness. Besides Congressional apportionment, the method is also directly applicable to other multi-regional or multi-constituency legislatures, to party-list proportional voting systems used in various parliamentary elections, and similar settings, where the task is to allocate a discrete number of seats or other resources, and the primary goal is one of maximal proportionality or equity. In addition, the same entropic figure-of-merit can be used in parallel to compare different choices for the total number of representatives, and then subsequently to assess different Congressional district sizes, after seats are assigned and proposed district boundaries drawn.},
archivePrefix = {arXiv},
arxivId = {1712.09440},
author = {Charman, A. E.},
eprint = {1712.09440},
file = {:home/kaslu/Documents/Mendeley/2017 - Charman - The Census and the Second Law An Entropic Approach to Optimal Apportionment for the U.S. House of Representatives.pdf:pdf},
month = {dec},
title = {{The Census and the Second Law: An Entropic Approach to Optimal Apportionment for the U.S. House of Representatives}},
url = {https://arxiv.org/abs/1712.09440},
year = {2017}
}
@article{Brunton2013,
abstract = {The gradual and noisy accumulation of evidence is a fundamental component of decision-making, with noise playing a key role as the source of variability and errors. However, the origins of this noise have never been determined. We developed decision-making tasks in which sensory evidence is delivered in randomly timed pulses, and analyzed the resulting data with models that use the richly detailed information of each trial's pulse timing to distinguish between different decision-making mechanisms. This analysis allowed measurement of the magnitude of noise in the accumulator's memory, separately from noise associated with incoming sensory evidence. In our tasks, the accumulator's memory was noiseless, for both rats and humans. In contrast, the addition of new sensory evidence was the primary source of variability. We suggest our task and modeling approach as a powerful method for revealing internal properties of decision-making processes.},
author = {Brunton, Bingni W. and Botvinick, Matthew M. and Brody, Carlos D.},
doi = {10.1126/science.1233912},
file = {:home/kaslu/Documents/Mendeley/2013 - Brunton, Botvinick, Brody - Rats and Humans Can Optimally Accumulate Evidence for Decision-Making.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
keywords = {Animal,Animal: physiology,Animals,Behavior,Decision Making,Decision Making: physiology,Humans,Models,Noise,Photic Stimulation,Psychological,Rats,Rats: psychology,Task Performance and Analysis,Visual Perception},
month = {apr},
number = {6128},
pages = {95--98},
pmid = {23559254},
title = {{Rats and Humans Can Optimally Accumulate Evidence for Decision-Making}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1233912},
volume = {340},
year = {2013}
}
@article{Dixit2015,
abstract = {Maximum entropy (maxEnt) inference of state probabilities using state-dependent constraints is popular in the study of complex systems. In stochastic dynamical systems, the effect of state space topology and path-dependent constraints on the inferred state probabilities is unknown. To that end, we derive the transition probabilities and the stationary distribution of a maximum {\{}$\backslash$it path{\}} entropy Markov process subject to state- and path-dependent constraints. The stationary distribution reflects a competition between path multiplicity and imposed constraints and is significantly different from the Boltzmann distribution. We illustrate our results with a particle diffusing on an energy landscape. Connections with the path integral approach to diffusion are discussed.},
archivePrefix = {arXiv},
arxivId = {1506.06103},
author = {Dixit, Purushottam D.},
doi = {10.13140/RG.2.1.2792.9765},
eprint = {1506.06103},
file = {:home/kaslu/Documents/Mendeley/2015 - Dixit - Stationary properties of maximum entropy random walks.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {1--7},
publisher = {American Physical Society},
title = {{Stationary properties of maximum entropy random walks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.92.042149 http://arxiv.org/abs/1506.06103 http://dx.doi.org/10.1103/PhysRevE.92.042149},
volume = {92},
year = {2015}
}
@article{Gilligan1990,
abstract = {The moral domain is broader than the empathy and justice concerns assessed by existing measures of moral competence, and it is not just a subset of the values assessed by value inventories. To fill the need for reliable and theoretically grounded measurement of the full range of moral concerns, we developed the Moral Foundations Questionnaire on the basis of a theoretical model of 5 universally available (but variably developed) sets of moral intuitions: Harm/Care, Fairness/Reciprocity, Ingroup/Loyalty, Authority/Respect, and Purity/Sanctity. We present evidence for the internal and external validity of the scale and the model, and in doing so we present new findings about morality: (a) Comparative model fitting of confirmatory factor analyses provides empirical justification for a 5-factor structure of moral concerns; (b) convergent/discriminant validity evidence suggests that moral concerns predict personality features and social group attitudes not previously considered morally relevant; and (c) we establish pragmatic validity of the measure in providing new knowledge and research opportunities concerning demographic and cultural differences in moral intuitions. These analyses provide evidence for the usefulness of Moral Foundations Theory in simultaneously increasing the scope and sharpening the resolution of psychological views of morality.},
archivePrefix = {arXiv},
arxivId = {arXiv:1604.04696v1},
author = {Gilligan, Carol and Graham, Jesse and Nosek, Brian a and Haidt, Jonathan and Iyer, Ravi and Koleva, Spassena and Ditto, Peter H},
doi = {10.1037/a0021847.Mapping},
eprint = {arXiv:1604.04696v1},
file = {:home/kaslu/Documents/Mendeley/2012 - Gilligan et al. - Mapping the Moral Domain.pdf:pdf},
isbn = {0022-3514},
issn = {0022-3018},
journal = {Journal of personality and social psychology},
keywords = {about what,copyediting,correspondence concerning this article,culture,disagree,edu,how can we measure,it has not been,jgraham,means,mfq,moral concerns when people,moral foundations,morality,presented in the,publisher,s disclaimer,scale validation,should be sent to,subjected to the final,the final accepted manuscript,the following manuscript is,the moral foundations questionnaire,to address this problem,values,virginia,we created},
number = {2},
pages = {366--385},
pmid = {21244182},
title = {{Mapping the Moral Domain}},
volume = {101},
year = {2012}
}
@article{Betzel2017,
abstract = {Advances in neuroimaging have made it possible to reconstruct functional networks from the activity patterns of brain regions distributed across the cerebral cortex. Recent work has shown that flexible reconfiguration of human brain networks over short timescales supports cognitive flexibility and learning. However, modulating network flexibility to enhance learning requires an understanding of an as-yet unknown relationship between flexibility and brain state. Here, we investigate the relationship between network flexibility and affect, leveraging an unprecedented longitudinal data set. We demonstrate that indices associated with positive mood and surprise are both associated with network flexibility – positive mood portends a more flexible brain while increased levels of surprise portend a less flexible brain. In both cases, these relationships are driven predominantly by a subset of brain regions comprising the somatomotor system. Our results simultaneously suggest a network-level mechanism underlying learning deficits in mood disorders as well as a potential target – altering an individual's mood or task novelty – to improve learning.},
author = {Betzel, Richard F. and Satterthwaite, Theodore D. and Gold, Joshua I. and Bassett, Danielle S.},
doi = {10.1038/s41598-017-00425-z},
file = {:home/kaslu/Documents/Mendeley/2017 - Betzel et al. - Positive affect, surprise, and fatigue are correlates of network flexibility.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {520},
pmid = {28364117},
publisher = {Springer US},
title = {{Positive affect, surprise, and fatigue are correlates of network flexibility}},
url = {http://www.nature.com/articles/s41598-017-00425-z},
volume = {7},
year = {2017}
}
@article{Beck2011a,
abstract = {A wide range of computations performed by the nervous system involves a type of probabilistic inference known as marginalization. This computation comes up in seemingly unrelated tasks, including causal reasoning, odor recognition, motor control, visual tracking, coordinate transformations, visual search, decision making, and object recognition, to name just a few. The question we address here is: how could neural circuits implement such marginalizations? We show that when spike trains exhibit a particular type of statistics--associated with constant Fano factors and gain-invariant tuning curves, as is often reported in vivo--some of the more common marginalizations can be achieved with networks that implement a quadratic nonlinearity and divisive normalization, the latter being a type of nonlinear lateral inhibition that has been widely reported in neural circuits. Previous studies have implicated divisive normalization in contrast gain control and attentional modulation. Our results raise the possibility that it is involved in yet another, highly critical, computation: near optimal marginalization in a remarkably wide range of tasks.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Beck, J. M. and Latham, P. E. and Pouget, A.},
doi = {10.1523/JNEUROSCI.1706-11.2011},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2011 - Beck, Latham, Pouget - Marginalization in Neural Circuits with Divisive Normalization.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {43},
pages = {15310--15319},
pmid = {22031877},
title = {{Marginalization in Neural Circuits with Divisive Normalization}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1706-11.2011},
volume = {31},
year = {2011}
}
@article{Dieckmann1999,
abstract = {Understanding speciation is a fundamental biological problem. It is believed that many species originated through allopatric divergence, where new species arise from geographically isolated populations of the same ancestral species. In contrast, the possibility of sympatric speciation (in which new species arise without geographical isolation) has often been dismissed, partly because of theoretical difficulties. Most previous models analysing sympatric speciation concentrated on particular aspects of the problem while neglecting others. Here we present a model that integrates a novel combination of different features and show that sympatric speciation is a likely outcome of competition for resources. We use multilocus genetics to describe sexual reproduction in an individual-based model, and we consider the evolution of assortative mating (where individuals mate preferentially with like individuals) depending either on an ecological character affecting resource use or on a selectively neutral marker trait. In both cases, evolution of assortative mating often leads to reproductive isolation between ecologically diverging subpopulations. When assortative mating depends on a marker trait, and is therefore not directly linked to resource competition, speciation occurs when genetic drift breaks the linkage equilibrium between the marker and the ecological trait. Our theory conforms well with mounting empirical evidence for the sympatric origin of many species },
author = {Dieckmann, Ulf and Doebeli, Michael},
doi = {doi:10.1038/22521},
file = {:home/kaslu/Documents/Mendeley/1999 - Dieckmann, Doebeli - On the origin of species by sympatric speciation.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
month = {jul},
number = {6742},
pages = {354--357},
pmid = {10432112},
title = {{On the origin of species by sympatric speciation}},
url = {http://dx.doi.org/10.1038/22521 http://www.nature.com/doifinder/10.1038/22521},
volume = {400},
year = {1999}
}
@article{Brette2015,
abstract = {Does the brain use a firing rate code or a spike timing code? Considering this controversial question from an epistemological perspective, I argue that progress has been hampered by its problematic phrasing. It takes the perspective of an external observer looking at whether those two observables vary with stimuli, and thereby misses the relevant question: which one has a causal role in neural activity? When rephrased in a more meaningful way, the rate-based view appears as an ad hoc methodological postulate, one that is practical but with virtually no empirical or theoretical support.},
author = {Brette, Romain},
doi = {10.3389/fnsys.2015.00151},
file = {:home/kaslu/Documents/Mendeley/2015 - Brette - Philosophy of the spike rate-based vs. spike-based theories of the brain.pdf:pdf},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
keywords = {action potentials,firing rate,information,neural coding,neural computation,neural variability,spike,spike timing},
number = {151},
pages = {1--14},
pmid = {26617496},
title = {{Philosophy of the spike: rate-based vs. spike-based theories of the brain}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2015.00151/pdf},
volume = {9},
year = {2015}
}
@article{Gershman2017a,
abstract = {This letter introduces a study to precisely measure what an increase in spike timing precision can add to spike-driven pattern recognition algorithms. The concept of generating spikes from images by converting gray levels into spike timings is currently at the basis of almost every spike-based modeling of biological visual systems. The use of images naturally leads to generating incorrect artificial and redundant spike timings and, more important, also contradicts biological findings indicating that visual processing is massively parallel, asynchronous with high temporal resolution. A new concept for acquiring visual information through pixel-individual asynchronous level-crossing sampling has been proposed in a recent generation of asynchronous neuromorphic visual sensors. Unlike conventional cameras, these sensors acquire data not at fixed points in time for the entire array but at fixed amplitude changes of their input, resulting optimally sparse in space and time-pixel individually and precisely timed only if new, (previously unknown) information is available (event based). This letter uses the high temporal resolution spiking output of neuromorphic event-based visual sensors to show that lowering time precision degrades performance on several recognition tasks specifically when reaching the conventional range of machine vision acquisition frequencies (30-60 Hz). The use of information theory to characterize separability between classes for each temporal resolution shows that high temporal acquisition provides up to 70{\%} more information that conventional spikes generated from frame-based acquisition as used in standard artificial vision, thus drastically increasing the separability between classes of objects. Experiments on real data show that the amount of information loss is correlated with temporal precision. Our information-theoretic study highlights the potentials of neuromorphic asynchronous visual sensors for both practical applications and theoretical investigations. Moreover, it suggests that representing visual information as a precise sequence of spike times as reported in the retina offers considerable advantages for neuro-inspired visual computations.},
author = {Gershman, Samuel J.},
doi = {10.1162/neco_a_01023},
file = {:home/kaslu/Documents/Mendeley/2017 - Gershman - Dopamine, Inference, and Uncertainty.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {sep},
number = {3},
pages = {1--16},
title = {{Dopamine, Inference, and Uncertainty}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco{\_}a{\_}01023},
volume = {27},
year = {2017}
}
@article{Sanders2016,
abstract = {Human confidence judgments are thought to originate from metacognitive processes that provide a subjective assessment about one's beliefs. Alternatively, confidence is framed in mathematics as an objective statistical quantity: the probability that a chosen hypothesis is correct. Despite similar terminology, it remains unclear whether the subjective feeling of confidence is related to the objective, statistical computation of confidence. To address this, we collected confidence reports from humans performing perceptual and knowledge-based psychometric decision tasks. We observed two counterintuitive patterns relating confidence to choice and evidence: apparent overconfidence in choices based on uninformative evidence, and decreasing confidence with increasing evidence strength for erroneous choices. We show that these patterns lawfully arise from statistical confidence, and therefore occur even for perfectly calibrated confidence measures. Furthermore, statistical confidence quantitatively accounted for human confidence in our tasks without necessitating heuristic operations. Accordingly, we suggest that the human feeling of confidence originates from a mental computation of statistical confidence. Sanders et al. show that human confidence judgments originate from the mental computation of statistical confidence in both a perceptual and a knowledge-based decision task.},
author = {Sanders, Joshua I. and Hangya, Bal{\'{a}}zs and Kepecs, Adam},
doi = {10.1016/j.neuron.2016.03.025},
file = {:home/kaslu/Documents/Mendeley/2016 - Sanders, Hangya, Kepecs - Signatures of a Statistical Computation in the Human Sense of Confidence.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {3},
pages = {499--506},
pmid = {27151640},
title = {{Signatures of a Statistical Computation in the Human Sense of Confidence}},
volume = {90},
year = {2016}
}
@incollection{Norton1995,
address = {Dordrecht},
author = {Norton, John D.},
booktitle = {The Creation of Ideas in Physics},
doi = {10.1007/978-94-011-0037-3_3},
file = {:home/kaslu/Documents/Mendeley/1995 - Norton - Eliminative Induction as a Method of Discovery How Einstein Discovered General Relativity.pdf:pdf},
pages = {29--69},
publisher = {Springer Netherlands},
title = {{Eliminative Induction as a Method of Discovery: How Einstein Discovered General Relativity}},
url = {http://link.springer.com/10.1007/978-94-011-0037-3{\_}3},
year = {1995}
}
@article{Strong1998,
abstract = {The nervous system represents time dependent signals in sequences of discrete, identical action potentials or spikes; information is carried only in the spike arrival times. We show how to quantify this information, in bits, free from any assumptions about which features of the spike train or input signal are most important, and we apply this approach to the analysis of experiments on a motion sensitive neuron in the fly visual system. This neuron transmits information about the visual stimulus at rates of up to 90 bits/s, within a factor of 2 of the physical limit set by the entropy of the spike train itself.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9603127},
author = {Strong, S. P. and K{\"{o}}berle, Roland and {de Ruyter van Steveninck}, Rob R. and Bialek, William and Koberle, Roland and van Steveninck, Rob R. de Ruyter and Bialek, William},
doi = {10.1103/PhysRevLett.80.197},
eprint = {9603127},
file = {:home/kaslu/Documents/Mendeley/1998 - Strong et al. - Entropy and Information in Neural Spike Trains.pdf:pdf},
isbn = {1111111111},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {mar},
number = {1},
pages = {197--200},
pmid = {15244887},
primaryClass = {cond-mat},
title = {{Entropy and Information in Neural Spike Trains}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.80.197 http://arxiv.org/abs/cond-mat/9603127},
volume = {80},
year = {1998}
}
@article{Derex2015,
abstract = {Technological innovations have allowed humans to settle in habitats for which they are poorly suited biologically. However, our understanding of how humans produce complex technologies is limited. We used a computer-based experiment, involving humans and learning bots, to investigate how reasoning abilities, social learning mechanisms and population structure affect the production of virtual artefacts. We found that humans' reasoning abilities play an important role in the production of innovations, but that groups of individuals are able to produce artefacts that are more complex than any isolated individual can produce during the same amount of time. We show that this group-level ability to produce complex innovations is maximized when social information is easy to acquire and when individuals are organized into large and partially connected populations. These results suggest that the transition to behavioural modernity could have been triggered by a change in ancestral between-group interaction patterns.},
author = {Derex, Maxime and Boyd, Robert},
doi = {10.1038/ncomms9398},
file = {:home/kaslu/Documents/Mendeley/2015 - Derex, Boyd - The foundations of the human cultural niche.pdf:pdf},
issn = {2041-1723},
journal = {Nature communications},
language = {en},
month = {jan},
pages = {8398},
pmid = {26400015},
publisher = {Nature Publishing Group},
title = {{The foundations of the human cultural niche.}},
url = {http://www.nature.com/ncomms/2015/150924/ncomms9398/full/ncomms9398.html},
volume = {6},
year = {2015}
}
@article{Huk2017,
abstract = {Over the past two decades, neurophysiological responses in the lateral intraparietal area (LIP) have received extensive study for insight into decision making. In a parallel manner, inferred cognitive processes have enriched interpretations of LIP activity. Because of this bidirectional interplay between physiology and cognition, LIP has served as fertile ground for developing quantitative models that link neural activity with decision making. These models stand as some of the most important frameworks for linking brain and mind, and they are now mature enough to be evaluated in finer detail and integrated with other lines of investigation of LIP function. Here, we focus on the relationship between LIP responses and known sensory and motor events in perceptual decision-making tasks, as assessed by correlative and causal methods. The resulting sensorimotor-focused approach offers an account of LIP activity as a multiplexed amalgam of sensory, cognitive, and motor-related activity, with a complex and often ...},
author = {Huk, Alexander C. and Katz, Leor N. and Yates, Jacob L.},
doi = {10.1146/ANNUREV-NEURO-072116-031508},
file = {:home/kaslu/Documents/Mendeley/2017 - Huk, Katz, Yates - The Role of the Lateral Intraparietal Area in (the Study of) Decision Making.pdf:pdf},
journal = {Https://Doi.Org/10.1146/Annurev-Neuro-072116-031508},
keywords = {decision making,lateral intraparietal cortex,parietal,visual motion,visual perception},
title = {{The Role of the Lateral Intraparietal Area in (the Study of) Decision Making}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-neuro-072116-031508?utm{\_}content=buffercf651{\&}utm{\_}medium=social{\&}utm{\_}source=facebook.com{\&}utm{\_}campaign=buffer},
year = {2017}
}
@article{Rao1999b,
abstract = {How does the visual system learn an internal model of the external environment? How is this internal model used during visual perception? How are occlusions and background clutter so effortlessly discounted for when recognizing a familiar object? How is a particular object of interest attended to and recognized in the presence of other objects in the field of view? In this paper, we attempt to address these questions from the perspective of Bayesian optimal estimation theory. Using the concept of generative models and the statistical theory of Kalman filtering, we show how static and dynamic events occurring in the visual environment may be learned and recognized given only the input images. We also describe an extension of the Kalman filter model that can handle multiple objects in the field of view. The resulting robust Kalman filter model demonstrates how certain forms of attention can be viewed as an emergent property of the interaction between top-down expectations and bottom-up signals. Experimental results are provided to help demonstrate the ability of such a model to perform robust segmentation and recognition of objects and image sequences in the presence of occlusions and clutter.},
author = {Rao, Rajesh P. N.},
doi = {10.1016/S0042-6989(98)00279-X},
file = {:home/kaslu/Documents/Mendeley/1999 - Rao - An optimal estimation approach to visual perception and learning.pdf:pdf},
isbn = {0042-6989 (Print)$\backslash$r0042-6989 (Linking)},
issn = {00426989},
journal = {Vision Research},
keywords = {Attention,Kalman filtering,Perceptual learning,Prediction,Segmentation,Visual recognition},
number = {11},
pages = {1963--1989},
pmid = {10343783},
title = {{An optimal estimation approach to visual perception and learning}},
volume = {39},
year = {1999}
}
@article{Clune2012,
abstract = {A central biological question is how natural organisms are so evolvable (capable of quickly adapting to new environments). A key driver of evolvability is the widespread modularity of biological networks--their organization as functional, sparsely connected subunits--but there is no consensus regarding why modularity itself evolved. While most hypotheses assume indirect selection for evolvability, here we demonstrate that the ubiquitous, direct selection pressure to reduce the cost of connections between network nodes causes the emergence of modular networks. Experiments with selection pressures to maximize network performance and minimize connection costs yield networks that are significantly more modular and more evolvable than control experiments that only select for performance. These results will catalyze research in numerous disciplines, including neuroscience, genetics and harnessing evolution for engineering purposes.},
archivePrefix = {arXiv},
arxivId = {1207.2743},
author = {Clune, Jeff and Mouret, Jean-Baptiste and Lipson, Hod},
doi = {10.1098/rspb.2012.2863},
editor = {Sporns, Olaf},
eprint = {1207.2743},
isbn = {1471-2954 (Electronic)$\backslash$n0962-8452 (Linking)},
issn = {15537358},
journal = {PLoS Computational Biology},
month = {jul},
number = {6},
pmid = {23363632},
title = {{The evolutionary origins of modularity}},
url = {http://arxiv.org/abs/1207.2743 http://dx.doi.org/10.1098/rspb.2012.2863},
volume = {12},
year = {2012}
}
@article{Berdahl2016,
abstract = {Pathogens can spread epidemically through populations. Beneficial contagions, such as viruses that enhance host survival or technological innovations that improve quality of life, also have the potential to spread epidemically. How do the dynamics of beneficial biological and social epidemics differ from those of detrimental epidemics? We investigate this question using three theoretical approaches as well as an empirical analysis of concept propagation. First, in evolutionary models, we show that a beneficial horizontally-transmissible element, such as viral DNA, spreads super-exponentially through a population, substantially more quickly than a beneficial mutation. Second, in an epidemiological social network approach, we show that infections that cause increased connectivity lead to faster-than-exponential fixation in the population. Third, in a sociological model with strategic rewiring, we find that preferences for increased global infection accelerate spread and produce super-exponential fixation rates, while preferences for local assortativity halt epidemics by disconnecting the infected from the susceptible. Finally, in an investigation of the Google Ngram corpus, we find that new words and phrases spread super-exponentially, as anticipated by our models. We conclude that the dynamics of beneficial biological and social epidemics are characterized by the remarkably rapid spread of beneficial elements, which can be facilitated in biological systems by horizontal transmission and in social systems by active spreading strategies of infected individuals.},
archivePrefix = {arXiv},
arxivId = {1604.02096},
author = {Berdahl, Andrew and Brelsford, Christa and {De Bacco}, Caterina and Dumas, Marion and Ferdinand, Vanessa and Grochow, Joshua A. and H{\'{e}}bert-Dufresne, Laurent and Kallus, Yoav and Kempes, Christopher P. and Kolchinsky, Artemy and Larremore, Daniel B. and Libby, Eric and Power, Eleanor A. and Stern, Caitlin A. and Tracey, Brendan},
eprint = {1604.02096},
month = {apr},
title = {{Dynamics of beneficial epidemics}},
url = {http://arxiv.org/abs/1604.02096},
year = {2016}
}
@article{Harrigan2010,
abstract = {Does the quantum state represent reality or our knowledge of reality? In making this distinction precise, we are led to a novel classification of hidden variable models of quantum theory. Indeed, representatives of each class can be found among existing constructions for two-dimensional Hilbert spaces. Our approach also provides a fruitful new perspective on arguments for the nonlocality and incompleteness of quantum theory. Specifically, we show that for models wherein the quantum state has the status of something real, the failure of locality can be established through an argument considerably more straightforward than Bell's theorem. The historical significance of this result becomes evident when one recognizes that the same reasoning is present in Einstein's preferred argument for incompleteness, which dates back to 1935. This fact suggests that Einstein was seeking not just any completion of quantum theory, but one wherein quantum states are solely representative of our knowledge. Our hypothesis is supported by an analysis of Einstein's attempts to clarify his views on quantum theory and the circumstance of his otherwise puzzling abandonment of an even simpler argument for incompleteness from 1927.},
archivePrefix = {arXiv},
arxivId = {0706.2661},
author = {Harrigan, Nicholas and Spekkens, Robert W.},
doi = {10.1007/s10701-009-9347-0},
eprint = {0706.2661},
file = {:home/kaslu/Documents/Mendeley/2007 - Harrigan, Spekkens - Einstein, incompleteness, and the epistemic view of quantum states.pdf:pdf},
issn = {00159018},
journal = {Foundations of Physics},
keywords = {Einstein,Incompleteness,Nonlocality,Quantum mechanics,Realism,The measurement problem},
month = {jun},
number = {2},
pages = {125--157},
title = {{Einstein, incompleteness, and the epistemic view of quantum states}},
url = {http://arxiv.org/abs/0706.2661 http://dx.doi.org/10.1007/s10701-009-9347-0},
volume = {40},
year = {2007}
}
@article{Linden2003,
abstract = {The mouse is a promising model system for auditory cortex research because of the powerful genetic tools available for manipulating its neural circuitry. Previous studies have identified two tonotopic auditory areas in the mouse-primary auditory cortex (AI) and anterior auditory field (AAF)- but auditory receptive fields in these areas have not yet been described. To establish a foundation for investigating auditory cortical circuitry and plasticity in the mouse, we characterized receptive-field structure in AI and AAF of anesthetized mice using spectrally complex and temporally dynamic stimuli as well as simple tonal stimuli. Spectrotemporal receptive fields (STRFs) were derived from extracellularly recorded responses to complex stimuli, and frequency-intensity tuning curves were constructed from responses to simple tonal stimuli. Both analyses revealed temporal differences between AI and AAF responses: peak latencies and receptive-field durations for STRFs and first-spike latencies for responses to tone bursts were significantly longer in AI than in AAF. Spectral properties of AI and AAF receptive fields were more similar, although STRF bandwidths were slightly broader in AI than in AAF. Finally, in both AI and AAF, a substantial minority of STRFs were spectrotemporally inseparable. The spectrotemporal interaction typically appeared in the form of clearly disjoint excitatory and inhibitory subfields or an obvious spectrotemporal slant in the STRF. These data provide the first detailed description of auditory receptive fields in the mouse and suggest that although neurons in areas AI and AAF share many response characteristics, area AAF may be specialized for faster temporal processing.},
author = {Linden, J. F. and Sahani, Maneesh},
doi = {10.1152/jn.00751.2002},
file = {:home/kaslu/Documents/Mendeley/2003 - Linden, Sahani - Spectrotemporal Structure of Receptive Fields in Areas AI and AAF of Mouse Auditory Cortex.pdf:pdf},
isbn = {1108911099},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {4},
pages = {2660--2675},
pmid = {12815016},
title = {{Spectrotemporal Structure of Receptive Fields in Areas AI and AAF of Mouse Auditory Cortex}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00751.2002},
volume = {90},
year = {2003}
}
@article{Haefner2016,
abstract = {We address two main challenges facing systems neuroscience today: understanding the nature and function of cortical feedback between sensory areas and of correlated variability. Starting from the old idea of perception as probabilistic inference, we show how to use knowledge of the psychophysical task to make testable predictions for the influence of feedback signals on early sensory representations. Applying our framework to a two-alternative forced choice task paradigm, we can explain multiple empirical findings that have been hard to account for by the traditional feedforward model of sensory processing, including the task dependence of neural response correlations and the diverging time courses of choice probabilities and psychophysical kernels. Our model makes new predictions and characterizes a component of correlated variability that represents task-related information rather than performance-degrading noise. It demonstrates a normative way to integrate sensory and cognitive components into physiologically testable models of perceptual decision-making. Feedback signals are ubiquitous in cortex yet underconstrained by empirical data. Haefner et al. derive predictions for their effect on sensory representations as a function of the behavioral task, with implications for the role of correlated variability in sensory coding.},
archivePrefix = {arXiv},
arxivId = {1409.0257},
author = {Haefner, Ralf M. and Berkes, Pietro and Fiser, J{\'{o}}zsef},
doi = {10.1016/j.neuron.2016.03.020},
eprint = {1409.0257},
file = {:home/kaslu/Documents/Mendeley/2016 - Haefner, Berkes, Fiser - Perceptual Decision-Making as Probabilistic Inference by Neural Sampling.pdf:pdf},
isbn = {08966273},
issn = {08966273},
journal = {Neuron},
month = {may},
number = {3},
pages = {649--660},
pmid = {27146267},
title = {{Perceptual Decision-Making as Probabilistic Inference by Neural Sampling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316300113},
volume = {90},
year = {2016}
}
@article{Tajima2016,
abstract = {For decades now, normative theories of perceptual decisions, and their implementation as drift diffusion models, have driven and significantly improved our understanding of human and animal behaviour and the underlying neural processes. While similar processes seem to govern value-based decisions, we still lack the theoretical understanding of why this ought to be the case. Here, we show that, similar to perceptual decisions, drift diffusion models implement the optimal strategy for value-based decisions. Such optimal decisions require the models' decision boundaries to collapse over time, and to depend on the a priori knowledge about reward contingencies. Diffusion models only implement the optimal strategy under specific task assumptions, and cease to be optimal once we start relaxing these assumptions, by, for example, using non-linear utility functions. Our findings thus provide the much-needed theory for value-based decisions, explain the apparent similarity to perceptual decisions, and predict conditions under which this similarity should break down.},
author = {Tajima, Satohiro and Drugowitsch, Jan and Pouget, Alexandre},
doi = {10.1038/ncomms12400},
file = {:home/kaslu/Documents/Mendeley/2016 - Tajima, Drugowitsch, Pouget - Optimal policy for value-based decision-making.pdf:pdf},
isbn = {2041-1723 (Electronic)$\backslash$r2041-1723 (Linking)},
issn = {2041-1723},
journal = {Nature communications},
pages = {12400},
pmid = {27535638},
publisher = {Nature Publishing Group},
title = {{Optimal policy for value-based decision-making.}},
url = {http://www.nature.com/ncomms/2016/160818/ncomms12400/full/ncomms12400.html},
volume = {7},
year = {2016}
}
@article{Bellomo2013,
abstract = {This paper deals with the kinetic theory modeling of crowd dynamics with the aim of showing how the dynamics at the micro-scale is transferred to the dynamics of collective behaviors. The derivation of a new model is followed by a qualitative analysis of the initial value problem. Existence of solutions is proved for arbitrary large times, while simulations are developed by computational schemes based on splitting methods, where the transport equations treated by nite difference methods for hyperbolic equations. Some preliminary reasonings toward the modeling of panic conditions are proposed.},
archivePrefix = {arXiv},
arxivId = {1301.5574},
author = {Bellomo, Nicola and Bellouquid, Abdelghani and Knopoff, Damian},
doi = {10.1137/130904569},
eprint = {1301.5574},
issn = {1540-3459},
journal = {Multiscale Modeling {\&} Simulation},
keywords = {Crowd dynamics,complexity,living systems,nonlinear interactions,relevant,scaling},
month = {sep},
number = {3},
pages = {943--963},
title = {{From the Microscale to Collective Crowd Dynamics}},
url = {http://arxiv.org/abs/1301.5574 http://epubs.siam.org/doi/abs/10.1137/130904569},
volume = {11},
year = {2013}
}
@article{Churchland2007a,
abstract = {Large, chronically implanted arrays of microelectrodes are an increasingly common tool for recording from primate cortex and can provide extracellular recordings from many (order of 100) neurons. While the desire for cortically based motor prostheses has helped drive their development, such arrays also offer great potential to advance basic neuroscience research. Here we discuss the utility of array recording for the study of neural dynamics. Neural activity often has dynamics beyond that driven directly by the stimulus. While governed by those dynamics, neural responses may nevertheless unfold differently for nominally identical trials, rendering many traditional analysis methods ineffective. We review recent studies - some employing simultaneous recording, some not - indicating that such variability is indeed present both during movement generation and during the preceding premotor computations. In such cases, large-scale simultaneous recordings have the potential to provide an unprecedented view of neural dynamics at the level of single trials. However, this enterprise will depend not only on techniques for simultaneous recording but also on the use and further development of analysis techniques that can appropriately reduce the dimensionality of the data, and allow visualization of single-trial neural behavior. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Churchland, Mark M. and Yu, Byron M. and Sahani, Maneesh and Shenoy, Krishna V.},
doi = {10.1016/j.conb.2007.11.001},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2007 - Churchland et al. - Techniques for extracting single-trial activity patterns from large-scale neural recordings.pdf:pdf},
isbn = {0959-4388 (Print)$\backslash$r0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {5},
pages = {609--618},
pmid = {18093826},
title = {{Techniques for extracting single-trial activity patterns from large-scale neural recordings}},
volume = {17},
year = {2007}
}
@article{Axler1995,
abstract = {This paper shows how linear algebra can be done better without determinants. The standard proof that a square matrix of complex numbers has an eigenvalue uses determinants. The simpler and clearer proof presented here provides more insight and avoids determinants. Without using determinants, this allows us to define the multiplicity of an eigenvalue and to prove that the number of eigenvalues, counting multiplicities, equals the dimension of the underlying space. Without using determinants, we can define the characteristic and minimal polynomials and then prove that they behave as expected. This leads to an easy proof that every matrix is similar to a nice upper-triangular one. Turning to inner product spaces, and still without mentioning determinants, this paper gives a simple proof of the finite-dimensional spectral theorem.},
author = {Axler, Sheldon},
doi = {10.2307/2975348},
file = {:home/kaslu/Documents/Mendeley/1995 - Axler - Down with Determinants!.pdf:pdf},
issn = {00029890},
journal = {The American Mathematical Monthly},
number = {2},
pages = {139},
title = {{Down with Determinants!}},
url = {http://www.jstor.org/stable/2975348?origin=crossref},
volume = {102},
year = {1995}
}
@article{Ni2017,
abstract = {The trial-to-trial response variability that is shared between pairs of neurons (termed spike count correlations or rSC) has been the subject of many recent studies largely because it might limit the amount of information that can be encoded by neuronal populations. Spike count correlations are flexible and change depending on task demands. However, the relationship between correlated variability and information coding is a matter of current debate. Here we simultaneously measured the effects of perceptual learning and attention, two processes that improve performance on visual tasks but operate on very different timescales, on behavioral performance and neuronal population responses in visual area V4, using the same task, subjects, trials, and neuronal populations. We found that there is a single, robust relationship between correlated variability in neuronal populations and behavioral performance, even though correlated variability changes rapidly with attention and slowly with perceptual learning. Further, this correlated variability is oriented along the dimensions in population space used by the animal on a trial-by-trial basis to make perceptual decisions. In conclusion, it appears that there is a common computation through which the correlated variability of neuronal populations affects perceptual performance.},
author = {Ni, Amy M and Ruff, Douglas A and Alberts, Joshua J and Symmonds, Jen and Cohen, Marlene R},
doi = {10.1101/137083},
issn = {0036-8075},
journal = {bioRxiv},
pmid = {29371470},
title = {{Learning and attention reveal a general relationship between neuronal variability and perception}},
year = {2017}
}
@article{Hunt2017,
abstract = {Many accounts of reward-based choice argue for distinct component processes that are serial and functionally localized. In this Opinion article, we argue for an alternative viewpoint, in which choices emerge from repeated computations that are distributed across many brain regions. We emphasize how several features of neuroanatomy may support the implementation of choice, including mutual inhibition in recurrent neural networks and the hierarchical organization of timescales for information processing across the cortex. This account also suggests that certain correlates of value are emergent rather than represented explicitly in the brain.},
author = {Hunt, Laurence T. and Hayden, Benjamin Y.},
doi = {10.1038/nrn.2017.7},
file = {:home/kaslu/Documents/Mendeley/2017 - Hunt, Hayden - A distributed, hierarchical and recurrent framework for reward-based choice.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {feb},
number = {3},
pages = {172--182},
pmid = {28209978},
title = {{A distributed, hierarchical and recurrent framework for reward-based choice}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2017.7},
volume = {18},
year = {2017}
}
@article{Gold2007,
abstract = {he study of decision making spans such varied fields as neuro-science, psychology, economics, statistics, political science, and com-puter science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Gold, Joshua I. and Shadlen, Michael N.},
doi = {10.1146/annurev.neuro.29.051605.113038},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2007 - Gold, Shadlen - The Neural Basis of Decision Making.pdf:pdf},
isbn = {0147-006X (Print)$\backslash$n0147-006X (Linking)},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {choice,motion,perception,psychophysics,reaction time,sequential analysis,signal detection theory,vibrotactile perception},
month = {jul},
number = {1},
pages = {535--574},
pmid = {17600525},
title = {{The Neural Basis of Decision Making}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.113038},
volume = {30},
year = {2007}
}
@incollection{Graham2013,
abstract = {Where does morality come from? Why are moral judgments often so similar across cultures, yet sometimes so variable? Is morality one thing, or many? Moral Foundations Theory (MFT) was created to answer these questions. In this chapter, we describe the origins, assumptions, and current conceptualization of the theory and detail the empirical findings that MFT has made possible, both within social psychology and beyond. Looking toward the future, we embrace several critiques of the theory and specify five criteria for determining what should be considered a foundation of human morality. Finally, we suggest a variety of future directions for MFT and moral psychology. ?? 2013 Elsevier Inc.},
author = {Graham, Jesse and Haidt, Jonathan and Koleva, Sena and Motyl, Matt and Iyer, Ravi and Wojcik, Sean P. and Ditto, Peter H.},
booktitle = {Advances in Experimental Social Psychology},
doi = {10.1016/B978-0-12-407236-7.00002-4},
isbn = {9780124072367},
issn = {00652601},
keywords = {Cultural learning,Intuition,Method-theory coevolution,Morality,Nativism,Pluralism},
pages = {55--130},
pmid = {22469268},
title = {{Moral Foundations Theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780124072367000024},
volume = {47},
year = {2013}
}
@article{Montroll1981,
abstract = {The entropy function H = -Sigmap(j) log p(j) (p(j) being the probability of a system being in state j) and its continuum analogue H = integralp(x) log p(x) dx are fundamental in Shannon's theory of information transfer in communication systems. It is here shown that the discrete form of H also appears naturally in single-lane traffic flow theory. In merchandising, goods flow from a whole-saler through a retailer to a customer. Certain features of the process may be deduced from price distribution functions derived from Sears Roebuck and Company catalogues. It is found that the dispersion in logarithm of catalogue prices of a given year has remained about constant, independently of the year, for over 75 years. From this it may be inferred that the continuum entropy function for the variable logarithm of price had inadvertently, through Sears Roebuck policies, been maximized for that firm subject to the observed dispersion.},
author = {Montroll, E W},
file = {:home/kaslu/Documents/Mendeley/1981 - Montroll - On the entropy function in sociotechnical systems.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {dec},
number = {12},
pages = {7839--43},
pmid = {16593136},
publisher = {National Academy of Sciences},
title = {{On the entropy function in sociotechnical systems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16593136 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC349367},
volume = {78},
year = {1981}
}
@article{Leigh2010,
abstract = {Many thought Darwinian natural selection could not explain altruism. This error led Wynne-Edwards to explain sustainable exploitation in animals by selection against overexploiting groups. Williams riposted that selection among groups rarely overrides within-group selection. Hamilton showed that altruism can evolve through kin selection. How strongly does group selection influence evolution? Following Price, Hamilton showed how levels of selection interact: group selection prevails if Hamilton's rule applies. Several showed that group selection drove some major evolutionary transitions. Following Hamilton's lead, Queller extended Hamilton's rule, replacing genealogical relatedness by the regression on an actor's genotypic altruism of interacting neighbours' phenotypic altruism. Price's theorem shows the generality of Hamilton's rule. All instances of group selection can be viewed as increasing inclusive fitness of autosomal genomes. Nonetheless, to grasp fully how cooperation and altruism evolve, most biologists need more concrete concepts like kin selection, group selection and selection among individuals for their common good.},
author = {Leigh, E. G.},
doi = {10.1111/j.1420-9101.2009.01876.x},
isbn = {1010-061X},
issn = {1010061X},
journal = {Journal of Evolutionary Biology},
keywords = {Common good,Cooperation,Fair meiosis,Green beards,Group selection,Kin selection,Levels of selection,Mutualism,Price's theorem,Superorganisms},
number = {1},
pages = {6--19},
pmid = {20002254},
title = {{The group selection controversy}},
volume = {23},
year = {2010}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114},
file = {:home/kaslu/Documents/Mendeley/2013 - Kingma, Welling - Auto-Encoding Variational Bayes.pdf:pdf},
month = {dec},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Diaconis2007,
abstract = {We analyze the natural process of flipping a coin which is caught in the hand. We prove that vigorously-flipped coins are biased to come up the same way they started. The amount of bias depends on a single parameter, the angle between the normal to the coin and the angular momentum vector. Measurements of this parameter based on high-speed photography are reported. For natural flips, the chance of coming up as started is about .51},
author = {Diaconis, Persi and Holmes, Susan and Montgomery, Richard},
doi = {10.1137/S0036144504446436},
file = {:home/kaslu/Documents/Mendeley/2007 - Diaconis, Holmes, Montgomery - Dynamical Bias in the Coin Toss.pdf:pdf},
issn = {0036-1445},
journal = {SIAM Review},
month = {jan},
number = {2},
pages = {211--235},
title = {{Dynamical Bias in the Coin Toss}},
url = {http://dx.doi.org/10.1088/1751-8113/44/8/085201 http://epubs.siam.org/doi/abs/10.1137/S0036144504446436},
volume = {49},
year = {2007}
}
@article{Meyer2017a,
abstract = {Rich, dynamic, and dense sensory stimuli are encoded within the nervous system by the time-varying activity of many individual neurons. A fundamental approach to understanding the nature of the encoded representation is to characterise the function that relates the moment-by-moment firing of a neuron to the recent history of a complex sensory input. This review provides a unifying and critical survey of the techniques that have been brought to bear on this effort thus far --- ranging from the classical linear receptive field model to modern approaches incorporating normalisation and other nonlinearities. We address separately the structure of the models; the criteria and algorithms used to identify the model parameters; and the role of regularising terms or ``priors''. In each case we consider benefits or drawbacks of various proposals, providing examples for when these methods work and when they may fail. Emphasis is placed on key concepts rather than mathematical details, so as to make the discussion accessible to readers from outside the field. Finally, we review ways in which the agreement between an assumed model and the neuron's response may be quantified.},
author = {Meyer, Arne F. and Williamson, Ross S. and Linden, Jennifer F. and Sahani, Maneesh},
doi = {10.3389/fnsys.2016.00109},
file = {:home/kaslu/Documents/Mendeley/2017 - Meyer et al. - Models of Neuronal Stimulus-Response Functions Elaboration, Estimation, and Evaluation.pdf:pdf},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
keywords = {neural coding,receptive field,receptive field, sensory system, neural coding,sensory system},
number = {January},
pages = {1--25},
pmid = {28127278},
title = {{Models of Neuronal Stimulus-Response Functions: Elaboration, Estimation, and Evaluation}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2016.00109/full},
volume = {10},
year = {2017}
}
@article{Churchland2016,
abstract = {Tissue and organ function has been conventionally understood in terms of the interactions among discrete and homogeneous cell types. This approach has proven difficult in neuroscience due to the marked diversity across different neuron classes, but it may be further hampered by prominent within-class variability. Here, we considered a well-defined canonical neuronal population-hippocampal CA1 pyramidal cells (CA1 PCs)-and systematically examined the extent and spatial rules of transcriptional heterogeneity. Using next-generation RNA sequencing, we identified striking variability in CA1 PCs, such that the differences within CA1 along the dorsal-ventral axis rivaled differences across distinct pyramidal neuron classes. This variability emerged from a spectrum of continuous gene-expression gradients, producing a transcriptional profile consistent with a multifarious continuum of cells. This work reveals an unexpected amount of variability within a canonical and narrowly defined neuronal population and suggests that continuous, within-class heterogeneity may be an important feature of neural circuits. Using next-generation RNA sequencing, Cembrowski et al. show that CA1 pyramidal cells (CA1 PCs) exhibit marked variability across the long hippocampal axis. This heterogeneity emerges from a spectrum of gene-expression gradients, producing a highly variable continuum of CA1 PCs.},
author = {Churchland, Anne K. and Abbott, Larry},
doi = {10.1038/nn.4255},
file = {:home/kaslu/Documents/Mendeley/2016 - Churchland, Abbott - Conceptual and technical advances define a key moment for theoretical neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {3},
pages = {348--349},
title = {{Conceptual and technical advances define a key moment for theoretical neuroscience}},
url = {http://www.nature.com/doifinder/10.1038/nn.4255},
volume = {19},
year = {2016}
}
@article{Hyvarinen2012,
author = {Hyv{\"{a}}rinen, Aapo},
doi = {10.1098/rsta.2011.0534},
file = {:home/kaslu/Documents/Mendeley/2012 - Hyv{\"{a}}rinen - Independent component analysis recent advances.pdf:pdf},
isbn = {10.1098/rsta.2011.0534},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {electrical engineering,statistics},
number = {1984},
pages = {20110534--20110534},
pmid = {23277597},
title = {{Independent component analysis: recent advances}},
url = {http://rsta.royalsocietypublishing.org/cgi/doi/10.1098/rsta.2011.0534},
volume = {371},
year = {2012}
}
@article{Borgs2017,
abstract = {The sparse matrix estimation problem consists of estimating the distribution of an n × n matrix Y , from a sparsely observed single instance of this matrix where the entries of Y are independent random variables. This captures a wide array of problems; special instances include matrix completion in the context of rec-ommendation systems, graphon estimation, and community detection in (mixed membership) stochastic block models. Inspired by classical collaborative filtering for recommendation systems, we propose a novel iterative, collaborative filtering-style algorithm for matrix estimation in this generic setting. We show that the mean squared error (MSE) of our estimator converges to 0 at the rate of O(d 2 (pn) −2/5) as long as $\omega$(d 5 n) random entries from a total of n 2 entries of Y are observed (uniformly sampled), E[Y ] has rank d, and the entries of Y have bounded support. The maximum squared error across all entries converges to 0 with high probability as long as we observe a little more, Ω(d 5 n ln 5 (n)) entries. Our results are the best known sample complexity results in this generality.},
archivePrefix = {arXiv},
arxivId = {1712.00710},
author = {Borgs, Christian and Lee, Christina E},
eprint = {1712.00710},
file = {:home/kaslu/Documents/Mendeley/2017 - Borgs, Lee - Thy Friend is My Friend Iterative Collaborative Filtering for Sparse Matrix Estimation.pdf:pdf},
journal = {Nips},
number = {Nips},
title = {{Thy Friend is My Friend : Iterative Collaborative Filtering for Sparse Matrix Estimation}},
url = {http://papers.nips.cc/paper/7057-thy-friend-is-my-friend-iterative-collaborative-filtering-for-sparse-matrix-estimation},
year = {2017}
}
@article{Lee2016,
abstract = {Circuits in the visual cortex integrate the information derived from separate ON (light-responsive) and OFF (dark-responsive) pathways to construct orderly columnar representations of stimulus orientation and visual space. How this transformation is achieved to meet the specific topographic constraints of each representation remains unclear. Here we report several novel features of ON-OFF convergence visualized by mapping the receptive fields of layer 2/3 neurons in the tree shrew (Tupaia belangeri) visual cortex using two-photon imaging of GCaMP6 calcium signals. We show that the spatially separate ON and OFF subfields of simple cells in layer 2/3 exhibit topologically distinct relationships with the maps of visual space and orientation preference. The centres of OFF subfields for neurons in a given region of cortex are confined to a compact region of visual space and display a smooth visuotopic progression. By contrast, the centres of the ON subfields are distributed over a wider region of visual space, display substantial visuotopic scatter, and have an orientation-specific displacement consistent with orientation preference map structure. As a result, cortical columns exhibit an invariant aggregate receptive field structure: an OFF-dominated central region flanked by ON-dominated subfields. This distinct arrangement of ON and OFF inputs enables continuity in the mapping of both orientation and visual space and the generation of a columnar map of absolute spatial phase.},
author = {Lee, Kuo-Sheng and Huang, Xiaoying and Fitzpatrick, David},
doi = {10.1038/nature17941},
file = {:home/kaslu/Documents/Mendeley/2016 - Lee, Huang, Fitzpatrick - Topology of ON and OFF inputs in visual cortex enables an invariant columnar architecture.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {apr},
number = {7601},
pages = {90--94},
pmid = {27120162},
publisher = {Nature Publishing Group},
title = {{Topology of ON and OFF inputs in visual cortex enables an invariant columnar architecture}},
url = {http://www.nature.com/doifinder/10.1038/nature17941},
volume = {533},
year = {2016}
}
@article{Whiteley2012,
abstract = {The behavioral phenomena of sensory attention are thought to reflect the allocation of a limited processing resource, but there is little consensus on the nature of the resource or why it should be limited. Here we argue that a fundamental bottleneck emerges naturally within Bayesian models of perception, and use this observation to frame a new computational account of the need for, and action of, attention - unifying diverse attentional phenomena in a way that goes beyond previous inferential, probabilistic and Bayesian models. Attentional effects are most evident in cluttered environments, and include both selective phenomena, where attention is invoked by cues that point to particular stimuli, and integrative phenomena, where attention is invoked dynamically by endogenous processing. However, most previous Bayesian accounts of attention have focused on describing relatively simple experimental settings, where cues shape expectations about a small number of upcoming stimuli and thus convey "prior" information about clearly defined objects. While operationally consistent with the experiments it seeks to describe, this view of attention as prior seems to miss many essential elements of both its selective and integrative roles, and thus cannot be easily extended to complex environments. We suggest that the resource bottleneck stems from the computational intractability of exact perceptual inference in complex settings, and that attention reflects an evolved mechanism for approximate inference which can be shaped to refine the local accuracy of perception. We show that this approach extends the simple picture of attention as prior, so as to provide a unified and computationally driven account of both selective and integrative attentional phenomena.},
author = {Whiteley, Louise and Sahani, Maneesh},
doi = {10.3389/fnhum.2012.00100},
file = {:home/kaslu/Documents/Mendeley/2012 - Whiteley, Sahani - Attention in a Bayesian Framework.pdf:pdf},
isbn = {1662-5161 (Electronic)$\backslash$r1662-5161 (Linking)},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {attention,attention, Bayesian modeling, perception,bayesian modeling,perception},
number = {June},
pages = {1--21},
pmid = {22712010},
title = {{Attention in a Bayesian Framework}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2012.00100/abstract},
volume = {6},
year = {2012}
}
@article{Arandia-Romero2017,
abstract = {Nowadays, it is possible to record the activity of hundreds of cells at the same time in behaving animals. However, these data are often treated and analyzed as if they consisted of many independently recorded neurons. How can neuronal populations be uniquely used to learn about cognition? We describe recent work that shows that populations of simultaneously recorded neurons are fundamental to understand the basis of decision-making, including processes such as ongoing deliberations and decision confidence, which generally fall outside the reach of single-cell analysis. Thus, neuronal population data allow addressing novel questions, but they also come with so far unsolved challenges.},
archivePrefix = {arXiv},
arxivId = {1711.01423},
author = {Arandia-Romero, I{\~{n}}igo and Nogueira, Ramon and Mochol, Gabriela and Moreno-Bote, Rub{\'{e}}n},
doi = {10.1016/j.conb.2017.07.008},
eprint = {1711.01423},
file = {:home/kaslu/Documents/Mendeley/2017 - Arandia-Romero et al. - What can neuronal populations tell us about cognition.pdf:pdf},
isbn = {1873-6882 (Electronic) 0959-4388 (Linking)},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {48--57},
pmid = {28806694},
title = {{What can neuronal populations tell us about cognition?}},
volume = {46},
year = {2017}
}
@article{Smaldino2014a,
abstract = {We demonstrate that individual behaviors directed at the attainment of distinctiveness can in fact produce complete social conformity. We thus offer an unexpected generative mechanism for this central social phenomenon. Specifically, we establish that agents who have fixed needs to be distinct and adapt their positions to achieve distinctiveness goals, can nevertheless self-organize to a limiting state of absolute conformity. This seemingly paradoxical result is deduced formally from a small number of natural assumptions, and is then explored at length computationally. Interesting departures from this conformity equilibrium are also possible, including divergence in positions. The effect of extremist minorities on these dynamics is discussed. A simple extension is then introduced, which allows the model to generate and maintain social diversity, including multimodal distinctiveness distributions. The paper contributes formal definitions, analytical deductions, and counterintuitive findings to the literature on individual distinctiveness and social conformity.},
archivePrefix = {arXiv},
arxivId = {1407.7908},
author = {Smaldino, Paul E. and Epstein, Joshua M.},
doi = {10.1098/rsos.140437},
eprint = {1407.7908},
keywords = {behaviour,computer modelling and,simulation,theoretical biology},
title = {{Social Conformity Despite Individual Preferences for Distinctiveness}},
url = {http://arxiv.org/abs/1407.7908{\%}0Ahttp://dx.doi.org/10.1098/rsos.140437},
year = {2014}
}
@inproceedings{Lindsey2014,
author = {Lindsey, Robert V. and Khajah, Mohammad and Mozer, Michael C.},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1386--1394},
title = {{Automatic Discovery of Cognitive Skills to Improve the Prediction of Student Learning}},
url = {http://papers.nips.cc/paper/5554-automatic-discovery-of-cognitive-skills-to-improve-the-prediction-of-student-learning},
year = {2014}
}
@article{Chiao2010,
abstract = {Social status hierarchy is a ubiquitous principle of social organization across the animal kingdom. Recent findings in social neuroscience reveal distinct neural networks associated with the recognition and experience of social hierarchy in humans, as well as modulation of these networks by personality and culture. Additionally, allelic variation in the serotonin transporter gene is associated with prevalence of social hierarchy across species and cultures, suggesting the importance of the study of genetic factors underlying social hierarchy. Future studies are needed to determine how genetic and environmental factors shape neural systems involved in the production and maintenance of social hierarchy across ontogeny and phylogeny. ?? 2010 Elsevier Ltd.},
author = {Chiao, Joan Y.},
doi = {10.1016/j.conb.2010.08.006},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {803--809},
pmid = {20850964},
publisher = {Elsevier Ltd},
title = {{Neural basis of social status hierarchy across species}},
url = {http://dx.doi.org/10.1016/j.conb.2010.08.006},
volume = {20},
year = {2010}
}
@article{Competition2008,
author = {Churchland, Anne K and Ditterich, Jochen},
doi = {10.1016/j.conb.2012.04.009},
file = {:home/kaslu/Documents/Mendeley/2012 - Churchland, Ditterich - New advances in understanding decisions among multiple alternatives.pdf:pdf},
isbn = {1110301197},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
keywords = {aedes aegypti,aedes albopictus,arborvirus model system,indirect effects,mosquitoes,sindbis virus,sinv,susceptibility to infection,trait-mediated effects},
month = {dec},
number = {6},
pages = {920--926},
pmid = {19772347},
title = {{New advances in understanding decisions among multiple alternatives}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438812000670},
volume = {22},
year = {2012}
}
@article{Franke2016,
abstract = {The neural representation of information suffers from "noise"-the trial-to-trial variability in the response of neurons. The impact of correlated noise upon population coding has been debated, but a direct connection between theory and experiment remains tenuous. Here, we substantiate this connection and propose a refined theoretical picture. Using simultaneous recordings from a population of direction-selective retinal ganglion cells, we demonstrate that coding benefits from noise correlations. The effect is appreciable already in small populations, yet it is a collective phenomenon. Furthermore, the stimulus-dependent structure of correlation is key. We develop simple functional models that capture the stimulus-dependent statistics. We then use them to quantify the performance of population coding, which depends upon interplays of feature sensitivities and noise correlations in the population. Because favorable structures of correlation emerge robustly in circuits with noisy, nonlinear elements, they will arise and benefit coding beyond the confines of retina. Coding in the brain suffers from the variability of neural responses. Using experiment and theory, Franke et al. show that this "noise" comes with a particular structure, which emerges from circuit properties and which counteracts the harmful effect of variability.},
annote = {NULL},
author = {Franke, Felix and Fiscella, Michele and Sevelev, Maksim and Roska, Botond and Hierlemann, Andreas and {Azeredo da Silveira}, Rava},
doi = {10.1016/j.neuron.2015.12.037},
file = {:home/kaslu/Documents/Mendeley/2016 - Franke et al. - Structures of Neural Correlation and How They Favor Coding.pdf:pdf},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {2},
pages = {409--422},
pmid = {26796692},
publisher = {Elsevier Inc.},
title = {{Structures of Neural Correlation and How They Favor Coding}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.12.037},
volume = {89},
year = {2016}
}
@article{Okubo2007a,
abstract = {Emergence of hierarchical society is analyzed by use of a simple agent-based model. We extend the mean-field model of Bonabeau et al. [Physica A 217, 373 (1995)] to societies obeying complex diffusion rules where each individual selects a moving direction following their power rankings. We apply this mean-field analysis to the pacifist society model recently investigated by use of Monte Carlo simulation [Physica A 367, 435 (2006)]. We show analytically that the self-organization of hierarchies occurs in two steps as the individual density is increased and there are three phases: one egalitarian and two hierarchical states. We also highlight that the transition from the egalitarian phase to the first hierarchical phase is a continuous change in the order parameter and the second transition causes a discontinuous jump in the order parameter.},
author = {Okubo, Tsuyoshi and Odagaki, Takashi},
doi = {10.1103/PhysRevE.76.036105},
file = {:home/kaslu/Documents/Mendeley/2007 - Okubo, Odagaki - Mean-field analysis of phase transitions in the emergence of hierarchical society.pdf:pdf},
isbn = {1539-3755},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {3},
pages = {1--13},
pmid = {17930304},
title = {{Mean-field analysis of phase transitions in the emergence of hierarchical society}},
volume = {76},
year = {2007}
}
@article{Park2014a,
abstract = {It has been suggested that the lateral intraparietal area (LIP) of macaques plays a fundamental role in sensorimotor decision-making. We examined the neural code in LIP at the level of individual spike trains using a statistical approach based on generalized linear models. We found that LIP responses reflected a combination of temporally overlapping task- and decision-related signals. Our model accounts for the detailed statistics of LIP spike trains and accurately predicts spike trains from task events on single trials. Moreover, we derived an optimal decoder for heterogeneous, multiplexed LIP responses that could be implemented in biologically plausible circuits. In contrast with interpretations of LIP as providing an instantaneous code for decision variables, we found that optimal decoding requires integrating LIP spikes over two distinct timescales. These analyses provide a detailed understanding of neural representations in LIP and a framework for studying the coding of multiplexed signals in higher brain areas.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Park, Il Memming and Meister, Miriam L. and Huk, Alexander C. and Pillow, Jonathan W.},
doi = {10.1038/nn.3800},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2014 - Park et al. - Encoding and decoding in parietal cortex during sensorimotor decision-making.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {1395--1403},
pmid = {25174005},
publisher = {Nature Publishing Group},
title = {{Encoding and decoding in parietal cortex during sensorimotor decision-making}},
url = {http://www.nature.com/doifinder/10.1038/nn.3800},
volume = {17},
year = {2014}
}
@inproceedings{Alamino2006,
abstract = {We present and analyse three online algorithms for learning in discrete Hidden Markov Models (HMMs) and compare them with the Baldi-Chauvin Algorithm. Using the Kullback-Leibler divergence as a measure of generalisation error we draw learning curves in simplified situations. The performance for learning drifting concepts of one of the presented algorithms is analysed and compared with the Baldi-Chauvin algorithm in the same situations. A brief discussion about learning and symmetry breaking based on our results is also presented.},
archivePrefix = {arXiv},
arxivId = {0708.2377},
author = {Alamino, Roberto and Caticha, Nestor},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.2423274},
eprint = {0708.2377},
file = {:home/kaslu/Documents/Mendeley/2006 - Alamino, Caticha - Online Learning in Discrete Hidden Markov Models.pdf:pdf},
issn = {0094243X},
month = {aug},
pages = {187--194},
publisher = {AIP},
title = {{Online Learning in Discrete Hidden Markov Models}},
url = {http://arxiv.org/abs/0708.2377 http://aip.scitation.org/doi/abs/10.1063/1.2423274},
volume = {872},
year = {2006}
}
@article{Solway2015,
author = {Botvinick, Matthew M. and Weinstein, Ari and Solway, Alec and Barto, Andrew},
doi = {10.1016/j.cobeha.2015.08.009},
file = {:home/kaslu/Documents/Mendeley/2015 - Botvinick et al. - Reinforcement learning, efficient coding, and the statistics of natural tasks.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
month = {oct},
pages = {71--77},
title = {{Reinforcement learning, efficient coding, and the statistics of natural tasks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2352154615001151},
volume = {5},
year = {2015}
}
@article{Dunbar2007,
abstract = {The evolution of unusually large brains in some groups of animals, notably primates, has long been a puzzle. Although early explanations tended to emphasize the brain's role in sensory or technical competence (foraging skills, innovations, and way-finding), the balance of evidence now clearly favors the suggestion that it was the computational demands of living in large, complex societies that selected for large brains. However, recent analyses suggest that it may have been the particular demands of the more intense forms of pairbonding that was the critical factor that triggered this evolutionary development. This may explain why primate sociality seems to be so different from that found in most other birds and mammals: Primate sociality is based on bonded relationships of a kind that are found only in pairbonds in other taxa.},
author = {Dunbar, Robin and Shultz, Susanne},
doi = {10.1126/science.1145463},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
keywords = {Animals,Biological Evolution,Birds,Brain,Brain: physiology,Humans,Interpersonal Relations,Mammals,Organ Size,Pair Bond,Primates,Primates: physiology,Social Behavior},
month = {sep},
number = {5843},
pages = {1344--1347},
pmid = {17823343},
title = {{Evolution in the Social Brain}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1145463},
volume = {317},
year = {2007}
}
@article{Ballentine1990,
abstract = {The projection postulate, which prescribes collapse of the state vector upon measurement, is not an essential part of quantum mechanics. Rather it is only an optional discarding of certain branches of the state vector that are expected to be irrelevant for the purpose at hand. However, its use is hazardous, and there are examples of repeated measurements for which the conventional application of the projection postulate leads to incorrect results.},
author = {Ballentine, L. E.},
doi = {10.1007/BF01883489},
file = {:home/kaslu/Documents/Mendeley/1990 - Ballentine - Limitations of the projection postulate.pdf:pdf},
issn = {00159018},
journal = {Foundations of Physics},
number = {11},
pages = {1329--1343},
title = {{Limitations of the projection postulate}},
volume = {20},
year = {1990}
}
@article{Chambers2017,
abstract = {A perceptual phenomenon is reported, whereby prior acoustic context has a large, rapid and long-lasting effect on a basic auditory judgement. Pairs of tones were devised to include ambiguous transitions between frequency components, such that listeners were equally likely to report an upward or downward 'pitch' shift between tones. We show that presenting context tones before the ambiguous pair almost fully determines the perceived direction of shift. The context effect generalizes to a wide range of temporal and spectral scales, encompassing the characteristics of most realistic auditory scenes. Magnetoencephalo-graphic recordings show that a relative reduction in neural responsivity is correlated to the behavioural effect. Finally, a computational model reproduces behavioural results, by implementing a simple constraint of continuity for binding successive sounds in a probabilistic manner. Contextual processing, mediated by ubiquitous neural mechanisms such as adaptation, may be crucial to track complex sound sources over time.},
author = {Chambers, Claire and Akram, Sahar and Adam, Vincent and Pelofi, Claire and Sahani, Maneesh and Shamma, Shihab and Pressnitzer, Daniel},
doi = {10.1038/ncomms15027},
file = {:home/kaslu/Documents/Mendeley/2017 - Chambers et al. - Prior context in audition informs binding and shapes simple features.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
pages = {1--11},
publisher = {Nature Publishing Group},
title = {{Prior context in audition informs binding and shapes simple features}},
url = {http://dx.doi.org/10.1038/ncomms15027},
volume = {8},
year = {2017}
}
@article{Sanzeni2016,
archivePrefix = {arXiv},
arxivId = {1610.04844},
author = {Sanzeni, A and Balasubramanian, Vijay and Tiana, G and Vergassola, Massimo},
doi = {10.1103/PhysRevE.94.062409},
eprint = {1610.04844},
issn = {15502376},
pages = {1--10},
pmid = {28085304},
title = {{Complete coverage of space favors modularity of the grid system in the brain}},
year = {2016}
}
@article{Brush2018,
abstract = {In many biological systems, the functional behavior of a group is collectively computed by the system's in-dividual components. An example is the brain's ability to make decisions via the activity of billions of neu-rons. A long-standing puzzle is how the components' decisions combine to produce beneficial group-level outputs, despite conflicts of interest and imperfect information. We derive a theoretical model of collective computation from mechanistic first principles, using results from previous work on the computation of power structure in a primate model system. Collective computation has two phases: an information accumulation phase, in which (in this study) pairs of individuals gather information about their fighting abilities and make decisions about their dominance relationships, and an information aggregation phase, in which these decisions are combined to produce a collective computation. To model information accumulation, we extend a stochastic decision-making model—the leaky integrator model used to study neural decision-making—to a multiagent game-theoretic framework. We then test alternative algorithms for aggregating information—in this study, decisions about dominance resulting from the stochastic model—and measure the mutual information between the resultant power structure and the " true " fighting abilities. We find that conflicts of interest can improve accuracy to the benefit of all agents. We also find that the computation can be tuned to produce different power structures by changing the cost of waiting for a decision. The successful application of a similar stochastic decision-making model in neural and social contexts suggests general prin-ciples of collective computation across substrates and scales.},
author = {Brush, Eleanor R and Krakauer, David C and Flack, Jessica C},
doi = {10.1126/sciadv.1603311},
file = {:home/kaslu/Documents/Mendeley/2018 - Brush, Krakauer, Flack - Conflicts of interest improve collective computation of adaptive social structures.pdf:pdf},
issn = {2375-2548},
journal = {Science Advances},
month = {jan},
number = {1},
pages = {e1603311},
title = {{Conflicts of interest improve collective computation of adaptive social structures}},
url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.1603311},
volume = {4},
year = {2018}
}
@article{Sadeh2016,
abstract = {For decades, there has been controversy about whether forgetting is caused by decay over time or by interference from irrelevant information. We suggest that forgetting occurs because of decay or interference, depending on the memory representation. Recollection-based memories, supported by the hippocampus, are represented in orthogonal patterns and are therefore relatively resistant to interference from one another. Decay should be a major source of their forgetting. By contrast, familiarity-based memories, supported by extrahippocampal structures, are not represented in orthogonal patterns and are therefore sensitive to interference. In a study in which we manipulated the postencoding task-interference level and the length of the delay between study and testing, we provide direct evidence in support of our representation theory of forgetting. Recollection and familiarity were measured using the remember/know procedure. We show that the causes of forgetting depend on the nature of the underlying memory representation, which places the century-old puzzle of forgetting in a coherent framework.},
author = {Sadeh, Talya and Ozubko, Jason D. and Winocur, Gordon and Moscovitch, Morris},
doi = {10.1177/0956797616638307},
issn = {0956-7976, 1467-9280},
journal = {Psychological Science},
keywords = {11,14,16,18,cognitive neuroscience,episodic memory,forgetting,memory,open materials,preregistered,received 7,revision accepted 2,this question has challenged,what causes forgetting},
pages = {0956797616638307},
pmid = {27154552},
title = {{Forgetting Patterns Differentiate Between Two Forms of Memory Representation}},
url = {http://pss.sagepub.com.proxy.libraries.smu.edu/content/early/2016/05/06/0956797616638307{\%}5Cnhttp://pss.sagepub.com.proxy.libraries.smu.edu/content/early/2016/05/06/0956797616638307.full.pdf{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/27154552},
year = {2016}
}
@article{Peixoto2017,
abstract = {A principled approach to characterize the hidden structure of networks is to formulate generative models, and then infer their parameters from data. When the desired structure is composed of modules or "communities", a suitable choice for this task is the stochastic block model (SBM), where nodes are divided into groups, and the placement of edges is conditioned on the group memberships. Here, we present a nonparametric Bayesian method to infer the modular structure of empirical networks, including the number of modules and their hierarchical organization. We focus on a microcanonical variant of the SBM, where the structure is imposed via hard constraints, i.e. the generated networks are not allowed to violate the patterns imposed by the model. We show how this simple model variation allows simultaneously for two important improvements over more traditional inference approaches: 1. Deeper Bayesian hierarchies, with noninformative priors replaced by sequences of priors and hyperpriors, that not only remove limitations that seriously degrade the inference on large networks, but also reveal structures at multiple scales; 2. A very efficient inference algorithm that scales well not only for networks with a large number of nodes and edges, but also with an unlimited number of modules. We show also how this approach can be used to sample modular hierarchies from the posterior distribution, as well as to perform model selection. We discuss and analyze the differences between sampling from the posterior and simply finding the single parameter estimate that maximizes it. Furthermore, we expose a direct equivalence between our microcanonical approach and alternative derivations based on the canonical SBM.},
archivePrefix = {arXiv},
arxivId = {1610.02703},
author = {Peixoto, Tiago P.},
doi = {10.1103/PhysRevE.95.012317},
eprint = {1610.02703},
file = {:home/kaslu/Documents/Mendeley/2017 - Peixoto - Nonparametric Bayesian inference of the microcanonical stochastic block model.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {012317},
title = {{Nonparametric Bayesian inference of the microcanonical stochastic block model}},
url = {http://arxiv.org/abs/1610.02703 http://dx.doi.org/10.1103/PhysRevE.95.012317 http://link.aps.org/doi/10.1103/PhysRevE.95.012317},
volume = {95},
year = {2017}
}
@article{Gelfand2011,
author = {Gelfand, Michele J. and Raver, J. L. and Nishii, L. and Leslie, L. M. and Lun, J. and Lim, B. C. and Duan, L. and Almaliach, A. and Ang, S. and Arnadottir, J. and Aycan, Z. and Boehnke, K. and Boski, P. and Cabecinhas, R. and Chan, D. and Chhokar, J. and D'Amato, A. and Ferrer, M. and Fischlmayr, I. C. and Fischer, R. and Fulop, M. and Georgas, J. and Kashima, E. S. and Kashima, Y. and Kim, K. and Lempereur, A. and Marquez, P. and Othman, R. and Overlaet, B. and Panagiotopoulou, P. and Peltzer, K. and Perez-Florizno, L. R. and Ponomarenko, L. and Realo, A. and Schei, V. and Schmitt, M. and Smith, P. B. and Soomro, N. and Szabo, E. and Taveesin, N. and Toyama, M. and {Van de Vliert}, E. and Vohra, N. and Ward, C. and Yamaguchi, S.},
doi = {10.1126/science.1197754},
file = {:home/kaslu/Documents/Mendeley/2011 - Gelfand et al. - Differences Between Tight and Loose Cultures A 33-Nation Study(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2011 - Gelfand et al. - Differences Between Tight and Loose Cultures A 33-Nation Study.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {may},
number = {6033},
pages = {1100--1104},
title = {{Differences Between Tight and Loose Cultures: A 33-Nation Study}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1197754},
volume = {332},
year = {2011}
}
@article{Lake2017,
abstract = {Humans can understand and produce new utterances effortlessly, thanks to their systematic compositional skills. Once a person learns the meaning of a new verb "dax," he or she can immediately understand the meaning of "dax twice" or "sing and dax." In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can generalize well when the differences between training and test commands are small, so that they can apply "mix-and-match" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the "dax" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, supporting the conjecture that lack of systematicity is an important factor explaining why neural networks need very large training sets.},
archivePrefix = {arXiv},
arxivId = {1711.00350},
author = {Lake, Brenden M. and Baroni, Marco},
eprint = {1711.00350},
file = {:home/kaslu/Documents/Mendeley/2017 - Lake, Baroni - Still not systematic after all these years On the compositional skills of sequence-to-sequence recurrent networks.pdf:pdf},
title = {{Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks}},
url = {http://arxiv.org/abs/1711.00350},
year = {2017}
}
@article{Janoff-Bulman2016,
abstract = {Two studies explored the relationship between political ideology and endorsement of a range of moral principles. Political liberals and conservatives did not differ on intrapersonal or interpersonal moralities, which require self-regulation. However differences emerged on collective moralities, which involve social regulation. Contrary to Moral Foundations Theory, both liberals and conservatives endorsed a group-focused binding morality, specifically Social Justice and Social Order respectively. Libertarians were the group without a binding morality. Although Social Justice and Social Order appear conflictual, analyses based on earlier cross-cultural work on societal tightness-looseness suggest that countries actually benefit in terms of economic success and societal well-being when these group-based moralities co-exist and serve as counterweights in social regulation.},
author = {Janoff-Bulman, Ronnie and Carnes, Nate C},
doi = {10.1371/journal.pone.0152479},
editor = {Zia, Asim},
file = {:home/kaslu/Documents/Mendeley/2016 - Janoff-Bulman, Carnes - Social Justice and Social Order Binding Moralities across the Political Spectrum.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
month = {mar},
number = {3},
pages = {e0152479},
title = {{Social Justice and Social Order: Binding Moralities across the Political Spectrum}},
url = {http://dx.plos.org/10.1371/journal.pone.0152479},
volume = {11},
year = {2016}
}
@article{Jaynes1980,
author = {Jaynes, Edwin T.},
doi = {10.1146/annurev.pc.31.100180.003051},
issn = {0066-426X},
journal = {Annual Review of Physical Chemistry},
month = {oct},
number = {1},
pages = {579--601},
title = {{The Minimum Entropy Production Principle}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.pc.31.100180.003051},
volume = {31},
year = {1980}
}
@article{Mease2017,
abstract = {High-frequency “burst” clusters of spikes are a generic output pattern of many neurons. While bursting is a ubiquitous computational feature of different nervous systems across animal species, the encoding of synaptic inputs by bursts is not well understood. We find that bursting neurons in the rodent thalamus employ “multiplexing” to differentially encode low- and high-frequency stimulus features associated with either T-type calcium “low-threshold” or fast sodium spiking events, respectively, and these events adapt differently. Thus, thalamic bursts encode disparate information in three channels: (1) burst size, (2) burst onset time, and (3) precise spike timing within bursts. Strikingly, this latter “intraburst” encoding channel shows millisecond-level feature selectivity and adapts across statistical contexts to maintain stable information encoded per spike. Consequently, calcium events both encode low-frequency stimuli and, in parallel, gate a transient window for high-frequency, adaptive stimulus encoding by sodium spike timing, allowing bursts to efficiently convey fine-scale temporal information.},
author = {Mease, Rebecca A. and Kuner, Thomas and Fairhall, Adrienne L. and Groh, Alexander},
doi = {10.1016/j.celrep.2017.04.050},
file = {:home/kaslu/Documents/Mendeley/2017 - Mease et al. - Multiplexed Spike Coding and Adaptation in the Thalamus.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {T-type calcium channel,adaptation,bursting,excitability,linear-nonlinear model,multiplexing,neural coding,thalamocortical system},
number = {6},
pages = {1130--1140},
pmid = {28494863},
publisher = {ElsevierCompany.},
title = {{Multiplexed Spike Coding and Adaptation in the Thalamus}},
url = {http://dx.doi.org/10.1016/j.celrep.2017.04.050},
volume = {19},
year = {2017}
}
@article{Hass2016,
author = {Hass, Joachim and Durstewitz, Daniel},
file = {:home/kaslu/Documents/Mendeley/2016 - Hass, Durstewitz - Time at the center, or time at the side Assessing current models of time perception.pdf:pdf},
journal = {Current Opinion in Behavioral Sciences},
title = {{Time at the center, or time at the side? Assessing current models of time perception}},
year = {2016}
}
@article{Machens2017,
author = {Machens, Christian and Fairhall, Adrienne},
doi = {10.1016/j.conb.2017.09.009},
file = {:home/kaslu/Documents/Mendeley/2017 - Machens, Fairhall - Editorial overview Computational neuroscience.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
publisher = {Elsevier Ltd},
title = {{Editorial overview: Computational neuroscience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438817302362},
year = {2017}
}
@article{Collett2016,
author = {Steveninck, R. D. R. V. and Bialek, William},
doi = {10.1098/rstb.1995.0071},
file = {:home/kaslu/Documents/Mendeley/1995 - Steveninck, Bialek - Reliability and Statistical Efficiency of a Blowfly Movement-Sensitive Neuron.pdf:pdf;:home/kaslu/Documents/Mendeley/1995 - Steveninck, Bialek - Reliability and Statistical Efficiency of a Blowfly Movement-Sensitive Neuron(2).pdf:pdf},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
month = {may},
number = {1325},
pages = {321--340},
title = {{Reliability and Statistical Efficiency of a Blowfly Movement-Sensitive Neuron}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.1995.0071},
volume = {348},
year = {1995}
}
@article{Pearce1980,
abstract = {Several formal models of excitatory classical conditioning are reviewed. It is suggested that a central problem for all of them is the explanation of cases in which learning does not occur in spite of the fact that the conditioned stimulus is a signal for the reinforcer. We propose a new model that deals with this problem by specifying that certain procedures cause a conditioned stimulus (CS) to lose effectiveness; in particular, we argue that a CS will lose associ-ability when its consequences are accurately predicted. In contrast to other current models, the effectiveness of the reinforcer remains constant throughout conditioning. The second part of the article presents a reformulation of the nature of the learning produced by inhibitory-conditioning procedures and a discussion of the way in which such learning can be accommodated within the model outlined for excitatory learning.},
author = {Pearce, John M. and Hall, Geoffrey},
doi = {10.1037/0033-295X.87.6.532},
file = {:home/kaslu/Documents/Mendeley/1980 - Pearce, Hall - A model for Pavlovian learning Variations in the effectiveness of conditioned but not of unconditioned stimuli.pdf:pdf},
isbn = {1939-1471 (Electronic); 0033-295X (Print)},
issn = {0033-295X},
journal = {Psychological Review},
number = {6},
pages = {532--552},
pmid = {7443916},
title = {{A model for Pavlovian learning: Variations in the effectiveness of conditioned but not of unconditioned stimuli.}},
url = {http://content.apa.org/journals/rev/87/6/532},
volume = {87},
year = {1980}
}
@article{Kording2007,
abstract = {Perceptual events derive their significance to an animal from their meaning about the world, that is from the information they carry about their causes. The brain should thus be able to efficiently infer the causes underlying our sensory events. Here we use multisensory cue combination to study causal inference in perception. We formulate an ideal-observer model that infers whether two sensory cues originate from the same location and that also estimates their location(s). This model accurately predicts the nonlinear integration of cues by human subjects in two auditory-visual localization tasks. The results show that indeed humans can efficiently infer the causal structure as well as the location of causes. By combining insights from the study of causal inference with the ideal-observer approach to sensory cue combination, we show that the capacity to infer causal structure is not limited to conscious, high-level cognition; it is also performed continually and effortlessly in perception.},
author = {K{\"{o}}rding, Konrad P. and Beierholm, Ulrik and Ma, Wei Ji and Quartz, Steven and Tenenbaum, Joshua B. and Shams, Ladan},
doi = {10.1371/journal.pone.0000943},
file = {:home/kaslu/Documents/Mendeley/2007 - K{\"{o}}rding et al. - Causal inference in multisensory perception.PDF:PDF},
isbn = {1932-6203 (Electronic)},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pmid = {17895984},
title = {{Causal inference in multisensory perception}},
volume = {2},
year = {2007}
}
@article{Mora2010,
abstract = {Recognition of pathogens relies on families of proteins showing great diversity. Here we construct maximum entropy models of the sequence repertoire, building on recent experiments that provide a nearly exhaustive sampling of the IgM sequences in zebrafish. These models are based solely on pairwise correlations between residue positions but correctly capture the higher order statistical properties of the repertoire. By exploiting the interpretation of these models as statistical physics problems, we make several predictions for the collective properties of the sequence ensemble: The distribution of sequences obeys Zipf's law, the repertoire decomposes into several clusters, and there is a massive restriction of diversity because of the correlations. These predictions are completely inconsistent with models in which amino acid substitutions are made independently at each site and are in good agreement with the data. Our results suggest that antibody diversity is not limited by the sequences encoded in the genome and may reflect rapid adaptation to antigenic challenges. This approach should be applicable to the study of the global properties of other protein families.},
archivePrefix = {arXiv},
arxivId = {0912.5175},
author = {Mora, Thierry and Walczak, Aleksandra M and Bialek, William and Callan, Curtis G},
doi = {10.1073/pnas.1001705107},
eprint = {0912.5175},
file = {:home/kaslu/Documents/Mendeley/2010 - Mora et al. - Maximum entropy models for antibody diversity.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Amino Acid Sequence,Animals,Antibody Diversity,Base Sequence,Biophysical Phenomena,DNA,DNA: chemistry,DNA: genetics,Entropy,Evolution,Immunoglobulin M,Immunoglobulin M: chemistry,Immunoglobulin M: genetics,Immunological,Models,Molecular,Zebrafish,Zebrafish Proteins,Zebrafish Proteins: chemistry,Zebrafish Proteins: genetics,Zebrafish: genetics,Zebrafish: immunology},
month = {mar},
number = {12},
pages = {5405--5410},
pmid = {20212159},
title = {{Maximum entropy models for antibody diversity}},
url = {http://arxiv.org/abs/0912.5175 http://www.pnas.org/cgi/doi/10.1073/pnas.1001705107},
volume = {107},
year = {2010}
}
@article{Doiron2016,
abstract = {Simultaneous recordings from large neural populations are becoming increasingly common. An important feature of population activity is the trial-to-trial correlated fluctuation of spike train outputs from recorded neuron pairs. Similar to the firing rate of single neurons, correlated activity can be modulated by a number of factors, from changes in arousal and attentional state to learning and task engagement. However, the physiological mechanisms that underlie these changes are not fully understood. We review recent theoretical results that identify three separate mechanisms that modulate spike train correlations: changes in input correlations, internal fluctuations and the transfer function of single neurons. We first examine these mechanisms in feedforward pathways and then show how the same approach can explain the modulation of correlations in recurrent networks. Such mechanistic constraints on the modulation of population activity will be important in statistical analyses of high-dimensional neural data.},
author = {Doiron, Brent and Litwin-Kumar, Ashok and Rosenbaum, Robert and Ocker, Gabriel K and Josi{\'{c}}, Kre{\v{s}}imir},
doi = {10.1038/nn.4242},
file = {:home/kaslu/Documents/Mendeley/2016 - Doiron et al. - The mechanics of state-dependent neural correlations.pdf:pdf},
isbn = {1097-6256$\backslash$r1546-1726},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {383--393},
pmid = {26906505},
title = {{The mechanics of state-dependent neural correlations}},
url = {http://www.nature.com/doifinder/10.1038/nn.4242},
volume = {19},
year = {2016}
}
@article{BARTLETT2006,
abstract = {A controversy that has arisen many times over in disparate contexts is whether quantum coherences between eigenstates of certain quantities are fact or fiction. We present a pedagogical introduction to the debate in the form of a hypothetical dialogue between proponents from each of the two camps: a factist and a fictionist. A resolution of the debate can be achieved, we argue, by recognizing that quantum states do not only contain information about the intrinsic properties of a system but about its extrinsic properties as well, that is, about its relation to other systems external to it. Specifically, the coherent quantum state of the factist is the appropriate description of the relation of the system to one reference frame, while the incoherent quantum state of the fictionist is the appropriate description of the relation of the system to another, uncorrelated, reference frame. The two views, we conclude, are alternative but equally valid paradigms of description.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0507214},
author = {Bartlett, Stephen D. and Rudolph, Terry and Spekkens, Robert W.},
doi = {10.1142/S0219749906001591},
eprint = {0507214},
file = {:home/kaslu/Documents/Mendeley/2005 - Bartlett, Rudolph, Spekkens - Dialogue Concerning Two Views on Quantum Coherence Factist and Fictionist.pdf:pdf},
issn = {0219-7499},
journal = {International Journal of Quantum Information},
month = {jul},
number = {01},
pages = {17--43},
primaryClass = {quant-ph},
title = {{Dialogue Concerning Two Views on Quantum Coherence: Factist and Fictionist}},
url = {http://arxiv.org/abs/quant-ph/0507214 http://dx.doi.org/10.1142/S0219749906001591 http://www.worldscientific.com/doi/abs/10.1142/S0219749906001591},
volume = {04},
year = {2005}
}
@article{Navajas2017,
abstract = {Confidence is the ‘feeling of knowing' that accompanies decision-making. Bayesian theory proposes that confidence is a function solely of the perceived probability of being correct. Empirical research has suggested, however, that different individuals may perform different computations to estimate confidence from uncertain evidence. To test this hypothesis, we collected confidence reports in a task in which subjects made categorical decisions about the mean of a sequence. We found that for most individuals, confidence did indeed reflect the perceived probability of being correct. However, in approximately half of them, confidence also reflected a different probabilistic quantity: the perceived uncertainty in the estimated variable. We found that the contribution of both quantities was stable over weeks. We also observed that the influence of the perceived probability of being correct was stable across two tasks, one perceptual and one cognitive. Overall, our findings provide a computational interpretation of individual differences in human confidence. Using behavioural experiments and computational modelling, Navajas and colleagues provide a systematic characterization of individual differences in human confidence.},
author = {Navajas, Joaquin and Hindocha, Chandni and Foda, Hebah and Keramati, Mehdi and Latham, Peter E. and Bahrami, Bahador},
doi = {10.1038/s41562-017-0215-1},
file = {:home/kaslu/Documents/Mendeley/2017 - Navajas et al. - The idiosyncratic nature of confidence.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
keywords = {Behavioral Sciences,Experimental Psychology,Life Sciences,Microeconomics,Neurosciences,Personality and Social Psychology,general},
month = {nov},
number = {11},
pages = {810--818},
publisher = {Nature Publishing Group},
title = {{The idiosyncratic nature of confidence}},
url = {http://www.nature.com/articles/s41562-017-0215-1},
volume = {1},
year = {2017}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories - optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.02142v2},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
eprint = {arXiv:1507.02142v2},
file = {:home/kaslu/Documents/Mendeley/2010 - Friston - The free-energy principle a unified brain theory.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
number = {2},
pages = {127--138},
pmid = {20068583},
publisher = {Nature Publishing Group},
title = {{The free-energy principle: a unified brain theory?}},
url = {http://www.nature.com/doifinder/10.1038/nrn2787},
volume = {11},
year = {2010}
}
@article{Realo2015,
abstract = {The importance of tightness-looseness as a dimension that explains a considerable amount of variance between cultures was demonstrated by Gelfand et al. (2011). Tight nations have many strong norms and a low tolerance of deviant behaviour, whereas loose nations have weak social norms and a high tolerance of deviant behaviour. The main aim of the current studies was to examine situational constraint in Estonia and Greece: that is, how the cultural dimension of tightness-looseness is manifested in everyday situations in those two countries. The findings of a questionnaire study (Study 1) suggested that, in general, there is higher constraint across everyday situations in Greece than in Estonia, but situational constraint in Greece is especially strong in school and organisational settings where people have hierarchically structured roles. The results of an observational study (Study 2) revealed a relatively high agreement between appropriateness of certain behaviours as judged by the respondents in Study 1 and the frequencies of observed behaviours in the two countries. Our findings suggest that the strength of situations may substantially vary both within and across cultures, and that the attitudes of the members about situational strength in their respective cultures are in concordance with observations of situations by neutral observers in how people in general behave in their culture.},
author = {Realo, Anu and Linnam{\"{a}}gi, Karmen and Gelfand, Michele J.},
doi = {10.1002/ijop.12097},
issn = {00207594},
journal = {International Journal of Psychology},
keywords = {Cultural dimensions,Situational constraint,Tightness-looseness},
month = {jun},
number = {3},
pages = {193--204},
pmid = {25130924},
title = {{The cultural dimension of tightness-looseness: An analysis of situational constraint in Estonia and Greece}},
url = {http://doi.wiley.com/10.1002/ijop.12097},
volume = {50},
year = {2015}
}
@article{Borondo2014,
abstract = {A system is said to be meritocratic if the compensation and power available to individuals is determined by their abilities and merits. A system is topocratic if the compensation and power available to an individual is determined primarily by her position in a network. Here we introduce a model that is perfectly meritocratic for fully connected networks but that becomes topocratic for sparse networks-like the ones in society. In the model, individuals produce and sell content, but also distribute the content produced by others when they belong to the shortest path connecting a buyer and a seller. The production and distribution of content defines two channels of compensation: a meritocratic channel, where individuals are compensated for the content they produce, and a topocratic channel, where individual compensation is based on the number of shortest paths that go through them in the network. We solve the model analytically and show that the distribution of payoffs is meritocratic only if the average degree of the nodes is larger than a root of the total number of nodes. We conclude that, in the light of this model, the sparsity and structure of networks represents a fundamental constraint to the meritocracy of societies.},
author = {Borondo, J and Borondo, F and Rodriguez-Sickert, Carlos and Hidalgo, C a},
doi = {10.1038/srep03784},
file = {:home/kaslu/Documents/Mendeley/2014 - Borondo et al. - To each according to its degree the meritocracy and topocracy of embedded markets.pdf:pdf},
issn = {2045-2322},
journal = {Scientific reports},
month = {jan},
pages = {3784},
pmid = {24445533},
title = {{To each according to its degree: the meritocracy and topocracy of embedded markets.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3896904{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2014}
}
@article{Bollimunta2012a,
abstract = {To investigate the contribution of parietal cortex to perceptual decisions, we trained monkeys on a perceptual decision task that allowed simultaneous experimental control over how much sensory evidence was provided for each of 3 possible alternative choices and recorded single unit activity and local field potentials (LFPs) from the lateral intraparietal area (LIP). While both the behavior and the spiking activity were largely determined by the difference between how much supporting sensory evidence was provided for a particular choice (pro evidence) and how much sensory evidence was provided for the other alternatives (anti evidence), the LFP reflected roughly the sum of these 2 components. Furthermore, the firing rates showed an earlier influence of the anti evidence than the pro evidence. These observations indicate that LIP does not simply receive already precomputed decision signals but that it plays an active role in computing the decision-relevant net sensory evidence and that this local computation is reflected in the LFP. The results further demonstrate that the competition between the different alternatives cannot solely be mediated by lateral or feedback inhibition, as proposed by a major class of decision models but that feedforward inhibition makes an important contribution.},
author = {Bollimunta, Anil and Ditterich, Jochen},
doi = {10.1093/cercor/bhr165},
file = {:home/kaslu/Documents/Mendeley/2012 - Bollimunta, Ditterich - Local computation of decision-relevant net sensory evidence in parietal cortex.pdf:pdf},
isbn = {1460-2199 (Electronic)$\backslash$n1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {LIP,decision mechanism,feedforward inhibition,local field potential,perceptual decision making},
number = {4},
pages = {903--917},
pmid = {21709177},
title = {{Local computation of decision-relevant net sensory evidence in parietal cortex}},
volume = {22},
year = {2012}
}
@article{Runyan2017,
abstract = {The cortex represents information across widely varying timescales 1–5 . For instance, sensory cortex encodes stimuli that fluctuate over few tens of milliseconds 6,7 , whereas in association cortex behavioural choices can require the maintenance of information over seconds 8,9 . However, it remains poorly understood whether diverse timescales result mostly from features intrinsic to individual neurons or from neuronal population activity. This question remains unanswered, because the timescales of coding in populations of neurons have not been studied extensively, and population codes have not been compared systematically across cortical regions. Here we show that population codes can be essential to achieve long coding timescales. Furthermore, we find that the properties of population codes differ between sensory and association cortices. We compared coding for sensory stimuli and behavioural choices in auditory cortex and posterior parietal cortex as mice performed a sound localization task. Auditory stimulus information was stronger in auditory cortex than in posterior parietal cortex, and both regions contained choice information. Although auditory cortex and posterior parietal cortex coded information by tiling in time neurons that were transiently informative for approximately 200 milliseconds, the areas had major differences in functional coupling between neurons, measured as activity correlations that could not be explained by task events. Coupling among posterior parietal cortex neurons was strong and extended over long time lags, whereas coupling among auditory cortex neurons was weak and short-lived. Stronger coupling in posterior parietal cortex led to a population code with long timescales and a representation of choice that remained consistent for approximately 1 second. In contrast, auditory cortex had a code with rapid fluctuations in stimulus and choice information over hundreds of milliseconds. Our results reveal that population codes differ across cortex and that coupling is a variable property of cortical populations that affects the timescale of information coding and the accuracy of behaviour. The goal of this work was to compare coding across cortical regions for two key features of behavioural tasks: stimulus and choice. We developed a sound localization task in which mice reported percep-tual decisions by navigating through a visual virtual reality T-maze 10 (Fig. 1a). As mice ran down the T-stem, a sound cue was played from one of eight possible locations in head-centred, real-world coordinates. Mice reported whether the sound originated from their left or right by turning in that direction at the T-intersection (Fig. 1b, c). We focused on auditory cortex (AC), because it is necessary for sound localization tasks 11},
author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
doi = {10.1038/nature23020},
file = {:home/kaslu/Documents/Mendeley/2017 - Runyan et al. - Distinct timescales of population coding across cortex.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
pmid = {28723889},
title = {{Distinct timescales of population coding across cortex}},
year = {2017}
}
@article{Short2008,
abstract = {Motivated by empirical observations of spatio-temporal clusters of crime across a wide variety of urban settings, we present a model to study the emergence, dynamics, and steady-state properties of crime hotspots. We focus on a two-dimensional lattice model for residential burglary, where each site is characterized by a dynamic attractiveness variable, and where each criminal is represented as a random walker. The dynamics of criminals and of the attractiveness field are coupled to each other via specific biasing and feedback mechanisms. Depending on parameter choices, we observe and describe several regimes of aggregation, including hotspots of high criminal activity. On the basis of the discrete system, we also derive a continuum model; the two are in good quantitative agreement for large system sizes. By means of a linear stability analysis we are able to determine the parameter values that will lead to the creation of stable hotspots. We discuss our model and results in the context of established criminological and sociological findings of criminal behavior.},
author = {Short, M B and D'Orsogna, M B and Pasqour, V B and Tita, G B and Brantingham, P J and Bertozzi, A L and Chayes, L B},
doi = {10.1142/S0218202508003029},
isbn = {0218-2025},
issn = {0218-2025},
journal = {Mathematical Models and Methods in Applied Sciences},
keywords = {35Q80,70K99,Crime models,linear stability AMS Subject Classification,reaction-diffusion equations},
pages = {1249--1267},
title = {{A Statistical Model of Criminal Behavior}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218202508003029},
volume = {18, Suppl.},
year = {2008}
}
@article{Gelfand2001,
abstract = {This article integrates theory from the cognitive tradition in negotiation with theory on culture and examines cultural influences on cognitive representations of conflict. The authors predicted that although there may be universal (etic) dimensions of conflict construals, there also may be culture-specific (emic) representations of conflict in the United States and Japan. Results of multidimensional scaling analyses of U.S. and Japanese conflict episodes supported this view. Japanese and Americans construed conflicts through a compromise versus win frame (R. L. Pinkley, 1990), providing evidence of a universal dimension of conflict construal. As the authors predicted, Japanese perceived conflicts to be more compromise-focused, as compared with Americans. There were also unique dimensions of construal among Americans and Japanese (infringements to self and giri violations, respectively), suggesting that identical conflict episodes are perceived differently across cultures. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Gelfand, Michele J. and Nishii, Lisa H and Holcombe, Karen M and Dyer, Naomi and Ohbuchi, Ken-Ichi and Fukuno, Mitsuteru},
doi = {10.1037/0021-9010.86.6.1059},
isbn = {1939-1854(Electronic);0021-9010(Print)},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
keywords = {*Attitudes,*Cognitive Processes,*Conflict,*Cross Cultural Differences,*Sociocultural Factors,Concepts},
number = {6},
pages = {1059--1074},
pmid = {11768050},
title = {{Cultural influences on cognitive representations of conflict: Interpretations of conflict episodes in the United States and Japan.}},
volume = {86},
year = {2001}
}
@article{Meshulam2016,
abstract = {Discussions of the hippocampus often focus on place cells, but many neurons are not place cells in any given environment. Here we describe the collective activity in such mixed populations, treating place and non-place cells on the same footing. We start with optical imaging experiments on CA1 in mice as they run along a virtual linear track, and use maximum entropy methods to approximate the distribution of patterns of activity in the population, matching the correlations between pairs of cells but otherwise assuming as little structure as possible. We find that these simple models accurately predict the activity of each neuron from the state of all the other neurons in the network, regardless of how well that neuron codes for position. These and other results suggest that place cells are not a distinct sub-network, but part of a larger system that encodes, collectively, more than just place information.},
archivePrefix = {arXiv},
arxivId = {1612.08935},
author = {Meshulam, Leenoy and Gauthier, Jeffrey L. and Brody, Carlos D. and Tank, David W. and Bialek, William},
eprint = {1612.08935},
file = {:home/kaslu/Documents/Mendeley/2016 - Meshulam et al. - Collective behavior of place and non-place neurons in the hippocampal network.pdf:pdf},
journal = {Neurons {\&} Cognition},
month = {dec},
pages = {1--17},
title = {{Collective behavior of place and non-place neurons in the hippocampal network}},
url = {http://arxiv.org/abs/1612.08935},
year = {2016}
}
@article{Piantadosi2016,
abstract = {SignificanceOne mystery of human evolution is why our cognition differs qualitatively from our closest evolutionary relatives. Here we show how natural selection for large brains may lead to premature newborns, which themselves require more intelligence to raise, and thus may select for even larger brains. As we show, these dynamics can be self-reinforcing and lead to runaway selection for extremely high intelligence and helpless newborns. We test a prediction of this account: the helplessness of a primates newborns should strongly predict their intelligence. We show that this is so and relate our account to theories of human uniqueness and the question of why human-level intelligence took so long to evolve in the history of life. We present evidence that pressures for early childcare may have been one of the driving factors of human evolution. We show through an evolutionary model that runaway selection for high intelligence may occur when (i) altricial neonates require intelligent parents, (ii) intelligent parents must have large brains, and (iii) large brains necessitate having even more altricial offspring. We test a prediction of this account by showing across primate genera that the helplessness of infants is a particularly strong predictor of the adults intelligence. We discuss related implications, including this accounts ability to explain why human-level intelligence evolved specifically in mammals. This theory complements prior hypotheses that link human intelligence to social reasoning and reproductive pressures and explains how human intelligence may have become so distinctive compared with our closest evolutionary relatives.},
author = {Piantadosi, Steven T. and Kidd, Celeste},
doi = {10.1073/pnas.1506752113},
file = {:home/kaslu/Documents/Mendeley/2016 - Piantadosi, Kidd - Extraordinary intelligence and the care of infants.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {may},
pages = {201506752},
title = {{Extraordinary intelligence and the care of infants}},
url = {http://www.pnas.org/content/early/2016/05/18/1506752113.short},
year = {2016}
}
@article{Norman1994,
abstract = {We define the relevant information in a signal {\$}x\backslashin X{\$} as being the information that this signal provides about another signal {\$}y\backslashin \backslashY{\$}. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal {\$}x{\$} requires more than just predicting {\$}y{\$}, it also requires specifying which features of {\$}\backslashX{\$} play a role in the prediction. We formalize this problem as that of finding a short code for {\$}\backslashX{\$} that preserves the maximum information about {\$}\backslashY{\$}. That is, we squeeze the information that {\$}\backslashX{\$} provides about {\$}\backslashY{\$} through a `bottleneck' formed by a limited set of codewords {\$}\backslashtX{\$}. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure {\$}d(x,\backslashx){\$} emerges from the joint statistics of {\$}\backslashX{\$} and {\$}\backslashY{\$}. This approach yields an exact set of self consistent equations for the coding rules {\$}X \backslashto \backslashtX{\$} and {\$}\backslashtX \backslashto \backslashY{\$}. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.},
archivePrefix = {arXiv},
arxivId = {physics/0004057},
author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
eprint = {0004057},
file = {:home/kaslu/Documents/Mendeley/2000 - Tishby, Pereira, Bialek - The information bottleneck method.pdf:pdf},
journal = {VINE},
month = {apr},
number = {3},
pages = {3--6},
primaryClass = {physics},
title = {{The information bottleneck method}},
url = {http://arxiv.org/abs/physics/0004057},
volume = {24},
year = {2000}
}
@article{Cialdini2004,
abstract = {This review covers recent developments in the social influence literature, focusing primarily on compliance and conformity research published between 1997 and 2002. The principles and processes underlying a target's susceptibility to outside influences are considered in light of three goals fundamental to rewarding human functioning. Specifically, targets are motivated to form accurate perceptions of reality and react accordingly, to develop and preserve meaningful social relationships, and to maintain a favorable self-concept. Consistent with the current movement in compliance and conformity research, this review emphasizes the ways in which these goals interact with external forces to engender social influence processes that are subtle, indirect, and outside of awareness.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cialdini, Robert B. and Goldstein, Noah J.},
doi = {10.1146/annurev.psych.55.090902.142015},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2004 - Cialdini, Goldstein - Social Influence Compliance and Conformity.pdf:pdf},
isbn = {0066-4308},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {1997 and 2002,and conformity research published,ature,between,covers recent developments in,door-in-the-face,focusing primarily on compliance,foot-in-the-door,motivation,norms,obedience,s abstract this review,s susceptibility to out-,the principles and processes,the social influence liter-,underlying a target},
number = {1},
pages = {591--621},
pmid = {14744228},
title = {{Social Influence: Compliance and Conformity}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.psych.55.090902.142015},
volume = {55},
year = {2004}
}
@article{Motesharrei2014,
abstract = {There are widespread concerns that current trends in resource-use are unsustainable, but possibilities of overshoot/collapse remain controversial. Collapses have occurred frequently in history, often followed by centuries of economic, intellectual, and population decline. Many different natural and social phenomena have been invoked to explain specific collapses, but a general explanation remains elusive.In this paper, we build a human population dynamics model by adding accumulated wealth and economic inequality to a predator-prey model of humans and nature. The model structure, and simulated scenarios that offer significant implications, are explained. Four equations describe the evolution of Elites, Commoners, Nature, and Wealth. The model shows Economic Stratification or Ecological Strain can independently lead to collapse, in agreement with the historical record.The measure "Carrying Capacity" is developed and its estimation is shown to be a practical means for early detection of a collapse. Mechanisms leading to two types of collapses are discussed. The new dynamics of this model can also reproduce the irreversible collapses found in history. Collapse can be avoided, and population can reach a steady state at maximum carrying capacity if the rate of depletion of nature is reduced to a sustainable level and if resources are distributed equitably. ?? 2014.},
author = {Motesharrei, Safa and Rivas, Jorge and Kalnay, Eugenia},
doi = {10.1016/j.ecolecon.2014.02.014},
file = {:home/kaslu/Documents/Mendeley/2014 - Motesharrei, Rivas, Kalnay - Human and nature dynamics (HANDY) Modeling inequality and use of resources in the collapse or sustai.pdf:pdf},
isbn = {0921-8009},
issn = {09218009},
journal = {Ecological Economics},
keywords = {Carrying capacity,Ecological strain,Economic inequality,Human-nature dynamics,Overshoot vs. sustainability,Societal collapse},
pages = {90--102},
publisher = {Elsevier B.V.},
title = {{Human and nature dynamics (HANDY): Modeling inequality and use of resources in the collapse or sustainability of societies}},
url = {http://dx.doi.org/10.1016/j.ecolecon.2014.02.014},
volume = {101},
year = {2014}
}
@article{Gershman2014,
abstract = {Psychophysical and neurophysiological studies have suggested that memory is not simply a carbon copy of our experience: Memories are modified or new memories are formed depending on the dynamic structure of our experience, and specifically, on how gradually or abruptly the world changes. We present a statistical theory of memory formation in a dynamic environment, based on a nonparametric generalization of the switching Kalman filter. We show that this theory can qualitatively account for several psychophysical and neural phenomena, and present results of a new visual memory experiment aimed at testing the theory directly. Our experimental findings suggest that humans can use temporal discontinuities in the structure of the environment to determine when to form new memory traces. The statistical perspective we offer provides a coherent account of the conditions under which new experience is integrated into an old memory versus forming a new memory, and shows that memory formation depends on inferences about the underlying structure of our experience.},
author = {Gershman, Samuel J. and Radulescu, Angela and Norman, Kenneth A. and Niv, Yael},
doi = {10.1371/journal.pcbi.1003939},
file = {:home/kaslu/Documents/Mendeley/2014 - Gershman et al. - Statistical Computations Underlying the Dynamics of Memory Updating.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {11},
pmid = {25375816},
title = {{Statistical Computations Underlying the Dynamics of Memory Updating}},
volume = {10},
year = {2014}
}
@article{Advani2013a,
abstract = {Recent experimental advances in neuroscience have opened new vistas into the immense complexity of neuronal networks. This proliferation of data challenges us on two parallel fronts. First, how can we form adequate theoretical frameworks for understanding how dynamical network processes cooperate across widely disparate spatiotemporal scales to solve important computational problems? And second, how can we extract meaningful models of neuronal systems from high dimensional datasets? To aid in these challenges, we give a pedagogical review of a collection of ideas and theoretical methods arising at the intersection of statistical physics, computer science and neurobiology. We introduce the interrelated replica and cavity methods, which originated in statistical physics as powerful ways to quantitatively analyze large highly heterogeneous systems of many interacting degrees of freedom. We also introduce the closely related notion of message passing in graphical models, which originated in computer science as a distributed algorithm capable of solving large inference and optimization problems involving many coupled variables. We then show how both the statistical physics and computer science perspectives can be applied in a wide diversity of contexts to problems arising in theoretical neuroscience and data analysis. Along the way we discuss spin glasses, learning theory, illusions of structure in noise, random matrices, dimensionality reduction, and compressed sensing, all within the unified formalism of the replica method. Moreover, we review recent conceptual connections between message passing in graphical models, and neural computation and learning. Overall, these ideas illustrate how statistical physics and computer science might provide a lens through which we can uncover emergent computational functions buried deep within the dynamical complexities of neuronal networks.},
archivePrefix = {arXiv},
arxivId = {1301.7115},
author = {Advani, Madhu and Lahiri, Subhaneil and Ganguli, Surya},
doi = {10.1088/1742-5468/2013/03/P03014},
eprint = {1301.7115},
file = {:home/kaslu/Documents/Mendeley/2013 - Advani, Lahiri, Ganguli - Statistical mechanics of complex neural systems and high dimensional data.pdf:pdf},
issn = {1742-5468},
keywords = {cavity method,glasses,high dimensional data,learning,message passing,neural networks,random matrices,random projections,replica method,spin},
title = {{Statistical mechanics of complex neural systems and high dimensional data}},
url = {http://arxiv.org/abs/1301.7115{\%}0Ahttp://dx.doi.org/10.1088/1742-5468/2013/03/P03014},
year = {2013}
}
@article{Fairhall2012a,
abstract = {The analysis of stimulus/response patterns using information theoretic approaches requires the full probability distribution of stimuli and response. Recent progress in using information-based tools to understand circuit function has advanced understanding of neural coding at the single cell and population level. In advances over traditional reverse correlation approaches, the determination of receptive fields using information as a metric has allowed novel insights into stimulus representation and transformation. The application of maximum entropy methods to population codes has opened a rich exploration of the internal structure of these codes, revealing stimulus-driven functional connectivity. We speculate about the prospects and limitations of information as a general tool for dissecting neural circuits and relating their structure and function. ?? 2012 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Fairhall, Adrienne and Shea-Brown, Eric and Barreiro, Andrea K.},
doi = {10.1016/j.conb.2012.06.005},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2012 - Fairhall, Shea-Brown, Barreiro - Information theoretic approaches to understanding circuit function.pdf:pdf},
isbn = {1873-6882 (Electronic)$\backslash$r0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {aug},
number = {4},
pages = {653--659},
pmid = {22795220},
publisher = {Elsevier Ltd},
title = {{Information theoretic approaches to understanding circuit function}},
url = {http://dx.doi.org/10.1016/j.conb.2012.06.005 http://linkinghub.elsevier.com/retrieve/pii/S0959438812001043},
volume = {22},
year = {2012}
}
@article{Minamimoto2009,
abstract = {Motivation is usually inferred from the likelihood or the intensity with which behavior is carried out. It is sensitive to external factors (e.g., the identity, amount, and timing of a rewarding outcome) and internal factors (e.g., hunger or thirst). We trained macaque monkeys to perform a nonchoice instrumental task (a sequential red-green color discrimination) while manipulating two external factors: reward size and delay-to-reward. We also inferred the state of one internal factor, level of satiation, by monitoring the accumulated reward. A visual cue indicated the forthcoming reward size and delay-to-reward in each trial. The fraction of trials completed correctly by the monkeys increased linearly with reward size and was hyperbolically discounted by delay-to-reward duration, relations that are similar to those found in free operant and choice tasks. The fraction of correct trials also decreased progressively as a function of the satiation level. Similar (albeit noiser) relations were obtained for reaction times. The combined effect of reward size, delay-to-reward, and satiation level on the proportion of correct trials is well described as a multiplication of the effects of the single factors when each factor is examined alone. These results provide a quantitative account of the interaction of external and internal factors on instrumental behavior, and allow us to extend the concept of subjective value of a rewarding outcome, usually confined to external factors, to account also for slow changes in the internal drive of the subject.},
author = {Minamimoto, Takafumi and {La Camera}, Giancarlo and Richmond, Barry J},
doi = {10.1152/jn.90959.2008},
file = {:home/kaslu/Documents/Mendeley/2009 - Minamimoto, La Camera, Richmond - Measuring and modeling the interaction among reward size, delay to reward, and satiation level.pdf:pdf},
isbn = {0022-3077 (Print) 0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
number = {1},
pages = {437--47},
pmid = {18987119},
title = {{Measuring and modeling the interaction among reward size, delay to reward, and satiation level on motivation in monkeys.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18987119{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2637024{\%}5Cnhttp://jn.physiology.org/cgi/doi/10.1152/jn.90959.2008},
volume = {101},
year = {2009}
}
@article{Herculano-Houzel2015,
abstract = {There is a strong trend toward increased brain size in mammalian evolution, with larger brains composed of more and larger neurons than smaller brains across species within each mammalian order. Does the evolution of increased numbers of brain neurons, and thus larger brain size, occur simply through the selection of individuals with more and larger neurons, and thus larger brains, within a population? That is, do individuals with larger brains also have more, and larger, neurons than individuals with smaller brains, such that allometric relationships across species are simply an extension of intraspecific scaling? Here we show that this is not the case across adult male mice of a similar age. Rather, increased numbers of neurons across individuals are accompanied by increased numbers of other cells and smaller average cell size of both types, in a trade-off that explains how increased brain mass does not necessarily ensue. Fundamental regulatory mechanisms thus must exist that tie numbers of neurons to numbers of other cells and to average cell size within individual brains. Finally, our results indicate that changes in brain size in evolution are not an extension of individual variation in numbers of neurons, but rather occur through step changes that must simultaneously increase numbers of neurons and cause cell size to increase, rather than decrease.},
author = {Herculano-Houzel, Suzana and Messeder, D{\~{A}}{\textcopyright}bora J and Fonseca-Azevedo, Karina and Pantoja, Nilma A},
doi = {10.3389/fnana.2015.00064},
file = {:home/kaslu/Documents/Mendeley/2015 - Herculano-Houzel et al. - When larger brains do not have more neurons increased numbers of cells are compensated by decreased ave.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in Neuroanatomy},
keywords = {Neurons,brain size,intraspecific variation,neuronal density,number of glia,number of neurons},
month = {jun},
number = {June},
pages = {64},
pmid = {26082686},
title = {{When larger brains do not have more neurons: increased numbers of cells are compensated by decreased average cell size across mouse individuals}},
url = {http://journal.frontiersin.org/article/10.3389/fnana.2015.00064/abstract http://www.frontiersin.org/Neuroanatomy/10.3389/fnana.2015.00064/abstract},
volume = {9},
year = {2015}
}
@article{Tullock1971,
abstract = {Revolutions are a favorite subject of many modern "committed scholars." The volume of their work, in my opinion, greatly exceeds its penetration. Indeed, it is the purpose of this essay to demonstrate that the image of revolution which we find in the literature (both by the committed scholars and by more traditional scholars) is a false one. I shall also, I hope, demonstrate why this false image is so appealing to intellectuals and historians},
author = {Tullock, Gordon},
doi = {10.1007/BF01726214},
isbn = {0048-5829 U6 - ctx{\_}ver=Z39.88-2004{\&}ctx{\_}enc=info{\%}3Aofi{\%}2Fenc{\%}3AUTF-8{\&}rfr{\_}id=info:sid/summon.serialssolutions.com{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:journal{\&}rft.genre=article{\&}rft.atitle=The+Paradox+of+Revolution{\&}rft.jtitle=Public+Choice{\&}rft.au=Tullock{\%}2C+Gordon{\&}rft.date=1971-10-01{\&}rft.pub=Springer{\&}rft.issn=0048-5829{\&}rft.volume=11{\&}rft.spage=89{\&}rft.epage=99{\&}rft.externalDocID=10{\_}2307{\_}30022655 U7 - Journal Article U8 - FETCH-LOGICAL-c871-a34d78183fadb7f8669a710808ca6964d0afecb8942c423fa863eceafddb0b361},
issn = {0048-5829},
journal = {Public Choice},
month = {sep},
number = {1},
pages = {89--99},
publisher = {Kluwer Academic Publishers},
title = {{The paradox of revolution}},
url = {http://link.springer.com/10.1007/BF01726214},
volume = {11},
year = {1971}
}
@article{Udell2014,
abstract = {This paper describes Convex, a convex optimization modeling framework in Julia. Convex translates problems from a user-friendly functional language into an abstract syntax tree describing the problem. This concise representation of the global structure of the problem allows Convex to infer whether the problem complies with the rules of disciplined convex programming (DCP), and to pass the problem to a suitable solver. These operations are carried out in Julia using multiple dispatch, which dramatically reduces the time required to verify DCP compliance and to parse a problem into conic form. Convex then automatically chooses an appropriate backend solver to solve the conic form problem.},
archivePrefix = {arXiv},
arxivId = {1410.4821},
author = {Udell, Madeleine and Mohan, Karanveer and Zeng, David and Hong, Jenny and Diamond, Steven and Boyd, Stephen},
eprint = {1410.4821},
file = {:home/kaslu/Documents/Mendeley/2014 - Udell et al. - Convex Optimization in Julia.pdf:pdf},
isbn = {9781479955008},
keywords = {automatic verification,convex programming,multiple dispatch,putation,symbolic com-},
month = {oct},
title = {{Convex Optimization in Julia}},
url = {http://arxiv.org/abs/1410.4821},
volume = {0},
year = {2014}
}
@article{Pessoa2017,
abstract = {The Renormalization Group (RG) is a set of methods that have been instrumental in tackling problems involving an infinite number of degrees of freedom. What all these methods have in common -- which is what explains their success -- is that they allow a systematic search for those degrees of freedom that happen to be relevant to the phenomena in question. In the standard approaches the RG transformations are implemented by either coarse graining or by changes of variables. When these transformations are infinitesimal the formalism can be described as a continuous dynamical flow in a fictitious time parameter. It is generally the case that these exact RG equations are functional diffusion equations. In this paper we show that the exact RG equations can be derived using entropic methods. The RG flow is then described as a form of entropic dynamics of field configurations. Although equivalent to other versions of the RG, in this approach the RG transformations receive a purely inferential interpretation that establishes a clear link to information theory.},
archivePrefix = {arXiv},
arxivId = {1712.02267},
author = {Pessoa, Pedro and Caticha, Ariel},
doi = {10.3390/e20010025},
eprint = {1712.02267},
file = {:home/kaslu/Documents/Mendeley/2018 - Pessoa, Caticha - Exact Renormalization Groups As a Form of Entropic Dynamics.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
month = {jan},
number = {1},
pages = {25},
title = {{Exact Renormalization Groups As a Form of Entropic Dynamics}},
url = {http://arxiv.org/abs/1712.02267 http://www.mdpi.com/1099-4300/20/1/25},
volume = {20},
year = {2018}
}
@article{Ashby1988,
abstract = {This article examines decision processes in the perception and categorization of stimuli constructed from one or more components. First, a general perceptual theory is used to formally characterize large classes of existing decision models according to the type of decision boundary they predict in a multidimensional perceptual space. A new experimental paradigm is developed that makes it possible to accurately estimate a subject's decision boundary in a categorization task. Three experiments using this paradigm are reported. Three conclusions stand out: (a) Subjects adopted deterministic decision rules, that is, for a given location in the perceptual space, most subjects always gave the same response; (b) subjects used decision rules that were nearly optimal; and (c) the only constraint on the type of decision bound that subjects used was the amount of cognitive capacity it required to implement. Subjects were not constrained to make independent decisions on each component or to attend to the distance to each prototype.},
author = {Ashby, F G and Gott, R E},
doi = {10.1037/0278-7393.14.1.33},
file = {:home/kaslu/Documents/Mendeley/1988 - Ashby, Gott - Decision rules in the perception and categorization of multidimensional stimuli.pdf:pdf},
isbn = {0278-7393 (Print)$\backslash$r0278-7393 (Linking)},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
number = {1},
pages = {33--53},
pmid = {2963894},
title = {{Decision rules in the perception and categorization of multidimensional stimuli.}},
volume = {14},
year = {1988}
}
@article{Vergassola2007,
abstract = {Chemotactic bacteria rely on local concentration gradients to guide them towards the source of a nutrient. Such local cues pointing towards the location of the source are not always available at macroscopic scales because mixing in a flowing medium breaks up regions of high concentration into random and disconnected patches. Thus, animals sensing odours in air or water detect them only intermittently as patches sweep by on the wind or currents. A macroscopic searcher must devise a strategy of movement based on sporadic cues and partial information. Here we propose a search algorithm, which we call 'infotaxis', designed to work under such conditions. Any search process can be thought of as acquisition of information on source location; for infotaxis, information plays a role similar to concentration in chemotaxis. The infotaxis strategy locally maximizes the expected rate of information gain. We demonstrate its efficiency using a computational model of odour plume propagation and experimental data on mixing flows. Infotactic trajectories feature 'zigzagging' and 'casting' paths similar to those observed in the flight of moths. The proposed search algorithm is relevant to the design of olfactory robots, but the general idea of infotaxis can be applied more broadly in the context of searching with sparse information.},
annote = {NULL},
author = {Vergassola, Massimo and Villermaux, Emmanuel and Shraiman, Boris I},
doi = {10.1038/nature05464},
file = {:home/kaslu/Documents/Mendeley/2007 - Vergassola, Villermaux, Shraiman - ‘Infotaxis' as a strategy for searching without gradients.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
month = {jan},
number = {7126},
pages = {406--409},
pmid = {17251974},
title = {{‘Infotaxis' as a strategy for searching without gradients}},
url = {http://www.nature.com/doifinder/10.1038/nature05464},
volume = {445},
year = {2007}
}
@article{Pitkow2017,
abstract = {It is widely believed that the brain performs approximate probabilistic inference to estimate causal variables in the world from ambiguous sensory data. To understand these computations, we need to analyze how information is represented and transformed by the actions of nonlinear recurrent neural networks. We propose that these probabilistic computations function by a message-passing algorithm operating at the level of redundant neural populations. To explain this framework, we review its underlying concepts, including graphical models, sufficient statistics, and message-passing, and then describe how these concepts could be implemented by recurrently connected probabilistic population codes. The relevant information flow in these networks will be most interpretable at the population level, particularly for redundant neural codes. We therefore outline a general approach to identify the essential features of a neural message-passing algorithm. Finally, we argue that to reveal the most important aspects of these neural computations, we must study large-scale activity patterns during moderately complex, naturalistic behaviors.},
archivePrefix = {arXiv},
arxivId = {1702.03492},
author = {Pitkow, Xaq and Angelaki, Dora E.},
doi = {10.1016/j.neuron.2017.05.028},
eprint = {1702.03492},
file = {:home/kaslu/Documents/Mendeley/2017 - Pitkow, Angelaki - Inference in the Brain Statistics Flowing in Redundant Population Codes.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {brain,coding,inference,message-passing,nonlinear,nuisance,population code,redundant,theory},
month = {jun},
number = {5},
pages = {943--953},
pmid = {28595050},
title = {{Inference in the Brain: Statistics Flowing in Redundant Population Codes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089662731730466X},
volume = {94},
year = {2017}
}
@article{Brush2018a,
abstract = {In many biological systems, the functional behavior of a group is collectively computed by the system's in-dividual components. An example is the brain's ability to make decisions via the activity of billions of neu-rons. A long-standing puzzle is how the components' decisions combine to produce beneficial group-level outputs, despite conflicts of interest and imperfect information. We derive a theoretical model of collective computation from mechanistic first principles, using results from previous work on the computation of power structure in a primate model system. Collective computation has two phases: an information accumulation phase, in which (in this study) pairs of individuals gather information about their fighting abilities and make decisions about their dominance relationships, and an information aggregation phase, in which these decisions are combined to produce a collective computation. To model information accumulation, we extend a stochastic decision-making model—the leaky integrator model used to study neural decision-making—to a multiagent game-theoretic framework. We then test alternative algorithms for aggregating information—in this study, decisions about dominance resulting from the stochastic model—and measure the mutual information between the resultant power structure and the " true " fighting abilities. We find that conflicts of interest can improve accuracy to the benefit of all agents. We also find that the computation can be tuned to produce different power structures by changing the cost of waiting for a decision. The successful application of a similar stochastic decision-making model in neural and social contexts suggests general prin-ciples of collective computation across substrates and scales.},
author = {Brush, Eleanor R. and Krakauer, David C. and Flack, Jessica C.},
doi = {10.1126/sciadv.1603311},
file = {:home/kaslu/Documents/Mendeley/2018 - Brush, Krakauer, Flack - Conflicts of interest improve collective computation of adaptive social structures(2).pdf:pdf},
issn = {2375-2548},
journal = {Science Advances},
month = {jan},
number = {1},
pages = {e1603311},
publisher = {American Association for the Advancement of Science},
title = {{Conflicts of interest improve collective computation of adaptive social structures}},
url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.1603311},
volume = {4},
year = {2018}
}
@article{Peterson2013,
abstract = {Probability distributions having power-law tails are observed in a broad range of social, economic, and biological systems. We describe here a potentially useful common framework. We derive distribution functions for situations in which a "joiner particle" k pays some form of price to enter a community of size , where costs are subject to economies of scale. Maximizing the Boltzmann-Gibbs-Shannon entropy subject to this energy-like constraint predicts a distribution having a power-law tail; it reduces to the Boltzmann distribution in the absence of economies of scale. We show that the predicted function gives excellent fits to 13 different distribution functions, ranging from friendship links in social networks, to protein-protein interactions, to the severity of terrorist attacks. This approach may give useful insights into when to expect power-law distributions in the natural and social sciences.},
author = {Peterson, Jack and Dixit, Purushottam D and Dill, Ken A},
doi = {10.1073/pnas.1320578110},
file = {:home/kaslu/Documents/Mendeley/2013 - Peterson, Dixit, Dill - A maximum entropy framework for nonexponential distributions.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {dec},
number = {51},
pages = {20380--5},
pmid = {24297895},
title = {{A maximum entropy framework for nonexponential distributions.}},
url = {http://www.pnas.org/cgi/content/short/110/51/20380},
volume = {110},
year = {2013}
}
@article{Kass1996,
abstract = {Subjectivism has become the dominant philosophical foundation for Bayesian inference. Yet in practice, most Bayesian analyses are performed with so-called "noninformative" priors, that is, priors constructed by some formal rule. We review the plethora of techniques for constructing such priors and discuss some of the practical and philosophical issues that arise when they are used. We give special emphasis to Jeffreys's rules and discuss the evolution of his viewpoint about the interpretation of priors, away from unique representation of ignorance toward the notion that they should be chosen by convention. We conclude that the problems raised by the research on priors chosen by formal rules are serious and may not be dismissed lightly: When sample sizes are small (relative to the number of parameters being estimated), it is dangerous to put faith in any "default" solution; but when asymptotics take over, Jeffreys's rules and their variants remain reasonable choices. We also provide an annotated bibliography.},
author = {Kass, Robert E. and Wasserman, Larry},
doi = {10.2307/2291752},
file = {:home/kaslu/Documents/Mendeley/1996 - Kass, Wasserman - The Selection of Prior Distributions by Formal Rules.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {an essential observation is,and,bayes factors,construct priors in estimation,entropy,haar measure,improper priors,jeffreys,marginalization paradoxes,mative priors,noninfor-,reference priors,s,s prior,techniques he used to,testiniproblems,that jeffreys},
number = {435},
pages = {1343--1370},
title = {{The Selection of Prior Distributions by Formal Rules}},
volume = {91},
year = {1996}
}
@article{Lim2015,
abstract = {Information about external stimuli is thought to be stored in cortical circuits through experience-dependent modifications of synaptic connectivity. These modifications of network connectivity should lead to changes in neuronal activity as a particular stimulus is repeatedly encountered. Here we ask what plasticity rules are consistent with the differences in the statistics of the visual response to novel and familiar stimuli in inferior temporal cortex, an area underlying visual object recognition. We introduce a method that allows one to infer the dependence of the presumptive learning rule on postsynaptic firing rate, and we show that the inferred learning rule exhibits depression for low postsynaptic rates and potentiation for high rates. The threshold separating depression from potentiation is strongly correlated with both mean and s.d. of the firing rate distribution. Finally, we show that network models implementing a rule extracted from data show stable learning dynamics and lead to sparser representations of stimuli.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lim, Sukbin and McKee, Jillian L and Woloszyn, Luke and Amit, Yali and Freedman, David J and Sheinberg, David L and Brunel, Nicolas},
doi = {10.1038/nn.4158},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2015 - Lim et al. - Inferring learning rules from distributions of firing rates in cortical neurons.pdf:pdf},
isbn = {9780874216561},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {12},
pages = {1804--1810},
pmid = {26523643},
publisher = {Nature Publishing Group},
title = {{Inferring learning rules from distributions of firing rates in cortical neurons}},
url = {http://www.nature.com/doifinder/10.1038/nn.4158},
volume = {18},
year = {2015}
}
@article{Sharpee2017,
abstract = {Discretization in neural circuits occurs on many levels, from the generation of action potentials and dendritic integration, to neuropeptide signaling and processing of signals from multiple neurons, to behavioral decisions. It is clear that discretization, when implemented properly, can convey many benefits. However, the optimal solutions depend on both the level of noise and how it impacts a particular computation. This Perspective discusses how current physiological data could potentially be integrated into one theoretical framework based on maximizing information. Key experiments for testing that framework are discussed.},
author = {Sharpee, Tatyana},
doi = {10.1016/j.neuron.2017.04.044},
file = {:home/kaslu/Documents/Mendeley/2017 - Sharpee - Optimizing Neural Information Capacity through Discretization.pdf:pdf},
issn = {10974199},
journal = {Neuron},
keywords = {dendrites,information theory,ion channels,ionic currents,neural cell types,neuromodulation,neuropeptide,phase transitions,power law,scale-free dynamics},
number = {5},
pages = {954--960},
pmid = {28595051},
publisher = {Elsevier Inc.},
title = {{Optimizing Neural Information Capacity through Discretization}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.04.044},
volume = {94},
year = {2017}
}
@article{Greene2002,
abstract = {Moral psychology has long focused on reasoning, but recent evidence suggests that moral judgment is more a matter of emotion and affective intuition than deliberate reasoning. Here we discuss recent findings in psychology and cognitive neuroscience, including several studies that specifically investigate moral judgment. These findings indicate the importance of affect, although they allow that reasoning can play a restricted but significant role in moral judgment. They also point towards a preliminary account of the functional neuroanatomy of moral judgment, according to which many brain areas make important contributions to moral judgment although none is devoted specifically to it.},
author = {Greene, Joshua D. and Haidt, Jonathan},
doi = {10.1016/S1364-6613(02)02011-9},
file = {:home/kaslu/Documents/Mendeley/2002 - Greene, Haidt - How (and where) does moral judgment work.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {12},
pages = {517--523},
pmid = {12475712},
title = {{How (and where) does moral judgment work?}},
volume = {6},
year = {2002}
}
@article{Titley2017,
abstract = {Synaptic plasticity (e.g., long-term potentiation [LTP]) is considered the cellular correlate of learning. Recent optogenetic studies on memory engram formation assign a critical role in learning to suprathreshold activation of neurons and their integration into active engrams (“engram cells”). Here we review evidence that ensemble integration may result from LTP but also from cell-autonomous changes in membrane excitability. We propose that synaptic plasticity determines synaptic connectivity maps, whereas intrinsic plasticity—possibly separated in time—amplifies neuronal responsiveness and acutely drives engram integration. Our proposal marks a move away from an exclusively synaptocentric toward a non-exclusive, neurocentric view of learning. Titley et al. argue that purely synaptic learning theories are not sufficient to explain memory representation in populations of neurons (memory engrams). Instead, engram integration results from intrinsic plasticity of neurons, whose connectivity maps were established by prior synaptic plasticity.},
author = {Titley, Heather K. and Brunel, Nicolas and Hansel, Christian},
doi = {10.1016/j.neuron.2017.05.021},
file = {:home/kaslu/Documents/Mendeley/2017 - Titley, Brunel, Hansel - Toward a Neurocentric View of Learning.pdf:pdf},
issn = {10974199},
journal = {Neuron},
keywords = {Purkinje cell,cerebellum,ensemble,hippocampus,intrinsic,memory engram,neocortex,plasticity,pyramidal cell,synaptic},
number = {1},
pages = {19--32},
pmid = {28683265},
publisher = {Elsevier Inc.},
title = {{Toward a Neurocentric View of Learning}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.05.021},
volume = {95},
year = {2017}
}
@article{Lake2013,
abstract = {People can learn a new visual class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on compositionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classification task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also tested the model on another conceptual task, generating new examples, by using a “visual Turing test” to show that our model produces human-like performance.},
author = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
file = {:home/kaslu/Documents/Mendeley/2013 - Lake, Salakhutdinov, Tenenbaum - One-shot learning by inverting a compositional causal process.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 27 (NIPS 2013)},
pages = {1--6},
title = {{One-shot learning by inverting a compositional causal process}},
year = {2013}
}
@article{Cunningham2014,
abstract = {Most sensory, cognitive and motor functions depend on the interactions of many neurons. In recent years, there has been rapid development and increasing use of technologies for recording from large numbers of neurons, either sequentially or simultaneously. A key question is what scientific insight can be gained by studying a population of recorded neurons beyond studying each neuron individually. Here, we examine three important motivations for population studies: single-trial hypotheses requiring statistical power, hypotheses of population response structure and exploratory analyses of large data sets. Many recent studies have adopted dimensionality reduction to analyze these populations and to find features that are not apparent at the level of individual neurons. We describe the dimensionality reduction methods commonly applied to population activity and offer practical advice about selecting methods and interpreting their outputs. This review is intended for experimental and computational researchers who seek to understand the role dimensionality reduction has had and can have in systems neuroscience, and who seek to apply these methods to their own data. A},
author = {Cunningham, John P. and Yu, Byron M.},
doi = {10.1038/nn.3776},
file = {:home/kaslu/Documents/Mendeley/2014 - Cunningham, Yu - Dimensionality reduction for large-scale neural recordings.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {aug},
number = {11},
pages = {1500--1509},
pmid = {25151264},
title = {{Dimensionality reduction for large-scale neural recordings}},
url = {http://www.nature.com/doifinder/10.1038/nn.3776},
volume = {17},
year = {2014}
}
@article{Shadlen2016,
abstract = {Decisions take time, and as a rule more difficult decisions take more time. But this only raises the question of what consumes the time. For decisions informed by a sequence of samples of evidence, the answer is straightforward: more samples are available with more time. Indeed, the speed and accuracy of such decisions are explained by the accumulation of evidence to a threshold or bound. However, the same framework seems to apply to decisions that are not obviously informed by sequences of evidence samples. Here, we proffer the hypothesis that the sequential character of such tasks involves retrieval of evidence from memory. We explore this hypothesis by focusing on value-based decisions and argue that mnemonic processes can account for regularities in choice and decision time. We speculate on the neural mechanisms that link sampling of evidence from memory to circuits that represent the accumulated evidence bearing on a choice. We propose that memory processes may contribute to a wider class of decisions that conform to the regularities of choice-reaction time predicted by the sequential sampling framework.},
author = {Shadlen, Michael N. and Shohamy, Daphna},
doi = {10.1016/j.neuron.2016.04.036},
file = {:home/kaslu/Documents/Mendeley/2016 - Shadlen, Shohamy - Decision Making and Sequential Sampling from Memory.pdf:pdf},
isbn = {doi:10.1016/j.neuron.2016.04.036},
issn = {10974199},
journal = {Neuron},
number = {5},
pages = {927--939},
pmid = {27253447},
publisher = {Elsevier Inc.},
title = {{Decision Making and Sequential Sampling from Memory}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.04.036},
volume = {90},
year = {2016}
}
@article{Copelli2002,
abstract = {Sensory arrays made of coupled excitable elements can improve both their input sensitivity and dynamic range due to collective nonlinear wave properties. This mechanism is studied in a neural network of electrically coupled (e.g., via gap junctions) elements subject to a Poisson signal process. The network response interpolates between a Weber-Fechner logarithmic law, and a Stevens power law depending on the relative refractory period of the cell. Therefore, these nonlinear transformations of the input level could be performed in the sensory periphery simply due to a basic property: the transfer function of excitable media.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0112395},
author = {Copelli, Mauro and Roque, Ant{\^{o}}nio C and Oliveira, Rodrigo F and Kinouchi, Osame},
doi = {10.1103/PhysRevE.65.060901},
eprint = {0112395},
issn = {1063-651X},
journal = {Physical Review E},
month = {jun},
number = {6},
pages = {060901},
pmid = {12188696},
primaryClass = {cond-mat},
title = {{Physics of psychophysics: Stevens and Weber-Fechner laws are transfer functions of excitable media}},
url = {http://arxiv.org/abs/cond-mat/0112395 https://link.aps.org/doi/10.1103/PhysRevE.65.060901},
volume = {65},
year = {2002}
}
@article{Kuhn1951,
abstract = {This extensive rigorous texbook, developed through instruction at MIT, focuses on nonlinear and other types of optimization: iterative algorithms for constrained and unconstrained optimization, Lagrange multipliers and duality, large scale problems, and the interface between continuous and discrete optimization. Among its special features, the book: 1) provides extensive coverage of iterative optimization methods within a unifying framework 2) provides a detailed treatment of interior point methods for linear programming 3) covers in depth duality theory from both a variational and a geometrical/convex analysis point of view 4) includes much new material on a number of topics, such as neural network training, discrete-time optimal control, and large-scale optimization 5) includes a large number of examples and exercises detailed solutions of many of which are posted on the internet Much supplementary/support material can be found at the book's web page http://www.athenasc.com/nonlinbook.html},
author = {Kuhn, H. W. and Tucker, A.W},
doi = {10.1007/BF01582292},
file = {:home/kaslu/Documents/Mendeley/1951 - Kuhn, Tucker - Nonlinear Programming.pdf:pdf},
isbn = {1886529000},
issn = {01605682},
journal = {Proceedings of the Second Symposium on Mathematical Statistics and Probability},
number = {x},
pages = {481--492},
pmid = {2091171},
title = {{Nonlinear Programming}},
url = {http://projecteuclid.org/euclid.bsmsp/1200500249},
year = {1951}
}
@inproceedings{Huber2011,
abstract = {— For Gaussian Assumed Density Filtering based on moment matching, a framework for the efficient calculation of posterior moments is proposed that exploits the structure of the given nonlinear system. The key idea is a careful discretization of some dimensions of the state space only in order to decompose the system into a set of nonlinear subsystems that are conditionally integrable in closed form. This approach is more efficient than full discretization approaches. In addition, the new decomposition is far more general than known Rao-Blackwellization approaches relying on conditionally linear subsystems. As a result, the new framework is applicable to a much larger class of nonlinear systems.},
author = {Huber, Marco F and Beutler, Frederik and Hanebeck, Uwe D},
booktitle = {Proceedings of the 2011 American Control Conference},
doi = {10.1109/ACC.2011.5991332},
file = {:home/kaslu/Documents/Mendeley/2011 - Huber, Beutler, Hanebeck - Semi-analytic Gaussian Assumed Density Filter.pdf:pdf},
isbn = {978-1-4577-0081-1},
month = {jun},
pages = {3006--3011},
publisher = {IEEE},
title = {{Semi-analytic Gaussian Assumed Density Filter}},
url = {http://ieeexplore.ieee.org/document/5991332/},
year = {2011}
}
@article{Wei2017,
author = {Wei, Xue-Xin and Stocker, Alan A.},
doi = {10.1073/pnas.1619153114},
file = {:home/kaslu/Documents/Mendeley/2017 - Wei, Stocker - Lawful relation between perceptual bias and discriminability.pdf:pdf},
isbn = {1619153114},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
pages = {201619153},
pmid = {28874578},
title = {{Lawful relation between perceptual bias and discriminability}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1619153114},
year = {2017}
}
@article{Zylberberg2015,
abstract = {While recent recordings from neural populations show beyond-pairwise, or higher-order, correlations (HOC), we have little understanding of how HOC arise from network interactions and of how they impact encoded information. Here, we show that input nonlinearities imply HOC in spin-glass-type statistical models. We then discuss one such model with parametrized pairwise- and higher-order interactions, revealing conditions under which beyond-pairwise interactions increase the mutual information between a given stimulus type and the population responses. For jointly Gaussian stimuli, coding performance is improved by shaping output HOC only when neural firing rates are constrained to be low. For stimuli with skewed probability distributions (like natural image luminances), performance improves for all firing rates. Our work suggests surprising connections between nonlinear integration of neural inputs, stimulus statistics, and normative theories of population coding. Moreover, it suggests that the inclusion of beyond-pairwise interactions could improve the performance of Boltzmann machines for machine learning and signal processing applications.},
author = {Zylberberg, Joel and Shea-Brown, Eric},
doi = {10.1103/PhysRevE.92.062707},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
title = {{Input nonlinearities can shape beyond-pairwise correlations and improve information transmission by neural populations}},
url = {http://www.mendeley.com/research/input-nonlinearities-shape-beyondpairwise-correlations-improve-information-transmission-neural-popul},
year = {2015}
}
@article{Solway2014,
abstract = {Human behavior has long been recognized to display hierarchical structure: actions fit together into subtasks, which cohere into extended goal-directed activities. Arranging actions hierarchically has well established benefits, allowing behaviors to be represented efficiently by the brain, and allowing solutions to new tasks to be discovered easily. However, these payoffs depend on the particular way in which actions are organized into a hierarchy, the specific way in which tasks are carved up into subtasks. We provide a mathematical account for what makes some hierarchies better than others, an account that allows an optimal hierarchy to be identified for any set of tasks. We then present results from four behavioral experiments, suggesting that human learners spontaneously discover optimal action hierarchies.},
author = {Solway, Alec and Diuk, Carlos and C{\'{o}}rdova, Natalia and Yee, Debbie and Barto, Andrew G. and Niv, Yael and Botvinick, Matthew M.},
doi = {10.1371/journal.pcbi.1003779},
file = {:home/kaslu/Documents/Mendeley/2014 - Solway et al. - Optimal Behavioral Hierarchy.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$n1553-734X (Linking)},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {8},
pmid = {25122479},
title = {{Optimal Behavioral Hierarchy}},
volume = {10},
year = {2014}
}
@article{Aitchison2016,
author = {Aitchison, Laurence and Corradi, Nicola and Latham, Peter E.},
doi = {10.1371/journal.pcbi.1005110},
file = {:home/kaslu/Documents/Mendeley/2016 - Aitchison, Corradi, Latham - Zipf's Law Arises Naturally When There Are Underlying, Unobserved Variables.pdf:pdf},
issn = {1553-7358},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1005110},
title = {{Zipf's Law Arises Naturally When There Are Underlying, Unobserved Variables}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1005110},
volume = {12},
year = {2016}
}
@article{Folke2016,
abstract = {Humans can reflect on decisions and report variable levels of confidence. But why maintain an explicit representation of confi- dence for choices that have already been made and therefore cannot be undone? Here we show that an explicit representation of confidence is harnessed for subsequent changes of mind. Specifically, when confidence is low, participants are more likely to change their minds when the same choice is presented again, an effect that is most pronounced in participants with greater fidelity in their confidence reports. Furthermore, we show that choices reported with high confidence follow a more consistent pattern (fewer transitivity violations). Finally, by tracking participants' eye movements, we demonstrate that lower-level gaze dynamics can track uncertainty but do not directly impact changes of mind. These results suggest that an explicit and accurate representation of confidence has a positive impact on the quality of future value-based decisions.},
author = {Folke, Tomas and Jacobsen, Catrine and Fleming, Stephen M. and {De Martino}, Benedetto},
doi = {10.1038/s41562-016-0002},
file = {:home/kaslu/Documents/Mendeley/2016 - Folke et al. - Explicit representation of confidence informs future value-based decisions.pdf:pdf},
isbn = {4156201600},
issn = {2397-3374},
journal = {Nature Human Behaviour},
number = {November},
pages = {0002},
title = {{Explicit representation of confidence informs future value-based decisions}},
url = {http://www.nature.com/articles/s41562-016-0002},
volume = {1},
year = {2016}
}
@article{Lefebvre2017,
annote = {compare with our liberals vs. conservative results
},
author = {Lefebvre, Germain and Lebreton, Ma{\"{e}}l and Meyniel, Florent and Bourgeois-Gironde, Sacha and Palminteri, Stefano},
doi = {10.1038/s41562-017-0067},
file = {:home/kaslu/Documents/Mendeley/2017 - Lefebvre et al. - Behavioural and neural characterization of optimistic reinforcement learning.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
number = {March},
pages = {1--9},
publisher = {Macmillan Publishers Limited, part of Springer Nature.},
title = {{Behavioural and neural characterization of optimistic reinforcement learning}},
url = {http://dx.doi.org/10.1038/s41562-017-0067},
volume = {0067},
year = {2017}
}
@article{Abbott2017a,
abstract = {The neural basis of decision-making has been elusive and involves the coordinated activity of multiple brain structures. This NeuroView, by the International Brain Laboratory (IBL), discusses their efforts to develop a standardized mouse decision-making behavior, to make coordinated measurements of neural activity across the mouse brain, and to use theory and analyses to uncover the neural computations that support decision-making. The neural basis of decision-making has been elusive and involves the coordinated activity of multiple brain structures. This NeuroView, by the International Brain Laboratory (IBL), discusses their efforts to develop a standardized mouse decision-making behavior, to make coordinated measurements of neural activity across the mouse brain, and to use theory and analyses to uncover the neural computations that support decision-making.},
author = {Abbott, Larry and Angelaki, Dora E. and Carandini, Matteo and Churchland, Anne K. and Dan, Yang and Dayan, Peter and Deneve, Sophie and Fiete, Ila and Ganguli, Surya and Harris, Kenneth D. and H{\"{a}}usser, Michael and Hofer, Sonja and Latham, Peter E. and Mainen, Zachary F. and Mrsic-Flogel, Thomas and Paninski, Liam and Pillow, Jonathan W. and Pouget, Alexandre and Svoboda, Karel and Witten, Ilana B. and Zador, Anthony M.},
doi = {10.1016/j.neuron.2017.12.013},
file = {:home/kaslu/Documents/Mendeley/2017 - Abbott et al. - An International Laboratory for Systems and Computational Neuroscience.pdf:pdf},
issn = {10974199},
journal = {Neuron},
number = {6},
pages = {1213--1218},
pmid = {29268092},
title = {{An International Laboratory for Systems and Computational Neuroscience}},
volume = {96},
year = {2017}
}
@article{Dose2003,
author = {Dose, V},
doi = {10.1088/0034-4885/66/9/202},
file = {:home/kaslu/Documents/Mendeley/2003 - Dose - Bayesian inference in physics case studies.pdf:pdf},
issn = {0034-4885},
journal = {Reports on Progress in Physics},
month = {sep},
number = {9},
pages = {1421--1461},
title = {{Bayesian inference in physics: case studies}},
url = {http://stacks.iop.org/0034-4885/66/i=9/a=202?key=crossref.9b824f09a8047595b31a734560bcb4ea},
volume = {66},
year = {2003}
}
@misc{Jaynes1998,
author = {Jaynes, Edwin T.},
booktitle = {Maximum-Entropy and Bayesian Methods in Science and Engineering},
doi = {10.1007/978-94-009-3049-0_1},
isbn = {978-94-010-7871-9},
pages = {1--24},
title = {{How does the brain do plausible reasoning?}},
url = {http://128.252.91.101/etj/articles/brain.pdf},
volume = {1},
year = {1998}
}
@article{Chen2015,
abstract = {Accurate wayfinding is essential to the survival of many animal species and requires the ability to maintain spatial orientation during locomotion. One of the ways that humans and other animals stay spatially oriented is through path integration, which operates by integrating self-motion cues over time, providing information about total displacement from a starting point [1, 2]. The neural substrate of path integration in mammals may exist in grid cells, which are found in dorsomedial entorhinal cortex and presubiculum and parasubiculum in rats [3, 4]. Grid cells have also been found in mice, bats, and monkeys [5-7], and signatures of grid cell activity have been observed in humans [8, 9]. We demonstrate that distance estimation by humans during path integration is sensitive to geometric deformations of a familiar environment and show that patterns of path integration error are predicted qualitatively by a model in which locations in the environment are represented in the brain as phases of arrays of grid cells with unique periods and decoded by the inverse mapping from phases to locations. The periods of these grid networks are assumed to expand and contract in response to expansions and contractions of a familiar environment [10]. Biases in distance estimation occur when the periods of the encoding and decoding grids differ. Our findings explicate the way in which grid cells could function in human path integration.},
author = {Chen, Xiaoli and He, Qiliang and Kelly, Jonathan W. and Fiete, Ila R. and McNamara, Timothy P.},
doi = {10.1016/j.cub.2015.05.031},
file = {:home/kaslu/Documents/Mendeley/2015 - Chen et al. - Bias in Human Path Integration is Predicted by Properties of Grid Cells.pdf:pdf},
isbn = {1879-0445},
issn = {09609822},
journal = {Current Biology},
number = {13},
pages = {1771--1776},
pmid = {26073138},
publisher = {Elsevier},
title = {{Bias in Human Path Integration is Predicted by Properties of Grid Cells}},
url = {http://dx.doi.org/10.1016/j.cub.2015.05.031},
volume = {25},
year = {2015}
}
@article{Sussillo2015,
abstract = {It remains an open question how neural responses in motor cortex relate to movement. We explored the hypothesis that motor cortex reflects dynamics appropriate for generating temporally patterned outgoing commands. To formalize this hypothesis, we trained recurrent neural networks to reproduce the muscle activity of reaching monkeys. Models had to infer dynamics that could transform simple inputs into temporally and spatially complex patterns of muscle activity. Analysis of trained models revealed that the natural dynamical solution was a low-dimensional oscillator that generated the necessary multiphasic commands. This solution closely resembled, at both the single-neuron and population levels, what was observed in neural recordings from the same monkeys. Notably, data and simulations agreed only when models were optimized to find simple solutions. An appealing interpretation is that the empirically observed dynamics of motor cortex may reflect a simple solution to the problem of generating temporally patterned descending commands.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Sussillo, David and Churchland, Mark M. and Kaufman, Matthew T. and Shenoy, Krishna V.},
doi = {10.1038/nn.4042},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2015 - Sussillo et al. - A neural network that finds a naturalistic solution for the production of muscle activity.pdf:pdf},
isbn = {0018-9294},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Electromyography,Electrophysiological Processes,Haplorhini,Motor Activity,Motor Activity: physiology,Motor Cortex,Motor Cortex: physiology,Muscle,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Skeletal,Skeletal: physiology},
number = {7},
pages = {1025--33},
pmid = {26075643},
title = {{A neural network that finds a naturalistic solution for the production of muscle activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26075643},
volume = {18},
year = {2015}
}
@article{Kinouchi1996,
author = {Kinouchi, Osame and Caticha, Nestor},
doi = {10.1103/PhysRevE.54.R54},
file = {:home/kaslu/Documents/Mendeley/1996 - Kinouchi, Caticha - Learning algorithm that gives the Bayes generalization limit for perceptrons.pdf:pdf},
issn = {1063-651X},
journal = {Physical Review E},
month = {jul},
number = {1},
pages = {R54--R57},
title = {{Learning algorithm that gives the Bayes generalization limit for perceptrons}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.54.R54},
volume = {54},
year = {1996}
}
@article{Kass1995,
author = {Kass, Robert E. and Raftery, Adrian E.},
doi = {10.1080/01621459.1995.10476572},
file = {:home/kaslu/Documents/Mendeley/1995 - Kass, Raftery - Bayes Factors.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {BIC,Bayesian hypothesis tests,importance samplin},
month = {jun},
number = {430},
pages = {773--795},
title = {{Bayes Factors}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476572},
volume = {90},
year = {1995}
}
@article{Delamotte2004,
abstract = {An elementary introduction to perturbative renormalization and renormalization group is presented. No prior knowledge of field theory is necessary because we do not refer to a particular physical theory. We are thus able to disentangle what is specific to field theory and what is intrinsic to renormalization. We link the general arguments and results to real phenomena encountered in particle physics and statistical mechanics.},
archivePrefix = {arXiv},
arxivId = {hep-th/0212049},
author = {Delamotte, Bertrand},
doi = {10.1119/1.1624112},
eprint = {0212049},
issn = {00029505},
journal = {American Journal of Physics},
month = {dec},
number = {2},
pages = {170},
primaryClass = {hep-th},
title = {{A hint of renormalization}},
url = {http://arxiv.org/abs/hep-th/0212049},
volume = {72},
year = {2004}
}
@article{Scott2017,
abstract = {Decision-making in dynamic environments often involves accumulation of evidence, in which new information is used to update beliefs and select future actions. Using in vivo cellular resolution imaging in voluntarily head-restrained rats, we examined the responses of neurons in frontal and parietal cortices during a pulse-based accumulation of evidence task. Neurons exhibited activity that predicted the animal's upcoming choice, previous choice, and graded responses that reflected the strength of the accumulated evidence. The pulsatile nature of the stimuli enabled characterization of the responses of neurons to a single quantum (pulse) of evidence. Across the population, individual neurons displayed extensive heterogeneity in the dynamics of responses to pulses. The diversity of responses was sufficiently rich to form a temporal basis for accumulated evidence estimated from a latent variable model. These results suggest that heterogeneous, often transient sensory responses distributed across the fronto-parietal cortex may support working memory on behavioral timescales. Leading models of decision-making postulate that individual fronto-parietal neurons encode accumulated sensory evidence with stable changes in firing rate. Using cellular resolution calcium imaging during a pulse-based accumulation task, Scott et al. reveal that stable representations of accumulated evidence in rat fronto-parietal cortex instead arise from neuronal populations with temporally diverse responses.},
author = {Scott, Benjamin B. and Constantinople, Christine M. and Akrami, Athena and Hanks, Timothy D. and Brody, Carlos D. and Tank, David W.},
doi = {10.1016/j.neuron.2017.06.013},
file = {:home/kaslu/Documents/Mendeley/2017 - Scott et al. - Fronto-parietal Cortical Circuits Encode Accumulated Evidence with a Diversity of Timescales.pdf:pdf},
isbn = {1097-4199 (Electronic)0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
keywords = {Accumulation of evidence,Calcium imaging,Decision-making,Drift diffusion model,Head restraint,Multiphoton fluorescence microscopy,Neocortex,Neural coding,Rodent,Working memory},
number = {2},
pages = {385--398.e5},
pmid = {28669543},
publisher = {Elsevier Inc.},
title = {{Fronto-parietal Cortical Circuits Encode Accumulated Evidence with a Diversity of Timescales}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.06.013},
volume = {95},
year = {2017}
}
@article{Koopman1936,
annote = {NULL},
author = {Koopman, B. O.},
doi = {10.2307/1989758},
file = {:home/kaslu/Documents/Mendeley/1936 - Koopman - On Distributions Admitting a Sufficient Statistic.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
month = {may},
number = {3},
pages = {399},
title = {{On Distributions Admitting a Sufficient Statistic}},
url = {http://www.jstor.org/stable/1989758?origin=crossref},
volume = {39},
year = {1936}
}
@article{Ipek2015a,
abstract = {Entropic Dynamics is an information-based framework that seeks to derive the laws of physics as an application of the methods of entropic inference. The dynamics is derived by maximizing an entropy subject to constraints that represent the physically relevant information that the motion is continuous and non-dissipative. Here we focus on the quantum theory of scalar fields. We provide an entropic derivation of Hamiltonian dynamics and using concepts from information geometry derive the standard quantum field theory in the Schroedinger representation.},
archivePrefix = {arXiv},
arxivId = {1412.5637},
author = {Ipek, Selman and Caticha, Ariel},
doi = {10.1063/1.4905997},
eprint = {1412.5637},
file = {:home/kaslu/Documents/Mendeley/2014 - Ipek, Caticha - Entropic Quantization of Scalar Fields.pdf:pdf},
month = {dec},
pages = {345--352},
title = {{Entropic Quantization of Scalar Fields}},
url = {http://arxiv.org/abs/1412.5637 http://dx.doi.org/10.1063/1.4905997 http://aip.scitation.org/doi/abs/10.1063/1.4905997},
year = {2014}
}
@article{Yates2017,
abstract = {Area MT plays a critical role in representing the motion information used for direction discrimination 1,2 , and neurons in LIP have spike rates that resemble the time course of decision formation 3,4 . These observations have been synthesized in the form of a two-stage compu-tational model. In this simple and elegant framework, MT represents instantaneous motion evidence and LIP reflects the integration of MT output up to a decision bound, thereby instantiating a neural correlate of an evolving decision variable 4–8 . Although many studies invoke MT-to-LIP integration to explain behavioral and neurophysiological phenomena during perceptual decision-making 6–9 , it remains unknown how closely LIP activity reflects the integration of sensory evidence from MT and how direct their relationship is. Indeed, several studies have reported weak and/or nonmonotonic dependencies of LIP ramping responses on motion strength 3,10–12 . Other studies have identified components of LIP fir-ing rates that are not linked to the integration of motion, such as simple visual input 13,14 , urgency 15 , prior probability 12,16 and subjec-tive value 17 . Additionally, several studies have identified the presence of substantial presaccadic response components present during the deliberation phase of direction discrimination and other tasks 18–20 . We therefore sought to more directly evaluate the basic tenets of the integrator model of LIP by assessing how single-trial dynamics of MT responses propagate to LIP. To accomplish this, we developed a reverse-correlation motion-discrimination task that allowed us to control the time course of visual motion on each trial and to dis-ambiguate the influence of various task variables, thus statistically resolving multiple response components. Monkeys performed this direction-discrimination task while we recorded neural activity in both MT and LIP. The combination of these approaches allowed us to use a single-trial statistical model to characterize how the stimulus, perceptual decisions and responses of MT and LIP neurons related to one another. This approach provided several insights into the relationship between MT and LIP. We found that both MT and LIP, as well as behavioral decisions, depended most strongly on motion early in the trial. MT contained a temporally reweighted representation of the stimulus, which was itself sufficient to explain a large portion of the strongly time-varying stimulus-weighting evident in both behavior and in LIP responses, implying that a substantial part the early weighting in decisions and their neural correlates may be inherited from MT output. As in prior reports 21 , LIP responses to brief pulses of motion were sustained over many hundreds of milliseconds, consistent with the notion of temporal integration underlying the transformation of MT responses to a decision variable. However, LIP responses were not completely explained by the integration of MT output and instead required the addition of large ramping signals that signified the even-tual choice on that trial and were statistically decoupled from the time-varying motion signal. Finally, LIP decision-related responses were not better explained by incorporating simultaneously measured MT activity, consistent with the idea that a number of stages intervene between the two areas 5,22 . Taken together, this constellation of results provides refinement of the MT–LIP integration framework. Our single-trial analyses identified dynamics in MT that likely contribute substantially to the temporal weighting seen in other brain areas and in decisions. They also cast LIP as an area with time-varying average activity that can},
author = {Yates, Jacob L. and Park, Il Memming and Katz, Leor N. and Pillow, Jonathan W. and Huk, Alexander C.},
doi = {10.1038/nn.4611},
file = {:home/kaslu/Documents/Mendeley/2017 - Yates et al. - Functional dissection of signal and noise in MT and LIP during decision-making.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {July},
pmid = {28758998},
publisher = {Nature Publishing Group},
title = {{Functional dissection of signal and noise in MT and LIP during decision-making}},
url = {http://www.nature.com/doifinder/10.1038/nn.4611},
year = {2017}
}
@article{Mooij2014,
abstract = {The discovery of causal relationships from purely observational data is a fundamental problem in science. The most elementary form of such a causal discovery problem is to decide whether X causes Y or, alternatively, Y causes X, given joint observations of two variables X, Y. An example is to decide whether altitude causes temperature, or vice versa, given only joint measurements of both variables. Even under the simplifying assumptions of no confounding, no feedback loops, and no selection bias, such bivariate causal discovery problems are challenging. Nevertheless, several approaches for addressing those problems have been proposed in recent years. We review two families of such methods: Additive Noise Methods (ANM) and Information Geometric Causal Inference (IGCI). We present the benchmark CauseEffectPairs that consists of data for 100 different cause-effect pairs selected from 37 datasets from various domains (e.g., meteorology, biology, medicine, engineering, economy, etc.) and motivate our decisions regarding the "ground truth" causal directions of all pairs. We evaluate the performance of several bivariate causal discovery methods on these real-world benchmark data and in addition on artificially simulated data. Our empirical results on real-world data indicate that certain methods are indeed able to distinguish cause from effect using only purely observational data, although more benchmark data would be needed to obtain statistically significant conclusions. One of the best performing methods overall is the additive-noise method originally proposed by Hoyer et al. (2009), which obtains an accuracy of 63+-10 {\%} and an AUC of 0.74+-0.05 on the real-world benchmark. As the main theoretical contribution of this work we prove the consistency of that method.},
archivePrefix = {arXiv},
arxivId = {1412.3773},
author = {Mooij, Joris M. and Peters, Jonas and Janzing, Dominik and Zscheischler, Jakob and Sch{\"{o}}lkopf, Bernhard},
eprint = {1412.3773},
file = {:home/kaslu/Documents/Mendeley/2014 - Mooij et al. - Distinguishing cause from effect using observational data methods and benchmarks.pdf:pdf},
month = {dec},
pages = {101},
title = {{Distinguishing cause from effect using observational data: methods and benchmarks}},
url = {http://arxiv.org/abs/1412.3773 http://arxiv.org/abs/1404.1100},
year = {2014}
}
@article{Jaynes1965,
abstract = {The status of the Gibbs and Boltzmann expressions for entropy has been a matter of some confusion in the literature. We show that: (1) the Gibbs H function yields the correct entropy as defined in phenomenological thermodynamics; (2) the Boltzmann H yields an “entropy” that is in error by a nonnegligible amount whenever interparticle forces affect thermodynamic properties; (3) Boltzmann's other interpretation of entropy, S = k log W, is consistent with the Gibbs H, and derivable from it; (4) the Boltzmann H theorem does not constitute a demonstration of the second law for dilute gases; (5) the dynamical invariance of the Gibbs H gives a simple proof of the second law for arbitrary interparticle forces; (6) the second law is a special case of a general requirement for any macroscopic process to be experimentally reproducible. Finally, the “anthropomorphic” nature of entropy, on both the statistical and phenomenological levels, is stressed.},
author = {Jaynes, E. T.},
doi = {10.1119/1.1971557},
isbn = {doi:10.1119/1.1971557},
issn = {00029505},
journal = {American Journal of Physics},
number = {5},
pages = {391},
title = {{Gibbs vs Boltzmann Entropies}},
volume = {33},
year = {1965}
}
@article{Griffiths2006,
abstract = {Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors. We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world.},
author = {Griffiths, Thomas L. and Tenenbaum, Joshua B.},
doi = {10.1111/j.1467-9280.2006.01780.x},
file = {:home/kaslu/Documents/Mendeley/2006 - Griffiths, Tenenbaum - Optimal Predictions in Everyday Cognition.pdf:pdf},
isbn = {0956-7976},
issn = {0956-7976},
journal = {Psychological Science},
month = {sep},
number = {9},
pages = {767--773},
pmid = {16984293},
title = {{Optimal Predictions in Everyday Cognition}},
url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01780.x},
volume = {17},
year = {2006}
}
@article{Oizumi2014,
author = {Oizumi, Masafumi and Albantakis, Larissa and Tononi, Giulio},
doi = {10.1371/journal.pcbi.1003588},
editor = {Sporns, Olaf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {may},
number = {5},
pages = {e1003588},
title = {{From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003588},
volume = {10},
year = {2014}
}
@article{Bialek2006,
abstract = {Does the brain construct an efficient representation of the sensory world? We review progress on this question, focusing on a series of experiments in the last decade which use fly vision as a model system in which theory and experiment can confront each other. Although the idea of efficient representation has been productive, clearly it is incomplete since it doesn't tell us which bits of sensory information are most valuable to the organism. We argue that, in fact, an organism which maximizes the (biologically meaningful) adaptive value of its actions given fixed resources must have internal representations of the outside world that are optimal in a very specific information theoretic sense: they maximize the information about the future of sensory inputs at a fixed value of the information about their past. This principle contains as special cases computations which the brain seems to carry out, and it should be possible to test this optimization directly. We return to the fly visual system and report the results of preliminary experiments that are in very suggestive agreement with theory},
archivePrefix = {arXiv},
arxivId = {0712.4381},
author = {Bialek, William and {de Ruyter Van Steveninck}, Robert R. and Tishby, Naftali},
doi = {10.1109/ISIT.2006.261867},
eprint = {0712.4381},
file = {:home/kaslu/Documents/Mendeley/2006 - Bialek, de Ruyter Van Steveninck, Tishby - Efficient representation as a design principle for neural coding and computation.pdf:pdf},
isbn = {1424405041},
issn = {21578101},
journal = {IEEE International Symposium on Information Theory - Proceedings},
pages = {659--663},
title = {{Efficient representation as a design principle for neural coding and computation}},
year = {2006}
}
@article{Hidalgo2014,
abstract = {Empirical evidence suggesting that living systems might operate in the vicinity of critical points, at the borderline between order and disorder, has proliferated in recent years, with examples ranging from spontaneous brain activity to flock dynamics. However, a well-founded theory for understanding how and why interacting living systems could dynamically tune themselves to be poised in the vicinity of a critical point is lacking. Here we use tools from statistical mechanics and information theory to show that complex adaptive or evolutionary systems can be much more efficient in coping with diverse heterogeneous environmental conditions when operating at criticality. Analytical as well as computational evolutionary and adaptive models vividly illustrate that a community of such systems dynamically self-tunes close to a critical state as the complexity of the environment increases while they remain noncritical for simple and predictable environments. A more robust convergence to criticality emerges in coevolutionary and coadaptive setups in which individuals aim to represent other agents in the community with fidelity, thereby creating a collective critical ensemble and providing the best possible tradeoff between accuracy and flexibility. Our approach provides a parsimonious and general mechanism for the emergence of critical-like behavior in living systems needing to cope with complex environments or trying to efficiently coordinate themselves as an ensemble.},
author = {Hidalgo, Jorge and Grilli, Jacopo and Suweis, Samir and Mu{\~{n}}oz, Miguel A and Banavar, Jayanth R and Maritan, Amos},
doi = {10.1073/pnas.1319166111},
file = {:home/kaslu/Documents/Mendeley/2014 - Hidalgo et al. - Information-based fitness and the emergence of criticality in living systems.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Brain,Brain: physiology,Humans,Models, Neurological},
month = {jul},
number = {28},
pages = {10095--100},
pmid = {24982145},
title = {{Information-based fitness and the emergence of criticality in living systems.}},
url = {http://www.pnas.org/cgi/content/long/111/28/10095},
volume = {111},
year = {2014}
}
@article{Deneve2008,
abstract = {In the companion letter in this issue (" Bayesian Spiking Neurons I: In-ference "), we showed that the dynamics of spiking neurons can be in-terpreted as a form of Bayesian integration, accumulating evidence over time about events in the external world or the body. We proceed to de-velop a theory of Bayesian learning in spiking neural networks, where the neurons learn to recognize temporal dynamics of their synaptic in-puts. Meanwhile, successive layers of neurons learn hierarchical causal models for the sensory input. The corresponding learning rule is local, spike-time dependent, and highly nonlinear. This approach provides a principled description of spiking and plasticity rules maximizing infor-mation transfer, while limiting the number of costly spikes, between successive layers of neurons.},
author = {Den{\`{e}}ve, Sophie},
file = {:home/kaslu/Documents/Mendeley/2008 - Den{\`{e}}ve - Bayesian Spiking Neurons II Learning.pdf:pdf},
pages = {118--145},
title = {{Bayesian Spiking Neurons II: Learning}},
volume = {145},
year = {2008}
}
@article{Sreenivasan2011,
abstract = {Entorhinal grid cells in mammals fire as a function of animal location, with spatially periodic response patterns. This nonlocal periodic representation of location, a local variable, is unlike other neural codes. There is no theoretical explanation for why such a code should exist. We examined how accurately the grid code with noisy neurons allows an ideal observer to estimate location and found this code to be a previously unknown type of population code with unprecedented robustness to noise. In particular, the representational accuracy attained by grid cells over the coding range was in a qualitatively different class from what is possible with observed sensory and motor population codes. We found that a simple neural network can effectively correct the grid code. To the best of our knowledge, these results are the first demonstration that the brain contains, and may exploit, powerful error-correcting codes for analog variables.},
author = {Sreenivasan, Sameet and Fiete, Ila R.},
doi = {10.1038/nn.2901},
file = {:home/kaslu/Documents/Mendeley/2011 - Sreenivasan, Fiete - Grid cells generate an analog error-correcting code for singularly precise neural computation.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {1330--1337},
pmid = {21909090},
title = {{Grid cells generate an analog error-correcting code for singularly precise neural computation}},
url = {http://www.nature.com/doifinder/10.1038/nn.2901},
volume = {14},
year = {2011}
}
@article{Lerner1999,
abstract = {This article reviews the now extensive research literature addressing the impact of accountability on a wide range of social judgments and choices. It focuses on 4 issues: (a) What impact do various accountability ground rules have on thoughts, feelings, and action? (b) Under what conditions will accountability attenuate, have no effect on, or amplify cognitive biases? (c) Does accountability alter how people think or merely what people say they think? and (d) What goals do accountable decision makers seek to achieve? In addition, this review explores the broader implications of accountability research. It highlights the utility of treating thought as a process of internalized dialogue; the importance of documenting social and institutional boundary conditions on putative cognitive biases; and the potential to craft empirical answers to such applied problems as how to structure accountability relationships in organizations.},
author = {Lerner, Jennifer S and Tetlock, Philip E},
doi = {10.1037/0033-2909.125.2.255},
isbn = {0033-2909$\backslash$r1939-1455},
issn = {1939-1455},
journal = {Psychological Bulletin},
number = {2},
pages = {255--275},
pmid = {10087938},
publisher = {Miller Peecher {\&} Kleinmuntz},
title = {{Accounting for the effects of accountability.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.125.2.255},
volume = {125},
year = {1999}
}
@article{Paine2017,
author = {Paine, P. J. and Preston, S. P. and Tsagris, M. and Wood, Andrew T. A.},
doi = {10.1007/s11222-017-9756-4},
file = {:home/kaslu/Documents/Mendeley/2017 - Paine et al. - An elliptically symmetric angular Gaussian distribution.pdf:pdf},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {Angular Gaussian,Bootstrap,Kent distribution,Spher,angular gaussian,bootstrap,kent distribution,spherical distribution},
number = {September 2016},
publisher = {Springer US},
title = {{An elliptically symmetric angular Gaussian distribution}},
url = {http://link.springer.com/10.1007/s11222-017-9756-4},
year = {2017}
}
@article{Schmiedebergs2017,
author = {Chen, Janice and Leong, Yuan Chang and Honey, Christopher J. and Yong, Chung H. and Norman, Kenneth A. and Hasson, Uri},
doi = {10.1038/nn.4450},
file = {:home/kaslu/Documents/Mendeley/2016 - Chen et al. - Shared memories reveal shared structure in neural activity across individuals.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {1},
pages = {115--125},
title = {{Shared memories reveal shared structure in neural activity across individuals}},
url = {http://www.nature.com/doifinder/10.1038/nn.4450},
volume = {20},
year = {2016}
}
@article{Wu2016,
abstract = {The understanding and prediction of information diffusion processes on networks is a major challenge in network theory with many implications in social sciences. Many theoretical advances came at the hand of stochastic spreading models. Nevertheless, these stochastic models overlooked the influence of rational decision on the outcome of the process. For instance, different levels of trust on acquaintances do play a role in the information spreading, and actors may change their spreading decisions during the information diffusion process accordingly. Here, we study an information spreading model where the decision to transmit or not is based on trust. We explore the interplay between the propagation of information and the trust dynamics happening on a two layer multiplex network. Actors' trustable or untrustable states are assimilated as accumulated cooperation or defection behaviors, respectively, in a prisoners' dilemma set up, and controlled by a memory span. The propagation of the information is abstracted as a threshold model on the information spreading layer. The analysis of the model is performed using a tree approximation and validated on homogeneous and heterogeneous networks. The results show that the memory of previous actions highly affects the spreading of information, being larger the diffusion when less memory is considered. Information is highly promoted by the emergence of trustable acquaintances. These results pave the way to a deeper understanding of, for example, gossip spreading dynamics.},
archivePrefix = {arXiv},
arxivId = {1606.01688},
author = {Wu, Hongrun and Arenas, Alex and G{\'{o}}mez, Sergio},
doi = {10.1103/PhysRevE.95.012301},
eprint = {1606.01688},
file = {:home/kaslu/Documents/Mendeley/2016 - Wu, Arenas, G{\'{o}}mez - On the influence of trust in the spreading of information.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {1--13},
title = {{On the influence of trust in the spreading of information}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.95.012301 http://arxiv.org/abs/1606.01688},
volume = {95},
year = {2016}
}
@article{Dimitrov2011,
abstract = {Cells interact with their environment and they have to react adequately to internal and external changes such changes in nutrient composition, physical properties like temperature or osmolarity and other stresses. More specifically, they must be able to evaluate whether the external change is significant or just in the range of noise. Based on multiple external parameters they have to compute an optimal response. Cellular signaling pathways are considered as the major means of information perception and transmission in cells.},
author = {Dimitrov, Alexander G. and Lazar, Aurel A. and Victor, Jonathan D.},
doi = {10.1007/s10827-011-0314-3},
file = {:home/kaslu/Documents/Mendeley/2011 - Dimitrov, Lazar, Victor - Information theory in neuroscience.pdf:pdf;:home/kaslu/Documents/Mendeley/2011 - Dimitrov, Lazar, Victor - Information theory in neuroscience(2).pdf:pdf},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Animals,Humans,Information Theory,Neurosciences},
month = {feb},
number = {1},
pages = {1--5},
pmid = {21279429},
title = {{Information theory in neuroscience.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3736735{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {30},
year = {2011}
}
@article{Shwartz-Ziv2017,
archivePrefix = {arXiv},
arxivId = {1703.00810},
author = {Shwartz-Ziv, Ravid and Tishby, Naftali},
eprint = {1703.00810},
file = {:home/kaslu/Documents/Mendeley/2017 - Shwartz-Ziv, Tishby - Opening the Black Box of Deep Neural Networks via Information.pdf:pdf},
title = {{Opening the Black Box of Deep Neural Networks via Information}},
url = {http://arxiv.org/abs/1703.00810},
year = {2017}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
author = {Schultz, W and Dayan, Peter and Montague, P. R.},
doi = {10.1126/science.275.5306.1593},
file = {:home/kaslu/Documents/Mendeley/1997 - Schultz, Dayan, Montague - A Neural Substrate of Prediction and Reward.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {mar},
number = {5306},
pages = {1593--1599},
pmid = {9054347},
publisher = {American Association for the Advancement of Science},
title = {{A Neural Substrate of Prediction and Reward}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9054347 http://www.sciencemag.org/cgi/doi/10.1126/science.275.5306.1593},
volume = {275},
year = {1997}
}
@article{Yoon2013,
abstract = {We examined simultaneously recorded spikes from multiple rat grid cells, to explain mechanisms underlying their activity. Among grid cells with similar spatial periods, the population activity was confined to lie close to a two-dimensional (2D) manifold: grid cells differed only along two dimensions of their responses and otherwise were nearly identical. Relationships between cell pairs were conserved despite extensive deformations of single-neuron responses. Results from novel environments suggest such structure is not inherited from hippocampal or external sensory inputs. Across conditions, cell-cell relationships are better conserved than responses of single cells. Finally, the system is continually subject to perturbations that, were the 2D manifold not attractive, would drive the system to inhabit a different region of state space than observed. These findings have strong implications for theories of grid-cell activity and substantiate the general hypothesis that the brain computes using low-dimensional continuous attractors.},
author = {Yoon, KiJung and Buice, Michael A and Barry, Caswell and Hayman, Robin and Burgess, Neil and Fiete, Ila R.},
doi = {10.1038/nn.3450},
file = {:home/kaslu/Documents/Mendeley/2013 - Yoon et al. - Specific evidence of low-dimensional continuous attractor dynamics in grid cells.pdf:pdf},
isbn = {doi:10.1038/nn.3450},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {8},
pages = {1077--1084},
pmid = {23852111},
publisher = {Nature Publishing Group},
title = {{Specific evidence of low-dimensional continuous attractor dynamics in grid cells}},
url = {http://www.nature.com/doifinder/10.1038/nn.3450},
volume = {16},
year = {2013}
}
@article{Gruntman2018,
abstract = {A neuron that extracts directionally selective motion information from upstream signals lacking this selectivity must compare visual responses from spatially offset inputs. Distinguishing among prevailing algorithmic models for this computation requires measuring fast neuronal activity and inhibition. In the Drosophila melanogaster visual system, a fourth-order neuron—T4—is the first cell type in the ON pathway to exhibit directionally selective signals. Here we use in vivo whole-cell recordings of T4 to show that directional selectivity originates from simple integration of spatially offset fast excitatory and slow inhibitory inputs, resulting in a suppression of responses to the nonpreferred motion direction. We constructed a passive, conductance-based model of a T4 cell that accurately predicts the neuron's response to moving stimuli. These results connect the known circuit anatomy of the motion pathway to the algorithmic mechanism by which the direction of motion is computed.},
author = {Gruntman, Eyal and Romani, Sandro and Reiser, Michael B.},
doi = {10.1038/s41593-017-0046-4},
issn = {1097-6256},
journal = {Nature Neuroscience 2017},
pages = {1},
title = {{Simple integration of fast excitation and offset, delayed inhibition computes directional selectivity in Drosophila}},
url = {http://www.nature.com/articles/s41593-017-0046-4 https://www.nature.com/articles/s41593-017-0046-4},
year = {2018}
}
@article{Caticha2017a,
abstract = {Entropic Dynamics (ED) is a framework in which Quantum Mechanics (QM) is derived as an application of entropic methods of inference. The magnitude of the wave function is manifestly epistemic: its square is a probability distribution. The epistemic nature of the phase of the wave function is also clear: it controls the flow of probability. The dynamics is driven by entropy subject to constraints that capture the relevant physi-cal information. The central concern is to identify those constraints and how they are updated. After reviewing previous work I describe how con-siderations from information geometry allow us to derive a phase space geometry that combines Riemannian, symplectic, and complex structures. The ED that preserves these structures is QM. The full equivalence be-tween ED and QM is achieved by taking account of how gauge symmetry and charge quantization are intimately related to quantum phases and the single-valuedness of wave functions.},
archivePrefix = {arXiv},
arxivId = {arXiv:1711.02538v1},
author = {Caticha, Ariel},
eprint = {arXiv:1711.02538v1},
file = {:home/kaslu/Documents/Mendeley/2017 - Caticha - Entropic Dynamics Quantum Mechanics from Entropy and Information Geometry.pdf:pdf},
title = {{Entropic Dynamics: Quantum Mechanics from Entropy and Information Geometry}},
year = {2017}
}
@article{Task1996,
author = {Task, Line Judgment and Bond, Rod and Smith, Peter B},
file = {:home/kaslu/Documents/Mendeley/1996 - Task, Bond, Smith - Culture and Conformity A Meta-Analysis of Studies Using Asch ' s.pdf:pdf},
journal = {Psychological Bulletin},
number = {1},
pages = {111--137},
title = {{Culture and Conformity : A Meta-Analysis of Studies Using Asch ' s}},
volume = {119},
year = {1996}
}
@article{Rao1999,
abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower- order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images. Neurons},
author = {Rao, Rajesh P. N. and Ballard, Dana H.},
doi = {10.1038/4580},
file = {:home/kaslu/Documents/Mendeley/1999 - Rao, Ballard - Predictive coding in the visual cortex a functional interpretation of some extra-classical receptive-field effects.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {1},
pages = {79--87},
pmid = {10195184},
title = {{Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects}},
url = {10.1038/4580{\%}5Cnhttp://www.nature.com/neuro/journal/v2/n1/abs/nn0199{\_}79.html},
volume = {2},
year = {1999}
}
@article{Herculano-Houzel2012,
abstract = {Neuroscientists have become used to a number of "facts" about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20{\%} of the total body energy budget despite representing only 2{\%} of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.},
author = {Herculano-Houzel, Suzana},
doi = {10.1073/pnas.1201895109},
file = {:home/kaslu/Documents/Mendeley/2012 - Herculano-Houzel - The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Biological Evolution,Brain,Brain: anatomy {\&} histology,Humans,Nerve Net,Nerve Net: anatomy {\&} histology,Neuroglia,Neuroglia: metabolism,Neurons,Neurons: metabolism,Primates,Primates: anatomy {\&} histology},
month = {jun},
number = {Supplement{\_}1},
pages = {10661--8},
pmid = {22723358},
title = {{The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost.}},
url = {http://www.pnas.org/cgi/content/long/109/Supplement{\_}1/10661},
volume = {109 Suppl },
year = {2012}
}
@article{Piet2017,
abstract = {We derive a synaptic weight update rule for learning temporally precise spike train to spike train transformations in multilayer feedforward networks of spiking neurons. The framework, aimed at seamlessly generalizing error backpropagation to the deterministic spiking neuron setting, is based strictly on spike timing and avoids invoking concepts pertaining to spike rates or probabilistic models of spiking. The derivation is founded on two innovations. First, an error functional is proposed that compares the spike train emitted by the output neuron of the network to the desired spike train by way of their putative impact on a virtual postsynaptic neuron. This formulation sidesteps the need for spike alignment and leads to closed form solutions for all quantities of interest. Second, virtual assignment of weights to spikes rather than synapses enables a perturbation analysis of individual spike times and synaptic weights of the output as well as all intermediate neurons in the network, which yields the gradients of the error functional with respect to the said entities. Learning proceeds via a gradient descent mechanism that leverages these quantities. Simulation experiments demonstrate the efficacy of the proposed learning framework. The experiments also highlight asymmetries between synapses on excitatory and inhibitory neurons.},
author = {Piet, Alex T. and Erlich, Jeffrey C. and Kopec, Charles D. and Brody, Carlos D.},
doi = {10.1162/neco_a_01005},
file = {:home/kaslu/Documents/Mendeley/2017 - Piet et al. - Rat Prefrontal Cortex Inactivations during Decision Making Are Explained by Bistable Attractor Dynamics.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {aug},
pages = {1--26},
title = {{Rat Prefrontal Cortex Inactivations during Decision Making Are Explained by Bistable Attractor Dynamics}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco{\_}a{\_}01005},
year = {2017}
}
@article{Burridge2016,
abstract = {We study the spread of a persuasive new idea through a population of continuous time random walkers in one dimension. The idea spreads via social gatherings involving groups of nearby walkers who act according to a biased "majority rule": After each gathering, the group takes on the new idea if more than a critical fraction {\$}\backslashfrac{\{}1-\backslashvarepsilon{\}}{\{}2{\}} {\textless} \backslashfrac{\{}1{\}}{\{}2{\}}{\$} of them already hold it; otherwise they all reject it. The boundary of a domain where the new idea has taken hold expands as a travelling wave in the density of new idea holders. Our walkers move by L$\backslash$'{\{}e{\}}vy Motion, and we compute the wave velocity analytically as a function of the frequency of social gatherings and the exponent of the jump distribution. When this distribution is sufficiently heavy tailed then, counter to intuition, the idea can propagate faster if social gatherings are held less frequently. When jumps are truncated, a critical gathering frequency can emerge which maximizes propagation velocity. We explore our model by simulation, confirming our analytical results.},
archivePrefix = {arXiv},
arxivId = {1609.09418},
author = {Burridge, James and Gnacik, Michal},
doi = {10.1103/PhysRevE.94.062319},
eprint = {1609.09418},
journal = {PHYSICAL REVIEW E},
title = {{Infrequent social interaction can accelerate the spread of a persuasive idea}},
url = {http://arxiv.org/abs/1609.09418},
volume = {94},
year = {2016}
}
@article{Parkinson2017,
abstract = {Humans form complex social networks that include numerous non‐reproductive bonds with non‐kin. Navigating these networks presents a considerable cognitive challenge thought to have comprised a driving force in human brain evolution. Yet, little is known about how and to what extent the human brain encodes the structure of the social networks in which it is embedded. By combining social network analysis and multi‐voxel pattern analysis of functional magnetic resonance imaging (fMRI) data, we show that social network information about direct relationships, bonds between third parties, and aspects of the broader network topology is accurately perceived and automatically activated upon seeing a familiar other.},
author = {Parkinson, Carolyn and Kleinbaum, Adam M. and Wheatley, Thalia},
doi = {10.1038/s41562-017-0072},
file = {:home/kaslu/Documents/Mendeley/2017 - Parkinson, Kleinbaum, Wheatley - Spontaneous neural encoding of social network position.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
month = {apr},
number = {April},
pages = {0072},
publisher = {Macmillan Publishers Limited, part of Springer Nature.},
title = {{Spontaneous neural encoding of social network position}},
url = {http://biorxiv.org/content/early/2017/01/09/098988.abstract http://www.ssrn.com/abstract=2894694 http://www.nature.com/articles/s41562-017-0072},
volume = {1},
year = {2017}
}
@article{Lahiri2016,
abstract = {Interesting data often concentrate on low dimensional smooth manifolds inside a high dimensional ambient space. Random projections are a simple, powerful tool for dimensionality reduction of such data. Previous works have studied bounds on how many projections are needed to accurately preserve the geometry of these manifolds, given their intrinsic dimensionality, volume and curvature. However, such works employ definitions of volume and curvature that are inherently difficult to compute. Therefore such theory cannot be easily tested against numerical simulations to understand the tightness of the proven bounds. We instead study typical distortions arising in random projections of an ensemble of smooth Gaussian random manifolds. We find explicitly computable, approximate theoretical bounds on the number of projections required to accurately preserve the geometry of these manifolds. Our bounds, while approximate, can only be violated with a probability that is exponentially small in the ambient dimension, and therefore they hold with high probability in cases of practical interest. Moreover, unlike previous work, we test our theoretical bounds against numerical experiments on the actual geometric distortions that typically occur for random projections of random smooth manifolds. We find our bounds are tighter than previous results by several orders of magnitude.},
archivePrefix = {arXiv},
arxivId = {1607.04331},
author = {Lahiri, Subhaneil and Gao, Peiran and Ganguli, Surya},
eprint = {1607.04331},
file = {:home/kaslu/Documents/Mendeley/2016 - Lahiri, Gao, Ganguli - Random projections of random manifolds.pdf:pdf},
isbn = {0001406108},
pages = {1--45},
title = {{Random projections of random manifolds}},
url = {http://arxiv.org/abs/1607.04331},
year = {2016}
}
@article{Wilson2014a,
abstract = {We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.},
author = {Wilson, Greg and Aruliah, D. A. and Brown, C. Titus and {Chue Hong}, Neil P. and Davis, Matt and Guy, Richard T. and Haddock, Steven H D and Huff, Kathryn D. and Mitchell, Ian M. and Plumbley, Mark D. and Waugh, Ben and White, Ethan P. and Wilson, Paul},
doi = {10.1371/journal.pbio.1001745},
editor = {Eisen, Jonathan A.},
file = {:home/kaslu/Documents/Mendeley/2014 - Wilson et al. - Best Practices for Scientific Computing.PDF:PDF},
issn = {1545-7885},
journal = {PLoS Biology},
month = {jan},
number = {1},
pages = {e1001745},
title = {{Best Practices for Scientific Computing}},
url = {http://dx.plos.org/10.1371/journal.pbio.1001745},
volume = {12},
year = {2014}
}
@article{Sharpee2002a,
abstract = {We propose a method that allows for a rigorous statistical analysis of neural responses to natural stimuli which are non-Gaussian and exhibit strong correlations. We have in mind a model in which neurons are selective for a small number of stimulus dimensions out of a high dimensional stimulus space, but within this subspace the responses can be arbitrarily nonlinear. Existing analysis methods are based on correlation functions between stimuli and responses, but these methods are guaranteed to work only in the case of Gaussian stimulus ensembles. As an alternative to correlation functions, we maximize the mutual information between the neural responses and projections of the stimulus onto low dimensional subspaces. The procedure can be done iteratively by increasing the dimensionality of this subspace. Those dimensions that allow the recovery of all of the information between spikes and the full unprojected stimuli describe the relevant subspace. If the dimensionality of the relevant subspace indeed is small, it becomes feasible to map the neuron's input-output function even under fully natural stimulus conditions. These ideas are illustrated in simulations on model visual and auditory neurons responding to natural scenes and sounds, respectively.},
archivePrefix = {arXiv},
arxivId = {physics/0212110},
author = {Sharpee, Tatyana and Rust, Nicole C. and Bialek, William},
doi = {10.1162/089976604322742010},
eprint = {0212110},
file = {:home/kaslu/Documents/Mendeley/2004 - Sharpee, Rust, Bialek - Analyzing Neural Responses to Natural Signals Maximally Informative Dimensions.pdf:pdf},
isbn = {0899-7667 (Print)},
issn = {0899-7667},
journal = {Neural Computation},
month = {feb},
number = {2},
pages = {223--250},
pmid = {15006095},
primaryClass = {physics},
title = {{Analyzing Neural Responses to Natural Signals: Maximally Informative Dimensions}},
url = {http://arxiv.org/abs/physics/0212110 http://www.mitpressjournals.org/doi/10.1162/089976604322742010},
volume = {16},
year = {2004}
}
@article{Garrido2016,
author = {Garrido, Marta Isabel and Teng, Chee Leong James and Taylor, Jeremy Alexander and Rowe, Elise Genevieve and Mattingley, Jason Brett},
doi = {10.1038/npjscilearn.2016.6},
file = {:home/kaslu/Documents/Mendeley/2016 - Garrido et al. - Surprise responses in the human brain demonstrate statistical learning under high concurrent cognitive demand.pdf:pdf},
issn = {2056-7936},
journal = {npj Science of Learning},
month = {jun},
pages = {16006},
publisher = {Nature Publishing Group},
title = {{Surprise responses in the human brain demonstrate statistical learning under high concurrent cognitive demand}},
url = {http://www.nature.com/articles/npjscilearn20166},
volume = {1},
year = {2016}
}
@article{Shen2016,
author = {Shen, Shan and Ma, Wei Ji},
doi = {10.1037/rev0000028},
file = {:home/kaslu/Documents/Mendeley/2016 - Shen, Ma - A detailed comparison of optimality and simplicity in perceptual decision making.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {2007,2011,according to which the,bayesian optimality,brain maximizes performance,geisler,ideal observer,k{\"{o}}rding et al,many forms of human,model comparison,optimality,perception,perception seem close to,the ideal set by,visual search},
month = {jan},
number = {4},
pages = {452--480},
title = {{A detailed comparison of optimality and simplicity in perceptual decision making.}},
url = {http://link.springer.com/10.1007/s00210-015-1172-8 http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000028},
volume = {123},
year = {2016}
}
@article{Haidt2010,
abstract = {In one of the earliest textbooks of social psychology, William McDougall wrote that “ The fundamental prob- lem of social psychology is the moralization of the indi- vidual by the society into which he is born as a creature in which the non - moral and purely egoistic tendencies are so much stronger than any altruistic tendencies ” (McDougall, 1908/1998, p. 18). McDougall dreamed of a social psychology that would span the study of individu- als and societies, and he believed morality would be the main bridge. He hoped that social psychology would one day document the full set of “ instincts ” and other endow- ments present in individual minds, and then demonstrate how these were activated and combined to create large and cooperative groups of individuals. If McDougall could come back today and see how his beloved fi eld has fared, what would he think of its progress? A},
author = {Haidt, Jonathan and Kesebir, Selin},
doi = {10.1002/9780470561119.socpsy002022},
file = {:home/kaslu/Documents/Mendeley/2010 - Haidt, Kesebir - Morality(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2010 - Haidt, Kesebir - Morality.pdf:pdf},
isbn = {978-1-60623-673-4},
issn = {0470561114},
journal = {Handbook of Social Psychology},
pages = {797--832},
title = {{Morality}},
year = {2010}
}
@article{Decety2017,
abstract = {Humans from a very early age are deeply sensitive to issues of justice and fairness, both in their own lives and in the lives of others. Most people are highly motivated to pursue justice and condemn injustice. Where does this concern for justice come from? Here we integrate findings in evolution, development, psychology, behavioral economics, and social neuroscience to highlight multiple potential drivers of justice motivation. We argue that justice motivation arises from complementary rapid heuristics and deliberation, each utilizing distinct and interacting neural circuitry. This framework is useful for explaining observed symmetries and asymmetries in responses to experiencing or observing injustice and may help to explain why individuals vary in their responses to injustice.},
author = {Decety, Jean and Yoder, Keith J.},
doi = {10.1016/j.tics.2016.10.008},
isbn = {1879-307X (Electronic) 1364-6613 (Linking)},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {development,evolution,fairness,justice,morality,neuroeconomics,neuroscience},
number = {1},
pages = {6--14},
pmid = {27865787},
publisher = {Elsevier Ltd},
title = {{The Emerging Social Neuroscience of Justice Motivation}},
url = {http://dx.doi.org/10.1016/j.tics.2016.10.008},
volume = {21},
year = {2017}
}
@article{Ramalho2013,
abstract = {The simulation of complex stochastic network dynamics arising, for instance, from models of coupled biomolecular processes remains computationally challenging. Often, the necessity to scan a model's dynamics over a large parameter space renders full-fledged stochastic simulations impractical, motivating approximation schemes. Here we propose an approximation scheme which improves upon the standard linear noise approximation while retaining similar computational complexity. The underlying idea is to minimize, at each time step, the Kullback-Leibler divergence between the true time evolved probability distribution and a Gaussian approximation (entropic matching). This condition leads to ordinary differential equations for the mean and the covariance matrix of the Gaussian. For cases of weak nonlinearity, the method is more accurate than the linear method when both are compared to stochastic simulations.},
archivePrefix = {arXiv},
arxivId = {1209.3700},
author = {Ramalho, Tiago and Selig, Marco and Gerland, Ulrich and En{\ss}lin, Torsten},
doi = {10.1103/PhysRevE.87.022719},
eprint = {1209.3700},
file = {:home/kaslu/Documents/Mendeley/2013 - Ramalho et al. - Simulation of stochastic network dynamics via entropic matching.pdf:pdf},
issn = {1550-2376},
journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},
keywords = {Animals,Biological,Computer Simulation,Entropy,Humans,Models,Proteome,Proteome: metabolism,Statistical,Stochastic Processes},
month = {feb},
number = {2},
pages = {022719},
pmid = {23496560},
title = {{Simulation of stochastic network dynamics via entropic matching.}},
url = {http://arxiv.org/abs/1209.3700},
volume = {87},
year = {2013}
}
@article{Huk2005,
abstract = {Decision-making often requires the accumulation and maintenance of evidence over time. Although the neural signals underlying sensory processing have been studied extensively, little is known about how the brain accrues and holds these sensory signals to guide later actions. Previous work has suggested that neural activity in the lateral intraparietal area (LIP) of the monkey brain reflects the formation of perceptual decisions in a random dot direction-discrimination task in which monkeys communicate their decisions with eye-movement responses. We tested the hypothesis that decision-related neural activity in LIP represents the time integral of the momentary motion "evidence." By briefly perturbing the strength of the visual motion stimulus during the formation of perceptual decisions, we tested whether this LIP activity reflected a persistent, integrated "memory" of these brief sensory events. We found that the responses of LIP neurons reflected substantial temporal integration. Brief pulses had persistent effects on both the monkeys' choices and the responses of neurons in LIP, lasting up to 800 ms after appearance. These results demonstrate that LIP is involved in neural time integration underlying the accumulation of evidence in this task. Additional analyses suggest that decision-related LIP responses, as well as behavioral choices and reaction times, can be explained by near-perfect time integration that stops when a criterion amount of evidence has been accumulated. Temporal integration may be a fundamental computation underlying higher cognitive functions that are dissociated from immediate sensory inputs or motor outputs.},
author = {Huk, Alexander C. and Shadlen, Michael N.},
doi = {10.1523/JNEUROSCI.4684-04.2005},
file = {:home/kaslu/Documents/Mendeley/2005 - Huk, Shadlen - Neural Activity in Macaque Parietal Cortex Reflects Temporal Integration of Visual Motion Signals during Perceptua.pdf:pdf},
isbn = {0270-6474},
issn = {1529-2401},
journal = {J. Neurosci.},
keywords = {electrophysiology,lateral intraparietal area,lip,reaction time,vision,visual motion},
number = {45},
pages = {10420--10436},
pmid = {16280581},
title = {{Neural Activity in Macaque Parietal Cortex Reflects Temporal Integration of Visual Motion Signals during Perceptual Decision Making}},
url = {http://www.jneurosci.org/cgi/content/abstract/25/45/10420{\%}5Cnhttp://www.jneurosci.org/cgi/content/full/25/45/10420},
volume = {25},
year = {2005}
}
@article{Momennejad2017,
abstract = {Theories of reinforcement learning in neuroscience have focused on two families of algorithms. Model-free algorithms cache action values, making them cheap but inflexible: a candidate mechanism for adaptive and maladaptive habits. Model-based algorithms achieve flexibility at computational expense, by rebuilding values from a model of the environment. We examine an intermediate class of algorithms, the successor representation (SR), which caches long-run state expectancies, blending model-free efficiency with model-based flexibility. Although previous reward revaluation studies distinguish model-free from model-based learning algorithms, such designs cannot discriminate between model-based and SR-based algorithms, both of which predict sensitivity to reward revaluation. However, changing the transition structure (" transition revaluation ") should selectively impair revaluation for the SR. In two studies we provide evidence that humans are differentially sensitive to reward vs. transition revaluation, consistent with SR predictions. These results support a new neuro-computational mechanism for flexible choice, while introducing a subtler, more cognitive notion of habit.},
author = {Momennejad, I. and Russek, E. M. and Cheong, J. H. and Botvinick, Matthew M. and Daw, Nathaniel D. and Gershman, Samuel J.},
doi = {10.1038/s41562-017-0180-8},
file = {:home/kaslu/Documents/Mendeley/2017 - Momennejad et al. - The successor representation in human reinforcement learning.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
keywords = {Behavioral Sciences,Experimental Psychology,Life Sciences,Microeconomics,Neurosciences,Personality and Social Psychology,general},
month = {sep},
number = {9},
pages = {680--692},
publisher = {Nature Publishing Group},
title = {{The successor representation in human reinforcement learning}},
url = {http://www.nature.com/articles/s41562-017-0180-8},
volume = {1},
year = {2017}
}
@article{Collins2017,
abstract = {Learning from rewards and punishments is essential to survival, and facilitates flexible human behavior. It is widely appreciated that multiple cognitive and reinforcement learning systems contribute to behavior, but the nature of their interactions is elusive. Here, we leverage novel methods for extracting trial-by-trial indices of reinforcement learning (RL) and working memory (WM) in human electro- encephalography to reveal single trial computations beyond that afforded by behavior alone. Within-trial dynamics confirmed that increases in neural expectation were predictive of reduced neural surprise in the following feedback period, supporting central tenets of RL models. Cross-trial dynamics revealed a cooperative interplay between systems for learning, in which WM contributes expectations to guide RL, despite competition between systems during choice. Together, these results provide a deeper understanding of how multiple neural systems interact for learning and decision making, and facilitate analysis of their disruption in clinical populations.},
author = {Collins, Anne and Frank, Michael},
doi = {10.1101/184812},
file = {:home/kaslu/Documents/Mendeley/2017 - Collins, Frank - Within and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and wo.pdf:pdf},
issn = {0027-8424},
journal = {Doi.Org},
pages = {184812},
pmid = {29463751},
title = {{Within and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory}},
url = {https://www.biorxiv.org/content/early/2017/09/05/184812.full.pdf+html},
year = {2017}
}
@article{Bezanson2014,
abstract = {Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical computing. Julia is designed to be easy and fast. Julia questions notions generally held as "laws of nature" by practitioners of numerical computing: 1. High-level dynamic programs have to be slow. 2. One must prototype in one language and then rewrite in another language for speed or deployment, and 3. There are parts of a system for the programmer, and other parts best left untouched as they are built by the experts. We introduce the Julia programming language and its design --- a dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch, a technique from computer science, picks the right algorithm for the right circumstance. Abstraction, what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that one can have machine performance without sacrificing human convenience.},
archivePrefix = {arXiv},
arxivId = {1411.1607},
author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
doi = {10.1137/141000671},
eprint = {1411.1607},
file = {:home/kaslu/Documents/Mendeley/2014 - Bezanson et al. - Julia A Fresh Approach to Numerical Computing.pdf:pdf},
issn = {0036-1445},
keywords = {10,1137,141000671,65y05,68n15,97p40,ams subject classifications,doi,julia,numerical,parallel,scientific computing},
month = {nov},
number = {1},
pages = {65--98},
title = {{Julia: A Fresh Approach to Numerical Computing}},
url = {http://arxiv.org/abs/1411.1607},
volume = {59},
year = {2014}
}
@article{DeMartino2012,
author = {{De Martino}, Benedetto and Fleming, Stephen M and Garrett, Neil and Dolan, Raymond J},
doi = {10.1038/nn.3279},
file = {:home/kaslu/Documents/Mendeley/2012 - De Martino et al. - Confidence in value-based choice.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {1},
pages = {105--110},
pmid = {23222911},
title = {{Confidence in value-based choice}},
url = {http://www.nature.com/doifinder/10.1038/nn.3279},
volume = {16},
year = {2012}
}
@article{Carroll2017,
abstract = {Some modern cosmological models predict the appearance of Boltzmann Brains: observers who randomly fluctuate out of a thermal bath rather than naturally evolving from a low-entropy Big Bang. A theory in which most observers are of the Boltzmann Brain type is generally thought to be unacceptable, although opinions differ. I argue that such theories are indeed unacceptable: the real problem is with fluctuations into observers who are locally identical to ordinary observers, and their existence cannot be swept under the rug by a choice of probability distributions over observers. The issue is not that the existence of such observers is ruled out by data, but that the theories that predict them are cognitively unstable: they cannot simultaneously be true and justifiably believed.},
archivePrefix = {arXiv},
arxivId = {1702.00850},
author = {Carroll, Sean M.},
eprint = {1702.00850},
file = {:home/kaslu/Documents/Mendeley/2017 - Carroll - Why Boltzmann Brains Are Bad.pdf:pdf},
pages = {1--27},
title = {{Why Boltzmann Brains Are Bad}},
url = {http://arxiv.org/abs/1702.00850},
year = {2017}
}
@article{Bang2017,
abstract = {Most important decisions in our society are made by groups, from cabinets and commissions to boards and juries. When dis- agreement arises, opinions expressed with higher confidence tend to carry more weight1,2 . Although an individual's degree of confidence often reflects the probability that their opinion is correct3,4 , it can also vary with task-irrelevant psychologi- cal, social, cultural and demographic factors5–9 . Therefore, to combine their opinions optimally, group members must adapt to each other's individual biases and express their confidence according to a common metric10–12 . However, solving this com- munication problem is computationally difficult. Here we show that pairs of individuals making group decisions meet this challenge by using a heuristic strategy that we call ‘confi- dence matching': they match their communicated confidence so that certainty and uncertainty is stated in approximately equal measure by each party. Combining the behavioural data with computational modelling, we show that this strategy is effective when group members have similar levels of exper- tise, and that it is robust when group members have no insight into their relative levels of expertise. Confidence matching is, however, sub-optimal and can cause miscommunication about who is more likely to be correct. This herding behaviour is one reason why groups can fail to make good decisions10–12 .},
author = {Bang, Dan and Aitchison, Laurence and Moran, Rani and {Herce Castanon}, Santiago and Rafiee, Banafsheh and Mahmoodi, Ali and Lau, Jennifer Y. F. and Latham, Peter E. and Bahrami, Bahador and Summerfield, Christopher},
doi = {10.1038/s41562-017-0117},
file = {:home/kaslu/Documents/Mendeley/2017 - Bang et al. - Confidence matching in group decision-making.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
number = {6},
pages = {0117},
title = {{Confidence matching in group decision-making}},
url = {http://www.nature.com/articles/s41562-017-0117},
volume = {1},
year = {2017}
}
@article{Schelling1969,
author = {Schelling, Thomas C.},
file = {:home/kaslu/Documents/Mendeley/1969 - Schelling - Models of segregation.pdf:pdf},
journal = {The American Economic Review},
number = {2},
pages = {488--493},
title = {{Models of segregation}},
volume = {59},
year = {1969}
}
@article{Soutschek2017,
author = {Soutschek, A and Burke, CJ and {Raja Beharelle}, A and Schreiber, R and Weber, SC and Karipidis, II and ten Velden, J and Weber, B and Haker, H and Kalenscher, T and Tobler, PN},
doi = {10.1038/s41562-017-0226-y},
file = {:home/kaslu/Documents/Mendeley/2017 - Soutschek et al. - The dopaminergic reward system underpins gender differences in social preferences.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behavior},
publisher = {Springer US},
title = {{The dopaminergic reward system underpins gender differences in social preferences}},
url = {http://dx.doi.org/10.1038/s41562-017-0226-y},
year = {2017}
}
@article{Niv2011,
abstract = {A wealth of research focuses on the decision-making processes that ani- mals and humans employ when selecting actions in the face of reward and punish- ment. Initially suchwork stemmed from psychological investigations of conditioned behavior, and explanations of these in terms of computational models. Increasingly, analysis at the computational level has drawn on ideas from reinforcement learn- ing, which provide a normative framework within which decision-making can be analyzed. More recently, the fruits of these extensive lines of research have made contact with investigations into the neural basis of decision making. Converging evi- dence nowlinks reinforcement learning to specific neural substrates, assigning them precise computational roles. Specifically, electrophysiological recordings in behav- ing animals and functional imaging of human decision-making have revealed in the brain the existence of a key reinforcement learning signal, the temporal difference reward prediction error. Here, we first introduce the formal reinforcement learning framework. We then review the multiple lines of evidence linking reinforcement learning to the function of dopaminergic neurons in the mammalian midbrain and to more recent data from human imaging experiments. We further extend the dis- cussion to aspects of learning not associated with phasic dopamine signals, such as learning of goal-directed responding that may not be dopamine-dependent, and learning about the vigor (or rate) with which actions should be performed that has been linked to tonic aspects of dopaminergic signaling. We end with a brief discus- sion of some of the limitations of the reinforcement learning framework, highlight- ing questions for future research.},
author = {Niv, Yael},
doi = {10.1016/j.jmp.2008.12.005},
file = {:home/kaslu/Documents/Mendeley/2011 - Niv - Reinforcement learning in the brain.pdf:pdf},
isbn = {0022-2496},
issn = {00222496},
journal = {Learning},
pages = {1--38},
title = {{Reinforcement learning in the brain}},
year = {2011}
}
@article{Averbeck2006,
abstract = {How the brain encodes information in population activity, and how it combines and manipulates that activity as it carries out computations, are questions that lie at the heart of systems neuroscience. During the past decade, with the advent of multi-electrode recording and improved theoretical models, these questions have begun to yield answers. However, a complete understanding of neuronal variability, and, in particular, how it affects population codes, is missing. This is because variability in the brain is typically correlated, and although the exact effects of these correlations are not known, it is known that they can be large. Here, we review studies that address the interaction between neuronal noise and population codes, and discuss their implications for population coding in general.},
author = {Averbeck, Bruno B. and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/nrn1888},
file = {:home/kaslu/Documents/Mendeley/2006 - Averbeck, Latham, Pouget - Neural correlations, population coding and computation.pdf:pdf},
isbn = {1471-003X (Print)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
number = {5},
pages = {358--366},
pmid = {16760916},
title = {{Neural correlations, population coding and computation.}},
volume = {7},
year = {2006}
}
@article{Friston2016,
abstract = {This Opinion article considers the implications for functional anatomy of how we represent temporal structure in our exchanges with the world. It offers a theoretical treatment that tries to make sense of the architectural principles seen in mammalian brains. Specifically, it considers a factorisation between representations of temporal succession and representations of content or, heuristically, a segregation into when and what. This segregation may explain the central role of the hippocampus in neuronal hierarchies while providing a tentative explanation for recent observations of how ordinal sequences are encoded. The implications for neuroanatomy and physiology may have something important to say about how self-organised cell assembly sequences enable the brain to exhibit purposeful behaviour that transcends the here and now.},
author = {Friston, Karl and Buzs{\'{a}}ki, Gyorgy},
doi = {10.1016/j.tics.2016.05.001},
file = {:home/kaslu/Documents/Mendeley/2016 - Friston, Buzs{\'{a}}ki - The Functional Anatomy of Time What and When in the Brain.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {Bayesian,Hippocampus,Inference,Ordinal,Sequences,Spatiotemporal},
month = {jul},
number = {7},
pages = {500--511},
pmid = {27261057},
title = {{The Functional Anatomy of Time: What and When in the Brain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661316300407},
volume = {20},
year = {2016}
}
@article{Brody2016,
abstract = {Gradual accumulation of evidence favoring one or another choice is considered a core component of many different types of decisions, and has been the subject of many neurophysiological studies in non-human primates. But its neural circuit mechanisms remain mysterious. Investigating it in rodents has recently become possible, facilitating perturbation experiments to delineate the relevant causal circuit, as well as the application of other tools more readily available in rodents. In addition, advances in stimulus design and analysis have aided studying the relevant neural encoding. In complement to ongoing non-human primate studies, these newly available model systems and tools place the field at an exciting time that suggests that the dynamical circuit mechanisms underlying accumulation of evidence could soon be revealed.},
author = {Brody, Carlos D. and Hanks, Timothy D.},
doi = {10.1016/j.conb.2016.01.003},
file = {:home/kaslu/Documents/Mendeley/2016 - Brody, Hanks - Neural underpinnings of the evidence accumulator.pdf:pdf},
isbn = {1873-6882 (Electronic)$\backslash$r0959-4388 (Linking)},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {149--157},
pmid = {26878969},
publisher = {Elsevier Ltd},
title = {{Neural underpinnings of the evidence accumulator}},
url = {http://dx.doi.org/10.1016/j.conb.2016.01.003},
volume = {37},
year = {2016}
}
@article{Rich2016,
abstract = {When making a subjective choice, the brain must compute a value for each option and compare those values to make a decision. The orbitofrontal cortex (OFC) is critically involved in this process, but the neural mechanisms remain obscure, in part due to limitations in our ability to measure and control the internal deliberations that can alter the dynamics of the decision process. Here we tracked these dynamics by recovering temporally precise neural states from multidimensional data in OFC. During individual choices, OFC alternated between states associated with the value of two available options, with dynamics that predicted whether a subject would decide quickly or vacillate between the two alternatives. Ensembles of value-encoding neurons contributed to these states, with individual neurons shifting activity patterns as the network evaluated each option. Thus, the mechanism of subjective decision-making involves the dynamic activation of OFC states associated with each choice alternative.},
author = {Rich, Erin L and Wallis, Jonathan D},
doi = {10.1038/nn.4320},
file = {:home/kaslu/Documents/Mendeley/2016 - Rich, Wallis - Decoding subjective decisions from orbitofrontal cortex.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jun},
number = {7},
pages = {973--980},
pmid = {27273768},
title = {{Decoding subjective decisions from orbitofrontal cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.4320},
volume = {19},
year = {2016}
}
@article{Kinouchi1992a,
abstract = {The generalization ability of Hebbian Boolean perceptrons can be improved by a kind of feedback mechanism in which the student net judges the difficulty of a new example from its previous experience. It is shown that by giving a higher weight to the hard examples both generalization and learning abilities can be increased. Analytical as well as numerical results are presented for both cases where the examples are drawn at random or selected in an intelligent form. ?? 1992.},
author = {Kinouchi, Osame and Caticha, Nestor},
doi = {10.1016/0378-4371(92)90482-6},
file = {:home/kaslu/Documents/Mendeley/1992 - Kinouchi, Caticha - Biased learning in Boolean perceptrons.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
month = {jun},
number = {1-4},
pages = {411--416},
title = {{Biased learning in Boolean perceptrons}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0378437192904826},
volume = {185},
year = {1992}
}
@article{Matejka2017,
author = {Matejka, Justin and Fitzmaurice, George},
doi = {10.1145/3025453.3025912},
isbn = {9781450346559},
title = {{Autodesk datasaurus}},
year = {2017}
}
@article{Mora2015,
abstract = {Recent experimental results based on multi-electrode and imaging techniques have reinvigorated the idea that large neural networks operate near a critical point, between order and disorder. However, evidence for criticality has relied on the definition of arbitrary order parameters, or on models that do not address the dynamical nature of network activity. Here we introduce a novel approach to assess criticality that overcomes these limitations, while encompassing and generalizing previous criteria. We find a simple model to describe the global activity of large populations of ganglion cells in the rat retina, and show that their statistics are poised near a critical point. Taking into account the temporal dynamics of the activity greatly enhances the evidence for criticality, revealing it where previous methods would not. The approach is general and could be used in other biological networks.},
archivePrefix = {arXiv},
arxivId = {1410.6769},
author = {Mora, Thierry and Deny, St{\'{e}}phane and Marre, Olivier},
doi = {10.1103/PhysRevLett.114.078105},
eprint = {1410.6769},
file = {:home/kaslu/Documents/Mendeley/2015 - Mora, Deny, Marre - Dynamical criticality in the collective activity of a population of retinal neurons.pdf:pdf},
issn = {10797114},
journal = {Physical Review Letters},
number = {7},
pages = {1--6},
title = {{Dynamical criticality in the collective activity of a population of retinal neurons}},
volume = {114},
year = {2015}
}
@article{Goris2013,
abstract = {Pattern detection is the bedrock of modern vision science. Nearly half a century ago, psychophysicists advocated a quantitative theoretical framework that connected visual pattern detection with its neurophysiological underpinnings. In this theory, neurons in primary visual cortex constitute linear and independent visual channels whose output is linked to choice behavior in detection tasks via simple read-out mechanisms. This model has proven remarkably successful in accounting for threshold vision. It is fundamentally at odds, however, with current knowledge about the neurophysiological underpinnings of pattern vision. In addition, the principles put forward in the model fail to generalize to suprathreshold vision or perceptual tasks other than detection. We propose an alternative theory of detection in which perceptual decisions develop from maximum-likelihood decoding of a neurophysiologically inspired model of population activity in primary visual cortex. We demonstrate that this theory explains a broad range of classic detection results. With a single set of parameters, our model can account for several summation, adaptation, and uncertainty effects, thereby offering a new theoretical interpretation for the vast psychophysical literature on pattern detection.},
author = {Goris, Robbe L. T. and Putzeys, Tom and Wagemans, Johan and Wichmann, Felix A.},
doi = {10.1037/a0033136},
file = {:home/kaslu/Documents/Mendeley/2013 - Goris et al. - A neural population model for visual pattern detection.pdf:pdf},
isbn = {0033-295X},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {extrinsic uncertainty,neural population model,pattern adaptation,summation experiments,visual detection},
number = {3},
pages = {472--496},
pmid = {23915083},
title = {{A neural population model for visual pattern detection.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033136},
volume = {120},
year = {2013}
}
@article{DePolavieja2014,
abstract = {Human groups can perform extraordinary accurate estimations compared to individuals by simply using the mean, median or geometric mean of the individual estimations [Galton 1907, Surowiecki 2005, Page 2008]. However, this is true only for some tasks and in general these collective estimations show strong biases. The method fails also when allowing for social interactions, which makes the collective estimation worse as individuals tend to converge to the biased result [Lorenz et al. 2011]. Here we show that there is a bright side of this apparently negative impact of social interactions into collective intelligence. We found that some individuals resist the social influence and, when using the median of this subgroup, we can eliminate the bias of the wisdom of the full crowd. To find this subgroup of individuals more confident in their private estimations than in the social influence, we model individuals as estimators that combine private and social information with different relative weights [Perez-Escudero {\&} de Polavieja 2011, Arganda et al. 2012]. We then computed the geometric mean for increasingly smaller groups by eliminating those using in their estimations higher values of the social influence weight. The trend obtained in this procedure gives unbiased results, in contrast to the simpler method of computing the median of the complete group. Our results show that, while a simple operation like the mean, median or geometric mean of a group may not allow groups to make good estimations, a more complex operation taking into account individuality in the social dynamics can lead to a better collective intelligence.},
archivePrefix = {arXiv},
arxivId = {1406.7578},
author = {{De Polavieja}, Gonzalo and Madirolas, Gabriel},
eprint = {1406.7578},
journal = {Arxiv Preprint},
month = {jun},
pages = {2012--2015},
title = {{Wisdom of the Confident: Using Social Interactions to Eliminate the Bias in Wisdom of the Crowds}},
url = {http://arxiv.org/abs/1406.7578},
year = {2014}
}
@article{Fortunato2013,
abstract = {This editorial opens the special issues that the Journal of Statistical Physics has dedicated to the growing field of statistical physics modeling of social dynamics. The issues include contributions from physicists and social scientists, with the goal of fostering a better communication between these two communities.},
archivePrefix = {arXiv},
arxivId = {1304.1171},
author = {Fortunato, Santo and Macy, Michael and Redner, Sidney},
doi = {10.1007/s10955-013-0703-2},
eprint = {1304.1171},
file = {:home/kaslu/Documents/Mendeley/2013 - Fortunato, Macy, Redner - Editorial Statistical Physics and Social Systems.pdf:pdf},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
month = {apr},
number = {1-2},
pages = {1--8},
title = {{Editorial: Statistical Physics and Social Systems}},
url = {http://arxiv.org/abs/1304.1171 http://dx.doi.org/10.1007/s10955-013-0703-2 http://link.springer.com/10.1007/s10955-013-0703-2},
volume = {151},
year = {2013}
}
@article{Latham2016,
abstract = {An elegant study answers a long-standing question: how do correlations arise in large, highly interconnected networks of neurons? The answer represents a major step forward in our understanding of spiking networks in the brain.},
author = {Latham, Peter E.},
doi = {10.1038/nn.4455},
file = {:home/kaslu/Documents/Mendeley/2016 - Latham - Correlations demystified.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {dec},
number = {1},
pages = {6--8},
pmid = {28025982},
title = {{Correlations demystified}},
url = {http://www.nature.com/doifinder/10.1038/nn.4455},
volume = {20},
year = {2016}
}
@article{Bash2015,
abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
author = {Knuth, Donald Ervin},
doi = {10.1093/comjnl/27.2.97},
file = {:home/kaslu/Documents/Mendeley/1984 - Knuth - Literate Programming.pdf:pdf;:home/kaslu/Documents/Mendeley/1984 - Knuth - Literate Programming.pdf:pdf},
issn = {0010-4620},
journal = {The Computer Journal},
keywords = {icle},
month = {feb},
number = {2},
pages = {97--111},
pmid = {25246403},
title = {{Literate Programming}},
url = {http://comjnl.oupjournals.org/cgi/doi/10.1093/comjnl/27.2.97 https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/27.2.97},
volume = {27},
year = {1984}
}
@article{BALLENTINE1986,
annote = {NULL},
author = {BALLENTINE, L. E.},
doi = {10.1111/j.1749-6632.1986.tb12439.x},
file = {:home/kaslu/Documents/Mendeley/1986 - BALLENTINE - Probability in Quantum Mechanics.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
month = {dec},
number = {1 New Technique},
pages = {382--392},
title = {{Probability in Quantum Mechanics}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1986.tb12439.x},
volume = {480},
year = {1986}
}
@article{Mcmahon2015,
abstract = {OBJECTIVE To evaluate moderators and mediators of brief alcohol interventions conducted in the emergency department. METHODS Patients (18-24 years; n = 172) in an emergency department received a motivational interview with personalized feedback (MI) or feedback only (FO), with 1- and 3-month booster sessions and 6- and 12-month follow-ups. Gender, alcohol status/severity group [ALC+ only, Alcohol Use Disorders Identification Test (AUDIT+) only, ALC+/AUDIT+], attribution of alcohol in the medical event, aversiveness of the event, perceived seriousness of the event and baseline readiness to change alcohol use were evaluated as moderators of intervention efficacy. Readiness to change also was evaluated as a mediator of intervention efficacy, as were perceived risks/benefits of alcohol use, self-efficacy and alcohol treatment seeking. RESULTS Alcohol status, attribution and readiness moderated intervention effects such that patients who had not been drinking prior to their medical event, those who had low or medium attribution for alcohol in the event and those who had low or medium readiness to change showed lower alcohol use 12 months after receiving MI compared to FO. In the AUDIT+ only group those who received MI showed lower rates of alcohol-related injury at follow-up than those who received FO. Patients who had been drinking prior to their precipitating event did not show different outcomes in the two interventions, regardless of AUDIT status. Gender did not moderate intervention efficacy and no significant mediation was found. CONCLUSIONS Findings may help practitioners target patients for whom brief interventions will be most effective. More research is needed to understand how brief interventions transmit their effects.},
author = {Sekihara, Kensuke and Sahani, Maneesh and Nagarajan, Srikantan S.},
doi = {10.1016/j.neuroimage.2004.11.051},
file = {:home/kaslu/Documents/Mendeley/2005 - Sekihara, Sahani, Nagarajan - Localization bias and spatial resolution of adaptive and non-adaptive spatial filters for MEG sourc.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Alcohol,Brief Intervention,Emergency Room},
month = {may},
number = {4},
pages = {1056--1067},
title = {{Localization bias and spatial resolution of adaptive and non-adaptive spatial filters for MEG source reconstruction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811904007256},
volume = {25},
year = {2005}
}
@article{Ding2015,
abstract = {The most critical attribute of human language is its unbounded combinatorial nature: smaller elements can be combined into larger structures on the basis of a grammatical system, resulting in a hierarchy of linguistic units, such as words, phrases and sentences. Mentally parsing and representing such structures, however, poses challenges for speech comprehension. In speech, hierarchical linguistic structures do not have boundaries that are clearly defined by acoustic cues and must therefore be internally and incrementally constructed during comprehension. We found that, during listening to connected speech, cortical activity of different timescales concurrently tracked the time course of abstract linguistic structures at different hierarchical levels, such as words, phrases and sentences. Notably, the neural tracking of hierarchical linguistic structures was dissociated from the encoding of acoustic cues and from the predictability of incoming words. Our results indicate that a hierarchy of neural processing timescales underlies grammar-based internal construction of hierarchical linguistic structure.},
author = {Ding, Nai and Melloni, Lucia and Zhang, Hang and Tian, Xing and Poeppel, David},
doi = {10.1038/nn.4186},
file = {:home/kaslu/Documents/Mendeley/2015 - Ding et al. - Cortical tracking of hierarchical linguistic structures in connected speech.pdf:pdf},
isbn = {1546-1726},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {1},
pages = {158--64},
pmid = {26642090},
publisher = {Nature Publishing Group},
title = {{Cortical tracking of hierarchical linguistic structures in connected speech}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26642090},
volume = {19},
year = {2015}
}
@article{Valiant1984,
abstract = {Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learned using it in a reasonable (polynomial) number of steps. Although inherent algorithmic complexity appears to set serious limits to the range of concepts that can be learned, we show that there are some important nontrivial classes of propositional concepts that can be learned in a realistic sense.},
author = {Valiant, L. G.},
doi = {10.1145/1968.1972},
isbn = {0897911334},
issn = {00010782},
journal = {Communications of the ACM},
number = {11},
pages = {1134--1142},
pmid = {12929239},
title = {{A theory of the learnable}},
volume = {27},
year = {1984}
}
@article{Goldt2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.09428v1},
author = {Goldt, Sebastian and Seifert, Udo},
doi = {10.1209/0295-5075/113/60009},
eprint = {arXiv:1611.09428v1},
issn = {0295-5075},
number = {2},
pages = {1--5},
title = {{Stochastic Thermodynamics of Learning}},
volume = {010601},
year = {2016}
}
@article{Rumelhart1985,
author = {Rumelhart, David E and Zipser, David},
doi = {10.1016/S0364-0213(85)80010-0},
isbn = {0-262-68053-X},
issn = {03640213},
journal = {Cognitive Science},
pages = {75--112},
title = {{Feature discovery by competive learning}},
volume = {9},
year = {1985}
}
@article{Brendel2017,
abstract = {A key question in neuroscience is at which level functional meaning emerges from biophysical phenomena. In most vertebrate systems, precise functions are assigned at the level of neural populations, while single-neurons are deemed unreliable and redundant. Here we challenge this view and show that many single-neuron quantities, including voltages, firing thresholds, excitation, inhibition, and spikes, acquire precise functional meaning whenever a network learns to transmit information parsimoniously and precisely to the next layer. Based on the hypothesis that neural circuits generate precise population codes under severe constraints on metabolic costs, we derive synaptic plasticity rules that allow a network to represent its time-varying inputs with maximal accuracy. We provide exact solutions to the learnt optimal states, and we predict the properties of an entire network from its input distribution and the cost of activity. Single-neuron variability and tuning curves as typically observed in cortex emerge over the course of learning, but paradoxically coincide with a precise, non-redundant spike-based population code. Our work suggests that neural circuits operate far more accurately than previously thought, and that no spike is fired in vain.},
archivePrefix = {arXiv},
arxivId = {1703.03777},
author = {Brendel, Wieland and Bourdoukan, Ralph and Vertechi, Pietro and Machens, Christian K and Den{\`{e}}ve, Sophie},
eprint = {1703.03777},
file = {:home/kaslu/Documents/Mendeley/2017 - Brendel et al. - Learning to represent signals spike by spike.pdf:pdf},
month = {mar},
title = {{Learning to represent signals spike by spike}},
url = {http://arxiv.org/abs/1703.03777},
year = {2017}
}
@article{Fortunato2007,
abstract = {A most debated topic of the last years is whether simple statistical physics models can explain collective features of social dynamics. A necessary step in this line of endeavor is to find regularities in data referring to large-scale social phenomena, such as scaling and universality. We show that, in proportional elections, the distribution of the number of votes received by candidates is a universal scaling function, identical in different countries and years. This finding reveals the existence in the voting process of a general microscopic dynamics that does not depend on the historical, political, and/or economical context where voters operate. A simple dynamical model for the behavior of voters, similar to a branching process, reproduces the universal distribution.},
archivePrefix = {arXiv},
arxivId = {physics/0612140},
author = {Fortunato, Santo and Castellano, Claudio},
doi = {10.1103/PhysRevLett.99.138701},
eprint = {0612140},
file = {:home/kaslu/Documents/Mendeley/2007 - Fortunato, Castellano - Scaling and universality in proportional elections.pdf:pdf},
isbn = {0031-9007},
issn = {00319007},
journal = {Physical Review Letters},
number = {13},
pages = {1--4},
pmid = {17930647},
primaryClass = {physics},
title = {{Scaling and universality in proportional elections}},
volume = {99},
year = {2007}
}
@article{Cavagna2014,
abstract = {We derive a new method to infer from data the out-of-equilibrium alignment dynamics of collectively moving animal groups, by considering the maximum entropy model distribution consistent with temporal and spatial correlations of flight direction. When bird neighborhoods evolve rapidly, this dynamical inference correctly learns the parameters of the model, while a static one relying only on the spatial correlations fails. When neighbors change slowly and the detailed balance is satisfied, we recover the static procedure. We demonstrate the validity of the method on simulated data. The approach is applicable to other systems of active matter.},
archivePrefix = {arXiv},
arxivId = {1310.3810},
author = {Cavagna, Andrea and Giardina, Irene and Ginelli, Francesco and Mora, Thierry and Piovani, Duccio and Tavarone, Raffaele and Walczak, Aleksandra M.},
doi = {10.1103/PhysRevE.89.042707},
eprint = {1310.3810},
file = {:home/kaslu/Documents/Mendeley/2014 - Cavagna et al. - Dynamical maximum entropy approach to flocking.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {042707},
title = {{Dynamical maximum entropy approach to flocking}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.89.042707},
volume = {89},
year = {2014}
}
@article{Dunbar1992,
abstract = {Two general kinds of theory (one ecological and one social) have been advanced to explain the fact that primates have larger brains and greater congnitive abilities than other animals. Data on neocortex volume, group size and a number of behavioural ecology variables are used to test between the various theories. Group size is found to be a function of relative neocortical volume, but the ecological variables are not. This is interpreted as evidence in favour of the social intellect theory and against the ecological theories. It is suggested that the number of neocortical neurons limits the organism's information-processing capacity and that this then limits the number of relationships that an individual can monitor simultaneously. When a group's size exceeds this limit, it becomes unstable and begins to fragment. This then places an upper limit on the size of groups which any given species can maintain as cohesive social units through time. The data suggest that the information overload occurs in terms of the structure of relationships within tightly bonded grooming cliques rather than in terms of the total number of dyads within the group as a whole that an individual has to monitor. It thus appears that, among primates, large groups are created by welding together sets of smaller grooming cliques. One implication of these results is that, since the actual group size will be determined by the ecological characteristics of the habitat in any given case, species will only be able to invade habitats that require larger groups than their current limit if they evolve larger neocortices. {\textcopyright} 1992.},
author = {Dunbar, Robin},
doi = {10.1016/0047-2484(92)90081-J},
isbn = {0047-2484},
issn = {00472484},
journal = {Journal of Human Evolution},
keywords = {behavioural ecology,body size,brain size,grooming,social intellect},
number = {6},
pages = {469--493},
pmid = {781},
title = {{Neocortex size as a constraint on group size in primates}},
volume = {22},
year = {1992}
}
@article{Chalk2018,
abstract = {A central goal in theoretical neuroscience is to predict the response properties of sensory neurons from first principles. Several theories have been proposed to this end. " Efficient coding " posits that neural circuits maximise information encoded about their inputs. " Sparse coding " posits that individual neurons respond selectively to spe-cific, rarely occurring, features. Finally, " predictive coding " posits that neurons preferentially encode stimuli that are useful for making predictions. Except in special cases, it is unclear how these theories relate to each other, or what is expected if different coding objec-tives are combined. To address this question, we developed a unified framework that encompasses these previous theories and extends to new regimes, such as sparse predictive coding. We explore cases when different coding objectives exert conflicting or synergistic ef-fects on neural response properties. We show that predictive coding can lead neurons to either correlate or decorrelate their inputs, de-pending on presented stimuli, while (at low-noise) efficient coding always predicts decorrelation. We compare predictive versus sparse coding of natural movies, showing that the two theories predict qual-itatively different neural responses to visual motion. Our approach promises a way to explain the observed diversity of sensory neural responses, as due to a multiplicity of functional goals performed by different cell types and/or circuits. S ensory neural circuits perform a myriad of computations, which allow us to make sense of, and interact with, our en-vironment. For example, neurons in the primary visual cortex encode information about local edges in an image [1], while neurons in higher-level areas encode more complex features, such as textures or faces [2, 3]. A central aim of sensory neu-roscience is to develop a mathematical theory to explain the purpose and nature of such computations, and, ultimately, predict neural responses to stimuli from first principles. Several theories have been proposed about the function that sensory systems have evolved to perform. The efficient coding hypothesis posits that sensory circuits transmit maximal in-formation about their inputs, given internal constraints, such as metabolic costs and/or noise [4, 5, 6, 7]. Alternatively, the sparse coding hypothesis posits that individual neurons re-spond selectively to specific, rarely occurring, features in the environment [8, 9, 10]. Finally, the more recent predictive cod-ing hypothesis 1 posits that sensory neurons transmit maximal information about stimuli that are predictive about the future while discarding non-predictive information [11, 12]. One may ask which, if any, of these objectives are fulfilled by sensory neural circuits. This question is all the more impor-tant given that, in many cases, different coding objectives ap-pear to directly conflict with each other. For example, a classic result of efficient coding in the low-noise regime is that neurons should temporally decorrelate their inputs and preferentially encode fast stimulus features [13, 14, 15, 16]. In contrast, pre-dictive coding favours the extraction of temporally-correlated, slow features [17, 18]. Likewise, sparse coding requires that neurons respond selectively to a single, preferred stimulus fea-ture. It is unclear if this is compatible with predictive coding, which requires neurons to respond to stimuli as quickly as possible. While a large body of theoretical work exists on efficient and sparse coding (reviewed in [19, 20]), there is little work on how neurons could optimally encode stimuli that are pre-dictive about the future (with the exception of [21, 17]); in short, the general implications of predictive coding for neural circuits are still unknown. We also do not understand how dif-ferent coding objectives relate to each other, or what happens when they are combined. Here, we incorporate the three existing theories—sparse coding, efficient coding, and predictive coding—into a unified framework. In this framework, a small set of optimisation pa-rameters determines the functional goals and constraints faced by sensory neurons. Previous theories correspond to specific values of these optimisation parameters. As a result, we can investigate the conditions under which different coding objec-tives, such as encoding predictive information versus maximis-ing efficiency, have conflicting or synergistic effects on neural responses. Further, we can explore qualitatively new coding regimes, such as neural codes that are both predictive and sparse. We end by hypothesizing that the observed diversity of sensory neural responses spans the space of coding tradeoffs accessible by varying the parameters of our new theory.},
author = {Chalk, Matthew and Marre, Olivier and Tka{\v{c}}ik, Ga{\v{s}}per},
doi = {10.1073/pnas.1711114115},
file = {:home/kaslu/Documents/Mendeley/2018 - Chalk, Marre, Tka{\v{c}}ik - Toward a unified theory of efficient, predictive, and sparse coding.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
pmid = {29259111},
title = {{Toward a unified theory of efficient, predictive, and sparse coding}},
year = {2018}
}
@article{Gregoire2003,
abstract = {A microscopic, stochastic, minimal model for collective and cohesive motion of identical self-propelled particles is introduced. Even though the particles interact strictly locally in a very noisy manner, we show that cohesion can be maintained, even in the zero-density limit of an arbitrarily large flock in an infinite space. The phase diagram spanned by the two main parameters of our model, which encode the tendencies for particles to align and to stay together, contains non-moving "gas", "liquid" and "solid" phases separated from their moving counterparts by the onset of collective motion. The "gas/liquid" and "liquid/solid" are shown to be first-order phase transitions in all cases. In the cohesive phases, we study also the diffusive properties of individuals and their relation to the macroscopic motion and to the shape of the flock. {\textcopyright} 2003 Elsevier Science B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0401257},
author = {Gr{\'{e}}goire, Guillaume and Chat{\'{e}}, Hugues and Tu, Yuhai},
doi = {10.1016/S0167-2789(03)00102-7},
eprint = {0401257},
file = {:home/kaslu/Documents/Mendeley/2003 - Gr{\'{e}}goire, Chat{\'{e}}, Tu - Moving and staying together without a leader.pdf:pdf},
isbn = {0167-2789},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {Cohesive flock,Collective motion,First-order phase transition,Vicsek's model},
month = {jul},
number = {3-4},
pages = {157--170},
primaryClass = {cond-mat},
title = {{Moving and staying together without a leader}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167278903001027},
volume = {181},
year = {2003}
}
@article{Hoel2017,
abstract = {The causal structure of any system can be analyzed at a multitude of spatial and temporal scales. It has long been thought that while higher scale (macro) descriptions of causal structure may be useful to observers, they are at best a compressed description and at worse leave out critical information. However, recent research applying information theory to causal analysis has shown that the causal structure of some systems can actually come into focus (be more informative) at a macroscale (Hoel et al. 2013). That is, a macro model of a system (a map) can be more informative than a fully detailed model of the system (the territory). This has been called causal emergence. While causal emergence may at first glance seem counterintuitive, this paper grounds the phenomenon in a classic concept from information theory: Shannon's discovery of the channel capacity. I argue that systems have a particular causal capacity, and that different causal models of those systems take advantage of that capacity to various degrees. For some systems, only macroscale causal models use the full causal capacity. Such macroscale causal models can either be coarse-grains, or may leave variables and states out of the model (exogenous) in various ways, which can improve the model's efficacy and its informativeness via the same mathematical principles of how error-correcting codes take advantage of an information channel's capacity. As model choice increase, the causal capacity of a system approaches the channel capacity. Ultimately, this provides a general framework for understanding how the causal structure of some systems cannot be fully captured by even the most detailed microscopic model.},
archivePrefix = {arXiv},
arxivId = {1612.09592},
author = {Hoel, Erik},
doi = {10.3390/e19050188},
eprint = {1612.09592},
file = {:home/kaslu/Documents/Mendeley/2017 - Hoel - When the Map Is Better Than the Territory.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
month = {apr},
number = {5},
pages = {188},
title = {{When the Map Is Better Than the Territory}},
url = {http://www.mdpi.com/1099-4300/19/5/188},
volume = {19},
year = {2017}
}
@article{Tkacik2013,
abstract = {Recent work emphasizes that the maximum entropy principle provides a bridge between statistical mechanics models for collective behavior in neural networks and experiments on networks of real neurons. Most of this work has focused on capturing the measured correlations among pairs of neurons. Here we suggest an alternative, constructing models that are consistent with the distribution of global network activity, i.e. the probability that K out of N cells in the network generate action potentials in the same small time bin. The inverse problem that we need to solve in constructing the model is analytically tractable, and provides a natural "thermodynamics" for the network in the limit of large N. We analyze the responses of neurons in a small patch of the retina to naturalistic stimuli, and find that the implied thermodynamics is very close to an unusual critical point, in which the entropy (in proper units) is exactly equal to the energy.},
archivePrefix = {arXiv},
arxivId = {1207.6319},
author = {Tka{\v{c}}ik, Ga{\v{s}}per and Marre, Olivier and Mora, Thierry and Amodei, Dario and {Berry II}, Michael J and Bialek, William},
doi = {10.1088/1742-5468/2013/03/P03011},
eprint = {1207.6319},
file = {:home/kaslu/Documents/Mendeley/2013 - Tka{\v{c}}ik et al. - The simplest maximum entropy model for collective behavior in a neural network.pdf:pdf},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
month = {mar},
number = {03},
pages = {P03011},
title = {{The simplest maximum entropy model for collective behavior in a neural network}},
url = {http://arxiv.org/abs/1207.6319},
volume = {2013},
year = {2013}
}
@article{Friston2012,
abstract = {The slight perversion of the original title of this piece (The Future of the Bayesian Brain) reflects my attempt to write prospectively about 'Science and Stories' over the past 20. years. I will meet this challenge by dealing with the future and then turning to its history. The future of the Bayesian brain (in neuroimaging) is clear: it is the application of dynamic causal modeling to understand how the brain conforms to the free energy principle. In this context, the Bayesian brain is a corollary of the free energy principle, which says that any self organizing system (like a brain or neuroimaging community) must maximize the evidence for its own existence, which means it must minimize its free energy using a model of its world. Dynamic causal modeling involves finding models of the brain that have the greatest evidence or the lowest free energy. In short, the future of imaging neuroscience is to refine models of the brain to minimize free energy, where the brain refines models of the world to minimize free energy. This endeavor itself minimizes free energy because our community is itself a self organizing system. I cannot imagine an alternative future that has the same beautiful self consistency as mine. Having dispensed with the future, we can now focus on the past, which is much more interesting:. {\textcopyright} 2011 Elsevier Inc.},
author = {Friston, Karl},
doi = {10.1016/j.neuroimage.2011.10.004},
file = {:home/kaslu/Documents/Mendeley/2012 - Friston - The history of the future of the Bayesian brain.pdf:pdf},
isbn = {1053-8119},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bayesian brain,Effective connectivity,Free energy,Functional integration,Generative models,Inference,Optimization,Predictive coding},
number = {2},
pages = {1230--1233},
pmid = {22023743},
publisher = {Elsevier Inc.},
title = {{The history of the future of the Bayesian brain}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2011.10.004},
volume = {62},
year = {2012}
}
@article{Koch1999,
abstract = {In predictive coding, only unexpected input features are signaled to thenext stage ofprocessing. Rao and Ballard use this approachtomodel extra-classical receptive field effects.},
author = {Koch, C and Poggio, T},
doi = {10.1038/4511},
file = {:home/kaslu/Documents/Mendeley/1999 - Koch, Poggio - Predicting the visual world silence is golden.pdf:pdf},
isbn = {doi:10.1038/4511},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {1},
pages = {9--10},
pmid = {10195172},
title = {{Predicting the visual world: silence is golden.}},
volume = {2},
year = {1999}
}
@article{Tka??ik2014,
abstract = {Maximum entropy models are the least structured probability distributions that exactly reproduce a chosen set of statistics measured in an interacting network. Here we use this principle to construct probabilistic models which describe the correlated spiking activity of populations of up to 120 neurons in the salamander retina as it responds to natural movies. Already in groups as small as 10 neurons, interactions between spikes can no longer be regarded as small perturbations in an otherwise independent system; for 40 or more neurons pairwise interactions need to be supplemented by a global interaction that controls the distribution of synchrony in the population. Here we show that such "K-pairwise" models--being systematic extensions of the previously used pairwise Ising models--provide an excellent account of the data. We explore the properties of the neural vocabulary by: 1) estimating its entropy, which constrains the population's capacity to represent visual information; 2) classifying activity patterns into a small set of metastable collective modes; 3) showing that the neural codeword ensembles are extremely inhomogenous; 4) demonstrating that the state of individual neurons is highly predictable from the rest of the population, allowing the capacity for error correction.},
archivePrefix = {arXiv},
arxivId = {http://arxiv.org/abs/1306.3061},
author = {Tka{\v{c}}ik, Ga{\v{s}}per and Marre, Olivier and Amodei, Dario and Schneidman, Elad and Bialek, William and Berry, Michael J. and Tka??ik, Ga??per and Marre, Olivier and Amodei, Dario and Schneidman, Elad and Bialek, William and Berry, Michael J.},
doi = {10.1371/journal.pcbi.1003408},
editor = {Sporns, Olaf},
eprint = {/arxiv.org/abs/1306.3061},
file = {:home/kaslu/Documents/Mendeley/2014 - Tka{\v{c}}ik et al. - Searching for Collective Behavior in a Large Network of Sensory Neurons.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$n1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computational Biology,Entropy,Fishes,Models,Movement,Nerve Net,Nerve Net: physiology,Neurological,Probability,Retina,Retina: pathology,Sensory Receptor Cells,Sensory Receptor Cells: cytology,Urodela,Urodela: physiology},
month = {jan},
number = {1},
pages = {e1003408},
pmid = {24391485},
primaryClass = {http:},
title = {{Searching for Collective Behavior in a Large Network of Sensory Neurons}},
url = {http://arxiv.org/abs/1306.3061 http://dx.plos.org/10.1371/journal.pcbi.1003408},
volume = {10},
year = {2014}
}
@article{Quartz2009,
abstract = {Many models of judgment and decision-making posit distinct cognitive and emotional contributions to decision-making under uncertainty. Cognitive processes typically involve exact computations according to a cost-benefit calculus, whereas emotional processes typically involve approximate, heuristic processes that deliver rapid evaluations without mental effort. However, it remains largely unknown what specific parameters of uncertain decision the brain encodes, the extent to which these parameters correspond to various decision-making frameworks, and their correspondence to emotional and rational processes. Here, I review research suggesting that emotional processes encode in a precise quantitative manner the basic parameters of financial decision theory, indicating a reorientation of emotional and cognitive contributions to risky choice. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Quartz, Steven R.},
doi = {10.1016/j.tics.2009.02.003},
file = {:home/kaslu/Documents/Mendeley/2009 - Quartz - Reason, emotion and decision-making risk and reward computation with feeling.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = {may},
number = {5},
pages = {209--215},
pmid = {19362037},
title = {{Reason, emotion and decision-making: risk and reward computation with feeling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661309000679},
volume = {13},
year = {2009}
}
@article{Daniels2017a,
abstract = {A central question in cognitive neuroscience is how unitary, coherent decisions at the whole organism level can arise from the distributed behavior of a large population of neurons with only partially overlapping information. We address this issue by studying neural spiking behavior recorded from a multielectrode array with 169 channels during a visual motion direction discrimination task. It is well known that in this task there are two distinct phases in neural spiking behavior. Here we show Phase I is a distributed or incompressible phase in which uncertainty about the decision is substantially reduced by pooling information from many cells. Phase II is a redundant or compressible phase in which numerous single cells contain all the information present at the population level in Phase I, such that the firing behavior of a single cell is enough to predict the subject's decision. Using an empirically grounded dynamical modeling framework, we show that in Phase I large cell populations with low redundancy produce a slow timescale of information aggregation through critical slowing down near a symmetry-breaking transition. Our model indicates that increasing collective amplification in Phase II leads naturally to a faster timescale of information pooling and consensus formation. Based on our results and others in the literature, we propose that a general feature of collective computation is a `coding duality' in which there are accumulation and consensus formation processes distinguished by different timescales.},
author = {Daniels, Bryan C. and Flack, Jessica C. and Krakauer, David C.},
doi = {10.3389/fnins.2017.00313},
file = {:home/kaslu/Documents/Mendeley/2017 - Daniels, Flack, Krakauer - Dual coding theory explains biphasic collective computation in neural decision-making.pdf:pdf},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Collective computation,Critical slowing down,Decision tasks},
number = {JUN},
pages = {1--16},
pmid = {28634436},
title = {{Dual coding theory explains biphasic collective computation in neural decision-making}},
volume = {11},
year = {2017}
}
@article{Herculano-Houzel2011,
abstract = {It is usually considered that larger brains have larger neurons, which consume more energy individually, and are therefore accompanied by a larger number of glial cells per neuron. These notions, however, have never been tested. Based on glucose and oxygen metabolic rates in awake animals and their recently determined numbers of neurons, here I show that, contrary to the expected, the estimated glucose use per neuron is remarkably constant, varying only by 40{\%} across the six species of rodents and primates (including humans). The estimated average glucose use per neuron does not correlate with neuronal density in any structure. This suggests that the energy budget of the whole brain per neuron is fixed across species and brain sizes, such that total glucose use by the brain as a whole, by the cerebral cortex and also by the cerebellum alone are linear functions of the number of neurons in the structures across the species (although the average glucose consumption per neuron is at least 10× higher in the cerebral cortex than in the cerebellum). These results indicate that the apparently remarkable use in humans of 20{\%} of the whole body energy budget by a brain that represents only 2{\%} of body mass is explained simply by its large number of neurons. Because synaptic activity is considered the major determinant of metabolic cost, a conserved energy budget per neuron has several profound implications for synaptic homeostasis and the regulation of firing rates, synaptic plasticity, brain imaging, pathologies, and for brain scaling in evolution.},
author = {Herculano-Houzel, Suzana},
doi = {10.1371/journal.pone.0017514},
file = {:home/kaslu/Documents/Mendeley/2011 - Herculano-Houzel - Scaling of brain metabolism with a fixed energy budget per neuron implications for neuronal activity, plastici.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Animals,Biological Evolution,Brain,Brain: metabolism,Cell Count,Cerebellum,Cerebellum: metabolism,Cerebral Cortex,Cerebral Cortex: metabolism,Energy Metabolism,Energy Metabolism: physiology,Glucose,Glucose: metabolism,Humans,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Neurons: metabolism,Oxygen Consumption},
month = {jan},
number = {3},
pages = {e17514},
pmid = {21390261},
publisher = {Public Library of Science},
title = {{Scaling of brain metabolism with a fixed energy budget per neuron: implications for neuronal activity, plasticity and evolution.}},
url = {http://dx.doi.org/10.1371/journal.pone.0017514},
volume = {6},
year = {2011}
}
@article{Micadei2017,
abstract = {The second law permits the prediction of the direction of natural processes, thus defining a thermodynamic arrow of time. However, standard thermodynamics presupposes the absence of initial correlations between interacting systems. We here experimentally demonstrate the reversal of the arrow of time for two initially quantum correlated spins-1/2, prepared in local thermal states at different temperatures, employing a Nuclear Magnetic Resonance setup. We observe a spontaneous heat flow from the cold to the hot system. This process is enabled by a trade off between correlations and entropy that we quantify with information-theoretical quantities.},
archivePrefix = {arXiv},
arxivId = {1711.03323},
author = {Micadei, Kaonan and Peterson, John P. S. and Souza, Alexandre M. and Sarthour, Roberto S. and Oliveira, Ivan S. and Landi, Gabriel T. and Batalh{\~{a}}o, Tiago B. and Serra, Roberto M. and Lutz, Eric},
eprint = {1711.03323},
file = {:home/kaslu/Documents/Mendeley/2017 - Micadei et al. - Reversing the thermodynamic arrow of time using quantum correlations.pdf:pdf},
journal = {arXiv},
month = {nov},
pages = {1--9},
title = {{Reversing the thermodynamic arrow of time using quantum correlations}},
url = {http://arxiv.org/abs/1711.03323},
volume = {6},
year = {2017}
}
@article{McElreath2015,
abstract = {Many published research results are false (Ioannidis, 2005), and controversy continues over the roles of replication and publication policy in improving the reliability of research. Addressing these problems is frustrated by the lack of a formal framework that jointly represents hypothesis formation, replication, publication bias, and variation in research quality. We develop a mathematical model of scientific discovery that combines all of these elements. This model provides both a dynamic model of research as well as a formal framework for reasoning about the normative structure of science. We show that replication may serve as a ratchet that gradually separates true hypotheses from false, but the same factors that make initial findings unreliable also make replications unreliable. The most important factors in improving the reliability of research are the rate of false positives and the base rate of true hypotheses, and we offer suggestions for addressing each. Our results also bring clarity to verbal debates about the communication of research. Surprisingly, publication bias is not always an obstacle, but instead may have positive impacts-suppression of negative novel findings is often beneficial. We also find that communication of negative replications may aid true discovery even when attempts to replicate have diminished power. The model speaks constructively to ongoing debates about the design and conduct of science, focusing analysis and discussion on precise, internally consistent models, as well as highlighting the importance of population dynamics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.02780v1},
author = {McElreath, Richard and Smaldino, Paul E.},
doi = {10.1371/journal.pone.0136088},
eprint = {arXiv:1503.02780v1},
isbn = {0894-0282},
issn = {19326203},
journal = {PLoS ONE},
number = {8},
pages = {1--16},
pmid = {26308448},
title = {{Replication, communication, and the population dynamics of scientific discovery}},
volume = {10},
year = {2015}
}
@article{Goldenfeld2010,
abstract = {Evolution is the fundamental physical process that gives rise to biological phenomena. Yet it is widely treated as a subset of population genetics, and thus its scope is artificially limited. As a result, the key issues of how rapidly evolution occurs, and its coupling to ecology have not been satisfactorily addressed and formulated. The lack of widespread appreciation for, and understanding of, the evolutionary process has arguably retarded the development of biology as a science, with disastrous consequences for its applications to medicine, ecology and the global environment. This review focuses on evolution as a problem in non-equilibrium statistical mechanics, where the key dynamical modes are collective, as evidenced by the plethora of mobile genetic elements whose role in shaping evolution has been revealed by modern genomic surveys. We discuss how condensed matter physics concepts might provide a useful perspective in evolutionary biology, the conceptual failings of the modern evolutionary synthesis, the open-ended growth of complexity, and the quintessentially self-referential nature of evolutionary dynamics.},
archivePrefix = {arXiv},
arxivId = {1011.4125},
author = {Goldenfeld, Nigel and Woese, Carl},
doi = {10.1146/annurev-conmatphys-062910-140509},
eprint = {1011.4125},
file = {:home/kaslu/Documents/Mendeley/2010 - Goldenfeld, Woese - Life is physics evolution as a collective phenomenon far from equilibrium.pdf:pdf},
isbn = {1947-5454},
issn = {1947-5454},
journal = {Annual Review of Condensed Matter Physics},
keywords = {collective effects,evolution,genes,statistical mechanics},
month = {mar},
number = {1},
pages = {375--399},
publisher = {Annual Reviews},
title = {{Life is physics: evolution as a collective phenomenon far from equilibrium}},
url = {http://arxiv.org/abs/1011.4125},
volume = {2},
year = {2010}
}
@article{Moreno-Bote2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.3159v1},
author = {Moreno-Bote, Rub{\'{e}}n and Beck, Jeffrey M. and Kanitscheider, Ingmar and Pitkow, Xaq and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/nn.3807},
eprint = {arXiv:1411.3159v1},
file = {:home/kaslu/Documents/Mendeley/2014 - Moreno-Bote et al. - Information-limiting correlations.pdf:pdf},
isbn = {2010276795},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {sep},
number = {10},
pages = {1410--1417},
pmid = {25195105},
publisher = {Nature Publishing Group},
title = {{Information-limiting correlations}},
url = {http://www.nature.com/doifinder/10.1038/nn.3807},
volume = {17},
year = {2014}
}
@article{Bitzer2015,
abstract = {Even for simple perceptual decisions, the mechanisms that the brain employs are still under debate. Although current consensus states that the brain accumulates evidence extracted from noisy sensory information, open questions remain about how this simple model relates to other perceptual phenomena such as flexibility in decisions, decision-dependent modulation of sensory gain, or confidence about a decision. We propose a novel approach of how perceptual decisions are made by combining two influential formalisms into a new model. Specifically, we embed an attractor model of decision making into a probabilistic framework that models decision making as Bayesian inference. We show that the new model can explain decision making behaviour by fitting it to experimental data. In addition, the new model combines for the first time three important features: First, the model can update decisions in response to switches in the underlying stimulus. Second, the probabilistic formulation accounts for top-down effects that may explain recent experimental findings of decision-related gain modulation of sensory neurons. Finally, the model computes an explicit measure of confidence which we relate to recent experimental evidence for confidence computations in perceptual decision tasks.},
author = {Bitzer, Sebastian and Bruineberg, Jelle and Kiebel, Stefan J.},
doi = {10.1371/journal.pcbi.1004442},
file = {:home/kaslu/Documents/Mendeley/2015 - Bitzer, Bruineberg, Kiebel - A Bayesian Attractor Model for Perceptual Decision Making.pdf:pdf},
journal = {PLoS Computational Biology},
title = {{A Bayesian Attractor Model for Perceptual Decision Making}},
url = {http://www.mendeley.com/research/bayesian-attractor-model-perceptual-decision-making},
year = {2015}
}
@article{Caticha2017,
abstract = {Entropic Dynamics is a framework in which dynamical laws such as those that arise in physics are derived as an application of entropic methods of inference. No underlying action principle is postulated. Instead, the dynamics is driven by entropy subject to constraints reflecting the information that is relevant to the problem at hand. In this work I review the derivation of quantum theory but the fact that Entropic Dynamics is based on inference methods that are of universal applicability suggests that it may be possible to adapt these methods to fields other than physics.},
archivePrefix = {arXiv},
arxivId = {1704.02663},
author = {Caticha, Ariel},
eprint = {1704.02663},
file = {:home/kaslu/Documents/Mendeley/2017 - Caticha - Entropic Dynamics Mechanics without Mechanism.pdf:pdf},
month = {apr},
pages = {1--23},
title = {{Entropic Dynamics: Mechanics without Mechanism}},
url = {http://arxiv.org/abs/1704.02663},
year = {2017}
}
@article{Miller2013,
abstract = {In many species, spatial navigation is supported by a network of place cells that exhibit increased firing whenever an animal is in a certain region of an environment. Does this neural representation of location form part of the spatiotemporal context into which episodic memories are encoded? We recorded medial temporal lobe neuronal activity as epilepsy patients performed a hybrid spatial and episodic memory task. We identified place-responsive cells active during virtual navigation and then asked whether the same cells activated during the subsequent recall of navigation-related memories without actual navigation. Place-responsive cell activity was reinstated during episodic memory retrieval. Neuronal firing during the retrieval of each memory was similar to the activity that represented the locations in the environment where the memory was initially encoded.},
author = {Miller, Jonathan F and Neufang, M and Solway, Alec and Brandt, A and Trippel, M and Mader, I and Hefft, S and Merkow, M and Polyn, S M and Jacobs, J and Kahana, M J and Schulze-Bonhage, A},
doi = {10.1126/science.1244056},
file = {:home/kaslu/Documents/Mendeley/2013 - Miller et al. - Neural activity in human hippocampal formation reveals the spatial context of retrieved memories.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {1095-9203},
journal = {Science},
keywords = {*Memory,Cell Separation,Electrodes,Epilepsy,Episodic,Hippocampus/cytology/*physiology,Humans,Implanted,Neurons/*physiology,Space Perception/*physiology,Temporal Lobe/cytology/physiology,User-Computer Interface},
number = {6162},
pages = {1111--1114},
pmid = {24288336},
title = {{Neural activity in human hippocampal formation reveals the spatial context of retrieved memories}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24288336},
volume = {342},
year = {2013}
}
@article{Nobrega2015,
abstract = {Our core hypothesis is that the emergence of human language arose very rapidly from the linking of two pre-adapted systems found elsewhere in the animal world-an expression system, found, for example, in birdsong, and a lexical system, suggestively found in non-human primate calls (Miyagawa et al., 2013, 2014). We challenge the view that language has undergone a series of gradual changes-or a single preliminary protolinguistic stage-before achieving its full character. We argue that a full-fledged combinatorial operation Merge triggered the integration of these two pre-adapted systems, giving rise to a fully developed language. This goes against the gradualist view that there existed a structureless, protolinguistic stage, in which a rudimentary proto-Merge operation generated internally flat words. It is argued that compounds in present-day language are a fossilized form of this prior stage, a point which we will question.},
author = {N{\'{o}}brega, Vitor A. and Miyagawa, Shigeru},
doi = {10.3389/fpsyg.2015.00271},
isbn = {1664-1078},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Biolinguistics,Compounding,Emergent view of language evolution,Language evolution,Linguistics,Word formation},
month = {mar},
number = {MAR},
pages = {271},
pmid = {25852595},
publisher = {Frontiers},
title = {{The precedence of syntax in the rapid emergence of human language in evolution as defined by the integration hypothesis}},
url = {http://www.frontiersin.org/Language{\_}Sciences/10.3389/fpsyg.2015.00271/abstract},
volume = {6},
year = {2015}
}
@article{Bezanson2012,
abstract = {Dynamic languages have become popular for scientific computing. They are generally considered highly productive, but lacking in performance. This paper presents Julia, a new dynamic language for technical computing, designed for performance from the beginning by adapting and extending modern programming language techniques. A design based on generic functions and a rich type system simultaneously enables an expressive programming model and successful type inference, leading to good performance for a wide range of programs. This makes it possible for much of the Julia library to be written in Julia itself, while also incorporating best-of-breed C and Fortran libraries.},
archivePrefix = {arXiv},
arxivId = {1209.5145},
author = {Bezanson, Jeff and Karpinski, Stefan and Shah, Viral B. and Edelman, Alan},
eprint = {1209.5145},
file = {:home/kaslu/Documents/Mendeley/2012 - Bezanson et al. - Julia A Fast Dynamic Language for Technical Computing.pdf:pdf},
issn = {{\textless}null{\textgreater}},
journal = {arXiv preprint},
month = {sep},
pages = {1--27},
title = {{Julia: A Fast Dynamic Language for Technical Computing}},
url = {http://arxiv.org/abs/1209.5145},
year = {2012}
}
@article{Gomez-Marin2016,
abstract = {Over the past decade neuroscience has been attacking the problem of cognition with increasing vigor. Yet, what exactly is cognition, beyond a general signifier of anything seemingly complex the brain does? Here, we briefly review attempts to define, describe, explain, build, enhance and experience cognition. We highlight perspectives including psychology, molecular biology, computation, dynamical systems, machine learning, behavior and phenomenology. This survey of the landscape reveals not a clear target for explanation but a pluralistic and evolving scene with diverse opportunities for grounding future research. We argue that rather than getting to the bottom of it, over the next century, by deconstructing and redefining cognition, neuroscience will and should expand rather than merely reduce our concept of the mind.},
author = {Gomez-Marin, Alex and Mainen, Zachary F},
doi = {10.1016/j.conb.2016.01.011},
file = {:home/kaslu/Documents/Mendeley/2016 - Gomez-Marin, Mainen - Expanding perspectives on cognition in humans, animals, and machines.pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Gomez-Marin, Mainen - Expanding perspectives on cognition in humans, animals, and machines(2).pdf:pdf},
isbn = {10.1101/037192},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {apr},
pages = {85--91},
pmid = {26868042},
title = {{Expanding perspectives on cognition in humans, animals, and machines}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S095943881600012X},
volume = {37},
year = {2016}
}
@article{Jacobs1995,
abstract = {This article reviews statistical techniques for combining multiple probability distributions. The framework is that of a decision maker who consults several experts regarding some events. The experts express their opinions in the form of probability distributions. The decision maker must aggregate the experts' distributions into a single distribution that can be used for decision making. Two classes of aggregation methods are reviewed. When using a supra Bayesian procedure, the decision maker treats the expert opinions as data that may be combined with its own prior distribution via Bayes' rule. When using a linear opinion pool, the decision maker forms a linear combination of the expert opinions. The major feature that makes the aggregation of expert opinions difficult is the high correlation or dependence that typically occurs among these opinions. A theme of this paper is the need for training procedures that result in experts with relatively independent opinions or for aggregation methods that implicitly or explicitly model the dependence among the experts. Analyses are presented that show that m dependent experts are worth the same as k independent experts where k {\textless} or = m. In some cases, an exact value for k can be given; in other cases, lower and upper bounds can be placed on k.},
author = {Jacobs, Robert A.},
doi = {10.1162/neco.1995.7.5.867},
file = {:home/kaslu/Documents/Mendeley/1995 - Jacobs - Methods for combining experts' probability assessments.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural computation},
keywords = {communicated by david wolpert,methods for combining experts,probability assessments},
number = {5},
pages = {867--888},
pmid = {7584890},
title = {{Methods for combining experts' probability assessments.}},
volume = {7},
year = {1995}
}
@article{Broido2018a,
abstract = {A central claim in modern network science is that real-world networks are typically "scale free," meaning that the fraction of nodes with degree {\$}k{\$} follows a power law, decaying like {\$}k{\^{}}{\{}-\backslashalpha{\}}{\$}, often with {\$}2 {\textless} \backslashalpha {\textless} 3{\$}. However, empirical evidence for this belief derives from a relatively small number of real-world networks. We test the universality of scale-free structure by applying state-of-the-art statistical tools to a large corpus of nearly 1000 network data sets drawn from social, biological, technological, and informational sources. We fit the power-law model to each degree distribution, test its statistical plausibility, and compare it via a likelihood ratio test to alternative, non-scale-free models, e.g., the log-normal. Across domains, we find that scale-free networks are rare, with only 4{\%} exhibiting the strongest-possible evidence of scale-free structure and 52{\%} exhibiting the weakest-possible evidence. Furthermore, evidence of scale-free structure is not uniformly distributed across sources: social networks are at best weakly scale free, while a handful of technological and biological networks can be called strongly scale free. These results undermine the universality of scale-free networks and reveal that real-world networks exhibit a rich structural diversity that will likely require new ideas and mechanisms to explain.},
archivePrefix = {arXiv},
arxivId = {1801.03400},
author = {Broido, Anna D. and Clauset, Aaron},
eprint = {1801.03400},
file = {:home/kaslu/Documents/Mendeley/2018 - Broido, Clauset - Scale-free networks are rare.pdf:pdf},
journal = {arXiv},
month = {jan},
title = {{Scale-free networks are rare}},
url = {http://arxiv.org/abs/1801.03400},
year = {2018}
}
@article{Baldassano2017,
abstract = {During realistic, continuous perception, humans automatically segment experiences into discrete events. Using a novel model of cortical event dynamics, we investigate how cortical structures generate event representations during narrative perception and how these events are stored to and retrieved from memory. Our data-driven approach allows us to detect event boundaries as shifts between stable patterns of brain activity without relying on stimulus annotations and reveals a nested hierarchy from short events in sensory regions to long events in high-order areas (including angular gyrus and posterior medial cortex), which represent abstract, multimodal situation models. High-order event boundaries are coupled to increases in hippocampal activity, which predict pattern reinstatement during later free recall. These areas also show evidence of anticipatory reinstatement as subjects listen to a familiar narrative. Based on these results, we propose that brain activity is naturally structured into nested events, which form the basis of long-term memory representations.},
author = {Baldassano, Christopher and Chen, Janice and Zadbood, Asieh and Pillow, Jonathan W. and Hasson, Uri and Norman, Kenneth A.},
doi = {10.1016/j.neuron.2017.06.041},
file = {:home/kaslu/Documents/Mendeley/2017 - Baldassano et al. - Discovering Event Structure in Continuous Narrative Perception and Memory(2).pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {Hidden Markov Model,event model,event segmentation,fMRI,hippocampus,memory,narrative,perception,recall,reinstatement,situation model},
month = {aug},
number = {3},
pages = {709--721.e5},
publisher = {Elsevier},
title = {{Discovering Event Structure in Continuous Narrative Perception and Memory}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28772125 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5558154 http://linkinghub.elsevier.com/retrieve/pii/S0896627317305937},
volume = {95},
year = {2017}
}
@article{Campbell2014,
abstract = {Campus activists and others might refer to slights of one's ethnicity or other cultural characteristics as “microaggressions,” and they might use various forums to publicize them. Here we examine this phenomenon by drawing from Donald Black's theories of conflict and from cross-cultural studies of conflict and morality. We argue that this behavior resembles other conflict tactics in which the aggrieved actively seek the support of third parties as well as those that focus on oppression. We identify the social conditions associated with each feature, and we discuss how the rise of these conditions has led to large-scale moral change such as the emergence of a victimhood culture that is distinct from the honor cultures and dignity cultures of the past.},
author = {Campbell, Bradley and Manning, Jason},
doi = {10.1163/15691330-12341332},
file = {:home/kaslu/Documents/Mendeley/2014 - Campbell, Manning - Microaggression and Moral Cultures.pdf:pdf},
issn = {1569-1322},
journal = {Comparative Sociology},
keywords = {dignity,honor,microaggression,morality,social control,victimhood},
number = {6},
pages = {692--726},
title = {{Microaggression and Moral Cultures}},
url = {http://booksandjournals.brillonline.com/content/journals/10.1163/15691330-12341332},
volume = {13},
year = {2014}
}
@article{Martins2009,
abstract = {We study the dynamics of the adoption of new products by agents with continuous opinions and discrete actions (CODA). The model is such that the refusal in adopting a new idea or product is increasingly weighted by neighbor agents as evidence against the product. Under these rules, we study the distribution of adoption times and the final proportion of adopters in the population. We compare the cases where initial adopters are clustered to the case where they are randomly scattered around the social network and investigate small world effects on the final proportion of adopters. The model predicts a fat tailed distribution for late adopters which is verified by empirical data. ?? 2009 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:0809.5114v3},
author = {Martins, Andr{\'{e}} C R and Pereira, Carlos de B and Vicente, Renato},
doi = {10.1016/j.physa.2009.04.007},
eprint = {arXiv:0809.5114v3},
file = {:home/kaslu/Documents/Mendeley/2009 - Martins, Pereira, Vicente - An opinion dynamics model for the diffusion of innovations.pdf:pdf},
isbn = {0378-4371},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Innovation diffusion,Marketing,Opinion dynamics,Sociophysics},
number = {15-16},
pages = {3225--3232},
publisher = {Elsevier B.V.},
title = {{An opinion dynamics model for the diffusion of innovations}},
url = {http://dx.doi.org/10.1016/j.physa.2009.04.007},
volume = {388},
year = {2009}
}
@article{Tkacik2016b,
abstract = {Life depends as much on the flow of information as on the flow of energy. Here we review the many efforts to make this intuition precise. Starting with the building blocks of information theory, we explore examples where it has been possible to measure, directly, the flow of information in biological networks, or more generally where information theoretic ideas have been used to guide the analysis of experiments. Systems of interest range from single molecules (the sequence diversity in families of proteins) to groups of organisms (the distribution of velocities in flocks of birds), and all scales in between. Many of these analyses are motivated by the idea that biological systems may have evolved to optimize the gathering and representation of information, and we review the experimental evidence for this optimization, again across a wide range of scales.},
archivePrefix = {arXiv},
arxivId = {1412.8752},
author = {Tka{\v{c}}ik, Ga{\v{s}}per and Bialek, William},
doi = {10.1146/annurev-conmatphys-031214-014803},
eprint = {1412.8752},
file = {:home/kaslu/Documents/Mendeley/2016 - Tka{\v{c}}ik, Bialek - Information Processing in Living Systems.pdf:pdf},
issn = {1947-5454},
journal = {Annual Review of Condensed Matter Physics},
keywords = {biological networks,gene,information theory,neuroscience,optimality},
month = {mar},
number = {1},
pages = {89--117},
pmid = {1000364184},
title = {{Information Processing in Living Systems}},
url = {http://arxiv.org/abs/1412.8752 http://www.annualreviews.org/doi/10.1146/annurev-conmatphys-031214-014803},
volume = {7},
year = {2016}
}
@article{Krakauer2017,
abstract = {There are ever more compelling tools available for neuroscience research, ranging from selective genetic targeting to optogenetic circuit control to mapping whole connectomes. These approaches are coupled with a deep-seated, often tacit, belief in the reductionist program for understanding the link between the brain and behavior. The aim of this program is causal explanation through neural manipulations that allow testing of necessity and sufficiency claims. We argue, however, that another equally important approach seeks an alternative form of understanding through careful theoretical and experimental decomposition of behavior. Specifically, the detailed analysis of tasks and of the behavior they elicit is best suited for discovering component processes and their underlying algorithms. In most cases, we argue that study of the neural implementation of behavior is best investigated after such behavioral work. Thus, we advocate a more pluralistic notion of neuroscience when it comes to the brain-behavior relationship: behavioral work provides understanding, whereas neural interventions test causality.},
author = {Krakauer, John W. and Ghazanfar, Asif A. and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
doi = {10.1016/j.neuron.2016.12.041},
file = {:home/kaslu/Documents/Mendeley/2017 - Krakauer et al. - Neuroscience Needs Behavior Correcting a Reductionist Bias.pdf:pdf},
isbn = {doi:10.1016/j.neuron.2016.12.041},
issn = {10974199},
journal = {Neuron},
number = {3},
pages = {480--490},
pmid = {28182904},
publisher = {Elsevier Inc.},
title = {{Neuroscience Needs Behavior: Correcting a Reductionist Bias}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.041},
volume = {93},
year = {2017}
}
@article{Cain2013a,
abstract = {A key step in many perceptual decision tasks is the integration of sensory inputs over time, but a fundamental questions remain about how this is accomplished in neural circuits. One possibility is to balance decay modes of membranes and synapses with recurrent excitation. To allow integration over long timescales, however, this balance must be exceedingly precise. The need for fine tuning can be overcome via a "robust integrator" mechanism in which momentary inputs must be above a preset limit to be registered by the circuit. The degree of this limiting embodies a tradeoff between sensitivity to the input stream and robustness against parameter mistuning. Here, we analyze the consequences of this tradeoff for decision-making performance. For concreteness, we focus on the well-studied random dot motion discrimination task and constrain stimulus parameters by experimental data. We show that mistuning feedback in an integrator circuit decreases decision performance but that the robust integrator mechanism can limit this loss. Intriguingly, even for perfectly tuned circuits with no immediate need for a robustness mechanism, including one often does not impose a substantial penalty for decision-making performance. The implication is that robust integrators may be well suited to subserve the basic function of evidence integration in many cognitive tasks. We develop these ideas using simulations of coupled neural units and the mathematics of sequential analysis.},
archivePrefix = {arXiv},
arxivId = {arXiv:1111.6573v1},
author = {Cain, Nicholas and Barreiro, Andrea K. and Shadlen, Michael N. and Shea-Brown, Eric},
doi = {10.1152/jn.00976.2012},
eprint = {arXiv:1111.6573v1},
file = {:home/kaslu/Documents/Mendeley/2013 - Cain et al. - Neural integrators for decision making a favorable tradeoff between robustness and sensitivity.pdf:pdf},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Decision Making,Discrimination (Psychology),Feedback,Humans,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Physiological,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Synapses,Synapses: physiology},
number = {10},
pages = {2542--59},
pmid = {23446688},
title = {{Neural integrators for decision making: a favorable tradeoff between robustness and sensitivity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23446688},
volume = {109},
year = {2013}
}
@article{Axelrod1981,
abstract = {Cooperation in organisms, whether bacteria or primates, has been a difficulty for evolutionary theory since Darwin. On the assumption that interactions between pairs of individuals occur on a probabilistic basis, a model is developed based on the concept of an evolutionarily stable strategy in the context of the Prisoner's Dilemma game. Deductions from the model, and the results of a computer tournament show how cooperation based on reciprocity can get started in an asocial world, can thrive while interacting with a wide range of other strategies, and can resist invasion once fully established. Potential applications include specific aspects of territoriality, mating, and disease.},
archivePrefix = {arXiv},
arxivId = {13960/t8jd4qr3m},
author = {Axelrod, Robert and Hamilton, W.},
doi = {10.1126/science.7466396},
eprint = {t8jd4qr3m},
file = {:home/kaslu/Documents/Mendeley/1981 - Axelrod, Hamilton - The evolution of cooperation.pdf:pdf},
isbn = {0036807518110},
issn = {0036-8075},
journal = {Science},
month = {mar},
number = {4489},
pages = {1390--1396},
pmid = {13321175},
primaryClass = {13960},
title = {{The evolution of cooperation}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.7466396},
volume = {211},
year = {1981}
}
@article{Harre2016,
abstract = {The cognitive ability to form social links that can bind individuals together into large cooperative groups for safety and resource sharing was a key development in human evolutionary and social history. The ‘social brain hypothesis' argues that the size of these social groups is based on a neurologically constrained capacity for maintaining long-term stable relationships. No model to date has been able to combine a specific socio-cognitive mechanism with the discrete scale invariance observed in ethnographic studies. We show that these properties result in nested layers of self-organizing Erdős–R{\'{e}}nyi networks formed by each individual's ability to maintain only a small number of social links. Each set of links plays a specific role in the formation of different social groups. The scale invariance in our model is distinct from previous ‘scale-free networks' studied using much larger social groups; here, the scale invariance is in the relationship between group sizes, rather than in the link degree distribution. We also compare our model with a dominance-based hierarchy and conclude that humans were probably egalitarian in hunter–gatherer-like societies, maintaining an average maximum of four or five social links connecting all members in a largest social network of around 132 people.},
author = {Harr{\'{e}}, Michael S and Prokopenko, Mikhail},
doi = {10.1098/rsif.2016.0044},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
month = {may},
number = {118},
pages = {20160044},
title = {{The social brain: scale-invariant layering of Erdős–R{\'{e}}nyi networks in small-scale human societies}},
url = {http://rsif.royalsocietypublishing.org/content/13/118/20160044.abstract http://rsif.royalsocietypublishing.org/lookup/doi/10.1098/rsif.2016.0044},
volume = {13},
year = {2016}
}
@article{Whiteley2008,
abstract = {Perception is an "inverse problem," in which the state of the world must be inferred from the sensory neural activity that results. However, this inference is both ill-posed (Helmholtz, 1856; Marr, 1982) and corrupted by noise (Green {\&} Swets, 1989), requiring the brain to compute perceptual beliefs under conditions of uncertainty. Here we show that human observers performing a simple visual choice task under an externally imposed loss function approach the optimal strategy, as defined by Bayesian probability and decision theory (Berger, 1985; Cox, 1961). In concert with earlier work, this suggests that observers possess a model of their internal uncertainty and can utilize this model in the neural computations that underlie their behavior (Knill {\&} Pouget, 2004). In our experiment, optimal behavior requires that observers integrate the loss function with an estimate of their internal uncertainty rather than simply requiring that they use a modal estimate of the uncertain stimulus. Crucially, they approach optimal behavior even when denied the opportunity to learn adaptive decision strategies based on immediate feedback. Our data thus support the idea that flexible representations of uncertainty are pre-existing, widespread, and can be propagated to decision-making areas of the brain.},
author = {Whiteley, Louise and Sahani, Maneesh},
doi = {10.1167/8.3.2},
file = {:home/kaslu/Documents/Mendeley/2008 - Whiteley, Sahani - Implicit knowledge of visual uncertainty guides decisions with asymmetric outcomes.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
keywords = {1,10,1167,15,2,2008,3,8,asymmetric,bayesian,citation,doi,early sensory noise,http,ideal observer,implicit knowledge of visual,journal of vision,journalofvision,l,m,org,outcomes,sahani,uncertainty guides decisions with,whiteley},
month = {mar},
number = {3},
pages = {2},
title = {{Implicit knowledge of visual uncertainty guides decisions with asymmetric outcomes}},
url = {http://jov.arvojournals.org/article.aspx?doi=10.1167/8.3.2},
volume = {8},
year = {2008}
}
@article{Lan2016,
abstract = {Living systems have to constantly sense their external environment and adjust their internal state in order to survive and reproduce. Biological systems, from as complex as the brain to a single E. coli cell, have to process these data in order to make appropriate decisions. How do biological systems sense external signals? How do they process the information? How do they respond to signals? Through years of intense study by biologists, many key molecular players and their interactions have been identified in different biological machineries that carry out these signaling functions. However, an integrated, quantitative understanding of the whole system is still lacking for most cellular signaling pathways, not to say the more complicated neural circuits. To study signaling processes in biology, the key thing to measure is the input-output relationship. The input is the signal itself, such as chemical concentration, external temperature, light (intensity and frequency), and more complex signals such as the face of a cat. The output can be protein conformational changes and covalent modifications (phosphorylation, methylation, etc), gene expression, cell growth and motility, as well as more complex output such as neuron firing patterns and behaviors of higher animals. Due to the inherent noise in biological systems, the measured input-output dependence is often noisy. These noisy data can be analysed by using powerful tools and concepts from information theory such as mutual information, channel capacity, and the maximum entropy hypothesis. This information theory approach has been successfully used to reveal the underlying correlations between key components of biological networks, to set bounds for network performance, and to understand possible network architecture in generating observed correlations. Although the information theory approach provides a general tool in analysing noisy biological data and may be used to suggest possible network architectures in preserving information, it does not reveal the underlying mechanism that leads to the observed input-output relationship, nor does it tell us much about which information is important for the organism and how biological systems use information to carry out specific functions. To do that, we need to develop models of the biological machineries, e.g. biochemical networks and neural networks, to understand the dynamics of biological information processes. This is a much more difficult task. It requires deep knowledge of the underlying biological network-the main players (nodes) and their interactions (links)-in sufficient detail to build a model with predictive power, as well as quantitative input-output measurements of the system under different perturbations (both genetic variations and different external conditions) to test the model predictions to guide further development of the model. Due to the recent growth of biological knowledge thanks in part to high throughput methods (sequencing, gene expression microarray, etc) and development of quantitative in vivo techniques such as various florescence technology, these requirements are starting to be realized in different biological systems. The possible close interaction between quantitative experimentation and theoretical modeling has made systems biology an attractive field for physicists interested in quantitative biology. In this review, we describe some of the recent work in developing a quantitative predictive model of bacterial chemotaxis, which can be considered as the hydrogen atom of systems biology. Using statistical physics approaches, such as the Ising model and Langevin equation, we study how bacteria, such as E. coli, sense and amplify external signals, how they keep a working memory of the stimuli, and how they use these data to compute the chemical gradient. In particular, we will describe how E. coli cells avoid cross-talk in a heterogeneous receptor cluster to keep a ligand-specific memory. We will also study the thermodynamic costs of adaptation for cells to maintain an accurate memory. The statistical physics based approach described here should be useful in understanding design principles for cellular biochemical circuits in general.},
author = {Lan, Ganhui and Tu, Yuhai},
doi = {10.1088/0034-4885/79/5/052601},
file = {:home/kaslu/Documents/Mendeley/2016 - Lan, Tu - Information processing in bacteria memory, computation, and statistical physics a key issues review.pdf:pdf},
isbn = {9781461459156},
issn = {0034-4885},
journal = {Reports on Progress in Physics},
month = {may},
number = {5},
pages = {052601},
pmid = {27058315},
title = {{Information processing in bacteria: memory, computation, and statistical physics: a key issues review}},
url = {http://dx.doi.org/10.1088/0034-4885/79/5/052601 http://stacks.iop.org/0034-4885/79/i=5/a=052601?key=crossref.abf4915771248da0ec3eb895c1a5cce2},
volume = {79},
year = {2016}
}
@article{Hastings1970,
abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
author = {Hastings, W. K.},
doi = {10.1093/biomet/57.1.97},
file = {:home/kaslu/Documents/Mendeley/1970 - Hastings - Monte Carlo sampling methods using Markov chains and their applications.pdf:pdf},
isbn = {0006-3444},
issn = {0006-3444},
journal = {Biometrika},
month = {apr},
number = {1},
pages = {97--109},
pmid = {18855289},
title = {{Monte Carlo sampling methods using Markov chains and their applications}},
url = {http://biomet.oxfordjournals.org/content/57/1/97.short http://www.jstor.org/stable/2334940?origin=crossref},
volume = {57},
year = {1970}
}
@article{Smaldino2016,
abstract = {Poor research design and data analysis encourage false-positive findings. Such poor methods persist despite perennial calls for improvement, suggesting that they result from something more than just misunderstanding. The persistence of poor methods results partly from incentives that favor them, leading to the natural selection of bad science. This dynamic requires no conscious strategizing---no deliberate cheating nor loafing---by scientists, only that publication is a principle factor for career advancement. Some normative methods of analysis have almost certainly been selected to further publication instead of discovery. In order to improve the culture of science, a shift must be made away from correcting misunderstandings and towards rewarding understanding. We support this argument with empirical evidence and computational modeling. We first present a 60-year meta-analysis of statistical power in the behavioral sciences and show that power has not improved despite repeated demonstrations of the necessity of increasing power. To demonstrate the logical consequences of structural incentives, we then present a dynamic model of scientific communities in which competing laboratories investigate novel or previously published hypotheses using culturally transmitted research methods. As in the real world, successful labs produce more "progeny", such that their methods are more often copied and their students are more likely to start labs of their own. Selection for high output leads to poorer methods and increasingly high false discovery rates. We additionally show that replication slows but does not stop the process of methodological deterioration. Improving the quality of research requires change at the institutional level.},
archivePrefix = {arXiv},
arxivId = {1605.09511},
author = {Smaldino, Paul E. and McElreath, Richard},
doi = {10.1098/rsos.160384},
eprint = {1605.09511},
file = {:home/kaslu/Documents/Mendeley/2016 - Smaldino, McElreath - The natural selection of bad science.pdf:pdf},
issn = {2054-5703},
journal = {Royal Society Open Science},
month = {sep},
number = {9},
pages = {160384},
title = {{The natural selection of bad science}},
url = {http://arxiv.org/abs/1605.09511 http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.160384},
volume = {3},
year = {2016}
}
@article{Poggio2003,
author = {Poggio, Tomaso and Smale, Steve},
file = {:home/kaslu/Documents/Mendeley/2003 - Poggio, Smale - The mathematics of learning Dealing with data.pdf:pdf},
journal = {Notices of the AMS},
number = {5},
pages = {537--544},
title = {{The mathematics of learning: Dealing with data}},
volume = {50},
year = {2003}
}
@article{Law2008,
abstract = {... Neural correlates of perceptual learning in a sensory - motor but not a sensory cortical area . Chi-Tat Law and Joshua I. Gold. Department of Neuroscience, 116 Johnson Pavillion, 3610 Hamilton Walk, University of Pennsylvania ...},
author = {Law, Chi-Tat and Gold, Joshua I.},
doi = {10.1038/nn2070},
file = {:home/kaslu/Documents/Mendeley/2008 - Law, Gold - Neural correlates of perceptual learning in a sensory-motor, but not a sensory, cortical area.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {4},
pages = {505--513},
pmid = {18327253},
title = {{Neural correlates of perceptual learning in a sensory-motor, but not a sensory, cortical area}},
url = {http://www.nature.com/doifinder/10.1038/nn2070{\%}5Cnpapers3://publication/doi/10.1038/nn2070},
volume = {11},
year = {2008}
}
@article{Kira2015,
abstract = {Difficult decisions often require evaluation of samples of evidence acquired sequentially. A sensible strategy is to accumulate evidence, weighted by its reliability, until sufficient support is attained. An optimal statistical approach would accumulate evidence in units of logarithms of likelihood ratios (logLR) to a desired level. Studies of perceptual decisions suggest that the brain approximates an analogous procedure, but a direct test of accumulation, in units of logLR, to a threshold in units of cumulative logLR is lacking. We trained rhesus monkeys to make decisions based on a sequence of evanescent, visual cues assigned different logLR, hence different reliability. Firing rates of neurons in the lateral intraparietal area (LIP) reflected the accumulation of logLR and reached a stereotyped level before the monkeys committed to a decision. The monkeys' choices and reaction times, including their variability, were explained by LIP activity in the context of accumulation of logLR to a threshold.},
author = {Kira, Shinichiro and Yang, Tianming and Shadlen, Michael N.},
doi = {10.1016/j.neuron.2015.01.007},
file = {:home/kaslu/Documents/Mendeley/2015 - Kira, Yang, Shadlen - A Neural Implementation of Wald's Sequential Probability Ratio Test.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {4},
pages = {861--873},
pmid = {25661183},
publisher = {Elsevier Inc.},
title = {{A Neural Implementation of Wald's Sequential Probability Ratio Test}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.01.007},
volume = {85},
year = {2015}
}
@article{Dubois2001,
abstract = {There has been a lon-lasting misunderstanding in the literature of artificial intelligence and uncertainty modeling, regarding the role of fuzzy set theory and many-valued logics. The recurring question is that of the mathematical and pragmatic meaningfulness of a compositional calculus and the validity of the excluded middle law. This confusion pervades the early developments of probabilistic logic, despite early warnings of some philosophers of probability. This paper tries to clarify this situation. It emphasizes three main points. First. it suggests that the root of the controversies lies in the unfortunate confusion between degrees of belief and what logicians call "degrees of truth". The latter are usually compositional, while the former cannot be so. This claim is first illustrated by laying bare the non-compositional belief representation embedded in the standard propositional calculus. It turns out to be an all-or-nothing version of possibility theory. This framework is then extended to discuss the case of fuzzy logic versus graded possibility theory. Next, it is demonstrated that any belief representation where compositionality is taken for granted is bound to at worst collapse to a Boolean truth assignment and at best to a poorly expressive tool. Lastly, some claims pertaining to an alleged compositionality of possibility theory are refuted, thus clarifying a pervasive confusion between possibility theory axioms and fuzzy set basic connectives.},
author = {Dubois, Didier and Prade, Henri},
doi = {10.1023/A:1016740830286},
isbn = {1012-2443},
issn = {10122443},
journal = {Annals of Mathematics and Artificial Intelligence},
number = {1-4},
pages = {35--66},
title = {{Possibility theory, probability theory and multiple-valued logics: A clarification}},
volume = {32},
year = {2001}
}
@article{Bialek2001,
abstract = {We define {\{}$\backslash$em predictive information{\}} {\$}I{\_}{\{}\backslashrm pred{\}} (T){\$} as the mutual information between the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times {\$}T{\$}: {\$}I{\_}{\{}\backslashrm pred{\}} (T){\$} can remain finite, grow logarithmically, or grow as a fractional power law. If the time series allows us to learn a model with a finite number of parameters, then {\$}I{\_}{\{}\backslashrm pred{\}} (T){\$} grows logarithmically with a coefficient that counts the dimensionality of the model space. In contrast, power--law growth is associated, for example, with the learning of infinite parameter (or nonparametric) models such as continuous functions with smoothness constraints. There are connections between the predictive information and measures of complexity that have been defined both in learning theory and in the analysis of physical systems through statistical mechanics and dynamical systems theory. Further, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of {\$}I{\_}{\{}\backslashrm pred{\}} (T){\$} provides the unique measure for the complexity of dynamics underlying a time series. Finally, we discuss how these ideas may be useful in different problems in physics, statistics, and biology.},
archivePrefix = {arXiv},
arxivId = {physics/0007070},
author = {Bialek, William and Nemenman, Ilya and Tishby, Naftali},
doi = {10.1162/089976601753195969},
eprint = {0007070},
file = {:home/kaslu/Documents/Mendeley/2001 - Bialek, Nemenman, Tishby - Predictability, Complexity, and Learning.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
month = {nov},
number = {11},
pages = {2409--2463},
pmid = {11674845},
primaryClass = {physics},
title = {{Predictability, Complexity, and Learning}},
url = {http://arxiv.org/abs/physics/0007070 http://www.mitpressjournals.org/doi/abs/10.1162/089976601753195969 http://www.mitpressjournals.org/doi/10.1162/089976601753195969},
volume = {13},
year = {2001}
}
@article{Bargmann1964,
author = {Bargmann, Valentine},
doi = {10.1063/1.1704188},
file = {:home/kaslu/Documents/Mendeley/1964 - Bargmann - Note on Wigner's Theorem on Symmetry Operations.pdf:pdf},
issn = {00222488},
journal = {Journal of Mathematical Physics},
number = {7},
pages = {862},
title = {{Note on Wigner's Theorem on Symmetry Operations}},
url = {http://scitation.aip.org/content/aip/journal/jmp/5/7/10.1063/1.1704188},
volume = {5},
year = {1964}
}
@article{Azevedo2009,
abstract = {The human brain is often considered to be the most cognitively capable among mammalian brains and to be much larger than expected for a mammal of our body size. Although the number of neurons is generally assumed to be a determinant of computational power, and despite the widespread quotes that the human brain contains 100 billion neurons and ten times more glial cells, the absolute number of neurons and glial cells in the human brain remains unknown. Here we determine these numbers by using the isotropic fractionator and compare them with the expected values for a human-sized primate. We find that the adult male human brain contains on average 86.1 +/- 8.1 billion NeuN-positive cells ("neurons") and 84.6 +/- 9.8 billion NeuN-negative ("nonneuronal") cells. With only 19{\%} of all neurons located in the cerebral cortex, greater cortical size (representing 82{\%} of total brain mass) in humans compared with other primates does not reflect an increased relative number of cortical neurons. The ratios between glial cells and neurons in the human brain structures are similar to those found in other primates, and their numbers of cells match those expected for a primate of human proportions. These findings challenge the common view that humans stand out from other primates in their brain composition and indicate that, with regard to numbers of neuronal and nonneuronal cells, the human brain is an isometrically scaled-up primate brain.},
author = {Azevedo, Frederico A C and Carvalho, Ludmila R B and Grinberg, Lea T. and Farfel, Jos{\'{e}} Marcelo and Ferretti, Renata E L and Leite, Renata E P and Filho, Wilson Jacob and Lent, Roberto and Herculano-Houzel, Suzana},
doi = {10.1002/cne.21974},
file = {:home/kaslu/Documents/Mendeley/2009 - Azevedo et al. - Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain.pdf:pdf},
isbn = {0021-9967},
issn = {00219967},
journal = {Journal of Comparative Neurology},
keywords = {Brain size,Comparative neuroanatomy,Evolution,Glia/neuron ratio,Human,Neuron numbers},
number = {5},
pages = {532--541},
pmid = {19226510},
title = {{Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain}},
volume = {513},
year = {2009}
}
@article{Shaham2015,
abstract = {We propose a general framework for increasing local stability of Artificial Neural Nets (ANNs) using Robust Optimization (RO). We achieve this through an alternating minimization-maximization procedure, in which the loss of the network is minimized over perturbed examples that are generated at each parameter update. We show that adversarial training of ANNs is in fact robustification of the network optimization, and that our proposed framework generalizes previous approaches for increasing local stability of ANNs. Experimental results reveal that our approach increases the robustness of the network to existing adversarial examples, while making it harder to generate new ones. Furthermore, our algorithm improves the accuracy of the network also on the original test data.},
archivePrefix = {arXiv},
arxivId = {1511.05432},
author = {Shaham, Uri and Yamada, Yutaro and Negahban, Sahand},
eprint = {1511.05432},
file = {:home/kaslu/Documents/Mendeley/2015 - Shaham, Yamada, Negahban - Understanding Adversarial Training Increasing Local Stability of Neural Nets through Robust Optimizati.pdf:pdf},
month = {nov},
title = {{Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization}},
url = {http://arxiv.org/abs/1511.05432},
year = {2015}
}
@article{Solway2017,
abstract = {The laboratory study of how humans and other animals trade-off value and time has a long and storied history, and is the subject of a vast literature. However, despite a long history of study, there is no agreed upon mechanistic explanation of how intertemporal choice preferences arise. Several theorists have recently proposed model-based reinforcement learning as a candidate framework. This framework describes a suite of algorithms by which a model of the environment, in the form of a state transition function and reward function, can be converted on-line into a decision. The state transition function allows the model-based system to make decisions based on projected future states, while the reward function assigns value to each state, together capturing the necessary components for successful intertemporal choice. Empirical work has also pointed to a possible relationship between increased prospection and reduced discounting. In the current paper, we look for direct evidence of a relationship between temporal discounting and model-based control in a large new data set (n = 168). However, testing the relationship under several different modeling formulations revealed no indication that the two quantities are related.},
author = {Solway, Alec and Lohrenz, Terry and Montague, P. Read},
doi = {10.1038/srep43119},
file = {:home/kaslu/Documents/Mendeley/2017 - Solway, Lohrenz, Montague - Simulating future value in intertemporal choice.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {January},
pages = {43119},
pmid = {28225034},
publisher = {Nature Publishing Group},
title = {{Simulating future value in intertemporal choice}},
url = {http://www.nature.com/articles/srep43119},
volume = {7},
year = {2017}
}
@article{Buhusi2005,
abstract = {Time is a fundamental dimension of life. It is crucial for decisions about quantity, speed of movement and rate of return, as well as for motor control in walking, speech, playing or appreciating music, and participating in sports. Traditionally, the way in which time is perceived, represented and estimated has been explained using a pacemaker-accumulator model that is not only straightforward, but also surprisingly powerful in explaining behavioural and biological data. However, recent advances have challenged this traditional view. It is now proposed that the brain represents time in a distributed manner and tells the time by detecting the coincidental activation of different neural populations.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Buhusi, Catalin V. and Meck, Warren H.},
doi = {10.1038/nrn1764},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2005 - Buhusi, Meck - What makes us tick Functional and neural mechanisms of interval timing.pdf:pdf},
isbn = {1471-003X},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {10},
pages = {755--765},
pmid = {16163383},
title = {{What makes us tick? Functional and neural mechanisms of interval timing}},
url = {http://www.nature.com/doifinder/10.1038/nrn1764},
volume = {6},
year = {2005}
}
@article{Jorgenson2015,
abstract = {The evolution of the field of neuroscience has been propelled by the advent of novel technological capabilities, and the pace at which these capabilities are being developed has accelerated dramatically in the past decade. Capitalizing on this momentum, the United States launched the Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative to develop and apply new tools and technologies for revolutionizing our understanding of the brain. In this article, we review the scientific vision for this initiative set forth by the National Institutes of Health and discuss its implications for the future of neuroscience research. Particular emphasis is given to its potential impact on the mapping and study of neural circuits, and how this knowledge will transform our understanding of the complexity of the human brain and its diverse array of behaviours, perceptions, thoughts and emotions.},
archivePrefix = {arXiv},
arxivId = {1703.10935},
author = {Jorgenson, L. A. and Newsome, W. T. and Anderson, D. J. and Bargmann, C. I. and Brown, E. N. and Deisseroth, K. and Donoghue, J. P. and Hudson, K. L. and Ling, G. S. F. and MacLeish, P. R. and Marder, E. and Normann, R. A. and Sanes, J. R. and Schnitzer, M. J. and Sejnowski, T. J. and Tank, D. W. and Tsien, R. Y. and Ugurbil, K. and Wingfield, J. C.},
doi = {10.1098/rstb.2014.0164},
eprint = {1703.10935},
file = {:home/kaslu/Documents/Mendeley/2015 - Jorgenson et al. - The BRAIN Initiative developing technology to catalyse neuroscience discovery.pdf:pdf},
isbn = {1471-2970 (Electronic)$\backslash$r0962-8436 (Linking)},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
number = {1668},
pages = {20140164--20140164},
pmid = {25823863},
title = {{The BRAIN Initiative: developing technology to catalyse neuroscience discovery}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2014.0164},
volume = {370},
year = {2015}
}
@article{Machens2010,
author = {Machens, Christian K and Romo, Ranulfo and Brody, Carlos D.},
doi = {10.1523/JNEUROSCI.3276-09.2010},
file = {:home/kaslu/Documents/Mendeley/2010 - Machens, Romo, Brody - Functional, but not anatomical, separation of what and when in prefrontal cortex.pdf:pdf;:home/kaslu/Documents/Mendeley/2010 - Machens, Romo, Brody - Functional, but not anatomical, separation of what and when in prefrontal cortex(2).pdf:pdf},
issn = {0270-6474},
journal = {J. Neurosci.},
number = {1},
pages = {350--360},
pmid = {20053916},
title = {{Functional, but not anatomical, separation of what and when in prefrontal cortex}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.3276-09.2010},
volume = {30},
year = {2010}
}
@article{Fisher1998,
abstract = {The nature and origins of renormalization group ideas in statistical physics and condensed matter theory are recounted informally, emphasizing those features of prime importance in these areas of science in contradistinction to quantum field theory, in particular: critical exponents and scaling, relevance, irrelevance and marginality, universality, and Wilson's crucial concept of flows and fixed points in a large space of Hamiltonians.},
author = {Fisher, Michael E},
doi = {10.1103/RevModPhys.70.653},
file = {:home/kaslu/Documents/Mendeley/1998 - Fisher - Renormalization group theory Its basis and formulation in statistical physics.pdf:pdf},
isbn = {0034-6861},
issn = {0034-6861},
journal = {Reviews of Modern Physics},
number = {2},
pages = {653--681},
pmid = {73219700009},
title = {{Renormalization group theory: Its basis and formulation in statistical physics}},
url = {http://link.aps.org/doi/10.1103/RevModPhys.70.653},
volume = {70},
year = {1998}
}
@article{Mukherjee2016,
abstract = {We study a model of continuous opinion dynamics with both positive and negative mutual interaction. The model shows a continuous phase transition between a phase with consensus (order) and a phase having no consensus (disorder). The mean field version of the model was already studied. Using extensive numerical simulations, we study the same model in {\$}2{\$} and {\$}3{\$} dimensions. The critical points of the phase transitions for various cases and the associated critical exponents have been estimated. The universality class of the phase transitions in the model is found to be same as Ising model in the respective dimensions.},
archivePrefix = {arXiv},
arxivId = {1609.01572},
author = {Mukherjee, Sudip and Chatterjee, Arnab},
doi = {10.1103/PhysRevE.94.062317},
eprint = {1609.01572},
issn = {15502376},
journal = {PHYSICAL REVIEW E},
pages = {1--5},
title = {{Disorder induced phase transition in an opinion dynamics model: results in 2 and 3 dimensions}},
url = {http://arxiv.org/abs/1609.01572},
volume = {94},
year = {2016}
}
@article{Hanks2017,
abstract = {Perceptual decision making is the process by which animals detect, discriminate, and categorize information from the senses. Over the past two decades, understanding how perceptual decisions are made has become a central theme in the neurosciences. Exceptional progress has been made by recording from single neurons in the cortex of the macaque monkey and using computational models from mathematical psychology to relate these neural data to behavior. More recently, however, the range of available techniques and paradigms has dramatically broadened, and researchers have begun to harness new approaches to explore how rodents and humans make perceptual decisions. The results have illustrated some striking convergences with findings from the monkey, but also raised new questions and provided new theoretical insights. In this review, we summarize key findings, and highlight open challenges, for understanding perceptual decision making in rodents, monkeys, and humans.},
archivePrefix = {arXiv},
arxivId = {073734},
author = {Hanks, Timothy D. and Summerfield, Christopher},
doi = {10.1016/j.neuron.2016.12.003},
eprint = {073734},
file = {:home/kaslu/Documents/Mendeley/2017 - Hanks, Summerfield - Perceptual Decision Making in Rodents, Monkeys, and Humans.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
keywords = {confidence,decision making,functional neuroimaging,human,non-human primate,parietal cortex,psychophysics,rodent,single-cell recordings},
number = {1},
pages = {15--31},
pmid = {28056343},
publisher = {Elsevier},
title = {{Perceptual Decision Making in Rodents, Monkeys, and Humans}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.12.003},
volume = {93},
year = {2017}
}
@article{Rossi2017,
author = {Rossi, Paulo and Vicente, Renato},
doi = {10.3390/e19120667},
isbn = {5511260851},
issn = {1099-4300},
journal = {Entropy},
keywords = {bayesian inference,compressed sensing,l1-minimization,online learning},
number = {12},
pages = {667},
title = {{L1-Minimization Algorithm for Bayesian Online Compressed Sensing}},
url = {http://www.mdpi.com/1099-4300/19/12/667},
volume = {19},
year = {2017}
}
@article{Luzzi2006,
author = {Luzzi, Roberto and Vasconcellos, {\'{A}}urea R. and Ramos, J. Galv{\~{a}}o},
doi = {10.1590/S0103-97332006000100017},
file = {:home/kaslu/Documents/Mendeley/2006 - Luzzi, Vasconcellos, Ramos - Thermo-statistics of irreversible processes a Boltzmann-Gibbs-style ensemble formalism.pdf:pdf},
issn = {0103-9733},
journal = {Brazilian Journal of Physics},
keywords = {irreversible processes,nonequilibrium statistics,thermostatistics},
month = {mar},
number = {1a},
title = {{Thermo-statistics of irreversible processes: a Boltzmann-Gibbs-style ensemble formalism}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S0103-97332006000100017{\&}lng=en{\&}nrm=iso{\&}tlng=en},
volume = {36},
year = {2006}
}
@article{Bargmann1954,
author = {Bargmann, Valentine},
doi = {10.2307/1969831},
file = {:home/kaslu/Documents/Mendeley/1954 - Bargmann - On Unitary Ray Representations of Continuous Groups.pdf:pdf},
issn = {0003486X},
journal = {The Annals of Mathematics},
month = {jan},
number = {1},
pages = {1},
title = {{On Unitary Ray Representations of Continuous Groups}},
url = {http://www.jstor.org/stable/1969831?origin=crossref},
volume = {59},
year = {1954}
}
@article{Takahashi2017,
abstract = {Midbrain dopamine neurons have been proposed to signal prediction errors as defined in model-free reinforcement learning algorithms. While these algorithms have been extremely powerful in interpreting dopamine activity, these models do not register any error unless there is a difference between the value of what is predicted and what is received. Yet learning often occurs in response to changes in the unique features that characterize what is received, sometimes with no change in its value at all. Here, we show that classic error-signaling dopamine neurons also respond to changes in value-neutral sensory features of an expected reward. This suggests that dopamine neurons have access to a wider variety of information than contemplated by the models currently used to interpret their activity and that, while their firing may conform to predictions of these models in some cases, they are not restricted to signaling errors in the prediction of value. In the current study, Takahashi et al. show that dopamine neurons signal errors in predicting the sensory features of reward independent of value. These data indicate a broader role for dopaminergic errors in learning than currently proposed.},
author = {Takahashi, Yuji K. and Batchelor, Hannah M. and Liu, Bing and Khanna, Akash and Morales, Marisela and Schoenbaum, Geoffrey},
doi = {10.1016/j.neuron.2017.08.025},
file = {:home/kaslu/Documents/Mendeley/2017 - Takahashi et al. - Dopamine Neurons Respond to Errors in the Prediction of Sensory Features of Expected Rewards.pdf:pdf},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
month = {sep},
number = {6},
pages = {1395--1405.e3},
pmid = {28910622},
title = {{Dopamine Neurons Respond to Errors in the Prediction of Sensory Features of Expected Rewards}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627317307407},
volume = {95},
year = {2017}
}
@article{Burak2012,
abstract = {Neural noise limits the fidelity of representations in the brain. This limitation has been extensively analyzed for sensory coding. However, in short-term memory and integrator networks, where noise accumulates and can play an even more prominent role, much less is known about how neural noise interacts with neural and network parameters to determine the accuracy of the computation. Here we analytically derive how the stored memory in continuous attractor networks of probabilistically spiking neurons will degrade over time through diffusion. By combining statistical and dynamical approaches, we establish a fundamental limit on the network's ability to maintain a persistent state: The noise-induced drift of the memory state over time within the network is strictly lower-bounded by the accuracy of estimation of the network's instantaneous memory state by an ideal external observer. This result takes the form of an information-diffusion inequality. We derive some unexpected consequences: Despite the persistence time of short-term memory networks, it does not pay to accumulate spikes for longer than the cellular time-constant to read out their contents. For certain neural transfer functions, the conditions for optimal sensory coding coincide with those for optimal storage, implying that short-term memory may be co-localized with sensory representation.},
author = {Burak, Y. and Fiete, Ila R.},
doi = {10.1073/pnas.1117386109},
file = {:home/kaslu/Documents/Mendeley/2012 - Burak, Fiete - Fundamental limits on persistent activity in networks of noisy neurons.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {43},
pages = {17645--17650},
pmid = {23047704},
title = {{Fundamental limits on persistent activity in networks of noisy neurons}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1117386109},
volume = {109},
year = {2012}
}
@article{Eldar2013,
abstract = {Attention is commonly thought to be manifest through local variations in neural gain. However, what would be the effects of brain-wide changes in gain? We hypothesized that global fluctuations in gain modulate the breadth of attention and the degree to which processing is focused on aspects of the environment to which one is predisposed to attend. We found that measures of pupil diameter, which are thought to track levels of locus coeruleus norepinephrine activity and neural gain, were correlated with the degree to which learning was focused on stimulus dimensions that individual human participants were more predisposed to process. In support of our interpretation of this effect in terms of global changes in gain, we found that the measured pupillary and behavioral variables were strongly correlated with global changes in the strength and clustering of functional connectivity, as brain-wide fluctuations of gain would predict.},
author = {Eldar, Eran and Cohen, Jonathan D. and Niv, Yael},
doi = {10.1038/nn.3428},
file = {:home/kaslu/Documents/Mendeley/2013 - Eldar, Cohen, Niv - The effects of neural gain on attention and learning.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Adolescent,Adult,Attention,Discrimination Learning,Discrimination Learning: physiology,Female,Humans,Locus Coeruleus,Locus Coeruleus: physiology,Magnetic Resonance Imaging,Male,Middle Aged,Muscle Contraction,Neural Networks (Computer),Norepinephrine,Norepinephrine: physiology,Pattern Recognition,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Pupil,Pupil: physiology,Reward,Semantics,Visual,Visual: physiology,Young Adult},
month = {jun},
number = {8},
pages = {1146--1153},
pmid = {23770566},
publisher = {Nature Research},
title = {{The effects of neural gain on attention and learning}},
url = {http://www.nature.com/doifinder/10.1038/nn.3428 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3725201{\&}tool=pmcentrez{\&}rendertype=abstract{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nn.3428},
volume = {16},
year = {2013}
}
@article{Palmer2013,
abstract = {Guiding behavior requires the brain to make predictions about future sensory inputs. Here we show that efficient predictive computation starts at the earliest stages of the visual system. We estimate how much information groups of retinal ganglion cells carry about the future state of their visual inputs, and show that every cell we can observe participates in a group of cells for which this predictive information is close to the physical limit set by the statistical structure of the inputs themselves. Groups of cells in the retina also carry information about the future state of their own activity, and we show that this information can be compressed further and encoded by downstream predictor neurons, which then exhibit interesting feature selectivity. Efficient representation of predictive information is a candidate principle that can be applied at each stage of neural computation.},
archivePrefix = {arXiv},
arxivId = {1307.0225},
author = {Palmer, Stephanie E and Marre, Olivier and Berry, Michael J and Bialek, William},
doi = {10.1073/pnas.1506855112},
eprint = {1307.0225},
file = {:home/kaslu/Documents/Mendeley/2015 - Palmer et al. - Predictive information in a sensory population.pdf:pdf;:home/kaslu/Documents/Mendeley/2015 - Palmer et al. - Predictive information in a sensory population(2).pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {information theory,neural coding,retina},
month = {jun},
number = {22},
pages = {6908--6913},
pmid = {18056803},
publisher = {National Academy of Sciences},
title = {{Predictive information in a sensory population}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26038544 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4460449 http://arxiv.org/abs/1307.0225 http://www.pnas.org/lookup/doi/10.1073/pnas.1506855112},
volume = {112},
year = {2015}
}
@article{Bialek2014,
abstract = {Flocks of birds exhibit a remarkable degree of coordination and collective response. It is not just that thousands of individuals fly, on average, in the same direction and at the same speed, but that even the fluctuations around the mean velocity are correlated over long distances. Quantitative measurements on flocks of starlings, in particular, show that these fluctuations are scale-free, with effective correlation lengths proportional to the linear size of the flock. Here we construct models for the joint distribution of velocities in the flock that reproduce the observed local correlations between individuals and their neighbors, as well as the variance of flight speeds across individuals, but otherwise have as little structure as possible. These minimally structured or maximum entropy models provide quantitative, parameter-free predictions for the spread of correlations throughout the flock, and these are in excellent agreement with the data. These models are mathematically equivalent to statistical physics models for ordering in magnets, and the correct prediction of scale-free correlations arises because the parameters--completely determined by the data--are in the critical regime. In biological terms, criticality allows the flock to achieve maximal correlation across long distances with limited speed fluctuations.},
author = {Bialek, William and Cavagna, Andrea and Giardina, Irene and Mora, Thierry and Pohl, Oliver and Silvestri, Edmondo and Viale, Massimiliano and Walczak, Aleksandra M},
doi = {10.1073/pnas.1324045111},
file = {:home/kaslu/Documents/Mendeley/2014 - Bialek et al. - Social interactions dominate speed control in poising natural flocks near criticality.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Behavior, Animal,Entropy,Flight, Animal,Flight, Animal: physiology,Models, Theoretical,Movement,Social Behavior,Starlings,Starlings: physiology},
month = {may},
number = {20},
pages = {7212--7},
pmid = {24785504},
title = {{Social interactions dominate speed control in poising natural flocks near criticality.}},
url = {http://www.pnas.org/cgi/content/long/111/20/7212},
volume = {111},
year = {2014}
}
@article{Sherif1937,
author = {Sherif, Muzafer},
doi = {10.2307/2785261},
file = {:home/kaslu/Documents/Mendeley/1937 - Sherif - An Experimental Approach to the Study of Attitudes.pdf:pdf},
issn = {00380431},
journal = {Sociometry},
month = {jul},
number = {1/2},
pages = {90},
title = {{An Experimental Approach to the Study of Attitudes}},
url = {http://www.jstor.org/stable/2785261?origin=crossref},
volume = {1},
year = {1937}
}
@article{Singelis1995,
abstract = {In developing a new scale, this article makes theoretical and measurement distinctions between vertical and horizontal individualism and collectivism. Vertical collectivism includes perceiving the selfas a part (or an aspect) of a collective and accepting inequalities within the collective. Horizontal collectivism includes perceiving the self as a part of the collective, but seeing all members of the collective as the same; thus equality is stressed. Vertical individualism includes the conception of an autonomous individual and acceptance of inequality. Horizontal individualism includes the conception of an autonomous individual and emphasis on equality. Measurement of these constructs is preferable theoretically and empirically (better internal consistency) to either of the more general constructs of individualism and collectivism or the constituent elements of these constructs, such as self-reliance, hedonism, family integrity, and so on. The usefulness of these theoretical distinctions is demonstrated and their implications are discussed.},
author = {Singelis, T. M. and Triandis, H. C. and Bhawuk, D. P. S. and Gelfand, Michele J.},
doi = {10.1177/106939719502900302},
isbn = {1069-3971},
issn = {1069-3971},
journal = {Cross-Cultural Research},
number = {3},
pages = {240--275},
pmid = {18954169},
title = {{Horizontal and vertical dimensions of individualism and collectivism: A theoretical and measurement refinement}},
url = {http://ccr.sagepub.com/cgi/doi/10.1177/106939719502900302},
volume = {29},
year = {1995}
}
@article{Mazzucato2015,
abstract = {Single trial analyses of ensemble activity in alert animals demonstrate that cortical circuits dy-namics evolve through temporal sequences of metastable states. Metastability has been studied for its potential role in sensory coding, memory and decision-making. Yet, very little is known about the network mechanisms responsible for its genesis. It is often assumed that the onset of state sequences is triggered by an external stimulus. Here we show that state sequences can be observed also in the absence of overt sensory stimulation. Analysis of multielectrode recordings from the gustatory cortex of alert rats revealed ongoing sequences of states, where single neurons spontaneously attain several firing rates across different states. This single neuron multi-stability represents a challenge to existing spiking network models, where typically each neuron is at most bi-stable. We present a recurrent spiking network model that accounts for both the spontaneous genera-tion of state sequences and the multi-stability in single neuron firing rates. Each state results from the activation of neural clusters with potentiated intra-cluster connections, with the firing rate in each cluster depending on the number of active clusters. Simulations show that the models ensemble activity hops among the different states, reproducing the ongoing dynamics observed in the data. When probed with external stimuli, the model predicts the quenching of single neuron multi-stability into bi-stability and the reduction of trial-by-trial vari-ability. Both predictions were confirmed in the data. Altogether, these results provide a theoretical framework that captures both ongoing and evoked network dynamics in a single mechanistic model.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.00165v3},
author = {Mazzucato, L. and Fontanini, A. and {La Camera}, G.},
doi = {10.1523/JNEUROSCI.4819-14.2015},
eprint = {arXiv:1508.00165v3},
file = {:home/kaslu/Documents/Mendeley/2015 - Mazzucato, Fontanini, La Camera - Dynamics of Multistable States during Ongoing and Evoked Cortical Activity.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {gustatory cortex,hidden markov models,network dynamics,ongoing activity,spiking network models},
number = {21},
pages = {8214--8231},
pmid = {26019337},
title = {{Dynamics of Multistable States during Ongoing and Evoked Cortical Activity}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4819-14.2015},
volume = {35},
year = {2015}
}
@article{Gershman2017b,
abstract = {Retrieving a memory can modify its influence on subsequent behavior. We develop a computational theory of memory modification, according to which modification of a memory trace occurs through classical associative learning, but which memory trace is eligible for modification depends on a structure learning mechanism that discovers the units of association by segmenting the stream of experience into statistically distinct clusters (latent causes). New memories are formed when the structure learning mechanism infers that a new latent cause underlies current sensory observations. By the same token, old memories are modified when old and new sensory observations are inferred to have been generated by the same latent cause. We derive this framework from probabilistic principles, and present a computational implementation. Simulations demonstrate that our model can reproduce the major experimental findings from studies of memory modification in the Pavlovian conditioning literature.},
author = {Gershman, Samuel J. and Monfils, Marie H. and Norman, Kenneth A. and Niv, Yael},
doi = {10.7554/eLife.23763},
issn = {2050084X},
journal = {eLife},
month = {mar},
pmid = {28294944},
title = {{The computational nature of memory modification}},
url = {https://elifesciences.org/articles/23763},
volume = {6},
year = {2017}
}
@article{Davis2015,
abstract = {Maximization of the path information entropy is a clear prescription for constructing models in non-equilibrium statistical mechanics. Here it is shown that, following this prescription under the assumption of arbitrary instanta-neous constraints on position and velocity, a Lagrangian emerges which determines the most probable trajectory. Deviations from the probability maximum can be consistently described as slices in time by a Hamiltonian, according to a nonlinear Langevin equation and its associated Fokker–Planck equation. The connections unveiled between the maximization of path entropy and the Langevin/Fokker–Planck equations imply that missing information about the phase space coordinate never decreases in time, a purely informa-tion-theoretical version of the second law of thermodynamics. All of these results are independent of any physical assumptions, and thus valid for any generalized coordinate as a function of time, or any other parameter. This reinforces the view that the second law is a fundamental property of plausible inference.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.3249v2},
author = {Davis, Sergio and Gonz{\'{a}}lez, Diego},
doi = {10.1088/1751-8113/48/42/425003},
eprint = {arXiv:1404.3249v2},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and Theoretical},
keywords = {Fokker–Planck,Langevin,maximum caliber,path entropy},
month = {oct},
number = {42},
publisher = {IOP Publishing},
title = {{Hamiltonian formalism and path entropy maximization}},
url = {http://dx.doi.org/10.1088/1751-8113/0/0/000000 http://stacks.iop.org/1751-8121/48/i=42/a=425003?key=crossref.c777060e9fe575f75e3b9c1be934c797},
volume = {48},
year = {2015}
}
@article{Zeldenrust2017,
author = {Zeldenrust, Fleur and de Knecht, Sicco and Wadman, Wytse J. and Den{\`{e}}ve, Sophie and Gutkin, Boris},
doi = {10.3389/fncom.2017.00049},
file = {:home/kaslu/Documents/Mendeley/2017 - Zeldenrust et al. - Estimating the Information Extracted by a Single Spiking Neuron from a Continuous Input Time Series.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {2008a,Bayesian neuron model,abbreviations,artificial neural network,bayesian neuron,bn,equation 14,equation 16,fmse,fraction of,fraction of output mse,in vitro  electrophysiology,in vitro electrophysiology,information theory,input mse,mean-squared error,model,mse,mse p,neural information processing,output mse relative to,poisson spike train,relative to mse in,see den{\`{e}}ve},
month = {jun},
number = {June},
title = {{Estimating the Information Extracted by a Single Spiking Neuron from a Continuous Input Time Series}},
url = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00049/full},
volume = {11},
year = {2017}
}
@article{Sallet2011,
abstract = {It has been suggested that variation in brain structure correlates with the sizes of individuals' social networks. Whether variation in social network size causes variation in brain structure, however, is unknown. To address this question, we neuroimaged 23 monkeys that had been living in social groups set to different sizes. Subject comparison revealed that living in larger groups caused increases in gray matter in mid-superior temporal sulcus and rostral prefrontal cortex and increased coupling of activity in frontal and temporal cortex. Social network size, therefore, contributes to changes both in brain structure and function. The changes have potential implications for an animal's success in a social context; gray matter differences in similar areas were also correlated with each animal's dominance within its social network.},
author = {Sallet, J. and Mars, R. B. and Noonan, M. P. and Andersson, J. L. and O'Reilly, J. X. and Jbabdi, S. and Croxson, P. L. and Jenkinson, M. and Miller, K. L. and Rushworth, M. F. S.},
doi = {10.1126/science.1210027},
isbn = {1095-9203},
issn = {0036-8075},
journal = {Science},
month = {nov},
number = {6056},
pages = {697--700},
pmid = {22053054},
title = {{Social Network Size Affects Neural Circuits in Macaques}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1210027},
volume = {334},
year = {2011}
}
@article{Drugowitsch2015,
abstract = {For decisions made under time pressure, effective decision making based on uncertain or ambiguous evidence requires efficient accumulation of evidence over time, as well as appropriately balancing speed and accuracy, known as the speed/accuracy trade-off. For simple unimodal stimuli, previous studies have shown that human subjects set their speed/accuracy trade-off to maximize reward rate. We extend this analysis to situations in which information is provided by multiple sensory modalities. Analyzing previously collected data (Drugowitsch et al., 2014), we show that human subjects adjust their speed/accuracy trade-off to produce near-optimal reward rates. This trade-off can change rapidly across trials according to the sensory modalities involved, suggesting that it is represented by neural population codes rather than implemented by slow neuronal mechanisms such as gradual changes in synaptic weights. Furthermore, we show that deviations from the optimal speed/accuracy trade-off can be explained by assuming an incomplete gradient-based learning of these trade-offs.},
author = {Drugowitsch, Jan and Deangelis, Gregory C. and Angelaki, Dora E. and Pouget, Alexandre},
doi = {10.7554/eLife.06678},
file = {:home/kaslu/Documents/Mendeley/2015 - Drugowitsch et al. - Tuning the speed-accuracy trade-off to maximize reward rate in multisensory decision-making.pdf:pdf},
isbn = {2050-084X (Electronic)$\backslash$r2050-084X (Linking)},
issn = {2050084X},
journal = {eLife},
number = {JUNE2015},
pages = {1--11},
pmid = {26090907},
title = {{Tuning the speed-accuracy trade-off to maximize reward rate in multisensory decision-making}},
volume = {4},
year = {2015}
}
@article{Simpson2017,
author = {Simpson, Brent and Willer, Robb and Harrell, Ashley},
doi = {10.1038/srep42844},
issn = {2045-2322},
journal = {Scientific Reports},
number = {February},
pages = {42844},
pmid = {28211503},
publisher = {Nature Publishing Group},
title = {{The Enforcement of Moral Boundaries Promotes Cooperation and Prosocial Behavior in Groups}},
url = {http://www.nature.com/articles/srep42844},
volume = {7},
year = {2017}
}
@article{Reid2016,
abstract = {Several recent studies hint at shared patterns in decision-making between taxonomically distant organisms, yet few studies demonstrate and dissect mechanisms of decision-making in simpler organisms. We examine decision-making in the unicellular slime mould Physarum polycephalum using a classical decision problem adapted from human and animal decision-making studies: the two-armed bandit problem. This problem has previously only been used to study organisms with brains, yet here we demonstrate that a brainless unicellular organism compares the relative qualities of multiple options, integrates over repeated samplings to perform well in random environments, and combines information on reward frequency and magnitude in order to make correct and adaptive decisions. We extend our inquiry by using Bayesian model selection to determine the most likely algorithm used by the cell when making decisions. We deduce that this algorithm centres around a tendency to exploit environments in proportion to their reward experienced through past sampling. The algorithm is intermediate in computational complexity between simple, reactionary heuristics and calculation-intensive optimal performance algorithms, yet it has very good relative performance. Our study provides insight into ancestral mechanisms of decision-making and suggests that fundamental principles of decision-making, information processing and even cognition are shared among diverse biological systems.},
author = {Reid, Chris R. and MacDonald, Hannelore and Mann, Richard P. and Marshall, James A. R. and Latty, Tanya and Garnier, Simon},
doi = {10.1098/rsif.2016.0030},
file = {:home/kaslu/Documents/Mendeley/2016 - Reid et al. - Decision-making without a brain how an amoeboid organism solves the two-armed bandit.pdf:pdf},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
keywords = {Bayesian model selection,Physarum polycephalum,decision-making,exploration–exploitation trade-off,slime mould,two-armed bandit},
month = {jun},
number = {119},
pages = {20160030},
pmid = {27278359},
publisher = {The Royal Society},
title = {{Decision-making without a brain: how an amoeboid organism solves the two-armed bandit}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27278359 http://rsif.royalsocietypublishing.org/lookup/doi/10.1098/rsif.2016.0030},
volume = {13},
year = {2016}
}
@article{Zaburdaev2015,
abstract = {Random walk is a fundamental concept with applications ranging from quantum physics to econometrics. Remarkably, one specific model of random walks appears to be ubiquitous across many fields as a tool to analyze transport phenomena in which the dispersal process is faster than dictated by Brownian diffusion. The L$\backslash$'{\{}e{\}}vy walk model combines two key features, the ability to generate anomalously fast diffusion and a finite velocity of a random walker. Recent results in optics, Hamiltonian chaos, cold atom dynamics, bio-physics, and behavioral science demonstrate that this particular type of random walks provides significant insight into complex transport phenomena. This review provides a self-consistent introduction to L$\backslash$'{\{}e{\}}vy walks, surveys their existing applications, including latest advances, and outlines further perspectives.},
archivePrefix = {arXiv},
arxivId = {1410.5100},
author = {Zaburdaev, V and Denisov, S and Klafter, J},
doi = {10.1103/RevModPhys.87.483},
eprint = {1410.5100},
issn = {0034-6861},
journal = {Reviews of Modern Physics},
month = {jun},
number = {2},
pages = {483--530},
title = {{L{\'{e}}vy walks}},
url = {http://link.aps.org/doi/10.1103/RevModPhys.87.483 http://arxiv.org/abs/1410.5100 http://dx.doi.org/10.1103/RevModPhys.87.483},
volume = {87},
year = {2015}
}
@article{Hiscock2016,
abstract = {Migratory birds have a light-dependent magnetic compass, the mechanism of which is thought to involve radical pairs formed photochemically in cryptochrome proteins in the retina. Theoretical descriptions of this compass have thus far been unable to account for the high precision with which birds are able to detect the direction of the Earth's magnetic field. Here we use coherent spin dynamics simulations to explore the behavior of realistic models of cryptochrome-based radical pairs. We show that when the spin coherence persists for longer than a few microseconds, the output of the sensor contains a sharp feature, referred to as a spike. The spike arises from avoided crossings of the quantum mechanical spin energy-levels of radicals formed in cryptochromes. Such a feature could deliver a heading precision sufficient to explain the navigational behavior of migratory birds in the wild. Our results (i) afford new insights into radical pair magnetoreception, (ii) suggest ways in which the performance of the compass could have been optimized by evolution, (iii) may provide the beginnings of an explanation for the magnetic disorientation of migratory birds exposed to anthropogenic electromagnetic noise, and (iv) suggest that radical pair magnetoreception may be more of a quantum biology phenomenon than previously realized.},
author = {Hiscock, Hamish G and Worster, Susannah and Kattnig, Daniel R and Steers, Charlotte and Jin, Ye and Manolopoulos, David E and Mouritsen, Henrik and Hore, P J},
doi = {10.1073/pnas.1600341113},
file = {:home/kaslu/Documents/Mendeley/2016 - Hiscock et al. - The quantum needle of the avian magnetic compass.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {magnetic compass,magnetoreception,migratory birds,quantum biology,radical pair mechanism},
month = {apr},
number = {17},
pages = {4634--4639},
pmid = {27044102},
publisher = {National Academy of Sciences},
title = {{The quantum needle of the avian magnetic compass}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27044102 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4855607 http://www.pnas.org/lookup/doi/10.1073/pnas.1600341113},
volume = {113},
year = {2016}
}
@article{Harvey2012,
abstract = {The posterior parietal cortex (PPC) has an important role in many cognitive behaviours; however, the neural circuit dynamics underlying PPC function are not well understood. Here we optically imaged the spatial and temporal activity patterns of neuronal populations in mice performing a PPC-dependent task that combined a perceptual decision and memory-guided navigation in a virtual environment. Individual neurons had transient activation staggered relative to one another in time, forming a sequence of neuronal activation spanning the entire length of a task trial. Distinct sequences of neurons were triggered on trials with opposite behavioural choices and defined divergent, choice-specific trajectories through a state space of neuronal population activity. Cells participating in the different sequences and at distinct time points in the task were anatomically intermixed over microcircuit length scales ({\textless}100 micrometres). During working memory decision tasks, the PPC may therefore perform computations through sequence-based circuit dynamics, rather than long-lived stable states, implemented using anatomically intermingled microcircuits.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Harvey, Christopher D. and Coen, Philip and Tank, David},
doi = {10.1038/nature10918},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2012 - Harvey, Coen, Tank - Choice-specific sequences in parietal cortex during a virtual-navigation decision task.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {1476-4687},
journal = {Nature},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Decision Making,Decision Making: physiology,Inbred C57BL,Male,Maze Learning,Maze Learning: physiology,Memory,Memory: physiology,Mice,Models,Neurological,Parietal Lobe,Parietal Lobe: cytology,Parietal Lobe: physiology,Photic Stimulation,User-Computer Interface},
number = {7392},
pages = {62--8},
pmid = {22419153},
publisher = {Nature Publishing Group},
title = {{Choice-specific sequences in parietal cortex during a virtual-navigation decision task.}},
url = {http://dx.doi.org/10.1038/nature10918{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/22419153{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3321074},
volume = {484},
year = {2012}
}
@article{Nassar2010,
abstract = {Maintaining appropriate beliefs about variables needed for effective decision making can be difficult in a dynamic environment. One key issue is the amount of influence that unexpected outcomes should have on existing beliefs. In general, outcomes that are unexpected because of a fundamental change in the environment should carry more influence than outcomes that are unexpected because of persistent environmental stochasticity. Here we use a novel task to characterize how well human subjects follow these principles under a range of conditions. We show that the influence of an outcome depends on both the error made in predicting that outcome and the number of similar outcomes experienced previously. We also show that the exact nature of these tendencies varies considerably across subjects. Finally, we show that these patterns of behavior are consistent with a computationally simple reduction of an ideal-observer model. The model adjusts the influence of newly experienced outcomes according to ongoing estimates of uncertainty and the probability of a fundamental change in the process by which outcomes are generated. A prior that quantifies the expected frequency of such environmental changes accounts for individual variability, including a positive relationship between subjective certainty and the degree to which new information influences existing beliefs. The results suggest that the brain adaptively regulates the influence of decision outcomes on existing beliefs using straightforward updating rules that take into account both recent outcomes and prior expectations about higher-order environmental structure.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Nassar, Matthew R and Wilson, Robert C and Heasly, Benjamin and Gold, Joshua I.},
doi = {10.1523/JNEUROSCI.0822-10.2010},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2010 - Nassar et al. - An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Adaptation,Adult,Bayes Theorem,Cognition,Cognition: physiology,Computer Simulation,Culture,Decision Making,Decision Making: physiology,Environment,Executive Function,Executive Function: physiology,Female,Humans,Male,Models,Neuronal Plasticity,Neuronal Plasticity: physiology,Neuropsychological Tests,Predictive Value of Tests,Psychological,Psychological: physiology,Young Adult},
number = {37},
pages = {12366--78},
pmid = {20844132},
title = {{An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment.}},
url = {http://www.jneurosci.org/content/30/37/12366.short},
volume = {30},
year = {2010}
}
@article{Ribeiro2018,
abstract = {Corruptive behaviour in politics limits economic growth, embezzles public funds, and promotes socio-economic inequality in modern democracies. We analyse well-documented political corruption scandals in Brazil over the past 27 years, focusing on the dynamical structure of networks where two individuals are connected if they were involved in the same scandal. Our research reveals that corruption runs in small groups that rarely comprise more than eight people, in networks that have hubs and a modular structure that encompasses more than one corruption scandal. We observe abrupt changes in the size of the largest connected component and in the degree distribution, which are due to the coalescence of different modules when new scandals come to light or when governments change. We show further that the dynamical structure of political corruption networks can be used for successfully predicting partners in future scandals. We discuss the important role of network science in detecting and mitigating political corruption.},
archivePrefix = {arXiv},
arxivId = {1801.01869},
author = {Ribeiro, Haroldo V. and Alves, Luiz G. A. and Martins, Alvaro F. and Lenzi, Ervin K. and Perc, Matjaz},
doi = {10.1093/comnet/cny002},
eprint = {1801.01869},
file = {:home/kaslu/Documents/Mendeley/2018 - Ribeiro et al. - The dynamical structure of political corruption networks.pdf:pdf},
issn = {2051-1310},
number = {March},
pages = {1--15},
title = {{The dynamical structure of political corruption networks}},
url = {http://arxiv.org/abs/1801.01869{\%}0Ahttp://dx.doi.org/10.1093/comnet/cny002},
year = {2018}
}
@article{Gao2017,
abstract = {In many experiments, neuroscientists tightly control behavior, record many trials, and obtain trial-averaged firing rates from hundreds of neurons in circuits containing billions of behaviorally relevant neurons. Dimensionality reduction methods reveal a striking simplicity underlying such multi-neuronal data: they can be reduced to a low-dimensional space, and the resulting neural trajectories in this space yield a remarkably insightful dynamical portrait of circuit computation. This simplicity raises profound and timely conceptual questions. What are its origins and its implications for the complexity of neural dynamics? How would the situation change if we recorded more neurons? When, if at all, can we trust dynamical portraits obtained from measuring an infinitesimal fraction of task relevant neurons? We present a theory that answers these questions, and test it using physiological recordings from reaching monkeys. This theory reveals conceptual insights into how task complexity governs both neural dimensionality and accurate recovery of dynamic portraits, thereby providing quantitative guidelines for future large-scale experimental design.},
author = {Gao, Peiran and Trautmann, Eric and Yu, Byron M. and Santhanam, Gopal and Ryu, Stephen and Shenoy, Krishna and Ganguli, Surya},
doi = {10.1101/214262},
file = {:home/kaslu/Documents/Mendeley/2017 - Gao et al. - A theory of multineuronal dimensionality, dynamics and measurement.pdf:pdf},
journal = {bioRxiv},
pages = {214262},
title = {{A theory of multineuronal dimensionality, dynamics and measurement}},
url = {https://www.biorxiv.org/content/early/2017/11/05/214262},
year = {2017}
}
@article{Shan2016,
abstract = {Precortical neural systems encode information collected by the senses, but the driving principles of the encoding used have remained a subject of debate. We present a model of retinal coding that is based on three constraints: information preservation, minimization of the neural wiring, and response equalization. The resulting novel version of sparse principal components analysis successfully captures a number of known characteristics of the retinal coding system, such as center-surround receptive fields, color opponency channels, and spatiotemporal responses that correspond to magnocellular and parvocellular pathways. Furthermore, when trained on auditory data, the same model learns receptive fields well fit by gammatone filters, commonly used to model precortical auditory coding. This suggests that efficient coding may be a unifying principle of precortical encoding across modalities.},
archivePrefix = {arXiv},
arxivId = {1602.08486},
author = {Shan, Honghao and Tong, Matthew H. and Cottrell, Garrison W.},
eprint = {1602.08486},
file = {:home/kaslu/Documents/Mendeley/2016 - Shan, Tong, Cottrell - A Single Model Explains both Visual and Auditory Precortical Coding.pdf:pdf},
month = {feb},
title = {{A Single Model Explains both Visual and Auditory Precortical Coding}},
url = {http://arxiv.org/abs/1602.08486},
year = {2016}
}
@article{Sarovar2010,
abstract = {Light harvesting components of photosynthetic organisms are complex, coupled, many-body quantum systems, in which electronic coherence has recently been shown to survive for relatively long time scales despite the decohering effects of their environments. Within this context, we critically analyze entanglement in multi-chromophoric light harvesting complexes; we clarify the connection between coherence and entanglement in these systems, and establish methods for quantification of entanglement by presenting necessary and sufficient conditions for entanglement and by deriving a measure of global entanglement. These methods are then applied to the Fenna-Matthews-Olson (FMO) protein to extract the initial state and temperature dependencies of entanglement in this complex. We show that while FMO in natural conditions largely contains bipartite entanglement between dimerized chromophores, a small amount of long-range and multipartite entanglement exists even at physiological temperatures. This constitutes the first rigorous quantification of entanglement in a biological system. Finally, we discuss the practical utilization of entanglement in densely packed molecular aggregates such as light harvesting complexes.},
archivePrefix = {arXiv},
arxivId = {0905.3787},
author = {Sarovar, Mohan and Ishizaki, Akihito and Fleming, Graham R. and Whaley, K. Birgitta},
doi = {10.1038/nphys1652},
eprint = {0905.3787},
file = {:home/kaslu/Documents/Mendeley/2010 - Sarovar et al. - Quantum entanglement in photosynthetic light-harvesting complexes.pdf:pdf},
isbn = {1876-6196},
issn = {1745-2473},
journal = {Nature Physics},
keywords = {Quantum Physics},
month = {jun},
number = {6},
pages = {462--467},
title = {{Quantum entanglement in photosynthetic light-harvesting complexes}},
url = {http://arxiv.org/abs/0905.3787 http://dx.doi.org/10.1038/nphys1652 http://www.nature.com/doifinder/10.1038/nphys1652},
volume = {6},
year = {2010}
}
@article{Lin2016,
abstract = {We show how the success of deep learning depends not only on mathematics but also on physics: although well-known mathematical theorems guarantee that neural networks can approximate arbitrary functions well, the class of functions of practical interest can be approximated through "cheap learning" with exponentially fewer parameters than generic ones, because they have simplifying properties tracing back to the laws of physics. The exceptional simplicity of physics-based functions hinges on properties such as symmetry, locality, compositionality and polynomial log-probability, and we explore how these properties translate into exceptionally simple neural networks approximating both natural phenomena such as images and abstract representations thereof such as drawings. We further argue that when the statistical process generating the data is of a certain hierarchical form prevalent in physics and machine-learning, a deep neural network can be more efficient than a shallow one. We formalize these claims using information theory and discuss the relation to renormalization group procedures. We prove various "no-flattening theorems" showing when such efficient deep networks cannot be accurately approximated by shallow ones without efficiency loss: flattening even linear functions can be costly, and flattening polynomials is exponentially expensive; we use group theoretic techniques to show that n variables cannot be multiplied using fewer than 2{\^{}}n neurons in a single hidden layer.},
archivePrefix = {arXiv},
arxivId = {1608.08225},
author = {Lin, Henry W. and Tegmark, Max},
eprint = {1608.08225},
file = {:home/kaslu/Documents/Mendeley/2016 - Lin, Tegmark - Why does deep and cheap learning work so well.pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Lin, Tegmark - Why does deep and cheap learning work so well(2).pdf:pdf},
month = {aug},
pages = {14},
title = {{Why does deep and cheap learning work so well?}},
url = {http://arxiv.org/abs/1608.08225},
year = {2016}
}
@article{MacCarron2016,
abstract = {The social brain hypothesis predicts that humans have an average of about 150 relationships at any given time. Within this 150, there are layers of friends of an ego, where the number of friends in a layer increases as the emotional closeness decreases. Here we analyse a mobile phone dataset, firstly, to ascertain whether layers of friends can be identified based on call frequency. We then apply different clustering algorithms to break the call frequency of egos into clusters and compare the number of alters in each cluster with the layer size predicted by the social brain hypothesis. In this dataset we find strong evidence for the existence of a layered structure. The clustering yields results that match well with previous studies for the innermost and outermost layers, but for layers in between we observe large variability.},
archivePrefix = {arXiv},
arxivId = {1604.02400},
author = {{Mac Carron}, P. and Kaski, Kimmo and Dunbar, Robin},
doi = {10.1016/j.socnet.2016.06.003},
eprint = {1604.02400},
file = {:home/kaslu/Documents/Mendeley/2016 - Mac Carron, Kaski, Dunbar - Calling Dunbar's numbers(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Mac Carron, Kaski, Dunbar - Calling Dunbar's numbers.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
month = {oct},
pages = {151--155},
title = {{Calling Dunbar's numbers}},
url = {http://arxiv.org/abs/1604.02400 http://linkinghub.elsevier.com/retrieve/pii/S0378873316301095},
volume = {47},
year = {2016}
}
@article{Shimizu2005,
abstract = {In recent years, several methods have been proposed for the discovery of causal structure from non-experimental data (Spirtes etal. 2000; Pearl 2000). Such methods make various assumptions on the data generating process to facilitate its identification from purely observational data. Continuing this line of research, we show how to discover the complete causal structure of continuous-valued data, under the assumptions that (a) the data generating process is linear, (b) there are no unobserved confounders, and (c) disturbance variables have non-gaussian distributions of non-zero variances. The solution relies on the use of the statistical method known as independent component analysis (ICA), and does not require any pre-specihfied time-ordering of the variables. We provide a complete Matlab package for performing this LiNGAM analysis (short for Linear Non-Gaussian Acyclic Model), and demonstrate the effectiveness of the method using artidicially generated data.},
author = {Shimizu, S. and Hyv{\"{a}}rinen, Aapo and Kano, Y. and Hoyer, P.O.},
file = {:home/kaslu/Documents/Mendeley/2005 - Shimizu et al. - Discovery of non-gaussian linear causal models using ICA.pdf:pdf},
isbn = {0974903914 | 9780974903910},
journal = {Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence, UAI 2005},
pages = {525--532},
title = {{Discovery of non-gaussian linear causal models using ICA}},
year = {2005}
}
@article{Churchland2008,
abstract = {Simple perceptual tasks have laid the groundwork for understanding the neurobiology of decision-making. Here, we examined this foundation to explain how decision-making circuitry adjusts in the face of a more difficult task. We measured behavioral and physiological responses of monkeys on a two- and four-choice direction-discrimination decision task. For both tasks, firing rates in the lateral intraparietal area appeared to reflect the accumulation of evidence for or against each choice. Evidence accumulation began at a lower firing rate for the four-choice task, but reached a common level by the end of the decision process. The larger excursion suggests that the subjects required more evidence before making a choice. Furthermore, on both tasks, we observed a time-dependent rise in firing rates that may impose a deadline for deciding. These physiological observations constitute an effective strategy for handling increased task difficulty. The differences appear to explain subjects' accuracy and reaction times.},
author = {Churchland, Anne K. and Kiani, Roozbeh and Shadlen, Michael N.},
doi = {10.1038/nn0708-851c},
file = {:home/kaslu/Documents/Mendeley/2008 - Churchland, Kiani, Shadlen - Decision-making with multiple alternatives.pdf:pdf},
isbn = {1097-6256 (Print)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {6},
pages = {693--702},
pmid = {18488024},
title = {{Decision-making with multiple alternatives.}},
volume = {11},
year = {2008}
}
@article{Clauset2009a,
abstract = {Power-law distributions occur in many situations of scientific interest and have significant consequences for our understanding of natural and man-made phenomena. Unfortunately, the detection and characterization of power laws is complicated by the large fluctuations that occur in the tail of the distribution—the part of the distribution representing large but rare events— and by the difficulty of identifying the range over which power-law behavior holds. Commonly used methods for analyzing power-law data, such as least-squares fitting, can produce substantially inaccurate estimates of parameters for power-law distributions, and even in cases where such methods return accurate answers they are still unsatisfactory because they give no indication of whether the data obey a power law at all. Here we present a principled statistical framework for discerning and quantifying power-law behavior in empirical data. Our approach combines maximum-likelihood fitting methods with goodness-of-fit tests based on the Kolmogorov-Smirnov statistic and likelihood ratios. We evaluate the effectiveness of the approach with tests on synthetic data and give critical comparisons to previous approaches. We also apply the proposed methods to twenty-four real-world data sets from a range of different disciplines, each of which has been conjectured to follow a power-law distribution. In some cases we find these conjectures to be consistent with the data while in others the power law is ruled out.},
archivePrefix = {arXiv},
arxivId = {arXiv:0706.1062v2},
author = {Clauset, Aaron and Shalizi, Cosma Rohilla and Newman, M. E. J.},
doi = {10.1137/070710111},
eprint = {arXiv:0706.1062v2},
isbn = {1932-6157},
issn = {0036-1445},
journal = {SIAM Review},
month = {nov},
number = {4},
pages = {661--703},
pmid = {1000172861},
title = {{Power-Law Distributions in Empirical Data}},
url = {http://epubs.siam.org/doi/10.1137/070710111},
volume = {51},
year = {2009}
}
@article{Izuma2013,
abstract = {Human attitudes and preferences are susceptible to social influence. Recent social neuroscience studies, using theories and experimental paradigms from social psychology, have begun to elucidate the neural mechanisms underlying how others influence our attitudes through processes such as social conformity, cognitive inconsistency and persuasion. The currently available evidence highlights the role of the posterior medial frontal cortex (pMFC) in social conformity and cognitive inconsistency, which represents the discrepancy between one's own and another person's opinion, or, more broadly, between currently inconsistent and ideally consistent states. Research on persuasion has revealed that people's susceptibility to persuasive messages is related to activation in a nearby but more anterior part of the medial frontal cortex. Future progress in this field will depend upon the ability of researchers to dissociate underlying motivations for attitude change in different paradigms, and to utilize neuroimaging methods to advance social psychological theories of social influence.},
author = {Izuma, Keise},
doi = {10.1016/j.conb.2013.03.009},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
month = {jun},
number = {3},
pages = {456--462},
title = {{The neural basis of social influence and attitude change}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S095943881300086X},
volume = {23},
year = {2013}
}
@article{Freedman2001,
abstract = {The ability to group stimuli into meaningful categories is a fundamental cognitive process. To explore its neural basis, we trained monkeys to categorize computer-generated stimuli as "cats" and "dogs." A morphing system was used to systematically vary stimulus shape and precisely define the category boundary. Neural activity in the lateral prefrontal cortex reflected the category of visual stimuli, even when a monkey was retrained with the stimuli assigned to new categories.},
author = {Freedman, D. J.},
doi = {10.1126/science.291.5502.312},
file = {:home/kaslu/Documents/Mendeley/2001 - Freedman - Categorical Representation of Visual Stimuli in the Primate Prefrontal Cortex.pdf:pdf},
isbn = {0891243208},
issn = {00368075},
journal = {Science},
number = {5502},
pages = {312--316},
pmid = {11209083},
title = {{Categorical Representation of Visual Stimuli in the Primate Prefrontal Cortex}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.291.5502.312},
volume = {291},
year = {2001}
}
@article{Lake2002,
abstract = {Provided by Bob Lambert for lecture},
author = {Lake, David},
doi = {10.1017/S777777770200002X},
issn = {00925853},
journal = {International Organization},
number = {1},
pages = {15--29},
title = {{Rational Extremism: Understanding Terrorism in the Twenty-First Century}},
volume = {1},
year = {2002}
}
@article{Ferrari2016,
abstract = {The principle of maximum entropy provides a useful method for inferring statistical mechanics models from observations in correlated systems, and is widely used in a variety of fields where accurate data are available. While the assumptions underlying maximum entropy are intuitive and appealing, its adequacy for describing complex empirical data has been little studied in comparison to alternative approaches. Here data from the collective spiking activity of retinal neurons is reanalysed. The accuracy of the maximum entropy distribution constrained by mean firing rates and pairwise correlations is compared to a random ensemble of distributions constrained by the same observables. In general, maximum entropy approximates the true distribution better than the typical or mean distribution from that ensemble. This advantage improves with population size, with groups as small as 8 being almost always better described by maximum entropy. Failure of maximum entropy to outperform random models is found to be associated with strong correlations in the population.},
archivePrefix = {arXiv},
arxivId = {1612.02807},
author = {Ferrari, Ulisse and Obuchi, Tomoyuki and Mora, Thierry},
doi = {10.1103/PhysRevE.95.042321},
eprint = {1612.02807},
file = {:home/kaslu/Documents/Mendeley/2017 - Ferrari, Obuchi, Mora - Random versus maximum entropy models of neural population activity.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {042321},
title = {{Random versus maximum entropy models of neural population activity}},
url = {http://arxiv.org/abs/1612.02807 http://link.aps.org/doi/10.1103/PhysRevE.95.042321},
volume = {95},
year = {2017}
}
@article{Chang2014,
abstract = {We demonstrate how path integrals often used in problems of theoretical physics can be adapted to provide a machinery for performing Bayesian inference in function spaces. Such inference comes about naturally in the study of inverse problems of recovering continuous (infinite dimensional) coefficient functions from ordinary or partial differential equations (ODE, PDE), a problem which is typically ill-posed. Regularization of these problems using {\$}L{\^{}}2{\$} function spaces (Tikhonov regularization) is equivalent to Bayesian probabilistic inference, using a Gaussian prior. The Bayesian interpretation of inverse problem regularization is useful since it allows one to quantify and characterize error and degree of precision in the solution of inverse problems, as well as examine assumptions made in solving the problem -- namely whether the subjective choice of regularization is compatible with prior knowledge. Using path-integral formalism, Bayesian inference can be explored through various perturbative techniques, such as the semiclassical approximation, which we use in this manuscript. Perturbative path-integral approaches, while offering alternatives to computational approaches like Markov-Chain-Monte-Carlo (MCMC), also provide natural starting points for MCMC methods that can be used to refine approximations.   In this manuscript, we illustrate a path-integral formulation for inverse problems and demonstrate it on an inverse problem in membrane biophysics as well as inverse problems in potential theories involving the Poisson equation.},
archivePrefix = {arXiv},
arxivId = {1312.2974},
author = {Chang, Joshua C. and Savage, Van M. and Chou, Tom},
doi = {10.1007/s10955-014-1059-y},
eprint = {1312.2974},
file = {:home/kaslu/Documents/Mendeley/2014 - Chang, Savage, Chou - A Path-Integral Approach to Bayesian Inference for Inverse Problems Using the Semiclassical Approximation.pdf:pdf},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
month = {aug},
number = {3},
pages = {582--602},
title = {{A Path-Integral Approach to Bayesian Inference for Inverse Problems Using the Semiclassical Approximation}},
url = {http://arxiv.org/abs/1312.2974},
volume = {157},
year = {2014}
}
@article{Perugini2016,
abstract = {Perceptual decisions arise after considering the available sensory evidence [1]. When sensory information is unreliable, a good strategy is to rely on previous experience in similar situations to guide decisions [2–6]. It is well known that patients with Parkinson's disease (PD) are impaired at value-based decision-making [7–11]. How patients combine past experience and sensory information to make perceptual decisions is unknown. We developed a novel, perceptual decision-making task and manipulated the statistics of the sensory stimuli presented to patients with PD and healthy participants to determine the influence of past experience on decision-making. We show that patients with PD are impaired at combining previously learned information with current sensory information to guide decisions. We modeled the results using the drift-diffusion model (DDM) and found that the impairment corresponds to a failure in adjusting the amount of sensory evidence needed to make a decision. Our modeling results also show that two complementary mechanisms operate to implement a bias when two sets of priors are learned concurrently. Asymmetric decision threshold adjustments, as reflected by changes in the starting point of evidence accumulation, are responsible for a general choice bias, whereas the adjustment of a dynamic bias that develops over the course of a trial, as reflected by a drift-rate offset, provides the stimulus-specific component of the prior. A proper interplay between these two processes is required to implement a bias based on concurrent, stimulus-specific priors in decision-making. We show here that patients with PD are impaired in these across-trial decision threshold adjustments.},
author = {Perugini, Alessandra and Ditterich, Jochen and Basso, Michele A.},
doi = {10.1016/j.cub.2016.05.039},
file = {:home/kaslu/Documents/Mendeley/2016 - Perugini, Ditterich, Basso - Patients with Parkinson's Disease Show Impaired Use of Priors in Conditions of Sensory Uncertainty.pdf:pdf},
issn = {09609822},
journal = {Current Biology},
keywords = {Glass patterns,basal ganglia,bias,cognition,decision-making,drift-diffusion model,expectancy,implicit learning,memory,perception},
number = {14},
pages = {1902--1910},
pmid = {27322000},
publisher = {Elsevier Ltd.},
title = {{Patients with Parkinson's Disease Show Impaired Use of Priors in Conditions of Sensory Uncertainty}},
volume = {26},
year = {2016}
}
@article{Macy2015,
abstract = {Noise is widely regarded as a residual category—the unexplained variance in a linear model or the random disturbance of a predictable pattern. Accordingly, formal models often impose the simplifying assumption that the world is noise-free and social dynamics are deterministic. Where noise is assigned causal importance, it is often assumed to be a source of inefficiency, unpredictability, or heterogeneity. We review recent sociological studies that are noteworthy for demonstrating the theoretical importance of noise for understanding the dynamics of a complex system. Contrary to widely held assumptions, these studies identify conditions in which noise can increase efficiency and predictability and reduce diversity. We conclude with a methodological warning that deterministic assumptions are not an innocent simplification.},
author = {Macy, Michael and Tsvetkova, Milena},
doi = {10.1177/0049124113508093},
issn = {0049-1241},
journal = {Sociological Methods {\&} Research},
keywords = {agent-based models,analytical sociology,complex systems,computer,determinism,game theory,random error,simulation,stochastic models},
month = {may},
number = {2},
pages = {306--328},
publisher = {SAGE Publications},
title = {{The Signal Importance of Noise}},
url = {http://smr.sagepub.com/cgi/doi/10.1177/0049124113508093 http://smr.sagepub.com/cgi/content/abstract/44/2/306},
volume = {44},
year = {2015}
}
@article{Shlens2014,
abstract = {Principal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as well as the when, the how and the why of applying this technique.},
archivePrefix = {arXiv},
arxivId = {1404.1100},
author = {Shlens, Jonathon},
eprint = {1404.1100},
file = {:home/kaslu/Documents/Mendeley/2014 - Shlens - A Tutorial on Principal Component Analysis.pdf:pdf},
month = {apr},
title = {{A Tutorial on Principal Component Analysis}},
url = {http://arxiv.org/abs/1404.1100},
year = {2014}
}
@article{DeMartino2006,
author = {{De Martino}, Benedetto},
doi = {10.1126/science.1128356},
file = {:home/kaslu/Documents/Mendeley/2006 - De Martino - Frames, Biases, and Rational Decision-Making in the Human Brain.pdf:pdf},
isbn = {3135787684},
issn = {0036-8075},
journal = {Science},
month = {aug},
number = {5787},
pages = {684--687},
pmid = {16888142},
title = {{Frames, Biases, and Rational Decision-Making in the Human Brain}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1128356},
volume = {313},
year = {2006}
}
@article{Orger2008,
abstract = {A basic question in the field of motor control is how different actions are represented by activity in spinal projection neurons. We used a new behavioral assay to identify visual stimuli that specifically drive basic motor patterns in zebrafish. These stimuli evoked consistent patterns of neural activity in the neurons projecting to the spinal cord, which we could map throughout the entire population using in vivo two-photon calcium imaging. We found that stimuli that drive distinct behaviors activated distinct subsets of projection neurons, consisting, in some cases, of just a few cells. This stands in contrast to the distributed activation seen for more complex behaviors. Furthermore, targeted cell by cell ablations of the neurons associated with evoked turns abolished the corresponding behavioral response. This description of the functional organization of the zebrafish motor system provides a framework for identifying the complete circuit underlying a vertebrate behavior.},
author = {Orger, Michael B. and Kampff, Adam R. and Severi, Kristen E. and Bollmann, Johann H. and Engert, Florian},
doi = {10.1038/nn2048},
file = {:home/kaslu/Documents/Mendeley/2008 - Orger et al. - Control of visually guided behavior by distinct populations of spinal projection neurons.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {3},
pages = {327--333},
pmid = {18264094},
title = {{Control of visually guided behavior by distinct populations of spinal projection neurons}},
volume = {11},
year = {2008}
}
@article{Schober2014,
abstract = {Runge-Kutta methods are the classic family of solvers for ordinary differential equations (ODEs), and the basis for the state-of-the-art. Like most numerical methods, they return point estimates. We construct a family of probabilistic numerical methods that instead return a Gauss-Markov process defining a probability distribution over the ODE solution. In contrast to prior work, we construct this family such that posterior means match the outputs of the Runge-Kutta family exactly, thus inheriting their proven good properties. Remaining degrees of freedom not identified by the match to Runge-Kutta are chosen such that the posterior probability measure fits the observed structure of the ODE. Our results shed light on the structure of Runge-Kutta solvers from a new direction, provide a richer, probabilistic output, have low computational cost, and raise new research questions.},
archivePrefix = {arXiv},
arxivId = {1406.2582},
author = {Schober, M and Duvenaud, David and Hennig, P},
eprint = {1406.2582},
file = {:home/kaslu/Documents/Mendeley/2014 - Schober, Duvenaud, Hennig - Probabilistic ODE Solvers with Runge-Kutta Means.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 27},
pages = {18},
title = {{Probabilistic ODE Solvers with Runge-Kutta Means}},
url = {http://arxiv.org/abs/1406.2582},
year = {2014}
}
@article{Nax2015,
abstract = {We consider an environment where players are involved in a public goods game and must decide repeatedly whether to make an individual contribution or not. However, players lack strategically relevant information about the game and about the other players in the population. The resulting behavior of players is completely uncoupled from such information, and the individual strategy adjustment dynamics are driven only by reinforcement feedbacks from each player's own past. We show that the resulting "directional learning" is sufficient to explain cooperative deviations away from the Nash equilibrium. We introduce the concept of k-strong equilibria, which nest both the Nash equilibrium and the Aumann-strong equilibrium as two special cases, and we show that, together with the parameters of the learning model, the maximal k-strength of equilibrium determines the stationary distribution. The provisioning of public goods can be secured even under adverse conditions, as long as players are sufficiently responsive to the changes in their own payoffs and adjust their actions accordingly. Substantial levels of public cooperation can thus be explained without arguments involving selflessness or social preferences, solely on the basis of uncoordinated directional (mis)learning.},
archivePrefix = {arXiv},
arxivId = {1501.06558},
author = {Nax, Heinrich H and Perc, Matja{\v{z}}},
doi = {10.1038/srep08010},
eprint = {1501.06558},
issn = {2045-2322},
journal = {Scientific reports},
month = {jan},
number = {1},
pages = {8010},
pmid = {25619192},
title = {{Directional learning and the provisioning of public goods.}},
url = {http://arxiv.org/abs/1501.06558},
volume = {5},
year = {2015}
}
@article{Frank2016,
abstract = {Shift and stretch invariance lead to the exponential-Boltzmann probability distribution. Rotational invariance generates the Gaussian distribution. Particular scaling relations transform the canonical exponential and Gaussian patterns into the variety of commonly observed patterns. The scaling relations themselves arise from the fundamental invariances of shift, stretch and rotation, plus a few additional invariances. Prior work described the three fundamental invariances as a consequence of the equilibrium canonical ensemble of statistical mechanics or the Jaynesian maximization of information entropy. By contrast, I emphasize the primacy and sufficiency of invariance alone to explain the commonly observed patterns. Primary invariance naturally creates the array of commonly observed scaling relations and associated probability patterns, whereas the classical approaches derived from statistical mechanics or information theory require special assumptions to derive commonly observed scales.},
author = {Frank, Steven},
doi = {10.3390/e18050192},
file = {:home/kaslu/Documents/Mendeley/2016 - Frank - Common Probability Patterns Arise from Simple Invariances.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
keywords = {extreme value distributions,information theory,maximum entropy,measurement,statistical mechanics},
language = {en},
month = {may},
number = {5},
pages = {192},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Common Probability Patterns Arise from Simple Invariances}},
url = {http://www.mdpi.com/1099-4300/18/5/192/htm},
volume = {18},
year = {2016}
}
@article{Lehmann2007,
abstract = {10.1073/pnas.0700662104 In a recent paper, Traulsen and Nowak use a multilevel selection model to show that cooperation can be favored by group selection in finite populations [Traulsen A, Nowak M (2006)  103:10952{\^{a}}10955]. The authors challenge the view that kin selection may be an appropriate interpretation of their results and state that group selection is a distinctive process {\^{a}}that permeates evolutionary processes from the emergence of the first cells to eusociality and the economics of nations.{\^{a}} In this paper, we start by addressing Traulsen and Nowak's challenge and demonstrate that all their results can be obtained by an application of kin selection theory. We then extend Traulsen and Nowak's model to life history conditions that have been previously studied. This allows us to highlight the differences and similarities between Traulsen and Nowak's model and typical kin selection models and also to broaden the scope of their results. Our retrospective analyses of Traulsen and Nowak's model illustrate that it is possible to convert group selection models to kin selection models without disturbing the mathematics describing the net effect of selection on cooperation.},
author = {Lehmann, Laurent and Keller, Laurent and West, Stuart and Roze, Denis},
doi = {10.1073/pnas.0700662104},
isbn = {1095210955},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {16},
pages = {6736--6739},
pmid = {17416674},
title = {{Group selection and kin selection: Two concepts but one process}},
url = {http://www.pnas.org/content/104/16/6736.abstract{\%}5Cnhttp://www.pnas.org/content/104/16/6736.full.pdf{\%}5Cnhttp://www.pnas.org/cgi/content/abstract/104/16/6736},
volume = {104},
year = {2007}
}
@misc{Koch2016,
abstract = {There have been a number of advances in the search for the neural correlates of consciousness - the minimum neural mechanisms sufficient for any one specific conscious percept. In this Review, we describe recent findings showing that the anatomical neural correlates of consciousness are primarily localized to a posterior cortical hot zone that includes sensory areas, rather than to a fronto-parietal network involved in task monitoring and reporting. We also discuss some candidate neurophysiological markers of consciousness that have proved illusory, and measures of differentiation and integration of neural activity that offer more promising quantitative indices of consciousness.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Koch, Christof and Massimini, Marcello and Boly, Melanie and Tononi, Giulio},
booktitle = {Nature Reviews Neuroscience},
doi = {10.1038/nrn.2016.22},
eprint = {arXiv:1011.1669v3},
isbn = {doi:10.1038/nrn.2016.22},
month = {may},
number = {5},
pages = {307--321},
title = {{Neural correlates of consciousness: Progress and problems}},
url = {http://www.nature.com/articles/nrn.2016.22},
volume = {17},
year = {2016}
}
@article{Bradde2016,
abstract = {A system with many degrees of freedom can be characterized by a covariance matrix; principal components analysis (PCA) focuses on the eigenvalues of this matrix, hoping to find a lower dimensional description. But when the spectrum is nearly continuous, any distinction between components that we keep and those that we ignore becomes arbitrary; it then is natural to ask what happens as we vary this arbitrary cutoff. We argue that this problem is analogous to the momentum shell renormalization group (RG). Following this analogy, we can define relevant and irrelevant operators, where the role of dimensionality is played by properties of the eigenvalue density. These results also suggest an approach to the analysis of real data. As an example, we study neural activity in the vertebrate retina as it responds to naturalistic movies, and find evidence of behavior controlled by a nontrivial fixed point. Applied to financial data, our analysis separates modes dominated by sampling noise from a smaller but still macroscopic number of modes described by a non--Gaussian distribution.},
archivePrefix = {arXiv},
arxivId = {1610.09733},
author = {Bradde, Serena and Bialek, William},
eprint = {1610.09733},
file = {:home/kaslu/Documents/Mendeley/2016 - Bradde, Bialek - PCA meets RG.pdf:pdf},
month = {oct},
title = {{PCA meets RG}},
url = {http://arxiv.org/abs/1610.09733},
year = {2016}
}
@article{Iniguez2014,
abstract = {Honesty plays a crucial role in any situation where organisms exchange information or resources. Dishonesty can thus be expected to have damaging effects on social coherence if agents cannot trust the information or goods they receive. However, a distinction is often drawn between prosocial lies ('white' lies) and antisocial lying (i.e. deception for personal gain), with the former being considered much less destructive than the latter. We use an agent-based model to show that antisocial lying causes social networks to become increasingly fragmented. Antisocial dishonesty thus places strong constraints on the size and cohesion of social communities, providing a major hurdle that organisms have to overcome (e.g. by evolving counter-deception strategies) in order to evolve large, socially cohesive communities. In contrast, 'white' lies can prove to be beneficial in smoothing the flow of interactions and facilitating a larger, more integrated network. Our results demonstrate that these group-level effects can arise as emergent properties of interactions at the dyadic level. The balance between prosocial and antisocial lies may set constraints on the structure of social networks, and hence the shape of society as a whole.},
archivePrefix = {arXiv},
arxivId = {1406.0673},
author = {Iniguez, G. and Govezensky, Tzipe and Dunbar, Robin and Kaski, Kimmo and Barrio, Rafael A.},
doi = {10.1098/rspb.2014.1195},
eprint = {1406.0673},
file = {:home/kaslu/Documents/Mendeley/2014 - Iniguez et al. - Effects of deception in social networks.pdf:pdf},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {agent-based modeling,deception,social networks},
month = {jul},
number = {1790},
pages = {20141195--20141195},
pmid = {25056625},
title = {{Effects of deception in social networks}},
url = {http://arxiv.org/abs/1406.0673 http://dx.doi.org/10.1098/rspb.2014.1195 http://rspb.royalsocietypublishing.org/cgi/doi/10.1098/rspb.2014.1195},
volume = {281},
year = {2014}
}
@article{Neuro-humoral2012,
author = {PAPEZ, JAMES W.},
doi = {10.1001/archneurpsyc.1937.02260220069003},
issn = {0096-6754},
journal = {Archives of Neurology And Psychiatry},
month = {oct},
number = {4},
pages = {725},
title = {{A PROPOSED MECHANISM OF EMOTION}},
url = {http://archneurpsyc.jamanetwork.com/article.aspx?doi=10.1001/archneurpsyc.1937.02260220069003},
volume = {38},
year = {1937}
}
@article{Salisbury2016,
author = {Salisbury, Jared M and Palmer, Stephanie E},
doi = {10.1007/s10955-015-1439-y},
file = {:home/kaslu/Documents/Mendeley/2016 - Salisbury, Palmer - Optimal Prediction in the Retina and Natural Motion Statistics.pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Salisbury, Palmer - Optimal Prediction in the Retina and Natural Motion Statistics(2).pdf:pdf},
issn = {00224715},
journal = {Journal of Statistical Physics},
keywords = {Motion processing,Natural statistics,Neural computation,Prediction,Retina},
month = {mar},
number = {5},
pages = {1309--1323},
publisher = {Springer US},
title = {{Optimal Prediction in the Retina and Natural Motion Statistics}},
url = {http://link.springer.com/10.1007/s10955-015-1439-y},
volume = {162},
year = {2016}
}
@article{Holzwarth2016,
abstract = {Spin models are used in many studies of complex systems because they exhibit rich macroscopic behavior despite their microscopic simplicity. Here, we prove that all the physics of every classical spin model is reproduced in the low-energy sector of certain “universal models,” with at most polynomial overhead. This holds for classical models with discrete or continuous degrees of freedom.We prove necessary and sufficient conditions for a spin model to be universal and show that one of the simplest and most widely studied spin models, the two-dimensional Ising model with fields, is universal. Our results may facilitate physical simulations of Hamiltonians with complex interactions.},
archivePrefix = {arXiv},
arxivId = {1406.5955},
author = {{De las Cuevas}, Gemma and Cubitt, Toby S.},
doi = {10.1126/science.aab3326},
eprint = {1406.5955},
file = {:home/kaslu/Documents/Mendeley/2016 - De las Cuevas, Cubitt - Simple universal models capture all classical spin physics.pdf:pdf},
isbn = {9788578110796},
issn = {0036-8075},
journal = {Science},
keywords = {Holographic principle,Ising model,Phase transitions},
number = {6278},
pages = {1180--83},
pmid = {26965624},
title = {{Simple universal models capture all classical spin physics}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aab3326{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26965624},
volume = {351},
year = {2016}
}
@article{Tobergte2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Tobergte, David R. and Curtis, Shirley},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2013 - Tobergte, Curtis - Independent Component Analysis by Minimization of Mutual Information.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Independent Component Analysis by Minimization of Mutual Information}},
volume = {53},
year = {2013}
}
@article{Schelling1971,
abstract = {Somesegregation resultsfrom the practicesof organizations,somefrom specializedcommunication ffstems, somefrom correlation with a variable that is non-random; and some results from the interplayof individual choices.This is an abstract studyof the interactivedynamicsof discriminatory individualchoices.One model is a simulation in which individual members of two recognizable groups distribute themselves in neighborhoods defined by reference to their own locations. A second model is analytic and deals with compartmented space. A final section applies the analytics to 'neighborhood tipping.' The systemic effects are found to be overwhelming: there is no simple correspondence of individual incentive to collective results. Exaggerated separation and patterning resultfrom the dynamics of movement. Inferences about individual motives can usually not be drawn from aggregate patterns. Some unexpected phenomena, like density and vacancy, are generated. A general theory of 'tipping' begins to emerge. People},
archivePrefix = {arXiv},
arxivId = {00368075},
author = {Schelling, Thomas C.},
doi = {10.1080/0022250X.1971.9989794},
eprint = {00368075},
file = {:home/kaslu/Documents/Mendeley/1971 - Schelling - Dynamic models of segregation.pdf:pdf},
isbn = {0022-250X},
issn = {0022-250X},
journal = {The Journal of Mathematical Sociology},
month = {jul},
number = {2},
pages = {143--186},
pmid = {17746758},
title = {{Dynamic models of segregation}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0022250X.1971.9989794},
volume = {1},
year = {1971}
}
@article{Vanslette2016,
abstract = {Kolmogorov's first axiom of probability is probability takes values between 0 and 1; however, in Cox's derivation of probability having a maximum value of unity is arbitrary since he derives probability as a tool to rank degrees of plausibility. Probability can then be used to make inferences in instances of incomplete information, which is the foundation of Baysian probability theory. This article formulates a rule, which if obeyed, allows probability to take complex values and still be consistent with the interpretation of probability theory as being a tool to rank plausibility. It is then shown that Kirkwood distributions and the conditional complex probability distributions proposed by Hofmann do not obey this rule and therefore cannot rank plausibility. Not only do these quasiprobability distributions relax Kolmogorov's first axiom of probability, they also are void of the defining property of a probability distribution from a Coxian and Baysian perspective - they lack the ability to rank plausibility.},
archivePrefix = {arXiv},
arxivId = {1612.00494},
author = {Vanslette, Kevin},
eprint = {1612.00494},
month = {nov},
title = {{How Kirkwood and Probability Distributions Differ: A Coxian Perspective}},
url = {http://arxiv.org/abs/1612.00494},
year = {2016}
}
@article{Tsafrir2005,
abstract = {SUMMARY: We introduce a novel unsupervised approach for the organization and visualization of multidimensional data. At the heart of the method is a presentation of the full pairwise distance matrix of the data points, viewed in pseudocolor. The ordering of points is iteratively permuted in search of a linear ordering, which can be used to study embedded shapes. Several examples indicate how the shapes of certain structures in the data (elongated, circular and compact) manifest themselves visually in our permuted distance matrix. It is important to identify the elongated objects since they are often associated with a set of hidden variables, underlying continuous variation in the data. The problem of determining an optimal linear ordering is shown to be NP-Complete, and therefore an iterative search algorithm with O(n3) step-complexity is suggested. By using sorting points into neighborhoods, i.e. SPIN to analyze colon cancer expression data we were able to address the serious problem of sample heterogeneity, which hinders identification of metastasis related genes in our data. Our methodology brings to light the continuous variation of heterogeneity--starting with homogeneous tumor samples and gradually increasing the amount of another tissue. Ordering the samples according to their degree of contamination by unrelated tissue allows the separation of genes associated with irrelevant contamination from those related to cancer progression. AVAILABILITY: Software package will be available for academic users upon request.},
annote = {NULL},
author = {Tsafrir, D. and Tsafrir, I. and Ein-Dor, L. and Zuk, O. and Notterman, D.A. and Domany, E.},
doi = {10.1093/bioinformatics/bti329},
file = {:home/kaslu/Documents/Mendeley/2005 - Tsafrir et al. - Sorting points into neighborhoods (SPIN) data analysis and visualization by ordering distance matrices.pdf:pdf;:home/kaslu/Documents/Mendeley/2005 - Tsafrir et al. - Sorting points into neighborhoods (SPIN) data analysis and visualization by ordering distance matrices(2).pdf:pdf},
isbn = {1367-4803 (Print)},
issn = {1367-4803},
journal = {Bioinformatics},
month = {may},
number = {10},
pages = {2301--2308},
pmid = {15722375},
title = {{Sorting points into neighborhoods (SPIN): data analysis and visualization by ordering distance matrices}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bti329 https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bti329},
volume = {21},
year = {2005}
}
@article{Destexhe2006,
abstract = {Neuronal networks in vivo are characterized by considerable spontaneous activity, which is highly complex and intrinsically generated by a combination of single-cell electrophysiological properties and recurrent circuits. As seen, for example, during waking compared with being asleep or under anesthesia, neuronal responsiveness differs, concomitant with the pattern of spontaneous brain activity. This pattern, which defines the state of the network, has a dramatic influence on how local networks are engaged by inputs and, therefore, on how information is represented. We review here experimental and theoretical evidence of the decisive role played by stochastic network states in sensory responsiveness with emphasis on activated states such as waking. From single cells to networks, experiments and computational models have addressed the relation between neuronal responsiveness and the complex spatiotemporal patterns of network activity. The understanding of the relation between network state dynamics and information representation is a major challenge that will require developing, in conjunction, specific experimental paradigms and theoretical frameworks.},
author = {Destexhe, Alain and Contreras, Diego},
doi = {10.1126/science.1127241},
file = {:home/kaslu/Documents/Mendeley/2006 - Destexhe, Contreras - Neuronal Computations with Stochastic Network States.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Anesthesia,Attention,Computer Simulation,Evoked Potentials,Humans,Models,Neocortex,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Sleep,Sleep: physiology,Stochastic Processes,Synapses,Synapses: physiology,Wakefulness,Wakefulness: physiology},
month = {oct},
number = {5796},
pages = {85--90},
pmid = {17023650},
title = {{Neuronal Computations with Stochastic Network States}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17023650 http://www.sciencemag.org/cgi/doi/10.1126/science.1127241},
volume = {314},
year = {2006}
}
@article{Miyagawa2014,
abstract = {How human language arose is a mystery in the evolution of Homo sapiens. Miyagawa, Berwick, {\&} Okanoya (Frontiers 2013) put forward a proposal, which we will call the Integration Hypothesis of human language evolution, which holds that human language is composed of two components, E for expressive, and L for lexical. Each component has an antecedent in nature: E as found, for example, in birdsong, and L in, for example, the alarm calls of monkeys. E and L integrated uniquely in humans to give rise to language. A challenge to the Integration Hypothesis is that while these non-human systems are finite-state in nature, human language is known to require characterization by a non-finite state grammar. Our claim is that E and L, taken separately, are finite-state; when a grammatical process crosses the boundary between E and L, it gives rise to the non-finite state character of human language. We provide empirical evidence for the Integration Hypothesis by showing that certain processes found in contemporary languages that have been characterized as non-finite state in nature can in fact be shown to be finite-state. We also speculate on how human language actually arose in evolution through the lens of the Integration Hypothesis.},
author = {Miyagawa, Shigeru and Ojima, Shiro and Berwick, Robert C. and Okanoya, Kazuo},
doi = {10.3389/fpsyg.2014.00564},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Linguistics,agreement,biolinguistics,birdsong,language evolution,movement in language},
month = {jun},
pages = {564},
publisher = {Frontiers},
title = {{The integration hypothesis of human language evolution and the nature of contemporary languages}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2014.00564/abstract},
volume = {5},
year = {2014}
}
@article{Castellano2009,
abstract = {Statistical physics has proven to be a fruitful framework to describe phenomena outside the realm of traditional physics. Recent years have witnessed an attempt by physicists to study collective phenomena emerging from the interactions of individuals as elementary units in social structures. A wide list of topics are reviewed ranging from opinion and cultural and language dynamics to crowd behavior, hierarchy formation, human dynamics, and social spreading. The connections between these problems and other, more traditional, topics of statistical physics are highlighted. Comparison of model results with empirical data from social systems are also emphasized.},
archivePrefix = {arXiv},
arxivId = {0710.3256},
author = {Castellano, Claudio and Fortunato, Santo and Loreto, Vittorio},
doi = {10.1103/RevModPhys.81.591},
eprint = {0710.3256},
file = {:home/kaslu/Documents/Mendeley/2009 - Castellano, Fortunato, Loreto - Statistical physics of social dynamics.pdf:pdf},
isbn = {0034-6861},
issn = {00346861},
journal = {Reviews of Modern Physics},
number = {2},
pages = {591--646},
pmid = {267197500005},
title = {{Statistical physics of social dynamics}},
volume = {81},
year = {2009}
}
@article{Smaldino2015,
abstract = {Many social phenomena do not result solely from intentional actions by isolated individuals, but rather emerge as the result of repeated interactions among multiple individuals over time. However, such phenomena are often poorly captured by traditional empirical techniques. Moreover, complex adaptive systems are insufficiently described by verbal models. In this paper, we discuss how organizational psychologists and group dynamics researchers may benefit from the adoption of formal modeling, particularly agent-based modeling, for developing and testing richer theories. Agent-based modeling is well suited to capture multilevel dynamic processes and offers superior precision to verbal models. As an example, we present a model on social identity dynamics used to test the predictions of Brewer's (1991) optimal distinctiveness theory, and dis-cuss how the model extends the theory and produces novel research questions. We close with a general discussion on theory development using agent-based models. A mathematical theory may be regarded as a kind of scaffolding within which a reasonably secure theory expressible in words may be built up. . . . Without such a scaffolding verbal arguments are insecure.},
author = {Smaldino, Paul E. and Calanchini, Jimmy and Pickett, Cynthia L.},
doi = {10.1177/2041386614546944},
isbn = {2041386614},
issn = {2041-3866},
journal = {Organizational Psychology Review},
keywords = {agent-based modeling,formal models,group dynamics,optimal distinctiveness,social identity},
number = {4},
pages = {300--317},
title = {{Theory development with agent-based models}},
url = {http://opr.sagepub.com/lookup/doi/10.1177/2041386614546944},
volume = {5},
year = {2015}
}
@article{Radicchi2016,
abstract = {Two very important problems regarding spreading phenomena in complex topologies are the optimal selection of node sets either to minimize or maximize the extent of outbreaks. Both problems are nontrivial when a small fraction of the nodes in the network can be used to achieve the desired goal. The minimization problem is equivalent to a structural optimization. The "superblockers", i.e., the nodes that should be removed from the network to minimize the size of outbreaks, are those nodes that make connected components as small as possible. "Superspreaders" are instead the nodes such that, if chosen as initiators, they maximize the average size of outbreaks. The identity of superspreaders is expected to depend not just on the topology, but also on the specific dynamics considered. Recently, it has been conjectured that the two optimization problems might be equivalent, in the sense that superblockers act also as superspreaders. In spite of its potential groundbreaking importance, no empirical study has been performed to validate this conjecture. In this paper, we perform an extensive analysis over a large set of real-world networks to test the similarity between sets of superblockers and of superspreaders. We show that the two optimization problems are not equivalent: superblockers do not act as optimal spreaders.},
archivePrefix = {arXiv},
arxivId = {1610.02908},
author = {Radicchi, Filippo and Castellano, Claudio},
doi = {10.1103/PhysRevE.95.012318},
eprint = {1610.02908},
issn = {2470-0045},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {012318},
publisher = {American Physical Society},
title = {{Fundamental difference between superblockers and superspreaders in networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.95.012318 http://arxiv.org/abs/1610.02908},
volume = {95},
year = {2016}
}
@article{Friston2010a,
abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception.},
author = {Friston, Karl and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J.},
doi = {10.1007/s00422-010-0364-z},
file = {:home/kaslu/Documents/Mendeley/2010 - Friston et al. - Action and behavior A free-energy formulation.pdf:pdf},
isbn = {1432-0770 (Electronic)$\backslash$n0340-1200 (Linking)},
issn = {03401200},
journal = {Biological Cybernetics},
keywords = {Bayesian,Computational,Control,Hierarchical,Motor,Priors},
number = {3},
pages = {227--260},
pmid = {20148260},
title = {{Action and behavior: A free-energy formulation}},
volume = {102},
year = {2010}
}
@inproceedings{Nawaz2016,
abstract = {Entropic dynamics is a framework in which quantum theory is derived as an application of entropic methods of inference. Entropic dynamics on flat spaces has been extensively studied. The objective of this paper is to extend the entropic dynamics of {\$}N{\$} particles to curved spaces. The important new feature is that the displacement of a particle does not transform like a vector because fluctuations can be large enough to feel the effects of curvature. The final result is a modified Schr$\backslash$"odinger equation in which the usual Laplacian is replaced by the Laplace-Beltrami operator.},
archivePrefix = {arXiv},
arxivId = {arXiv:1601.01708v1},
author = {Nawaz, Shahid and Abedi, Mohammad and Caticha, Ariel},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.4959053},
eprint = {arXiv:1601.01708v1},
file = {:home/kaslu/Documents/Mendeley/2016 - Nawaz, Abedi, Caticha - Entropic dynamics on curved spaces.pdf:pdf},
isbn = {9780735414150},
issn = {15517616},
keywords = {Entropic Dynamics,Information Geometry,Quantum Theory,Riemannian Manifold},
month = {jan},
title = {{Entropic dynamics on curved spaces}},
url = {http://arxiv.org/abs/1601.01708},
volume = {1757},
year = {2016}
}
@article{Itthipuripat2014,
author = {Itthipuripat, Sirawaj and Ester, E. F. and Deering, S. and Serences, John T.},
doi = {10.1523/JNEUROSCI.2277-14.2014},
file = {:home/kaslu/Documents/Mendeley/2014 - Itthipuripat et al. - Sensory Gain Outperforms Efficient Readout Mechanisms in Predicting Attention-Related Improvements in Behav.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {attention,contrast discrimination,contrast response function,eeg,efficient readout,sensory gain},
number = {40},
pages = {13384--13398},
title = {{Sensory Gain Outperforms Efficient Readout Mechanisms in Predicting Attention-Related Improvements in Behavior}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2277-14.2014},
volume = {34},
year = {2014}
}
@article{Caticha2007a,
abstract = {We propose and analyze two different Bayesian online algorithms for learning in discrete Hidden Markov Models and compare their performance with the already known Baldi-Chauvin Algorithm. Using the Kullback-Leibler divergence as a measure of generalization we draw learning curves in simplified situations for these algorithms and compare their performances.},
author = {Caticha, Nestor and Alamino, Roberto},
doi = {10.3934/dcdsb.2008.9.1},
issn = {1531-3492},
journal = {Discrete and Continuous Dynamical Systems - Series B},
keywords = {artificial intelligence,computer science},
month = {oct},
number = {1},
pages = {1--10},
title = {{Bayesian online algorithms for learning in discrete hidden Markov models}},
url = {http://www.aimsciences.org/journals/displayArticles.jsp?paperID=2980 http://eprints.aston.ac.uk/7248/},
volume = {9},
year = {2007}
}
@article{Greenberg2008a,
author = {Greenberg, Jeff and Kosloff, Spee},
doi = {10.1111/j.1751-9004.2008.00144.x},
file = {:home/kaslu/Documents/Mendeley/2008 - Greenberg, Kosloff - Terror Management Theory Implications for Understanding Prejudice, Stereotyping, Intergroup Conflict, and Po.pdf:pdf},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
keywords = {social},
mendeley-tags = {social},
month = {sep},
number = {5},
pages = {1881--1894},
title = {{Terror Management Theory: Implications for Understanding Prejudice, Stereotyping, Intergroup Conflict, and Political Attitudes}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00144.x},
volume = {2},
year = {2008}
}
@article{Deneve1999,
abstract = {Many sensory and motor variables are encoded in the nervous system by the activities of large populations of neurons with bell-shaped tuning curves. Extracting information from these population codes is difficult because of the noise inherent in neuronal responses. In most cases of interest, maximum likelihood (ML) is the best read-out method and would be used by an ideal observer. Using simulations and analysis, we show that a close approximation to ML can be implemented in a biologically plausible model of cortical circuitry. Our results apply to a wide range of nonlinear activation functions, suggesting that cortical areas may, in general, function as ideal observers of activity in preceding areas.},
author = {Den{\`{e}}ve, Sophie and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/11205},
file = {:home/kaslu/Documents/Mendeley/1999 - Den{\`{e}}ve, Latham, Pouget - Reading population codes a neural implementation of ideal observers.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Brain Mapping,Computer Simulation,Likelihood Functions,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Normal Distribution,Poisson Distribution,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
number = {8},
pages = {740--5},
pmid = {10412064},
title = {{Reading population codes: a neural implementation of ideal observers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10412064},
volume = {2},
year = {1999}
}
@article{Doya2008,
abstract = {Human and animal decisions are modulated by a variety of environmental and intrinsic contexts. Here I consider computational factors that can affect decision making and review anatomical structures and neurochemical systems that are related to contextual modulation of decision making. Expectation of a high reward can motivate a subject to go for an action despite a large cost, a decision that is influenced by dopamine in the anterior cingulate cortex. Uncertainty of action outcomes can promote risk taking and exploratory choices, in which norepinephrine and the orbitofrontal cortex appear to be involved. Predictable environments should facilitate consideration of longer-delayed rewards, which depends on serotonin in the dorsal striatum and dorsal prefrontal cortex. This article aims to sort out factors that affect the process of decision making from the viewpoint of reinforcement learning theory and to bridge between such computational needs and their neurophysiological substrates.},
author = {Doya, Kenji},
doi = {nn2077 [pii]\r10.1038/nn2077},
file = {:home/kaslu/Documents/Mendeley/2008 - Doya - Modulators of decision making.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nat Neurosci},
keywords = {*Computational Biology,*Decision Making,*Models,*Probability Learning,Algorithms,Animals,Environment,Gyrus Cinguli/*physiology,Humans,Models,Neurological,Neurotransmitter Agents/physiology,Psychological,Reward},
number = {4},
pages = {410--416},
pmid = {18368048},
title = {{Modulators of decision making}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}db=PubMed{\&}dopt=Citation{\&}list{\_}uids=18368048},
volume = {11},
year = {2008}
}
@article{Caticha2010,
abstract = {Moral Foundation Theory states that groups of different observers may rely on partially dissimilar sets of moral foundations, thereby reaching different moral valuations. The use of functional imaging techniques has revealed a spectrum of cognitive styles with respect to the differential handling of novel or corroborating information that is correlated to political affiliation. Here we characterize the collective behavior of an agent-based model whose inter individual interactions due to information exchange in the form of opinions are in qualitative agreement with experimental neuroscience data. The main conclusion derived connects the existence of diversity in the cognitive strategies and statistics of the sets of moral foundations and suggests that this connection arises from interactions between agents. Thus a simple interacting agent model, whose interactions are in accord with empirical data on conformity and learning processes, presents statistical signatures consistent with moral judgment patterns of conservatives and liberals as obtained by survey studies of social psychology.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1005.5718},
author = {Caticha, Nestor and Vicente, Renato},
doi = {10.1142/S0219525911003190},
eprint = {1005.5718},
file = {:home/kaslu/Documents/Mendeley/2011 - Caticha, Vicente - Agent-based Social Psychology From Neurocognitive processes to Social data(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2011 - Caticha, Vicente - Agent-based Social Psychology From Neurocognitive processes to Social data.pdf:pdf},
isbn = {0219-5259},
issn = {0219-5259},
journal = {Advances in Complex Systems},
month = {oct},
number = {05},
pages = {711--731},
title = {{Agent-based Social Psychology: From Neurocognitive processes to Social data}},
url = {http://arxiv.org/abs/1005.5718 http://www.worldscientific.com/doi/abs/10.1142/S0219525911003190},
volume = {14},
year = {2011}
}
@article{Alves2015Higgs,
abstract = {A successful connection between Higgs boson decays and the Maximum Entropy Principle is presented. Based on the information theory inference approach we determine the Higgs boson mass as {\$}M{\_}H= 125.04\backslashpm 0.25{\$} GeV, a value fully compatible to the LHC measurement. This is straightforwardly obtained by taking the Higgs boson branching ratios as the target probability distributions of the inference, without any extra assumptions beyond the Standard Model. Yet, the principle can be a powerful tool in the construction of any model affecting the Higgs sector. We give, as an example, the case where the Higgs boson has an extra invisible decay channel. Our findings suggest that a system of Higgs bosons undergoing a collective decay to Standard Model particles is among the most fundamental ones where the Maximum Entropy Principle applies.},
archivePrefix = {arXiv},
arxivId = {1408.0827},
author = {Alves, Alexandre and Dias, Alex G. and da Silva, Roberto},
doi = {10.1016/j.physa.2014.10.084},
eprint = {1408.0827},
file = {:home/kaslu/Documents/Mendeley/2015 - Alves, Dias, da Silva - Maximum Entropy Principle and the Higgs boson mass.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
month = {feb},
pages = {1--7},
title = {{Maximum Entropy Principle and the Higgs boson mass}},
url = {http://arxiv.org/abs/1408.0827 http://dx.doi.org/10.1016/j.physa.2014.10.084 http://linkinghub.elsevier.com/retrieve/pii/S037843711400939X},
volume = {420},
year = {2015}
}
@article{VonToussaint2011,
abstract = {Bayesian inference provides a consistent method for the extraction of information from physics experiments even in ill-conditioned circumstances. The approach provides a unified rationale for data analysis, which both justifies many of the commonly used analysis procedures and reveals some of the implicit underlying assumptions. This review summarizes the general ideas of the Bayesian probability theory with emphasis on the application to the evaluation of experimental data. As case studies for Bayesian parameter estimation techniques examples ranging from extra-solar planet detection to the deconvolution of the apparatus functions for improving the energy resolution and change point estimation in time series are discussed. Special attention is paid to the numerical techniques suited for Bayesian analysis, with a focus on recent developments of Markov chain Monte Carlo algorithms for high-dimensional integration problems. Bayesian model comparison, the quantitative ranking of models for the explanation of a given data set, is illustrated with examples collected from cosmology, mass spectroscopy, and surface physics, covering problems such as background subtraction and automated outlier detection. Additionally the Bayesian inference techniques for the design and optimization of future experiments are introduced. Experiments, instead of being merely passive recording devices, can now be designed to adapt to measured data and to change the measurement strategy on the fly to maximize the information of an experiment. The applied key concepts and necessary numerical tools which provide the means of designing such inference chains and the crucial aspects of data fusion are summarized and some of the expected implications are highlighted.},
author = {von Toussaint, Udo},
doi = {10.1103/RevModPhys.83.943},
file = {:home/kaslu/Documents/Mendeley/2011 - von Toussaint - Bayesian inference in physics.pdf:pdf},
isbn = {0034-6861$\backslash$n1539-0756},
issn = {0034-6861},
journal = {Reviews of Modern Physics},
month = {sep},
number = {3},
pages = {943--999},
publisher = {American Physical Society},
title = {{Bayesian inference in physics}},
url = {http://link.aps.org/doi/10.1103/RevModPhys.83.943},
volume = {83},
year = {2011}
}
@article{Dyble2015a,
abstract = {The social organization of mobile hunter-gatherers has several derived features, including low within-camp relatedness and fluid meta-groups. Although these features have been proposed to have provided the selective context for the evolution of human hypercooperation and cumulative culture, how such a distinctive social system may have emerged remains unclear. We present an agent-based model suggesting that, even if all individuals in a community seek to live with as many kin as possible, within-camp relatedness is reduced if men and women have equal influence in selecting camp members. Our model closely approximates observed patterns of co-residence among Agta and Mbendjele BaYaka hunter-gatherers. Our results suggest that pair-bonding and increased sex egalitarianism in human evolutionary history may have had a transformative effect on human social organization.},
author = {Dyble, M. and Salali, G. D. and Chaudhary, N. and Page, A. and Smith, D. and Thompson, J. and Vinicius, L. and Mace, R. and Migliano, A. B.},
doi = {10.1126/science.aaa5139},
file = {:home/kaslu/Documents/Mendeley/2015 - Dyble et al. - Sex equality can explain the unique social structure of hunter-gatherer bands.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
month = {may},
number = {6236},
pages = {796--798},
pmid = {25977551},
title = {{Sex equality can explain the unique social structure of hunter-gatherer bands}},
url = {http://www.sciencemag.org/content/348/6236/796.abstract http://www.sciencemag.org/cgi/doi/10.1126/science.aaa5139},
volume = {348},
year = {2015}
}
@inproceedings{Caticha2006,
abstract = {We show that Skilling's method of induction leads to a unique general theory of inductive inference, the method of Maximum relative Entropy (ME). The main tool for updating probabilities is the logarithmic relative entropy; other entropies such as those of Renyi or Tsallis are ruled out. We also show that Bayes updating is a special case of ME updating and thus, that the two are completely compatible.},
archivePrefix = {arXiv},
arxivId = {physics/0608185},
author = {Caticha, Ariel and Giffin, Adom},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.2423258},
eprint = {0608185},
file = {:home/kaslu/Documents/Mendeley/2006 - Caticha, Giffin - Updating Probabilities.pdf:pdf},
issn = {0094243X},
month = {aug},
pages = {31--42},
primaryClass = {physics},
publisher = {AIP},
title = {{Updating Probabilities}},
url = {http://arxiv.org/abs/physics/0608185 http://aip.scitation.org/doi/abs/10.1063/1.2423258},
volume = {872},
year = {2006}
}
@article{Birkhead2017,
abstract = {In this article, we investigate whether it is appropriate to generalize about the ideological and demographic characteristics of American party activists. Many studies on party polarization emphasize the role of activists in encouraging the divisions within the parties, and in so doing, commonly treat activists as a homogeneous group. Here, we show that different forms of political activity attract systematically different types of individuals. Similarly, we show that ideological extremism is more strongly associated with some forms of activism than others. Importantly, we find that extremism is most strongly associated with the forms of activity that are most likely to influence elected officials through the provision of resources, information or support in a nomination. Thus, while our findings broadly support the notion that extremists are more engaged than moderates, we challenge the consensus that the various forms of activism are interchangeable.},
author = {Birkhead, Nathaniel A and Hershey, Marjorie Randon},
doi = {10.1177/1354068817730721},
issn = {1354-0688},
journal = {Party Politics},
keywords = {ideological extremism,party activists,party polarization,political participation,political parties},
number = {March},
pages = {135406881773072},
title = {{Assessing the ideological extremism of American party activists}},
url = {http://journals.sagepub.com/doi/10.1177/1354068817730721},
year = {2017}
}
@article{Kumar2016,
abstract = {Given that many fundamental questions in neuroscience are still open, it seems pertinent to explore whether the brain might use other physical modalities than the ones that have been discovered so far. In particular it is well established that neurons can emit photons, which prompts the question whether these biophotons could serve as signals between neurons, in addition to the well-known electro-chemical signals. For such communication to be targeted, the photons would need to travel in waveguides. Here we show, based on detailed theoretical modeling, that myelinated axons could serve as photonic waveguides, taking into account realistic optical imperfections. We propose experiments, both in vivo and in vitro, to test our hypothesis. We discuss the implications of our results, including the question whether photons could mediate long-range quantum entanglement in the brain.},
archivePrefix = {arXiv},
arxivId = {1607.02969},
author = {Kumar, Sourabh and Boone, Kristine and Tuszy{\'{n}}ski, Jack and Barclay, Paul and Simon, Christoph},
doi = {10.1038/srep36508},
eprint = {1607.02969},
file = {:home/kaslu/Documents/Mendeley/2016 - Kumar et al. - Possible existence of optical communication channels in the brain.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {36508},
pmid = {27819310},
title = {{Possible existence of optical communication channels in the brain}},
url = {http://www.nature.com/articles/srep36508},
volume = {6},
year = {2016}
}
@article{QuianQuiroga2009,
abstract = {To a large extent, progress in neuroscience has been driven by the study of single-cell responses averaged over several repetitions of stimuli or behaviours. However,the brain typically makes decisions based on single events by evaluating the activity of large neuronal populations. Therefore, to further understand how the brain processes information, it is important to shift from a single-neuron, multiple-trial framework to multiple-neuron, single-trial methodologies. Two related approaches--decoding and information theory--can be used to extract single-trial information from the activity of neuronal populations. Such population analysis can give us more information about how neurons encode stimulus features than traditional single-cell studies.},
archivePrefix = {arXiv},
arxivId = {10.1126/science.aab3050},
author = {{Quian Quiroga}, Rodrigo and Panzeri, Stefano},
doi = {10.1038/nrn2578},
eprint = {science.aab3050},
file = {:home/kaslu/Documents/Mendeley/2009 - Quian Quiroga, Panzeri - Extracting information from neuronal populations Information theory and decoding approaches.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
number = {3},
pages = {173--185},
pmid = {19229240},
primaryClass = {10.1126},
title = {{Extracting information from neuronal populations: Information theory and decoding approaches}},
volume = {10},
year = {2009}
}
@article{Schuck2016,
abstract = {Although the orbitofrontal cortex (OFC) has been studied intensely for decades, its precise functions have remained elusive. We recently hypothesized that the OFC contains a ''cognitive map'' of task space in which the current state of the task is repre-sented, and this representation is especially critical for behavior when states are unobservable from sensory input. To test this idea, we apply pattern-classification techniques to neuroimaging data from humans performing a decision-making task with 16 states. We show that unobservable task states can be decoded from activity in OFC, and decoding accuracy is related to task performance and the occurrence of individual behavioral errors. Moreover, similarity between the neural representations of consecutive states correlates with behavioral accu-racy in corresponding state transitions. These results support the idea that OFC represents a cognitive map of task space and establish the feasibility of decoding state representations in humans using non-invasive neuroimaging.},
author = {Schuck, Nicolas W and Wilson, Robert C and Cai, Ming Bo and Niv, Yael},
doi = {10.1016/j.neuron.2016.08.019},
file = {:home/kaslu/Documents/Mendeley/2016 - Schuck et al. - Human Orbitofrontal Cortex Represents a Cognitive Map of State Space.pdf:pdf},
journal = {Neuron},
pages = {1402--1412},
title = {{Human Orbitofrontal Cortex Represents a Cognitive Map of State Space}},
volume = {91},
year = {2016}
}
@article{Oizumi2016,
abstract = {We propose a unified theoretical framework for quantifying spatio-temporal interactions in a stochastic dynamical system based on information geometry. In the proposed framework, the degree of interactions is quantified by the divergence between the actual probability distribution of the system and a constrained probability distribution where the interactions of interest are disconnected. This framework provides novel geometric interpretations of various information theoretic measures of interactions, such as mutual information, transfer entropy, and stochastic interaction in terms of how interactions are disconnected. The framework therefore provides an intuitive understanding of the relationships between the various quantities. By extending the concept of transfer entropy, we propose a novel measure of integrated information which measures causal interactions between parts of a system. Integrated information quantifies the extent to which the whole is more than the sum of the parts and can be potentially used as a biological measure of the levels of consciousness.},
archivePrefix = {arXiv},
arxivId = {1510.04455},
author = {Oizumi, Masafumi and Tsuchiya, Naotsugu and Amari, Shun-ichi},
doi = {10.1073/pnas.1603583113},
eprint = {1510.04455},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {dec},
number = {51},
pages = {14817--14822},
pmid = {27930289},
title = {{Unified framework for information integration based on information geometry}},
url = {http://arxiv.org/abs/1510.04455{\%}0Ahttp://dx.doi.org/10.1073/pnas.1603583113 http://www.pnas.org/lookup/doi/10.1073/pnas.1603583113},
volume = {113},
year = {2016}
}
@article{Snoek2011,
abstract = {Unsupervised discovery of latent representations, in addition to being useful for density modeling, visualisation and exploratory data analysis, is also increasingly important for learning features relevant to discriminative tasks. Autoencoders, in particular, have proven to be an effective way to learn latent codes that reflect meaningful variations in data. A continuing challenge, however, is guiding an autoencoder toward representations that are useful for particular tasks. A complementary challenge is to find codes that are invariant to irrelevant transformations of the data. The most common way of introducing such problem-specific guidance in autoencoders has been through the incorporation of a parametric component that ties the latent representation to the label information. In this work, we argue that a preferable approach relies instead on a nonparametric guidance mechanism. Conceptually, it ensures that there exists a function that can predict the label information, without explicitly instantiating that function. The superiority of this guidance mechanism is confirmed on two datasets. In particular, this approach is able to incorporate invariance information (lighting, elevation, etc.) from the small NORB object recognition dataset and yields state-of-the-art performance for a single layer, non-convolutional network.},
archivePrefix = {arXiv},
arxivId = {1102.1492},
author = {Snoek, Jasper and Adams, Ryan Prescott and Larochelle, Hugo},
eprint = {1102.1492},
file = {:home/kaslu/Documents/Mendeley/2011 - Snoek, Adams, Larochelle - On Nonparametric Guidance for Learning Autoencoder Representations.pdf:pdf},
month = {feb},
pages = {9},
title = {{On Nonparametric Guidance for Learning Autoencoder Representations}},
url = {http://arxiv.org/abs/1102.1492},
year = {2011}
}
@article{Bartolotta2015,
abstract = {We derive a generalization of the Second Law of Thermodynamics that uses Bayesian updates to explicitly incorporate the effects of a measurement of a system at some point in its evolution. By allowing an experimenter's knowledge to be updated by the measurement process, this formulation resolves a tension between the fact that the entropy of a statistical system can sometimes fluctuate downward and the information-theoretic idea that knowledge of a stochastically-evolving system degrades over time. The Bayesian Second Law can be written as {\$}\backslashDelta H(\backslashrho{\_}m, \backslashrho) + \backslashlangle \backslashmathcal{\{}Q{\}}\backslashrangle{\_}{\{}F|m{\}}\backslashgeq 0{\$}, where {\$}\backslashDelta H(\backslashrho{\_}m, \backslashrho){\$} is the change in the cross entropy between the original phase-space probability distribution {\$}\backslashrho{\$} and the measurement-updated distribution {\$}\backslashrho{\_}m{\$}, and {\$}\backslashlangle \backslashmathcal{\{}Q{\}}\backslashrangle{\_}{\{}F|m{\}}{\$} is the expectation value of a generalized heat flow out of the system. We also derive refined versions of the Second Law that bound the entropy increase from below by a non-negative number, as well as Bayesian versions of the Jarzynski equality. We demonstrate the formalism using simple analytical and numerical examples.},
archivePrefix = {arXiv},
arxivId = {1508.02421},
author = {Bartolotta, Anthony and Carroll, Sean M. and Leichenauer, Stefan and Pollack, Jason},
doi = {10.1103/PhysRevE.94.022102},
eprint = {1508.02421},
file = {:home/kaslu/Documents/Mendeley/2016 - Bartolotta et al. - Bayesian second law of thermodynamics.pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Bartolotta et al. - Bayesian second law of thermodynamics(2).pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {aug},
number = {2},
pages = {022102},
title = {{Bayesian second law of thermodynamics}},
url = {http://arxiv.org/abs/1508.02421 http://dx.doi.org/10.1103/PhysRevE.94.022102 http://link.aps.org/doi/10.1103/PhysRevE.94.022102},
volume = {94},
year = {2016}
}
@article{Starkweather2017,
abstract = {Midbrain dopamine neurons signal reward prediction error (RPE), or actual minus expected reward. The temporal difference (TD) learning model has been a cornerstone in understanding how dopamine RPEs could drive associative learning. Classically, TD learning imparts value to features that serially track elapsed time relative to observable stimuli. In the real world, however, sensory stimuli provide ambiguous information about the hidden state of the environment, leading to the proposal that TD learning might instead compute a value signal based on an inferred distribution of hidden states (a 'belief state'). Here we asked whether dopaminergic signaling supports a TD learning framework that operates over hidden states. We found that dopamine signaling showed a notable difference between two tasks that differed only with respect to whether reward was delivered in a deterministic manner. Our results favor an associative learning rule that combines cached values with hidden-state inference.},
author = {Starkweather, Clara Kwon and Babayan, Benedicte M. and Uchida, Naoshige and Gershman, Samuel J.},
doi = {10.1038/nn.4520},
file = {:home/kaslu/Documents/Mendeley/2017 - Starkweather et al. - Dopamine reward prediction errors reflect hidden-state inference across time.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {mar},
number = {4},
pages = {581--589},
pmid = {28263301},
title = {{Dopamine reward prediction errors reflect hidden-state inference across time}},
url = {http://www.nature.com/doifinder/10.1038/nn.4520},
volume = {20},
year = {2017}
}
@article{Stachenfeld2016,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Stachenfeld, Kimberly L. and Botvinick, Matthew M. and Gershman, Samuel J.},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2016 - Stachenfeld, Botvinick, Gershman - Hippocampus as predictive map.pdf:pdf},
isbn = {9788578110796},
issn = {09953914},
journal = {bioRxiv},
keywords = {Burkina Faso,Delivery of health care,Motivation,Patient preference,Rural health services,Treatment refusal},
number = {3},
pages = {391--397},
pmid = {25246403},
publisher = {Nature Publishing Group},
title = {{Hippocampus as predictive map}},
url = {http://dx.doi.org/10.1038/nn.4650},
volume = {28},
year = {2016}
}
@article{Tsafrir2005b,
author = {Tsafrir, D. and Tsafrir, I. and Ein-Dor, L. and Zuk, O. and Notterman, D.A. A. and Domany, E.},
file = {:home/kaslu/Documents/Mendeley/2005 - Tsafrir et al. - Sorting points into neighborhoods (SPIN) Data analysis and visualization by ordering distance matrices SUPPLEMEN.pdf:pdf},
journal = {Bioinformatics},
number = {10},
pages = {Supp},
title = {{Sorting points into neighborhoods (SPIN): Data analysis and visualization by ordering distance matrices SUPPLEMENTARY MATERIAL}},
volume = {21},
year = {2005}
}
@article{Broido2018,
abstract = {A central claim in modern network science is that real-world networks are typically "scale free," meaning that the fraction of nodes with degree {\$}k{\$} follows a power law, decaying like {\$}k{\^{}}{\{}-\backslashalpha{\}}{\$}, often with {\$}2 {\textless} \backslashalpha {\textless} 3{\$}. However, empirical evidence for this belief derives from a relatively small number of real-world networks. We test the universality of scale-free structure by applying state-of-the-art statistical tools to a large corpus of nearly 1000 network data sets drawn from social, biological, technological, and informational sources. We fit the power-law model to each degree distribution, test its statistical plausibility, and compare it via a likelihood ratio test to alternative, non-scale-free models, e.g., the log-normal. Across domains, we find that scale-free networks are rare, with only 4{\%} exhibiting the strongest-possible evidence of scale-free structure and 52{\%} exhibiting the weakest-possible evidence. Furthermore, evidence of scale-free structure is not uniformly distributed across sources: social networks are at best weakly scale free, while a handful of technological and biological networks can be called strongly scale free. These results undermine the universality of scale-free networks and reveal that real-world networks exhibit a rich structural diversity that will likely require new ideas and mechanisms to explain.},
archivePrefix = {arXiv},
arxivId = {1801.03400},
author = {Broido, Anna D. and Clauset, Aaron},
eprint = {1801.03400},
file = {:home/kaslu/Documents/Mendeley/2018 - Broido, Clauset - Scale-free networks are rare.pdf:pdf},
month = {jan},
title = {{Scale-free networks are rare}},
url = {http://arxiv.org/abs/1801.03400},
year = {2018}
}
@article{Schelling2010,
author = {Luzzi, Roberto and Mesquita, Marcus V. and Madureira, Justino R.},
doi = {10.1080/0022250X.2001.9990250},
file = {:home/kaslu/Documents/Mendeley/2001 - Luzzi, Mesquita, Madureira - An information‐theoretic‐based (MaxEnt) approach to social dynamical systems.pdf:pdf},
isbn = {0022250050},
issn = {0022-250X},
journal = {The Journal of Mathematical Sociology},
month = {jun},
number = {2},
pages = {179--224},
title = {{An information‐theoretic‐based (MaxEnt) approach to social dynamical systems}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0022250X.2001.9990250},
volume = {25},
year = {2001}
}
@article{Lin2016a,
abstract = {We show that in many data sequences - from texts in different languages to melodies and genomes - the mutual information between two symbols decays roughly like a power law with the number of symbols in between the two. In contrast, we prove that Markov/hidden Markov processes generically exhibit exponential decay in their mutual information, which explains why natural languages are poorly approximated by Markov processes. We present a broad class of models that naturally reproduce this critical behavior. They all involve deep dynamics of a recursive nature, as can be approximately implemented by tree-like or recurrent deep neural networks. This model class captures the essence of probabilistic context-free grammars as well as recursive self-reproduction in physical phenomena such as turbulence and cosmological inflation. We derive an analytic formula for the asymptotic power law and elucidate our results in a statistical physics context: 1-dimensional "shallow" models (such as Markov models or regular grammars) will fail to model natural language, because they cannot exhibit criticality, whereas "deep" models with one or more "hidden" dimensions representing levels of abstraction or scale can potentially succeed.},
archivePrefix = {arXiv},
arxivId = {1606.06737},
author = {Lin, Henry W. and Tegmark, Max},
eprint = {1606.06737},
month = {jun},
pages = {17},
title = {{Critical Behavior from Deep Dynamics: A Hidden Dimension in Natural Language}},
url = {http://arxiv.org/abs/1606.06737},
year = {2016}
}
@article{Davis2012,
abstract = {For a continuous maximum-entropy distribution (obtained from an arbitrary number of simultaneous constraints), we derive a general relation connecting the Lagrange multipliers and the expectation values of certain particularly constructed functions of the states of the system. From this relation, an estimator for a given Lagrange multiplier can be constructed from derivatives of the corresponding constraining function. These estimators sometimes lead to the determination of the Lagrange multipliers by way of solving a linear system, and, in general, they provide another tool to widen the applicability of Jaynes's formalism. This general relation, especially well suited for computer simulation techniques, also provides some insight into the interpretation of the hypervirial relations known in statistical mechanics and the recently derived microcanonical dynamical temperature. We illustrate the usefulness of these new relations with several applications in statistics.},
author = {Davis, Sergio and Guti{\'{e}}rrez, Gonzalo},
doi = {10.1103/PhysRevE.86.051136},
file = {:home/kaslu/Documents/Mendeley/2012 - Davis, Guti{\'{e}}rrez - Conjugate variables in continuous maximum-entropy inference.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
month = {nov},
number = {5},
pages = {051136},
title = {{Conjugate variables in continuous maximum-entropy inference}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.86.051136},
volume = {86},
year = {2012}
}
@article{Rodriguez2010,
abstract = {The use of {\{}$\backslash$it dyadic interaction{\}} between agents, in combination with {\{}$\backslash$it homophily{\}} (the principle that ``likes attract'') in the Axelrod model for the study of cultural dissemination has two important problems: the prediction of monoculture in large societies and an extremely narrow window of noise levels in which diversity with local convergence is obtained. Recently, the inclusion of {\{}$\backslash$it social influence{\}} has proven to overcome them (A. Flache and M. W. Macey, arXiv:0808.2710). Here we extend the Axelrod model with social influence interaction for the study of Mass Media effects through the inclusion of a super-agent which acts over the whole system and has nonnull overlap with each agent of the society. The dependence with different parameters as the initial social diversity, size effects, Mass Media strength and noise is outlined. Our results might be relevant in several socio-economic contexts and for the study of the emergence of collective behavior in complex social systems.},
archivePrefix = {arXiv},
arxivId = {1002.4615},
author = {Rodr{\'{i}}guez, Arezky H. and Moreno, Y.},
doi = {10.1103/PhysRevE.82.016111},
eprint = {1002.4615},
file = {:home/kaslu/Documents/Mendeley/2010 - Rodr{\'{i}}guez, Moreno - Effects of Mass Media action on the Axelrod Model with Social Influence.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
month = {feb},
number = {1},
pages = {016111},
title = {{Effects of Mass Media action on the Axelrod Model with Social Influence}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.82.016111 http://arxiv.org/abs/1002.4615 http://dx.doi.org/10.1103/PhysRevE.82.016111},
volume = {82},
year = {2010}
}
@article{Breakspear2017,
author = {Breakspear, Michael},
doi = {10.1038/nn.4497},
file = {:home/kaslu/Documents/Mendeley/2017 - Breakspear - Dynamic models of large-scale brain activity.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {340--352},
title = {{Dynamic models of large-scale brain activity}},
url = {http://www.nature.com/doifinder/10.1038/nn.4497},
volume = {20},
year = {2017}
}
@article{Murray2017,
abstract = {Challenges of assessing complexity and clonality in populations of mixed species arise in diverse areas of modern biology, including estimating diversity and clonality in microbiome populations, measuring patterns of T and B cell clonality, and determining the underlying tumor cell population structure in cancer. Here we address the problem of quantifying populations, with our analysis directed toward systems for which previously defined algorithms allow the sequence-based identification of clonal subpopulations. Data come from replicate sequencing libraries generated from a sample, potentially with very different depths. While certain properties of the underlying clonal distribution (most notably the total number of clones) are difficult to estimate accurately from data representing a small fraction of the total population, the population-level "clonality" metric that is the sum of squared probabilities of the respective species can be calculated. (This is the sum of squared entries of a high-dimensional vector {\$}p{\$} of relative frequencies.) The clonality score is the probability of a clonal relationship between two randomly chosen members of the population of interest. A principal takeaway message is that knowing a functional of {\$}p{\$} well may not depend on knowing {\$}p{\$} itself very well. Our work has led to software, which we call {\{}$\backslash$it lymphclon{\}}; it has been deposited in the CRAN library.},
author = {Murray, John D. and Bernacchia, Alberto and Roy, Nicholas A. and Constantinidis, Christos and Romo, Ranulfo and Wang, Xiao-Jing},
doi = {10.1073/pnas.1619449114},
isbn = {1215421109},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jan},
number = {2},
pages = {394--399},
pmid = {28028221},
title = {{Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1619449114},
volume = {114},
year = {2017}
}
@article{Vicente1997,
abstract = {We study the online dynamics of learning in fully connected soft committee machines in the student-teacher scenario. The locally optimal modulation function, which determines the learning algorithm, is obtained from a variational argument in such a manner as to maximise the average generalisation error decay per example. Simulations results for the resulting algorithm are presented for a few cases. The symmetric phase plateaux are found to be vastly reduced in comparison to those found when online backpropagation algorithms are used. A discussion of the implementation of these ideas as practical algorithms is given.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9706015},
author = {Vicente, Renato and Caticha, Nestor},
doi = {10.1088/0305-4470/30/17/002},
eprint = {9706015},
file = {:home/kaslu/Documents/Mendeley/1997 - Vicente, Caticha - Functional optimization of online algorithms in multilayer neural networks.pdf:pdf},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
month = {sep},
number = {17},
pages = {L599--L605},
primaryClass = {cond-mat},
title = {{Functional optimization of online algorithms in multilayer neural networks}},
url = {http://arxiv.org/abs/cond-mat/9706015 http://stacks.iop.org/0305-4470/30/i=17/a=002?key=crossref.a298d9e89d7409d9ed7c82f5bb59a7b8},
volume = {30},
year = {1997}
}
@article{Launay2015,
abstract = {Homophily, the tendency for people to cluster with similar others, has primarily been studied in terms of proximal, psychological causes, such as a tendency to have positive associations with people who share traits with us. Here we investigate whether homophily could be correlated with perceived group membership, given that sharing traits with other people might signify membership of a specific community. In order to investigate this, we tested whether the amount of homophily that occurs between strangers is dependent on the number of people they believe share the common trait (i.e. the size of group that the trait identifies). In two experiments, we show that more exclusive (smaller) groups evoke more positive ratings of the likeability of a stranger. When groups appear to be too inclusive (i.e. large) homophily no longer occurs, suggesting that it is not only positive associations with a trait that cause homophily, but a sense of the exclusiveness of a group is also important. These results suggest that group membership based on a variety of traits can encourage cohesion between people from diverse backgrounds, and may be a useful tool in overcoming differences between groups.},
author = {Launay, Jacques and Dunbar, Robin},
doi = {10.1016/j.evolhumbehav.2014.08.005},
file = {:home/kaslu/Documents/Mendeley/2015 - Launay, Dunbar - Does implied community size predict likeability of a similar stranger.pdf:pdf},
issn = {10905138},
journal = {Evolution and Human Behavior},
month = {jan},
number = {1},
pages = {32--37},
title = {{Does implied community size predict likeability of a similar stranger?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1090513814001044},
volume = {36},
year = {2015}
}
@article{Pizarro2003,
abstract = {The social intuitionist model (J. Haidt, 2001) posits that fast and automatic intuitions are the primary source of moral judgments. Conscious deliberations play little causal role; they are used mostly to construct post hoc justifications for judgments that have already occurred. In this article, the authors present evidence that fast and automatic moral intuitions are actually shaped and informed by prior reasoning. More generally, there is considerable evidence from outside the laboratory that people actively engage in reasoning when faced with real-world moral dilemmas. Together, these facts limit the strong claims of the social intuitionist model concerning the irrelevance of conscious deliberation.},
author = {Pizarro, David A. and Bloom, Paul},
doi = {10.1037/0033-295X.110.1.193},
file = {:home/kaslu/Documents/Mendeley/2003 - Pizarro, Bloom - The intelligence of the moral intuitions A comment on Haidt (2001).pdf:pdf},
isbn = {0033-295X$\backslash$r1939-1471},
issn = {1939-1471},
journal = {Psychological Review},
number = {1},
pages = {193--196},
pmid = {12529062},
title = {{The intelligence of the moral intuitions: A comment on Haidt (2001).}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.1.193},
volume = {110},
year = {2003}
}
@article{Palmeri2016,
author = {Palmeri, Thomas J and Love, Bradley C and Turner, Brandon M},
doi = {10.1016/j.jmp.2016.10.010},
file = {:home/kaslu/Documents/Mendeley/2016 - Palmeri, Love, Turner - Model-based cognitive neuroscience.pdf:pdf},
issn = {0022-2496},
journal = {Journal of Mathematical Psychology},
pages = {59--64},
publisher = {Elsevier Inc.},
title = {{Model-based cognitive neuroscience}},
url = {http://dx.doi.org/10.1016/j.jmp.2016.10.010},
volume = {76},
year = {2016}
}
@article{Koopman1955,
annote = {NULL},
author = {Koopman, B. O.},
isbn = {0821813072, 9780821813072},
journal = {Proceedings of Symposia in Applied Mathematics},
pages = {97--102},
title = {{Quantum Theory and the Foundations of Probability}},
url = {http://books.google.ca/books?id=CQmQOyHl5EoC{\&}{\#}38;dq=“Quantum+Theory+and+the+Foundations+of+Probability{\&}{\#}38;source=gbs{\_}navlinks{\_}s{\%}5Cnhttp://books.google.ca/books?id=CQmQOyHl5EoC{\&}{\#}38;dq=“Quantum+Theory+and+the+Foundations+of+Probability{\&}{\#}38;source=gbs{\_}navli},
volume = {7},
year = {1955}
}
@article{Nigam2016,
abstract = {The performance of complex networks, like the brain, depends on how effectively their elements communicate. Despite the importance of communication, it is virtually unknown how information is transferred in local cortical networks, consisting of hundreds of closely spaced neurons. To address this, it is important to record simultaneously from hundreds of neurons at a spacing that matches typical axonal connection distances, and at a temporal resolution that matches synaptic delays. We used a 512-electrode array (60 ␮m spacing) to record spontaneous activity at 20 kHz from up to 500 neurons simultaneously in slice cultures of mouse somatosensory cortex for 1 h at a time. We applied a previously validated version of transfer entropy to quantify information transfer. Similar to in vivo reports, we found an approximately lognormal distribution of firing rates. Pairwise information transfer strengths also were nearly lognormally distributed, similar to reports of synaptic strengths. Some neurons transferred and received much more information than others, which is consistent with previous predictions. Neurons with the highest outgoing and incoming information transfer were more strongly connected to each other than chance, thus forming a " rich club. " We found similar results in networks recorded in vivo from rodent cortex, suggesting the generality of these findings. A rich-club structure has been found previously in large-scale human brain networks and is thought to facilitate communication between cortical regions. The discovery of a small, but information-rich, subset of neurons within cortical regions suggests that this population will play a vital role in communica-tion, learning, and memory. Many studies have focused on communication networks between cortical brain regions. In contrast, very few studies have exam-ined communication networks within a cortical region. This is the first study to combine such a large number of neurons (several hundred at a time) with such high temporal resolution (so we can know the direction of communication between neurons) for mapping networks within cortex. We found that information was not transferred equally through all neurons. Instead, ϳ70{\%} of the information passed through only 20{\%} of the neurons. Network models suggest that this highly concentrated pattern of information transfer would be both efficient and robust to damage. Therefore, this work may help in understanding how the cortex processes information and responds to neurodegenerative diseases.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Nigam, Sunny and Shimono, Masanori and Ito, Shinya and Yeh, Fang-Chin and Timme, Nicholas and Myroshnychenko, Maxym and Lapish, Christopher C and Tosi, Zachary and Hottowy, Pawel and Smith, Wesley C and Masmanidis, Sotiris C and Litke, Alan M. and Sporns, Olaf and Beggs, John M.},
doi = {10.1523/JNEUROSCI.2177-15.2016},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2016 - Nigam et al. - SystemsCircuits Rich-Club Organization in Effective Connectivity among Cortical Neurons.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {@BULLET The Journal of Neuroscience},
keywords = {effective connectivity,information transfer,microcircuits,rich club,transfer entropy Significance Statement},
number = {3},
pages = {670--684},
pmid = {26791200},
title = {{Systems/Circuits Rich-Club Organization in Effective Connectivity among Cortical Neurons}},
volume = {36},
year = {2016}
}
@article{Deneve2001,
abstract = {The brain represents sensory and motor variables through the activity of large populations of neurons. It is not understood how the nervous system computes with these population codes, given that individual neurons are noisy and thus unreliable. We focus here on two general types of computation, function approximation and cue integration, as these are powerful enough to handle a range of tasks, including sensorimotor transformations, feature extraction in sensory systems and multisensory integration. We demonstrate that a particular class of neural networks, basis function networks with multidimensional attractors, can perform both types of computation optimally with noisy neurons. Moreover, neurons in the intermediate layers of our model show response properties similar to those observed in several multimodal cortical areas. Thus, basis function networks with multidimensional attractors may be used by the brain to compute efficiently with population codes.},
author = {Den{\`{e}}ve, Sophie and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/90541},
file = {:home/kaslu/Documents/Mendeley/2001 - Den{\`{e}}ve, Latham, Pouget - Efficient computation and cue integration with noisy population codes.pdf:pdf;:home/kaslu/Documents/Mendeley/2001 - Den{\`{e}}ve, Latham, Pouget - Efficient computation and cue integration with noisy population codes(2).pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
keywords = {*Models,Action Potentials/*physiology,Animals,Artifacts,Cerebral Cortex/cytology/*physiology,Cues,Demography,Eye Movements/physiology,Feedback/physiology,Humans,Nerve Net/cytology/*physiology,Neurological,Neurons/cytology/*physiology,Nonlinear Dynamics,Orientation/physiology,Psychomotor Performance/physiology,Space Perception/physiology,Synaptic Transmission/*physiology},
month = {aug},
number = {8},
pages = {826--831},
title = {{Efficient computation and cue integration with noisy population codes}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11477429 http://www.nature.com/doifinder/10.1038/90541},
volume = {4},
year = {2001}
}
@article{Lundstrom2008,
abstract = {Neural systems adapt to changes in stimulus statistics. However, it is not known how stimuli with complex temporal dynamics drive the dynamics of adaptation and the resulting firing rate. For single neurons, it has often been assumed that adaptation has a single time scale. We found that single rat neocortical pyramidal neurons adapt with a time scale that depends on the time scale of changes in stimulus statistics. This multiple time scale adaptation is consistent with fractional order differentiation, such that the neuron's firing rate is a fractional derivative of slowly varying stimulus parameters. Biophysically, even though neuronal fractional differentiation effectively yields adaptation with many time scales, we found that its implementation required only a few properly balanced known adaptive mechanisms. Fractional differentiation provides single neurons with a fundamental and general computation that can contribute to efficient information processing, stimulus anticipation and frequency-independent phase shifts of oscillatory neuronal firing.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lundstrom, Brian Nils and Higgs, Matthew H. and Spain, William J. and Fairhall, Adrienne L.},
doi = {10.1038/nn.2212},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2008 - Lundstrom et al. - Fractional differentiation by neocortical pyramidal neurons.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {nov},
number = {11},
pages = {1335--1342},
pmid = {18931665},
title = {{Fractional differentiation by neocortical pyramidal neurons}},
url = {http://www.nature.com/doifinder/10.1038/nn.2212},
volume = {11},
year = {2008}
}
@article{Shibata2017,
author = {Shibata, Kazuhisa and Sasaki, Yuka and Bang, Ji Won and Walsh, Edward G and Machizawa, Maro G and Tamaki, Masako and Chang, Li-Hung and Watanabe, Takeo},
doi = {10.1038/nn.4490},
file = {:home/kaslu/Documents/Mendeley/2017 - Shibata et al. - Overlearning hyperstabilizes a skill by rapidly making neurochemical processing inhibitory-dominant.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {3},
title = {{Overlearning hyperstabilizes a skill by rapidly making neurochemical processing inhibitory-dominant}},
url = {http://www.nature.com/doifinder/10.1038/nn.4490},
volume = {23},
year = {2017}
}
@article{Presse2013,
abstract = {The variational principles called maximum entropy (MaxEnt) and maximum caliber (MaxCal) are reviewed. MaxEnt originated in the statistical physics of Boltzmann and Gibbs, as a theoretical tool for predicting the equilibrium states of thermal systems. Later, entropy maximization was also applied to matters of information, signal transmission, and image reconstruction. Recently, since the work of Shore and Johnson, MaxEnt has been regarded as a principle that is broader than either physics or information alone. MaxEnt is a procedure that ensures that inferences drawn from stochastic data satisfy basic self-consistency requirements. The different historical justifications for the entropy S=-∑ipilog⁡pi and its corresponding variational principles are reviewed. As an illustration of the broadening purview of maximum entropy principles, maximum caliber, which is path entropy maximization applied to the trajectories of dynamical systems, is also reviewed. Examples are given in which maximum caliber is used to interpret dynamical fluctuations in biology and on the nanoscale, in single-molecule and few-particle systems such as molecular motors, chemical reactions, biological feedback circuits, and diffusion in microfluidics devices.},
author = {Press{\'{e}}, Steve and Ghosh, Kingshuk and Lee, Julian and Dill, Ken A.},
doi = {10.1103/RevModPhys.85.1115},
file = {:home/kaslu/Documents/Mendeley/2013 - Press{\'{e}} et al. - Principles of maximum entropy and maximum caliber in statistical physics.pdf:pdf},
issn = {00346861},
journal = {Reviews of Modern Physics},
month = {jul},
number = {3},
pages = {1115--1141},
pmid = {1000339939},
title = {{Principles of maximum entropy and maximum caliber in statistical physics}},
url = {http://link.aps.org/doi/10.1103/RevModPhys.85.1115},
volume = {85},
year = {2013}
}
@article{Asch1956,
abstract = {The investigations described in this series are concerned with the conditions of independence and lack of independence in the face of group pressure. The abstract temper of present-day theory and investigation in this region rests to a considerable degree on a neglect of the cognitive and emotional experiences that are part of the individual's psychological field. The understanding of social influences will require the study of a wide range of conditions and of the interrelated operations of different psychological functions. A group of seven to nine individuals was gathered in a classroom to take part in what appeared to be a simple experiment in visual discrimination. The subjects were all male, white college students, ranging in age from 17 to 25; the mean age was 20. For certain purposes a large number of critical subjects was required for the present experiment. The present report is based on a total of 123 subjects. The task consisted of the comparison of a standard line with three other lines, one of which was equal in length to the standard. We investigated some of the conditions responsible for independence and lack of independence in the face of arbitrary group pressure. To this end we produced a disagreement between a group and one individual member about a clear and simple issue of fact. The interview, which followed the experimental session, provided qualitative evidence concerning the effects produced by the majority, The particular properties of the experimental situation and their relation to more usual social contradictions were described. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Asch, Solomon E.},
doi = {10.1037/h0093718},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/1956 - Asch - Studies of independence and conformity I. A minority of one against a unanimous majority.pdf:pdf},
isbn = {0096-9753},
issn = {0096-9753},
journal = {Psychological Monographs: General and Applied},
number = {9},
pages = {1--70},
pmid = {25246403},
title = {{Studies of independence and conformity: I. A minority of one against a unanimous majority.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0093718},
volume = {70},
year = {1956}
}
@article{Manning2015a,
abstract = {I propose that suicide attacks can be explained by structural patterns such as social distance, status inferiority, organization, and large movements of social time. Furthermore, sacrifice is greater among those who are socially marginal individuals whose locations are otherwise conducive to both partisanship and self-destruction.},
author = {Manning, Jason},
doi = {10.1108/S1521-613620150000020009},
issn = {15216136},
journal = {Sociology of Crime, Law, and Deviance},
keywords = {altruism,conflict,social control,social structure,suicide},
pages = {151--171},
title = {{Suicide Attacks and the Social Structure of Sacrifice}},
url = {http://www.emeraldinsight.com/doi/10.1108/S1521-613620150000020009},
volume = {20},
year = {2015}
}
@article{Soutschek2017a,
abstract = {Women are known to have stronger prosocial preferences than men, but it remains an open question as to how these behavioural differences arise from differences in brain functioning. Here, we provide a neurobiological account for the hypothesized gender difference. In a pharmacological study and an independent neuroimaging study, we tested the hypothesis that the neural reward system encodes the value of sharing money with others more strongly in women than in men. In the pharmacological study, we reduced receptor type-specific actions of dopamine, a neurotransmitter related to reward processing, which resulted in more selfish decisions in women and more prosocial decisions in men. Converging findings from an independent neuroimaging study revealed gender-related activity in neural reward circuits during prosocial decisions. Thus, the neural reward system appears to be more sensitive to prosocial rewards in women than in men, providing a neurobiological account for why women often behave more prosocially than men. Women often behave more prosocially than men. Soutschek et al. use pharmacology and neuroimaging to show that the neural reward system appears to be more sensitive to prosocial rewards in women than men, providing a neurobiological account for this gender difference.},
author = {Soutschek, Alexander and Burke, Christopher J. and {Raja Beharelle}, Anjali and Schreiber, Robert and Weber, Susanna C. and Karipidis, Iliana I. and ten Velden, Jolien and Weber, Bernd and Haker, Helene and Kalenscher, Tobias and Tobler, Philippe N.},
doi = {10.1038/s41562-017-0226-y},
file = {:home/kaslu/Documents/Mendeley/2017 - Soutschek et al. - The dopaminergic reward system underpins gender differences in social preferences.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
keywords = {Behavioral Sciences,Experimental Psychology,Life Sciences,Microeconomics,Neurosciences,Personality and Social Psychology,general},
month = {nov},
number = {11},
pages = {819--827},
publisher = {Nature Publishing Group},
title = {{The dopaminergic reward system underpins gender differences in social preferences}},
url = {http://www.nature.com/articles/s41562-017-0226-y},
volume = {1},
year = {2017}
}
@article{Artstein-Avidan2009,
abstract = {In the main theorem of this paper we show that any involution on the class of lower semi-continuous convex functions which is order-reversing, must be, up to linear terms, the well known Legendre transform.},
author = {Artstein-Avidan, Shiri and Milman, Vitali},
doi = {10.4007/annals.2009.169.661},
file = {:home/kaslu/Documents/Mendeley/2009 - Artstein-Avidan, Milman - The concept of duality in convex analysis, and the characterization of the Legendre transform.pdf:pdf},
issn = {0003486X},
journal = {Annals of Mathematics},
number = {2},
pages = {661--674},
title = {{The concept of duality in convex analysis, and the characterization of the Legendre transform}},
volume = {169},
year = {2009}
}
@article{Kassa,
author = {Orellana, Josue and Rodu, Jordan and Kass, Robert E.},
doi = {10.1162/neco_a_00992},
file = {:home/kaslu/Documents/Mendeley/2017 - Orellana, Rodu, Kass - Population Vectors Can Provide Near Optimal Integration of Information.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {aug},
number = {8},
pages = {2021--2029},
title = {{Population Vectors Can Provide Near Optimal Integration of Information}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco{\_}a{\_}00992},
volume = {29},
year = {2017}
}
@article{Meszena2000,
abstract = {Matrix game theory and optimisation models offer two radically different perspectives on the outcome of evolu- tion. Optimisation models consider frequency-independent selection and envisage evolution as a hill-climbing process on a constant fitness landscape, with the optimal strategy corresponding to the fitness maximum. By contrast, in evolutionary matrix games selection is frequency-dependent and leads to fitness equality among alternative strategies once an evolutionarily stable strategy has been established. In this review we demonstrate that both optimisation models and matrix games represent limiting cases of the general framework of nonlinear frequency- dependent selection. Adaptive dynamics theory considers arbitrary nonlinear frequency and density dependence and envisages evolution as proceeding on an adaptive landscape that changes its shape according to which strate- gies are present in the population. In adaptive dynamics, evolutionarily stable strategies correspond to conditional fitness maxima: the ESS is characterised by the fact that it has the highest fitness if it is the established strategy. In this framework it can also be shown that dynamical attainability, evolutionary stability, and invading potential of strategies are pairwise independent properties. In optimisation models, on the other hand, these properties be- come linked such that the optimal strategy is always attracting, evolutionarily stable and can invade any other strategy. In matrix games fitness is a linear function of the potentially invading strategy and can thus never ex- hibit an interior maximum: Instead, the fitness landscape is a plane that becomes horizontal once the ESS is es- tablished. Due to this degeneracy, invading potential is part of the ESS definition for matrix games and dynamical attainability is a dependent property. We conclude that nonlinear frequency-dependent theory provides a unifying framework for overcoming the traditional divide between evolutionary optimisation models and matrix games. Keywords:},
author = {Mesz{\'{e}}na, G. and Kisdi, {\'{E}}. and Dieckmann, Ulf and Geritz, S. a. H. and Metz, J. a. J. and Kisdi, E and Dieckmann, Ulf and Geritz, S. a. H. and Metz, J. a. J.},
doi = {10.1556/Select.2.2001.1-2.14},
file = {:home/kaslu/Documents/Mendeley/2000 - Mesz{\'{e}}na et al. - Evolutionary optimisation models and matrix games in the unified perspective of adaptive dynamics.pdf:pdf},
isbn = {IIASA Interim Report IR-00-039},
issn = {1585-1931},
journal = {Interim Report},
keywords = {adaptive dynamics,ess,evolution,fitness landscapes,fre-,matrix games,optimisation models,quency-dependent selection},
month = {apr},
number = {July},
pages = {193--220},
title = {{Evolutionary optimisation models and matrix games in the unified perspective of adaptive dynamics}},
url = {http://www.akademiai.com/openurl.asp?genre=article{\&}id=doi:10.1556/Select.2.2001.1-2.14},
volume = {IR-00-039},
year = {2000}
}
@article{Brunel2016,
abstract = {Cortical networks are thought to be shaped by experience-dependent synaptic plasticity. Theoretical studies have shown that synaptic plasticity allows a network to store a memory of patterns of activity such that they become attractors of the dynamics of the network. Here we study the properties of the excitatory synaptic connectivity in a network that maximizes the number of stored patterns of activity in a robust fashion. We show that the resulting synaptic connectivity matrix has the following properties: it is sparse, with a large fraction of zero synaptic weights (‘potential' synapses); bidirectionally coupled pairs of neurons are over-represented in comparison to a random network; and bidirectionally connected pairs have stronger synapses on average than unidirectionally connected pairs. All these features reproduce quantitatively available data on connectivity in cortex. This suggests synaptic connectivity in cortex is optimized to store a large number of attractor states in a robust fashion.},
author = {Brunel, Nicolas},
doi = {10.1038/nn.4286},
file = {:home/kaslu/Documents/Mendeley/2016 - Brunel - Is cortical connectivity optimized for storing information.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {apr},
number = {5},
pages = {749--755},
pmid = {27065365},
title = {{Is cortical connectivity optimized for storing information?}},
url = {http://www.nature.com/doifinder/10.1038/nn.4286},
volume = {19},
year = {2016}
}
@article{Huh2017,
abstract = {Much of studies on neural computation are based on network models of static neurons that produce analog output, despite the fact that information processing in the brain is predominantly carried out by dynamic neurons that produce discrete pulses called spikes. Research in spike-based computation has been impeded by the lack of efficient supervised learning algorithm for spiking networks. Here, we present a gradient descent method for optimizing spiking network models by introducing a differentiable formulation of spiking networks and deriving the exact gradient calculation. For demonstration, we trained recurrent spiking networks on two dynamic tasks: one that requires optimizing fast ({\~{}}millisecond) spike-based interactions for efficient encoding of information, and a delayed memory XOR task over extended duration ({\~{}}second). The results show that our method indeed optimizes the spiking network dynamics on the time scale of individual spikes as well as behavioral time scales. In conclusion, our result offers a general purpose supervised learning algorithm for spiking neural networks, thus advancing further investigations on spike-based computation.},
archivePrefix = {arXiv},
arxivId = {1706.04698},
author = {Huh, Dongsung and Sejnowski, Terrence J.},
eprint = {1706.04698},
file = {:home/kaslu/Documents/Mendeley/2017 - Huh, Sejnowski - Gradient Descent for Spiking Neural Networks.pdf:pdf},
month = {jun},
title = {{Gradient Descent for Spiking Neural Networks}},
url = {http://arxiv.org/abs/1706.04698},
year = {2017}
}
@article{COUZIN2002,
author = {COUZIN, IAIN D. and KRAUSE, JENS and JAMES, RICHARD and RUXTON, GRAEME D. and FRANKS, NIGEL R.},
doi = {10.1006/jtbi.2002.3065},
issn = {00225193},
journal = {Journal of Theoretical Biology},
month = {sep},
number = {1},
pages = {1--11},
title = {{Collective Memory and Spatial Sorting in Animal Groups}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022519302930651},
volume = {218},
year = {2002}
}
@article{Manuscript2008a,
author = {Kording, Konrad P. and Tenenbaum, Joshua B. and Shadmehr, Reza},
doi = {10.1038/nn1901},
file = {:home/kaslu/Documents/Mendeley/2007 - Kording, Tenenbaum, Shadmehr - The dynamics of memory as a consequence of optimal adaptation to a changing body.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jun},
number = {6},
pages = {779--786},
title = {{The dynamics of memory as a consequence of optimal adaptation to a changing body}},
url = {http://www.nature.com/doifinder/10.1038/nn1901},
volume = {10},
year = {2007}
}
@article{Neilson2017,
author = {Neilson, Christopher and Contreras, Dante and Cooper, Ryan and Hermann, Jorge and Journal, Source and Studies, American and May, No and Neilson, Christopher and Contreras, Dante},
number = {2},
pages = {251--273},
title = {{The Dynamics of Poverty in Chile Linked references are available on JSTOR for this article : The Dynamics of Poverty in Chile *}},
volume = {40},
year = {2017}
}
@article{Ramkumar2016,
abstract = {When we search for visual objects, the features of those objects bias our attention across the visual landscape (feature-based attention). The brain uses these top-down cues to select eye movement targets (spatial selection). The frontal eye field (FEF) is a prefrontal brain region implicated in selecting eye movements and is thought to reflect feature-based attention and spatial selection. Here, we study how FEF facilitates attention and selection in complex natural scenes. We ask whether FEF neurons facilitate feature-based attention by representing search-relevant visual features, or whether they are primarily involved in selecting eye movement targets in space. We show that search-relevant visual features are weakly predictive of gaze in natural scenes and additionally have no significant influence on FEF activity. Instead, FEF activity appears to primarily correlate with the direction of the upcoming eye movement. Our result demonstrates a concrete need for better models of natural scene search and suggests that FEF activity during natural scene search is explained primarily by spatial selection.},
author = {Ramkumar, Pavan and Lawlor, Patrick N. and Glaser, Joshua I. and Wood, Daniel K. and Phillips, Adam N. and Segraves, Mark A. and Kording, Konrad P.},
doi = {10.1152/jn.01044.2015},
file = {:home/kaslu/Documents/Mendeley/2016 - Ramkumar et al. - Feature-based attention and spatial selection in frontal eye fields during natural scene search.pdf:pdf},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {3},
pages = {1328--1343},
pmid = {27250912},
title = {{Feature-based attention and spatial selection in frontal eye fields during natural scene search}},
url = {http://jn.physiology.org/lookup/doi/10.1152/jn.01044.2015},
volume = {116},
year = {2016}
}
@article{Katz2016,
abstract = {During decision making, neurons in multiple brain regions exhibit responses that are correlated with decisions. However, it remains uncertain whether or not various forms of decision-related activity are causally related to decision making. Here we address this question by recording and reversibly inactivating the lateral intraparietal (LIP) and middle temporal (MT) areas of rhesus macaques performing a motion direction discrimination task. Neurons in area LIP exhibited firing rate patterns that directly resembled the evidence accumulation process posited to govern decision making, with strong correlations between their response fluctuations and the animal's choices. Neurons in area MT, in contrast, exhibited weak correlations between their response fluctuations and choices, and had firing rate patterns consistent with their sensory role in motion encoding. The behavioural impact of pharmacological inactivation of each area was inversely related to their degree of decision-related activity: while inactivation of neurons in MT profoundly impaired psychophysical performance, inactivation in LIP had no measurable impact on decision-making performance, despite having silenced the very clusters that exhibited strong decision-related activity. Although LIP inactivation did not impair psychophysical behaviour, it did influence spatial selection and oculomotor metrics in a free-choice control task. The absence of an effect on perceptual decision making was stable over trials and sessions and was robust to changes in stimulus type and task geometry, arguing against several forms of compensation. Thus, decision-related signals in LIP do not appear to be critical for computing perceptual decisions, and may instead reflect secondary processes. Our findings highlight a dissociation between decision correlation and causation, showing that strong neuron-decision correlations do not necessarily offer direct access to the neural computations underlying decisions.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Katz, Leor N. and Yates, Jacob L. and Pillow, Jonathan W. and Huk, Alexander C.},
doi = {10.1038/nature18617},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2016 - Katz et al. - Dissociated functional significance of decision-related activity in the primate dorsal stream.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {7611},
pages = {285--288},
pmid = {27376476},
publisher = {Nature Publishing Group},
title = {{Dissociated functional significance of decision-related activity in the primate dorsal stream}},
url = {http://www.nature.com/doifinder/10.1038/nature18617},
volume = {535},
year = {2016}
}
@article{Linderman2017,
abstract = {Computational neuroscience is, to first order, dominated by two approaches: the ‘bottom-up' approach, which searches for statistical patterns in large-scale neural recordings, and the ‘top-down' approach, which begins with a theory of computation and considers plausible neural implementations. While this division is not clear-cut, we argue that these approaches should be much more intimately linked. From a Bayesian perspective, computational theories provide constrained prior distributions on neural data — albeit highly sophisticated ones. By connecting theory to observation via a probabilistic model, we provide the link necessary to test, evaluate, and revise our theories in a data-driven and statistically rigorous fashion. This review highlights examples of this theory-driven pipeline for neural data analysis in recent literature and illustrates it with a worked example based on the temporal difference learning model of dopamine.},
author = {Linderman, Scott W. and Gershman, Samuel J.},
doi = {10.1016/j.conb.2017.06.004},
file = {:home/kaslu/Documents/Mendeley/2017 - Linderman, Gershman - Using computational theory to constrain statistical models of neural data.pdf:pdf},
isbn = {1873-6882 (Electronic)0959-4388 (Linking)},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {14--24},
pmid = {28732273},
publisher = {Elsevier Ltd},
title = {{Using computational theory to constrain statistical models of neural data}},
url = {http://dx.doi.org/10.1016/j.conb.2017.06.004},
volume = {46},
year = {2017}
}
@incollection{Baumard2015,
abstract = {People often make moral judgments that go against the greater good, which is in stark contrast with a view of morality (utilitarianism) that claims the correct action is whatever leads to the highest overall welfare. In recent years, as psychologists have constructed an ever-lengthening list of departures from utilitarian thinking, many have suggested that human moral cognition is a utilitarian system beset with various defective biases . Here, we argue that deviations from utilitarianism are not due to diverse bugs in our moral psychology, but instead are the predictable output of a contractualist moral psychology that evolved for navigating a social environment in which people can choose with whom they associate for mutualistic endeavors.},
author = {Baumard, Nicolas and Sheskin, Mark},
booktitle = {The moral brain: A multidisciplinary perspective},
file = {:home/kaslu/Documents/Mendeley/2015 - Baumard, Sheskin - Partner choice and the evolution of a contractualist morality.pdf:pdf},
isbn = {0262028719},
pages = {35--48},
title = {{Partner choice and the evolution of a contractualist morality}},
year = {2015}
}
@article{Marzen2015,
abstract = {The mutual information between stimulus and spike-train response is commonly used to monitor neural coding efficiency, but neuronal computation broadly conceived requires more refined and targeted information measures of input-output joint processes. A first step toward that larger goal is to develop information measures for individual output processes, including information generation (entropy rate), stored information (statistical complexity), predictable information (excess entropy), and active information accumulation (bound information rate). We calculate these for spike trains generated by a variety of noise-driven integrate-and-fire neurons as a function of time resolution and for alternating renewal processes. We show that their time-resolution dependence reveals coarse-grained structural properties of interspike interval statistics; e.g., $\tau$-entropy rates that diverge less quickly than the firing rate indicated by interspike interval correlations. We also find evidence that the excess entropy and regularized statistical complexity of different types of integrate-and-fire neurons are universal in the continuous-time limit in the sense that they do not depend on mechanism details. This suggests a surprising simplicity in the spike trains generated by these model neurons. Interestingly, neurons with gamma-distributed ISIs and neurons whose spike trains are alternating renewal processes do not fall into the same universality class. These results lead to two conclusions. First, the dependence of information measures on time resolution reveals mechanistic details about spike train generation. Second, information measures can be used as model selection tools for analyzing spike train processes.},
archivePrefix = {arXiv},
arxivId = {1504.04756},
author = {Marzen, Sarah E and DeWeese, Michael R and Crutchfield, James P},
doi = {10.3389/fncom.2015.00105},
eprint = {1504.04756},
file = {:home/kaslu/Documents/Mendeley/2015 - Marzen, DeWeese, Crutchfield - Time resolution dependence of information measures for spiking neurons scaling and universality.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {05,10,19,45,50,alternating renewal process,entropy ra,entropy rate,excess entropy,ey 87,integrate and fire neuron,leaky integrate and fire,ll 87,lo 87,ls,neuron,pacs numbers,quadratic integrate and fire,renewal process,statistical complexity,tp 02,vg 87},
number = {August},
pages = {105},
pmid = {26379538},
title = {{Time resolution dependence of information measures for spiking neurons: scaling and universality.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4551861{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2015}
}
@article{Balasubramanian2014,
abstract = {We study the question of how reliably one can distinguish two quantum field theories (QFTs). Each QFT defines a probability distribution on the space of fields. The relative entropy provides a notion of proximity between these distributions and quantifies the number of measurements required to distinguish between them. In the case of nearby conformal field theories, this reduces to the Zamolodchikov metric on the space of couplings. Our formulation quantifies the information lost under renormalization group flow from the UV to the IR and leads us to a quantification of fine-tuning. This formalism also leads us to a criterion for distinguishability of low energy effective field theories generated by the string theory landscape.},
archivePrefix = {arXiv},
arxivId = {1410.6809},
author = {Balasubramanian, Vijay and Heckman, Jonathan J. and Maloney, Alexander},
eprint = {1410.6809},
file = {:home/kaslu/Documents/Mendeley/2014 - Balasubramanian, Heckman, Maloney - Relative Entropy and Proximity of Quantum Field Theories.pdf:pdf},
month = {oct},
pages = {7},
title = {{Relative Entropy and Proximity of Quantum Field Theories}},
url = {http://arxiv.org/abs/1410.6809},
year = {2014}
}
@article{Chandrasekaran2007,
abstract = {We develop a novel approach to approximate a specified collection of marginal distributions on subsets of variables by a globally consistent distribution on the entire collection of variables. In general, the specified marginal distributions may be inconsistent on overlapping subsets of variables. Our method is based on maximizing entropy over an exponential family of graphical models, subject to divergence constraints on small subsets of variables that enforce closeness to the specified marginals. The resulting optimization problem is convex, and can be solved efficiently using a primal-dual interiorpoint algorithm. Moreover, this framework leads naturally to a solution that is a sparse graphical model. Index Terms — Graphical models, maximum entropy principle, model selection, inconsistent statistics 1.},
author = {Chandrasekaran, Venkat and Johnson, Jason K. and Willsky, Alan S.},
doi = {10.1109/SSP.2007.4301334},
file = {:home/kaslu/Documents/Mendeley/2007 - Chandrasekaran, Johnson, Willsky - Maximum entropy relaxation for graphical model selection given inconsistent statistics.pdf:pdf},
isbn = {142441198X},
journal = {IEEE Workshop on Statistical Signal Processing Proceedings},
keywords = {Graphical models,Inconsistent statistics,Maximum entropy principle,Model selection},
pages = {625--629},
title = {{Maximum entropy relaxation for graphical model selection given inconsistent statistics}},
year = {2007}
}
@article{Castellana2014,
abstract = {When birds come together to form a flock, the distribution of their individual velocities narrows around the mean velocity of the flock. We argue that, in a broad class of models for the joint distribution of positions and velocities, this narrowing generates an entropic force that opposes the cohesion of the flock. The strength of this force depends strongly on the nature of the interactions among birds: if birds are coupled to a fixed number of neighbors, the entropic forces are weak, while if they couple to all other birds within a fixed distance, the entropic forces are sufficient to tear a flock apart. Similar entropic forces should occur in other non-equilibrium systems. For the joint distribution of protein structures and amino-acid sequences, these forces favor the occurrence of "highly designable" structures.},
archivePrefix = {arXiv},
arxivId = {1412.8654},
author = {Castellana, Michele and Bialek, William and Cavagna, Andrea and Giardina, Irene},
doi = {10.1103/PhysRevE.93.052416},
eprint = {1412.8654},
file = {:home/kaslu/Documents/Mendeley/2016 - Castellana et al. - Entropic effects in a nonequilibrium system Flocks of birds.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {may},
number = {5},
pages = {052416},
title = {{Entropic effects in a nonequilibrium system: Flocks of birds}},
url = {http://arxiv.org/abs/1412.8654 http://link.aps.org/doi/10.1103/PhysRevE.93.052416},
volume = {93},
year = {2016}
}
@article{Savin2017,
abstract = {Neural responses are highly structured, with population activity restricted to a small subset of the astronomical range of possible activity patterns. Characterizing these statistical regularities is important for understanding circuit computation, but challenging in practice. Here we review recent approaches based on the maximum entropy principle used for quantifying collective behavior in neural activity. We highlight recent models that capture population-level statistics of neural data, yielding insights into the organization of the neural code and its biological substrate. Furthermore, the MaxEnt framework provides a general recipe for constructing surrogate ensembles that preserve aspects of the data, but are otherwise maximally unstructured. This idea can be used to generate a hierarchy of controls against which rigorous statistical tests are possible.},
author = {Savin, Cristina and Tka{\v{c}}ik, Ga{\v{s}}per},
doi = {10.1016/j.conb.2017.08.001},
file = {:home/kaslu/Documents/Mendeley/2017 - Savin, Tka{\v{c}}ik - Maximum entropy models as a tool for building precise neural controls.pdf:pdf},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {120--126},
title = {{Maximum entropy models as a tool for building precise neural controls}},
volume = {46},
year = {2017}
}
@article{DellaPosta2015,
abstract = {Popular accounts of “lifestyle politics” and “culture wars” suggest that political and ideological divisions extend also to leisure activities, consumption, aesthetic taste, and personal morality. Drawing on a total of 22,572 pairwise correlations from the General Social Survey (1972–2010), the authors provide comprehensive empirical support for the anecdotal accounts. Moreover, most ideological differences in lifestyle cannot be explained by demographic covariates alone. The authors propose a surprisingly simple solution to the puzzle of lifestyle politics. Computational experiments show how the self-reinforcing dynamics of homophily and influence dramatically amplify even very small elective affinities between lifestyle and ideology, producing a stereotypical world of “latte liberals” and “bird-hunting conservatives” much like the one in which we live.},
author = {DellaPosta, Daniel and Shi, Yongren and Macy, Michael},
doi = {10.1086/681254},
isbn = {7737021736},
issn = {0002-9602},
journal = {American Journal of Sociology},
month = {mar},
number = {5},
pages = {1473--1511},
pmid = {17891731},
title = {{Why Do Liberals Drink Lattes?}},
url = {http://www.journals.uchicago.edu/doi/10.1086/681254 http://www.jstor.org/stable/10.1086/681254{\%}5Cnhttp://www.journals.uchicago.edu/doi/10.1086/681254},
volume = {120},
year = {2015}
}
@article{Bialek2015,
abstract = {Theoretical physics is the search for simple and universal mathematical descriptions of the natural world. In contrast, much of modern biology is an exploration of the complexity and diversity of life. For many, this contrast is prima facie evidence that theory, in the sense that physicists use the word, is impossible in a biological context. For others, this contrast serves to highlight a grand challenge. I'm an optimist, and believe (along with many colleagues) that the time is ripe for the emergence of a more unified theoretical physics of biological systems, building on successes in thinking about particular phenomena. In this essay I try to explain the reasons for my optimism, through a combination of historical and modern examples.},
archivePrefix = {arXiv},
arxivId = {1512.08954},
author = {Bialek, William},
eprint = {1512.08954},
file = {:home/kaslu/Documents/Mendeley/2015 - Bialek - Perspectives on theory at the interface of physics and biology.pdf:pdf},
month = {dec},
title = {{Perspectives on theory at the interface of physics and biology}},
url = {http://arxiv.org/abs/1512.08954},
year = {2015}
}
@article{Payzan-LeNestour2013,
abstract = {Uncertainty is an inherent property of the environment and a central feature of models of decision-making and learning. Theoretical propositions suggest that one form, unexpected uncertainty, may be used to rapidly adapt to changes in the environment, while being influenced by two other forms: risk and estimation uncertainty. While previous studies have reported neural representations of estimation uncertainty and risk, relatively little is known about unexpected uncertainty. Here, participants performed adecision-making task while undergoing functional magnetic resonance imaging (fMRI), which, in combination with a Bayesian model-based analysis, enabled us to separately examine each form of uncertainty examined. We found representations of unexpected uncertainty in multiple cortical areas, as well as thenoradrenergic brainstem nucleus locus coeruleus. Other unique cortical regions were found to encode risk, estimation uncertainty, and learning rate. Collectively, these findings support theoretical models in which several formally separable uncertainty computations determine the speed of learning},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Payzan-LeNestour, Elise and Dunne, Simon and Bossaerts, Peter and O'Doherty, JohnP},
doi = {10.1016/j.neuron.2013.04.037},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2013 - Payzan-LeNestour et al. - The Neural Representation of Unexpected Uncertainty during Value-Based Decision Making.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {191--201},
pmid = {23849203},
publisher = {Elsevier},
title = {{The Neural Representation of Unexpected Uncertainty during Value-Based Decision Making}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.04.037},
volume = {79},
year = {2013}
}
@article{Fang2017,
abstract = {{\textcopyright} 2017 The Author(s). People vary considerably in moral reasoning. According to Kohlberg's theory, individuals who reach the highest level of post-conventional moral reasoning judge moral issues based on deeper principles and shared ideals rather than self-interest or adherence to laws and rules. Recent research has suggested the involvement of the brain's frontostriatal reward system in moral judgments and prosocial behaviors. However, it remains unknown whether moral reasoning level is associated with differences in reward system function. Here, we combined arterial spin labeling perfusion and blood oxygen level-dependent functional magnetic resonance imaging and measured frontostriatal reward system activity both at rest and during a sequential risky decision making task in a sample of 64 participants at different levels of moral reasoning. Compared to individuals at the pre-conventional and conventional level of moral reasoning, post-conventional individuals showed increased resting cerebral blood flow in the ventral striatum and ventromedial prefrontal cortex. Cerebral blood flow in these brain regions correlated with the degree of post-conventional thinking across groups. Post-conventional individuals also showed greater task-induced activation in the ventral striatum during risky decision making. These findings suggest that high-level post-conventional moral reasoning is associated with increased activity in the brain's frontostriatal system, regardless of task-dependent or task-independent states.},
author = {Fang, Zhuo and Jung, Wi Hoon and Korczykowski, Marc and Luo, Lijuan and Prehn, Kristin and Xu, Sihua and Detre, John A. and Kable, Joseph W. and Robertson, Diana C. and Rao, Hengyi},
doi = {10.1038/s41598-017-07115-w},
file = {:home/kaslu/Documents/Mendeley/2017 - Fang et al. - Post-conventional moral reasoning is associated with increased ventral striatal activity at rest and during task.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {7105},
title = {{Post-conventional moral reasoning is associated with increased ventral striatal activity at rest and during task}},
url = {http://www.nature.com/articles/s41598-017-07115-w},
volume = {7},
year = {2017}
}
@article{Grinstein2007,
abstract = {We show that (1) an error invalidates the derivation ( Dewar 2005 J. Phys. A: Math. Gen.$\backslash$r [/0305-4470/38/21/l01] 38 L371 ) of the maximum entropy production (MaxEP) principle for systems far$\backslash$r from equilibrium, for which the constitutive relations are nonlinear; and (2) the claim ( Dewar 2003$\backslash$r J. Phys. A: Math. Gen. [/0305-4470/36/3/303] 36 631 ) that the phenomenon of 'self-organized$\backslash$r criticality' is a consequence of MaxEP for slowly driven systems is unjustified.},
author = {Grinstein, G and Linsker, R},
doi = {10.1088/1751-8113/40/31/N01},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and Theoretical},
number = {31},
pages = {9717--9720},
title = {{Comments on a derivation and application of the ‘maximum entropy production' principle}},
url = {http://stacks.iop.org/1751-8121/40/i=31/a=N01?key=crossref.a3ac3576d036ffe766f1f90b553d7ee4},
volume = {40},
year = {2007}
}
@article{Neirotti2017,
abstract = {We developed a statistical mechanics approach to the problem of opinion formation in interacting agents, constrained by a set of social rules, {\$}B{\$}. To provide the agents with an adaptive quality, we represented both the social agents and the social rule by perceptrons. For fully connected societies we find that if the agents' interaction is weak, all agents adapt to the social rule {\$}B{\$}, with which they form a consensus; but if the interaction is sufficiently strong a consensus is built against the established {\$}status{\$} {\$}quo{\$}. This behavior is observed for all temperatures {\$}T{\$} and for all values of the agents' interaction parameter {\$}H{\_}{\{}0{\}}{\$}, except in the limit {\$}T\backslashto\backslashinfty{\$} or when the interaction reaches the critical value {\$}H{\_}{\{}0{\}}=1,{\$} where no consensus is formed. The agents follow a path where, after a time {\$}\backslashalpha{\_}{\{}c{\}},{\$} they disregard their peers' opinions on socially neutral issues and reach a full consensus at time {\$}\backslashalpha{\_}{\{}d{\}}{\textgreater}\backslashalpha{\_}{\{}c{\}}.{\$} The measure of time {\$}\backslashalpha{\$} is proportional to the volume of information provided to the agents.},
archivePrefix = {arXiv},
arxivId = {1612.06588},
author = {Neirotti, Juan Pablo},
doi = {10.1103/PhysRevE.95.062305},
eprint = {1612.06588},
file = {:home/kaslu/Documents/Mendeley/2017 - Neirotti - Consensus formation times in anisotropic societies.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {jun},
number = {6},
pages = {062305},
title = {{Consensus formation times in anisotropic societies}},
url = {http://arxiv.org/abs/1612.06588 http://link.aps.org/doi/10.1103/PhysRevE.95.062305},
volume = {95},
year = {2017}
}
@article{Miller2017b,
abstract = {Planning can be defined as a process of action selection that leverages an internal model of the environment. Such models provide information about the likely outcomes that will follow each selected action, and their use is a key function underlying complex adaptive behavior. However, the neural mechanisms supporting this ability remain poorly understood. In the present work, we adapt for rodents recent advances from work on human planning, presenting for the first time a task for animals which produces many trials of planned behavior per session, allowing the experimental toolkit available for use in trial-by-trial tasks for rodents to be applied to the study of planning. We take advantage of one part of this toolkit to address a perennially controversial issue in planning research: the role of the dorsal hippocampus. Although prospective representations in the hippocampus have been proposed to support model-based planning, intact planning in hippocampally damaged animals has been observed in a number of assays. Combining formal algorithmic behavioral analysis with muscimol inactivation, we provide the first causal evidence directly linking dorsal hippocampus with planning behavior. The results reported, and the methods introduced, open the door to new and more detailed investigations of the neural mechanisms of planning, in the hippocampus and throughout the brain.},
author = {Miller, Kevin J. and Botvinick, Matthew M. and Brody, Carlos D.},
doi = {10.1038/nn.4613},
file = {:home/kaslu/Documents/Mendeley/2017 - Miller, Botvinick, Brody - Dorsal hippocampus contributes to model-based planning(2).pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {jul},
number = {9},
pages = {1269--1276},
pmid = {28758995},
publisher = {Nature Research},
title = {{Dorsal hippocampus contributes to model-based planning}},
url = {http://www.nature.com/doifinder/10.1038/nn.4613},
volume = {20},
year = {2017}
}
@article{Reents1998,
author = {Reents, G and Urbanczik, R},
doi = {10.1103/PhysRevLett.80.5445},
file = {:home/kaslu/Documents/Mendeley/1998 - Reents, Urbanczik - Self-Averaging and On-Line Learning.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {jun},
number = {24},
pages = {5445--5448},
title = {{Self-Averaging and On-Line Learning}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.80.5445},
volume = {80},
year = {1998}
}
@article{Mazurek2003,
abstract = {Decisions based on uncertain information may benefit from an accumulation of information over time. We asked whether such an accumulation process may underlie decisions about the direction of motion in a random dot kinetogram. To address this question we developed a computational model of the decision process using ensembles of neurons whose spiking activity mimics neurons recorded in the extrastriate visual cortex (area MT or V5) and a sensorimotor association area of the parietal lobe (area LIP). The model instantiates the hypothesis that neurons in sensorimotor association areas compute the time integral of sensory signals from the visual cortex, construed as evidence for or against a proposition, and that the decision is made when the integrated evidence reaches a threshold. The model explains a variety of behavioral and physiological measurements obtained from monkeys.},
author = {Mazurek, Mark E. and Roitman, Jamie D. and Ditterich, Jochen and Shadlen, Michael N.},
doi = {10.1093/cercor/bhg097},
file = {:home/kaslu/Documents/Mendeley/2003 - Mazurek et al. - A Role for Neural Integrators in Perceptual Decision Making.pdf:pdf},
isbn = {1047-3211 (Print)},
issn = {10473211},
journal = {Cerebral Cortex},
number = {11},
pages = {1257--1269},
pmid = {14576217},
title = {{A Role for Neural Integrators in Perceptual Decision Making}},
volume = {13},
year = {2003}
}
@article{Potters1994,
abstract = {The nervous system solves a wide variety of problems in signal processing. In many cases the performance of the nervous system is so good that it apporaches fundamental physical limits, such as the limits imposed by diffraction and photon shot noise in vision. In this paper we show how to use the language of statistical field theory to address and solve problems in signal processing, that is problems in which one must estimate some aspect of the environment from the data in an array of sensors. In the field theory formulation the optimal estimator can be written as an expectation value in an ensemble where the input data act as external field. Problems at low signal-to-noise ratio can be solved in perturbation theory, while high signal-to-noise ratios are treated with a saddle-point approximation. These ideas are illustrated in detail by an example of visual motion estimation which is chosen to model a problem solved by the fly's brain. In this problem the optimal estimator has a rich structure, adapting to various parameters of the environment such as the mean-square contrast and the correlation time of contrast fluctuations. This structure is in qualitative accord with existing measurements on motion sensitive neurons in the fly's brain, and we argue that the adaptive properties of the optimal estimator may help resolve conlficts among different interpretations of these data. Finally we propose some crucial direct tests of the adaptive behavior.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9401072},
author = {Potters, Marc and Bialek, William},
doi = {10.1051/jp1:1994219},
eprint = {9401072},
file = {:home/kaslu/Documents/Mendeley/1994 - Potters, Bialek - Statistical mechanics and visual signal processing.pdf:pdf},
issn = {1155-4304},
journal = {Journal de Physique I},
month = {nov},
number = {11},
pages = {1755--1775},
primaryClass = {cond-mat},
title = {{Statistical mechanics and visual signal processing}},
url = {http://arxiv.org/abs/cond-mat/9401072 http://dx.doi.org/10.1051/jp1:1994219 http://www.edpsciences.org/10.1051/jp1:1994219},
volume = {4},
year = {1994}
}
@article{Marblestone2016,
abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
author = {Marblestone, Adam Henry and Wayne, Greg and Kording, Konrad P.},
doi = {10.3389/fncom.2016.00094},
file = {:home/kaslu/Documents/Mendeley/2016 - Marblestone, Wayne, Kording - Toward an Integration of Deep Learning and Neuroscience.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {cognitive architecture,cost functions,neural networks,neuroscience},
month = {sep},
pages = {94},
title = {{Toward an Integration of Deep Learning and Neuroscience}},
url = {http://journal.frontiersin.org/Article/10.3389/fncom.2016.00094/abstract},
volume = {10},
year = {2016}
}
@article{Gleeson2017a,
abstract = {Modern neuroscience increasingly relies on custom-developed software, but much of this is not being made available to the wider community. A group of researchers are pledging to make code they produce for data analysis and modeling open source, and are actively encouraging their colleagues to follow suit. Should custom software that is essential to reproducing results of publications be publicly released? Arguing that it must, Gleeson et al. have, together with other researchers, signed a commitment to releasing their code and will ask the same upon peer review.},
author = {Gleeson, Padraig and Davison, Andrew P. and Silver, R. Angus and Ascoli, Giorgio A.},
doi = {10.1016/j.neuron.2017.10.013},
file = {:home/kaslu/Documents/Mendeley/2017 - Gleeson et al. - A Commitment to Open Source in Neuroscience.pdf:pdf},
issn = {10974199},
journal = {Neuron},
number = {5},
pages = {964--965},
pmid = {29216458},
publisher = {Elsevier Inc.},
title = {{A Commitment to Open Source in Neuroscience}},
url = {https://doi.org/10.1016/j.neuron.2017.10.013},
volume = {96},
year = {2017}
}
@article{Ekanadham2014,
abstract = {Automatic identification of action potentials from one or more extracellular electrode recordings is generally achieved by clustering similar segments of the measured voltage trace, a method that fails (or requires substantial human intervention) for spikes whose waveforms overlap. We formulate the problem in terms of a simple probabilistic model, and develop a unified method to identify spike waveforms along with continuous-valued estimates of their arrival times, even in the presence of overlap. Specifically, we make use of a recent algorithm known as Continuous Basis Pursuit for solving linear inverse problems in which the component occurrences are sparse and are at arbitrary continuous-valued times. We demonstrate significant performance improvements over current state-of-the-art clustering methods for four simulated and two real data sets with ground truth, each of which has previously been used as a benchmark for spike sorting. In addition, performance of our method on each of these data sets surpasses that of the best possible clustering method (i.e., one that is specifically optimized to minimize errors on each data set). Finally, the algorithm is almost completely automated, with a computational cost that scales well for multi-electrode arrays. ?? 2013 Elsevier B.V.},
author = {Ekanadham, Chaitanya and Tranchina, Daniel and Simoncelli, Eero P.},
doi = {10.1016/j.jneumeth.2013.10.001},
file = {:home/kaslu/Documents/Mendeley/2014 - Ekanadham, Tranchina, Simoncelli - A unified framework and method for automatic neural spike identification.pdf:pdf},
isbn = {9781618395993},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Action potential,Clustering,Multi-electrode,Neural spike identification,Spike detection,Spike sorting},
month = {jan},
pages = {47--55},
pmid = {24184059},
title = {{A unified framework and method for automatic neural spike identification}},
url = {http://www.sciencedirect.com/science/article/pii/S0165027013003415 http://linkinghub.elsevier.com/retrieve/pii/S0165027013003415 http://dx.doi.org/10.1088/1751-8113/44/8/085201},
volume = {222},
year = {2014}
}
@article{Gershman2015,
abstract = {After growing up together, and mostly growing apart in the second half of the 20th century, the fields of artificial intelligence (AI), cognitive science, and neuroscience are reconverging on a shared view of the computational foundations of intelligence that promotes valuable cross-disciplinary exchanges on questions, methods, and results. We chart advances over the past several decades that address challenges of perception and action under uncertainty through the lens of computation. Advances include the development of representations and inferential procedures for large-scale probabilistic inference and machinery for enabling reflection and decisions about tradeoffs in effort, precision, and timeliness of computations. These tools are deployed toward the goal of computational rationality: identifying decisions with highest expected utility, while taking into consideration the costs of computation in complex real-world problems in which most relevant calculations can only be approximated. We highlight key concepts with examples that show the potential for interchange between computer science, cognitive science, and neuroscience.},
author = {Gershman, Samuel J. and Horvitz, Eric J. and Tenenbaum, Joshua B.},
doi = {10.1126/science.aac6076},
file = {:home/kaslu/Documents/Mendeley/2015 - Gershman, Horvitz, Tenenbaum - Computational rationality A converging paradigm for intelligence in brains, minds, and machines.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {jul},
number = {6245},
pages = {273--278},
pmid = {26185246},
title = {{Computational rationality: A converging paradigm for intelligence in brains, minds, and machines}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aac6076},
volume = {349},
year = {2015}
}
@article{Anholt2012,
abstract = {Aggression mediates competition for food, mating partners, and habitats and, among social animals, establishes stable dominance hierarchies. In humans, abnormal aggression is a hallmark of neuropsychiatric disorders and can be elicited by environmental factors acting on an underlying genetic susceptibility. Identifying the genetic architecture that predisposes to aggressive behavior in people is challenging because of difficulties in quantifying the phenotype, genetic heterogeneity, and uncontrolled environmental conditions. Studies on mice have identified single-gene mutations that result in hyperaggression, contingent on genetic background. These studies can be complemented by systems genetics approaches in Drosophila melanogaster, in which mutational analyses together with genome-wide transcript analyses, artificial selection studies, and genome-wide analysis of epistasis have revealed that a large segment of the genome contributes to the manifestation of aggressive behavior with widespread epistatic interactions. Comparative genomic analyses based on the principle of evolutionary conservation are needed to enable a complete dissection of the neurogenetic underpinnings of this universal fitness trait.},
author = {Anholt, Robert R.H. and Mackay, Trudy F.C.},
doi = {10.1146/annurev-genet-110711-155514},
isbn = {1545-2948 (Electronic)$\backslash$r0066-4197 (Linking)},
issn = {0066-4197},
journal = {Annual Review of Genetics},
month = {dec},
number = {1},
pages = {145--164},
pmid = {22934647},
title = {{Genetics of Aggression}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22934647 http://www.annualreviews.org/doi/10.1146/annurev-genet-110711-155514},
volume = {46},
year = {2012}
}
@article{Bialek2012,
abstract = {Flocking is a typical example of emergent collective behavior, where interactions between individuals produce collective patterns on the large scale. Here we show how a quantitative microscopic theory for directional ordering in a flock can be derived directly from field data. We construct the minimally structured (maximum entropy) model consistent with experimental correlations in large flocks of starlings. The maximum entropy model shows that local, pairwise interactions between birds are sufficient to correctly predict the propagation of order throughout entire flocks of starlings, with no free parameters. We also find that the number of interacting neighbors is independent of flock density, confirming that interactions are ruled by topological rather than metric distance. Finally, by comparing flocks of different sizes, the model correctly accounts for the observed scale invariance of long-range correlations among the fluctuations in flight direction.},
author = {Bialek, William and Cavagna, Andrea and Giardina, Irene and Mora, Thierry and Silvestri, Edmondo and Viale, Massimiliano and Walczak, Aleksandra M},
doi = {10.1073/pnas.1118633109},
file = {:home/kaslu/Documents/Mendeley/2012 - Bialek et al. - Statistical mechanics for natural flocks of birds.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Biomechanical Phenomena,Entropy,Flight, Animal,Flight, Animal: physiology,Models, Biological,Models, Statistical,Starlings,Starlings: physiology},
month = {mar},
number = {13},
pages = {4786--91},
pmid = {22427355},
title = {{Statistical mechanics for natural flocks of birds.}},
url = {http://www.pnas.org/cgi/content/long/109/13/4786},
volume = {109},
year = {2012}
}
@article{Friston2015,
abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes- optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and FitzGerald, Thomas and Pezzulo, Giovanni},
doi = {10.1080/17588928.2015.1020053},
file = {:home/kaslu/Documents/Mendeley/2015 - Friston et al. - Active inference and epistemic value.pdf:pdf},
isbn = {1758-8936 (Electronic)$\backslash$r1758-8928 (Linking)},
issn = {1758-8928},
journal = {Cognitive Neuroscience},
keywords = {Active inference,Agency,Bayesian inference,Bayesian surprise,Bounded rationality,Epistemic value,Exploitation,Exploration,Free energy,Information gain,Utility theory},
number = {April},
pages = {150217111908007},
pmid = {25689102},
publisher = {Routledge},
title = {{Active inference and epistemic value}},
url = {http://www.tandfonline.com/doi/abs/10.1080/17588928.2015.1020053},
volume = {6},
year = {2015}
}
@article{Latimer2016,
abstract = {Latimeret al (Reports, 10 July 2015, p. 184) claim that during perceptual decision formation, parietal neurons undergo one-time, discrete steps in firing rate instead of gradual changes that represent the accumulation of evidence. However, that conclusion rests on unsubstantiated assumptions about the time window of evidence accumulation, and their stepping model cannot explain existing data as effectively as evidence-accumulation models.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.7245v1},
author = {Latimer, K. W. and Yates, J. L. and Meister, M. L. R. and Huk, Alexander C. and Pillow, Jonathan W.},
doi = {10.1126/science.aad3596},
eprint = {arXiv:1402.7245v1},
file = {:home/kaslu/Documents/Mendeley/2016 - Latimer et al. - Response to Comment on Single-trial spike trains in parietal cortex reveal discrete steps during decision-making.pdf:pdf},
isbn = {10.1126/science.aaa4056},
issn = {0036-8075},
journal = {Science},
number = {6280},
pages = {1406--1406},
pmid = {27013723},
title = {{Response to Comment on "Single-trial spike trains in parietal cortex reveal discrete steps during decision-making"}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aad3596},
volume = {351},
year = {2016}
}
@article{The2007,
author = {Wilson, David Sloan and Wilson, Edward O.},
doi = {10.1086/522809},
issn = {0033-5770},
journal = {The Quarterly Review of Biology},
keywords = {altruism,cooperation,eusociality,group selection,human evolution,inclusive tness theory,kin selection,major transitions,multilevel selection,pluralism,sociobiology},
month = {dec},
number = {4},
pages = {327--348},
title = {{Rethinking the Theoretical Foundation of Sociobiology}},
url = {http://www.journals.uchicago.edu/doi/10.1086/522809},
volume = {82},
year = {2007}
}
@article{Mardia1975,
abstract = {Directional data analysis is emerging as an important area of statistics. Within the past two decades, various new techniques have appeared, mostly to meet the needs of scientific workers dealing with directional data. The paper first introduces the two basic models for the multi-dimensional case known as the von Mises-Fisher distribution and the Bingham distribution. Their sampling distribution theory depends heavily on the isotropic case and some developments are discussed. An optimum property of an important test for the von Mises-Fisher case is established. A nonparametric test is proposed for the hypothesis of independence for observations on a torus. In addition to some numerical examples on the preceding topics, five case studies are given which illuminate the power of this new methodology. The case studies are concerned with cancer research, origins of comets, arrival times of patients, navigational problems and biological rhythms. Some unsolved problems are also indicated.},
author = {Mardia, K},
file = {:home/kaslu/Documents/Mendeley/1975 - Mardia - Statistics of Directional Data.pdf:pdf},
isbn = {0124711502},
issn = {0035-9246},
journal = {Journal Of The Royal Statistical Society Series B-Methodological},
keywords = {arrival times,bingham distribution,biological rhythms,bird,cancer cells,characterization,correlation on,directional data,independence,navigation,origin of comets,random,torus,uniform scores,von mises-fisher distribution,walk},
number = {3},
pages = {349--393},
title = {{Statistics of Directional Data}},
volume = {37},
year = {1975}
}
@article{Doya1999,
abstract = {The classical notion that the cerebellum and the basal ganglia are dedicated to motor control is under dispute given increasing evidence of their involvement in non-motor functions. Is it then impossible to characterize the functions of the cerebellum, the basal ganglia and the cerebral cortex in a simplistic manner? This paper presents a novel view that their computational roles can be characterized not by asking what are the “goals” of their computation, such as motor or sensory, but by asking what are the “methods” of their computation, specifically, their learning algorithms. There is currently enough anatomical, physiological, and theoretical evidence to support the hypotheses that the cerebellum is a specialized organism for supervised learning, the basal ganglia are for reinforcement learning, and the cerebral cortex is for unsupervised learning. This paper investigates how the learning modules specialized for these three kinds of learning can be assembled into goal-oriented behaving systems. In general, supervised learning modules in the cerebellum can be utilized as “internal models” of the environment. Reinforcement learning modules in the basal ganglia enable action selection by an “evaluation” of environmental states. Unsupervised learning modules in the cerebral cortex can provide statistically efficient representation of the states of the environment and the behaving system. Two basic action selection architectures are shown, namely, reactive action selection and predictive action selection. They can be implemented within the anatomical constraint of the network linking these structures. Furthermore, the use of the cerebellar supervised learning modules for state estimation, behavioral simulation, and encapsulation of learned skill is considered. Finally, the usefulness of such theoretical frameworks in interpreting brain imaging data is demonstrated in the paradigm of procedural learning. ?1999 Published by Elsevier Science Ltd. All rights reserved.},
author = {Doya, Kenji},
doi = {10.1016/S0893-6080(99)00046-5},
file = {:home/kaslu/Documents/Mendeley/1999 - Doya - What are the computations of the cerebellum, the basal ganglia and the cerebral cortex.pdf:pdf},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {model-free,reinforcement learning,sequence learning,state prediction,supervised learning,unsupervised learning,value function},
month = {oct},
number = {7-8},
pages = {961--974},
pmid = {12662639},
title = {{What are the computations of the cerebellum, the basal ganglia and the cerebral cortex?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608099000465},
volume = {12},
year = {1999}
}
@article{VandenBerg2016,
abstract = {Demanding tasks often require a series of decisions to reach a goal. Recent progress in perceptual decision-making has served to unite decision accuracy, speed, and confidence in a common framework of bounded evidence accumulation, furnishing a platform for the study of such multi-stage decisions. In many instances, the strategy applied to each decision, such as the speed-accuracy trade-off, ought to depend on the accuracy of the previous decisions. However, as the accuracy of each decision is often unknown to the decision maker, we hypothesized that subjects may carry forward a level of confidence in previous decisions to affect subsequent decisions. Subjects made two perceptual decisions sequentially and were rewarded only if they made both correctly. The speed and accuracy of individual decisions were explained by noisy evidence accumulation to a terminating bound. We found that subjects adjusted their speed-accuracy setting by elevating the termination bound on the second decision in proportion to their confidence in the first. The findings reveal a novel role for confidence and a degree of flexibility, hitherto unknown, in the brain's ability to rapidly and precisely modify the mechanisms that control the termination of a decision.},
author = {van den Berg, Ronald and Zylberberg, Ariel and Kiani, Roozbeh and Shadlen, Michael N. and Wolpert, Daniel M.},
doi = {10.1016/j.cub.2016.10.021},
file = {:home/kaslu/Documents/Mendeley/2016 - van den Berg et al. - Confidence Is the Bridge between Multi-stage Decisions.pdf:pdf},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
keywords = {confidence,decision bound,decision-making,psychophysics,reaching,sensorimotor control,sequential choice,speed-accuracy trade-off},
number = {23},
pages = {3157--3168},
pmid = {27866891},
publisher = {Elsevier Ltd.},
title = {{Confidence Is the Bridge between Multi-stage Decisions}},
url = {http://dx.doi.org/10.1016/j.cub.2016.10.021},
volume = {26},
year = {2016}
}
@article{Bassett2017,
abstract = {Despite substantial recent progress, our understanding of the principles and mechanisms underlying complex brain function and cognition remains incomplete. Network neuroscience proposes to tackle these enduring challenges. Approaching brain structure and function from an explicitly integrative perspective, network neuroscience pursues new ways to map, record, analyze and model the elements and interactions of neurobiological systems. Two parallel trends drive the approach: the availability of new empirical tools to create comprehensive maps and record dynamic patterns among molecules, neurons, brain areas and social systems; and the theoretical framework and computational tools of modern network science. The convergence of empirical and computational advances opens new frontiers of scientific inquiry, including network dynamics, manipulation and control of brain networks, and integration of network processes across spatiotemporal domains. We review emerging trends in network neuroscience and attempt to chart a path toward a better understanding of the brain as a multiscale networked system.},
author = {Bassett, Danielle S. and Sporns, Olaf},
doi = {10.1038/nn.4502},
file = {:home/kaslu/Documents/Mendeley/2017 - Bassett, Sporns - Network neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {353--364},
title = {{Network neuroscience}},
url = {http://www.nature.com/doifinder/10.1038/nn.4502},
volume = {20},
year = {2017}
}
@article{QuianQuiroga2012,
abstract = {Intracranial recordings in subjects suffering from intractable epilepsy — made during their evaluation for an eventual surgical removal of the epileptic focus — have allowed the extraordinary opportunity to study the firing of multiple single neurons in awake and behaving human subjects. These studies have shown that neurons in the human medial temporal lobe respond in a remarkably selective and abstract manner to particular persons or objects, such as Jennifer Aniston, Luke Skywalker or the Tower of Pisa. These neurons have been named ‘Jennifer Aniston neurons' or, more recently, ‘concept cells'. I argue that the sparse, explicit and abstract representation of these neurons is crucial for memory functions, such as the creation of associations and the transition between related concepts that leads to episodic memories and the flow of consciousness.},
author = {Quiroga, Rodrigo Quian},
doi = {10.1038/nrn3251},
file = {:home/kaslu/Documents/Mendeley/2012 - Quian Quiroga - Concept cells the building blocks of declarative memory functions.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
number = {8},
pages = {587--597},
pmid = {22760181},
title = {{Concept cells: the building blocks of declarative memory functions}},
volume = {13},
year = {2012}
}
@article{Sitaram2016,
abstract = {Neurofeedback is a psychophysiological procedure in which online feedback of neural activation is provided to the participant for the purpose of self-regulation. Learning control over specific neural substrates has been shown to change specific behaviours. As a progenitor of brain-machine interfaces, neurofeedback has provided a novel way to investigate brain function and neuroplasticity. In this Review, we examine the mechanisms underlying neurofeedback, which have started to be uncovered. We also discuss how neurofeedback is being used in novel experimental and clinical paradigms from a multidisciplinary perspective, encompassing neuroscientific, neuroengineering and learning-science viewpoints.},
author = {Sitaram, Ranganatha and Ros, Tomas and Stoeckel, Luke and Haller, Sven and Scharnowski, Frank and Lewis-Peacock, Jarrod and Weiskopf, Nikolaus and Blefari, Maria Laura and Rana, Mohit and Oblak, Ethan and Birbaumer, Niels and Sulzer, James},
doi = {10.1038/nrn.2016.164},
file = {:home/kaslu/Documents/Mendeley/2016 - Sitaram et al. - Closed-loop brain training the science of neurofeedback.pdf:pdf},
isbn = {1471-0048 (Electronic) 1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {2},
pages = {86--100},
pmid = {28003656},
publisher = {Nature Publishing Group},
title = {{Closed-loop brain training: the science of neurofeedback}},
url = {http://www.nature.com/doifinder/10.1038/nrn.2016.164},
volume = {18},
year = {2016}
}
@article{Goris2017,
abstract = {Responses of individual task-relevant sensory neurons can predict monkeys' trial-by-trial choices in perceptual decision-making tasks. Choice-correlated activity has been interpreted as evidence that the responses of these neurons are causally linked to perceptual judg-ments. To further test this hypothesis, we studied responses of orientation-selective neurons in V1 and V2 while two macaque monkeys performed a fine orientation discrimination task. Although both animals exhibited a high level of neuronal and behavioral sensitivity, only one exhibited choice-correlated activity. Surprisingly, this correlation was negative: when a neuron fired more vigorously, the animal was less likely to choose the orientation preferred by that neuron. Moreover, choice-correlated activity emerged late in the trial, earlier in V2 than in V1, and was correlated with anticipatory signals. Together, these results suggest that choice-correlated activity in task-relevant sensory neurons can reflect postdecision modulatory signals.},
author = {Goris, Robbe L.T. and Ziemba, Corey M. and Stine, Gabriel M. and Simoncelli, Eero P. and Movshon, J. Anthony},
doi = {10.1523/JNEUROSCI.3331-16.2017},
file = {:home/kaslu/Documents/Mendeley/2017 - Goris et al. - Dissociation of Choice Formation and Choice-Correlated Activity in Macaque Visual Cortex.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {choice probability,correlates with variability in,decision-making,different,difficult sensory discrimination,neurons driven by the,perceptual judgments,repeated presentations of the,same stimulus can elicit,significance statement,the activity of sensory,this behavioral variability often,v1,v2,when observers perform a},
number = {20},
pages = {5195--5203},
title = {{Dissociation of Choice Formation and Choice-Correlated Activity in Macaque Visual Cortex}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3331-16.2017},
volume = {37},
year = {2017}
}
@article{Fineberg2016,
author = {Fineberg, S. K. and Corlett, P. R.},
doi = {10.1080/13546805.2015.1136206},
issn = {1354-6805},
journal = {Cognitive Neuropsychiatry},
month = {jan},
number = {1},
pages = {73--89},
title = {{The doxastic shear pin: delusions as errors of learning and memory}},
url = {http://www.tandfonline.com/doi/full/10.1080/13546805.2015.1136206},
volume = {21},
year = {2016}
}
@article{Grangier1986a,
author = {Grangier, P. and Roger, G. and Aspect, a.},
doi = {10.1111/j.1749-6632.1986.tb12413.x},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
number = {1 New Technique},
pages = {98--107},
title = {{A New Light on Single Photon Interferences}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1986.tb12413.x},
volume = {480},
year = {1986}
}
@article{Cain2012,
abstract = {Decision making demands the accumulation of sensory evidence over time. Questions remain about how this occurs, but recent years have seen progress on several fronts. The first concerns when optimal accumulation of evidence coincides with the simplest method of accumulating neural activity: summation over time. The second involves what computations the brain might perform when summation is difficult due to imprecision in neural circuits or is suboptimal due to uncertainty or variability in how evidence arrives. Finally, the third concerns sources of noise in decision circuits. Empirical studies have better constrained the extent of this noise, and modeling work is helping to clarify its possible origins.},
archivePrefix = {arXiv},
arxivId = {arXiv:1207.5159v1},
author = {Cain, Nicholas and Shea-Brown, Eric},
doi = {10.1016/j.conb.2012.04.013},
eprint = {arXiv:1207.5159v1},
file = {:home/kaslu/Documents/Mendeley/2012 - Cain, Shea-Brown - Computational models of decision making Integration, stability, and noise.pdf:pdf},
isbn = {1873-6882 (Electronic)$\backslash$r0959-4388 (Linking)},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {1047--1053},
pmid = {22591667},
publisher = {Elsevier Ltd},
title = {{Computational models of decision making: Integration, stability, and noise}},
url = {http://dx.doi.org/10.1016/j.conb.2012.04.013},
volume = {22},
year = {2012}
}
@article{Graves2016,
author = {Graves, Alex and Wayne, Greg and Et al.},
doi = {10.1038/nature20101},
issn = {1476-4687},
journal = {Nature (in Press)},
month = {oct},
number = {7626},
pages = {471--476},
publisher = {Nature Research},
title = {{Hybrid computing using a neural network with dynamic external memory}},
url = {http://www.nature.com/doifinder/10.1038/nature20101},
volume = {538},
year = {2016}
}
@article{Graham2010,
abstract = {Social psychologists have often followed other scientists in treating religiosity primarily as a set of beliefs held by individuals. But, beliefs are only one facet of this complex and multidimensional construct. The authors argue that social psychology can best contribute to scholarship on religion by being relentlessly social. They begin with a social-functionalist approach in which beliefs, rituals, and other aspects of religious practice are best understood as means of creating a moral community. They discuss the ways that religion is intertwined with five moral foundations, in particular the group-focused “binding” foundations of Ingroup/loyalty, Authority/respect, Purity/sanctity. The authors use this theoretical perspective to address three mysteries about religiosity, including why religious people are happier, why they are more charitable, and why most people in the world are religious.},
author = {Graham, Jesse and Haidt, Jonathan},
doi = {10.1177/1088868309353415},
file = {:home/kaslu/Documents/Mendeley/2010 - Graham, Haidt - Beyond Beliefs Religions Bind Individuals Into Moral Communities.pdf:pdf},
isbn = {1088-8683},
issn = {1088-8683},
journal = {Personality and Social Psychology Review},
keywords = {culture,group processes,if a lot of,it,know,morality,motion surrounds a single,object,religion,s often hard to,well-being,when viewing complex phenomena,where to look},
number = {1},
pages = {140--150},
pmid = {20089848},
title = {{Beyond Beliefs: Religions Bind Individuals Into Moral Communities}},
url = {http://journals.sagepub.com/doi/10.1177/1088868309353415},
volume = {14},
year = {2010}
}
@article{Skilling2006,
abstract = {Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional by-product, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the “nested” contours of likelihood, and not on the likelihood values. This invariance (over monotonic relabelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Skilling, John},
doi = {10.1214/06-BA127},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2006 - Skilling - Nested sampling for general Bayesian computation.pdf:pdf},
isbn = {9788578110796},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Algorithm,Annealing,Bayesian computation,Evidence,Marginal likelihood,Model selection,Nest,Phase change},
number = {4},
pages = {833--860},
pmid = {25246403},
title = {{Nested sampling for general Bayesian computation}},
volume = {1},
year = {2006}
}
@article{Tesileanu2017a,
abstract = {Trial-and-error learning requires evaluating variable actions and reinforcing successful variants. In songbirds, vocal exploration is induced by LMAN, the output of a basal ganglia-related circuit that also contributes a corrective bias to the vocal output. This bias is gradually consolidated in RA, a motor cortex analogue downstream of LMAN. We develop a new model of such two-stage learning. Using stochastic gradient descent, we derive how the activity in ‘tutor' circuits (e.g., LMAN) should match plasticity mechanisms in ‘student' circuits (e.g., RA) to achieve efficient learning. We further describe a reinforcement learning framework through which the tutor can build its teaching signal. We show that mismatches between the tutor signal and the plasticity mechanism can impair learning. Applied to birdsong, our results predict the temporal structure of the corrective bias from LMAN given a plasticity rule in RA. Our framework can be applied predictively to other paired brain areas showing two-stage learning.},
author = {Teşileanu, Tiberiu and {\"{O}}lveczky, Bence and Balasubramanian, Vijay},
doi = {10.7554/eLife.20944},
file = {:home/kaslu/Documents/Mendeley/2017 - Teşileanu, {\"{O}}lveczky, Balasubramanian - Rules and mechanisms for efficient two-stage learning in neural circuits.pdf:pdf},
issn = {2050-084X},
journal = {eLife},
month = {apr},
pages = {1--29},
title = {{Rules and mechanisms for efficient two-stage learning in neural circuits}},
url = {https://elifesciences.org/articles/20944},
volume = {6},
year = {2017}
}
@inproceedings{Caticha2015b,
abstract = {To what extent can we distinguish one probability distribution from another? Are there quantitative measures of distinguishability? The goal of this tutorial is to approach such questions by introducing the notion of the "distance" between two probability distributions and exploring some basic ideas of such an "information geometry".},
archivePrefix = {arXiv},
arxivId = {1412.5633},
author = {Caticha, Ariel},
doi = {10.1063/1.4905960},
eprint = {1412.5633},
file = {:home/kaslu/Documents/Mendeley/2015 - Caticha - The basics of information geometry.pdf:pdf},
month = {dec},
pages = {15--26},
title = {{The basics of information geometry}},
url = {http://arxiv.org/abs/1412.5633 http://scitation.aip.org/content/aip/proceeding/aipcp/10.1063/1.4905960 http://aip.scitation.org/doi/abs/10.1063/1.4905960},
year = {2015}
}
@article{Wichmann2001,
abstract = {The psychometric function relates an observer' s performance to an independent variable, usually some physical quantity of a stimulus in a psychophysical task. This paper, together with its companion paper (Wichmann {\&} Hill, 2001), describes an integrated approach to (1) fitting psychometric functions, (2) as-sessing the goodness of fit, and (3) providing confidence intervals for the function' s parameters and other estimates derived from them, for the purposes of hypothesis testing. The present paper deals with the first two topics, describing a constrained maximum-likelihood method of parameter estimation and develop-ing several goodness-of-fit tests. Using Monte Carlo simulations, we deal with two specific difficulties that arise when fitting functions to psychophysical data. First, we note that human observers are prone to stimulus-independent errors (or lapses). We show that failure to account for this can lead to serious bi-ases in estimates of the psychometric function' s parameters and illustrate how the problem may be over-come. Second, we note that psychophysical data sets are usually rather small by the standards required by most of the commonly applied statistical tests. We demonstrate the potential errors of applying tradi-tional c2methods to psychophysical data and advocate use of Monte Carlo resampling techniques that do not rely on asymptotic theory. We have made available the software to implement our methods.},
archivePrefix = {arXiv},
arxivId = {1003.3921v1},
author = {Wichmann, Felix A. and Hill, N. Jeremy},
doi = {10.3758/BF03194544},
eprint = {1003.3921v1},
file = {:home/kaslu/Documents/Mendeley/2001 - Wichmann, Hill - The psychometric function I. Fitting, sampling, and goodness of fit.pdf:pdf},
isbn = {0031-5117 (Print)$\backslash$n0031-5117 (Linking)},
issn = {0031-5117},
journal = {Perception {\&} Psychophysics},
number = {8},
pages = {1293--1313},
pmid = {11800458},
title = {{The psychometric function: I. Fitting, sampling, and goodness of fit}},
url = {http://www.springerlink.com/index/10.3758/BF03194544},
volume = {63},
year = {2001}
}
@article{Wang2015,
author = {Kass, Robert E. and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N. and Diekman, Casey O. and Diesmann, Markus and Doiron, Brent and Eden, Uri T. and Fairhall, Adrienne L. and Fiddyment, Grant M. and Fukai, Tomoki and Gr{\"{u}}n, Sonja and Harrison, Matthew T. and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J. and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G. and Shea-Brown, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M. and Kramer, Mark A.},
doi = {10.1146/annurev-statistics-041715-033733},
file = {:home/kaslu/Documents/Mendeley/2018 - Kass et al. - Computational Neuroscience Mathematical and Statistical Perspectives.pdf:pdf},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
month = {mar},
number = {1},
pages = {annurev--statistics--041715--033733},
title = {{Computational Neuroscience: Mathematical and Statistical Perspectives}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-statistics-041715-033733},
volume = {5},
year = {2018}
}
@article{DeWeese1994,
abstract = {Summary. -- Recent experiments show that the neural codes at work in a wide range of creatures share some common features. At first sight, these observations seem unrelated. However, we show that all of these features of},
author = {DeWeese, M. and Bialek, William},
doi = {10.1007/BF02451830},
file = {:home/kaslu/Documents/Mendeley/1995 - DeWeese, Bialek - Information flow in sensory neurons.pdf:pdf},
issn = {0392-6737},
journal = {Il Nuovo Cimento D},
month = {jul},
number = {7-8},
pages = {733--741},
title = {{Information flow in sensory neurons}},
url = {http://link.springer.com/10.1007/BF02451830},
volume = {17},
year = {1995}
}
@article{Kinouchi1993,
author = {Kinouchi, Osame and Caticha, Nestor},
doi = {10.1088/0305-4470/26/22/017},
file = {:home/kaslu/Documents/Mendeley/1993 - Kinouchi, Caticha - Lower bounds on generalization errors for drifting rules.pdf:pdf},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
month = {nov},
number = {22},
pages = {6161--6171},
title = {{Lower bounds on generalization errors for drifting rules}},
url = {http://stacks.iop.org/0305-4470/26/i=22/a=017?key=crossref.eee2d7829e2fb348af5dc330c8efc3d1},
volume = {26},
year = {1993}
}
@misc{Wood1994,
abstract = {A meta-analytic review of 97 minority influence experiments evaluated the processes by which sources advocating deviant, minority opinions exert influence. Minority impact was most marked on measures of influence that were private from the source and indirectly related to the content of the appeal and less evident on direct private influence measures and on public measures. This attenuated impact of minorities on direct private and public measures suggests that in response to normative pressures, recipients avoided aligning themselves with a deviant source. Mediator analyses revealed that minorities perceived as especially consistent in the advocacy of their views were especially influential. The relation between normative and informational pressures in the minority influence paradigm was discussed.},
author = {Wood, Wendy and Lundgren, Sharon and Ouellette, Judith A. and Busceme, Shelly and Blackstone, Tamela},
booktitle = {Psychological bulletin},
doi = {10.1037/0033-2909.115.3.323},
file = {:home/kaslu/Documents/Mendeley/1994 - Wood et al. - Minority influence a meta-analytics.pdf:pdf},
isbn = {0033-2909$\backslash$r1939-1455},
issn = {0033-2909},
keywords = {Humans,Informal,Minority Groups,Minority Groups: psychology,Public Opinion,Social Conformity,Social Control,Social Identification},
number = {3},
pages = {323--45},
pmid = {8016284},
title = {{Minority influence a meta-analytics}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8016284},
volume = {115},
year = {1994}
}
@article{Hawkins2017,
abstract = {Neocortical regions are organized into columns and layers. Connections between layers run mostly perpendicular to the surface suggesting a columnar functional organization. Some layers have long-range excitatory lateral connections suggesting interactions between columns. Similar patterns of connectivity exist in all regions but their exact role remain a mystery. In this paper, we propose a network model composed of columns and layers that performs robust object learning and recognition. Each column integrates its changing input over time to learn complete predictive models of observed objects. Excitatory lateral connections across columns allow the network to more rapidly infer objects based on the partial knowledge of adjacent columns. Because columns integrate input over time and space, the network learns models of complex objects that extend well beyond the receptive field of individual cells. Our network model introduces a new feature to cortical columns. We propose that a representation of location relative to the object being sensed is calculated within the sub-granular layers of each column. The location signal is provided as an input to the network, where it is combined with sensory data. Our model contains two layers and one or more columns. Simulations show that using Hebbian-like learning rules small single-column networks can learn to recognize hundreds of objects, with each object containing tens of features. Multi-column networks recognize objects with significantly fewer movements of the sensory receptors. Given the ubiquity of columnar and laminar connectivity patterns throughout the neocortex, we propose that columns and regions have more powerful recognition and modeling capabilities than previously assumed.},
author = {Hawkins, Jeff and Ahmad, Subutai and Cui, Yuwei},
doi = {10.3389/fncir.2017.00081},
file = {:home/kaslu/Documents/Mendeley/2017 - Hawkins, Ahmad, Cui - A Theory of How Columns in the Neocortex Enable Learning the Structure of the World.pdf:pdf},
issn = {1662-5110},
journal = {Frontiers in Neural Circuits},
keywords = {cortical columns,cortical layers,hierarchical temporal memory,neocortex,neocortex, cortical columns, cortical layers, sens,sensorimotor learning},
number = {October},
pages = {1--18},
title = {{A Theory of How Columns in the Neocortex Enable Learning the Structure of the World}},
url = {http://journal.frontiersin.org/article/10.3389/fncir.2017.00081/full},
volume = {11},
year = {2017}
}
@misc{Tyagi2017,
abstract = {Risk taking is often associated with creativity, yet little evidence exists to support this association. The present article aimed to systematically explore this association. In two studies, we investigated the relationship between five different domains of risk taking (financial, health {\&} safety, recreational, ethical and social) and five different measures of creativity. Results from the first (laboratory-based) offline study suggested that creativity is associated with high risk taking tendencies in the social domain but not the other domains. Indeed, in the second study conducted online with a larger and diverse sample, the likelihood of social risk taking was the strongest predictor of creative personality and ideation scores. These findings illustrate the necessity to treat creativity and risk taking as multi-dimensional traits and the need to have a more nuanced framework of creativity and other related cognitive functions.},
author = {Tyagi, Vaibhav and Hanoch, Yaniv and Hall, Stephen D and Runco, Mark and Denham, Susan L},
booktitle = {Frontiers in Psychology},
isbn = {1664-1078},
pages = {145},
title = {{The Risky Side of Creativity: Domain Specific Risk Taking in Creative Individuals}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00145},
volume = {8},
year = {2017}
}
@article{Amodio2007,
abstract = {Political scientists and psychologists have noted that, on average, conservatives show more structured and persistent cognitive styles, whereas liberals are more responsive to informational complexity, ambiguity and novelty. We tested the hypothesis that these profiles relate to differences in general neurocognitive functioning using event-related potentials, and found that greater liberalism was associated with stronger conflict-related anterior cingulate activity, suggesting greater neurocognitive sensitivity to cues for altering a habitual response pattern. Political scientists and psychologists have long noted differences in the cognitive and motivational profiles of liberals and conservatives in the USA and elsewhere. Across dozens of behavioral studies, conservatives have been found to be more structured and persistent in their judgments and approaches to decision-making, as indicated by higher average scores on psychological measures of personal needs for order, structure and closure 1 . Liberals, by contrast, report higher tolerance of ambiguity and complexity, and greater openness to new experiences on psychological measures. Given that these associations between political orientation and cognitive styles have been shown to be heritable, evident in early childhood, and relatively stable across the lifespan 2,3 , we hypothesized that political orientation may be associated with individual differences in a basic neurocognitive mechanism involved broadly in self-regulation. Behavioral research suggests that psychological differences between conservatives and liberals map onto the widely-studied self-regulatory process of conflict monitoring 4 . Conflict monitoring is a general mechanism for detecting when one's habitual response tendency is mismatched with responses required by the current situation, and this function has been associated with neurocognitive activity in the anterior cingulate cortex (ACC) 5 . For example, in the Go/No-Go task used in our study, participants must quickly respond to a frequently presented Go stimulus, such that the 'Go' response becomes habitual. However, on a small proportion of trials, a No-Go stimulus appears, signaling that one's habitual response should be withheld. Hence, a No-Go stimulus conflicts with the prepotent Go response tendency. Such response conflict is typically associated with enhanced ACC activity, measured using functional magnetic resonance imaging or event-related potentials (ERPs) 6,7 . We proposed that differences in conservatives' and liberals' responsiveness to complex and poten-tially conflicting information relates to the sensitivity of this general mechanism for monitoring response conflict. To test the hypothesis that political liberalism (versus conservatism) would be associated with greater conflict-related ACC activity, we recorded electroencephalographs from 43 right-handed subjects (63{\%} female) as they performed the Go/No-Go task. Subjects reported their political attitudes confidentially on a –5 (extremely liberal) to +5 (extremely conservative) scale. This single-item measure has been found to account for approximately 85{\%} of the statistical variance in presidential voting intentions in American National Election studies between 1972 and 2004 (ref. 8). Among participants in the present study who reported voting in the 2004 presidential election, a more liberal (versus conservative) ideological orientation strongly predicted voting for John Kerry versus George Bush (r(21) ¼ 0.79, P o 0.001). In our study, conflict-related ACC activity was indexed by two ERP components. ERPs are scalp-recorded voltage changes reflecting the concerted firing of neurons in response to a psychological event. The response-locked error-related negativity (ERN), which peaks at approxi-mately 50 ms following an incorrect behavioral response 9,10 , reflects},
author = {Amodio, David M and Jost, John T and Master, Sarah L and Yee, Cindy M},
doi = {10.1038/nn1979},
file = {:home/kaslu/Documents/Mendeley/2007 - Amodio et al. - Neurocognitive correlates of liberalism and conservatism.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {10},
pages = {1246--1247},
pmid = {17828253},
title = {{Neurocognitive correlates of liberalism and conservatism}},
url = {http://www.nature.com/doifinder/10.1038/nn1979},
volume = {10},
year = {2007}
}
@article{Goris2014,
abstract = {Responses of sensory neurons differ across repeated measurements. This variability is usually treated as stochasticity arising within neurons or neural circuits. However, some portion of the variability arises from fluctuations in excitability due to factors that are not purely sensory, such as arousal, attention and adaptation. To isolate these fluctuations, we developed a model in which spikes are generated by a Poisson process whose rate is the product of a drive that is sensory in origin and a gain summarizing stimulus-independent modulatory influences on excitability. This model provides an accurate account of response distributions of visual neurons in macaque lateral geniculate nucleus and cortical areas V1, V2 and MT, revealing that variability originates in large part from excitability fluctuations that are correlated over time and between neurons, and that increase in strength along the visual pathway. The model provides a parsimonious explanation for observed systematic dependencies of response variability and covariability on firing rate.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goris, Robbe L. T. and Movshon, J Anthony and Simoncelli, Eero P.},
doi = {10.1038/nn.3711},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2014 - Goris, Movshon, Simoncelli - Partitioning neuronal variability.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {6},
pages = {858--865},
pmid = {24777419},
publisher = {Nature Publishing Group},
title = {{Partitioning neuronal variability}},
url = {http://www.nature.com/doifinder/10.1038/nn.3711},
volume = {17},
year = {2014}
}
@article{Barlow1961,
author = {Barlow, Horace},
file = {:home/kaslu/Documents/Mendeley/1961 - Barlow - Possible principles underlying the transformations of sensory messages.pdf:pdf;:home/kaslu/Documents/Mendeley/1961 - Barlow - Possible principles underlying the transformations of sensory messages(2).pdf:pdf;:home/kaslu/Documents/Mendeley/1961 - Barlow - Possible principles underlying the transformations of sensory messages(3).pdf:pdf;:home/kaslu/Documents/Mendeley/1961 - Barlow - Possible principles underlying the transformations of sensory messages(4).pdf:pdf;:home/kaslu/Documents/Mendeley/1961 - Barlow - Possible principles underlying the transformations of sensory messages(5).pdf:pdf},
title = {{Possible principles underlying the transformations of sensory messages}},
year = {1961}
}
@article{Bareinboim,
abstract = {The Multi-Armed Bandit problem constitutes an archetypal setting for sequential decision-making, permeating multiple domains including engineering, business, and medicine. One of the hallmarks of a bandit setting is the agent's capacity to explore its environment through active intervention, which contrasts with the ability to collect passive data by estimating associational relationships between actions and payouts. The existence of unobserved confounders, namely unmea-sured variables affecting both the action and the outcome variables, implies that these two data-collection modes will in general not coincide. In this paper, we show that formalizing this distinction has conceptual and algorithmic implications to the bandit setting. The current generation of bandit algorithms implicitly try to maximize rewards based on estimation of the experimental distribution, which we show is not always the best strategy to pursue. Indeed, to achieve low regret in certain realistic classes of bandit problems (namely, in the face of unobserved confounders), both experimental and observational quantities are required by the rational agent. After this realization, we propose an optimization metric (employ-ing both experimental and observational distributions) that bandit agents should pursue, and illustrate its benefits over traditional algorithms.},
author = {Bareinboim, Elias and Forney, Andrew and Pearl, Judea},
file = {:home/kaslu/Documents/Mendeley/2015 - Bareinboim, Forney, Pearl - Bandits with Unobserved Confounders A Causal Approach.pdf:pdf},
issn = {10495258},
journal = {Nips},
number = {November},
pages = {1--9},
title = {{Bandits with Unobserved Confounders: A Causal Approach}},
year = {2015}
}
@article{Giardini2015,
abstract = {The study of opinions − e.g., their formation and change, and their effects on our society − by means of theoretical and numerical models has been one of the main goals of sociophysics until now, but it is one of the defining topics addressed by social psychology and complexity science. Despite the flourishing of different models and theories, several key questions still remain unanswered. The aim of this paper is to provide a cognitively grounded computational model of opinions in which they are described as mental representations and defined in terms of distinctive mental features. We also define how these representations change dynamically through different processes, describing the interplay between mental and social dynamics of opinions. We present two versions of the model, one with discrete opinions (voter model-like), and one with continuous ones (Deffuant-like). By means of numerical simulations, we compare the behaviour of our cognitive model with the classical sociophysical models, and we identify interesting differences in the dynamics of consensus for each of the models considered.},
archivePrefix = {arXiv},
arxivId = {1502.06430},
author = {Giardini, Francesca and Vilone, Daniele and Conte, Rosaria},
doi = {10.3389/fphy.2015.00064},
eprint = {1502.06430},
file = {:home/kaslu/Documents/Mendeley/2015 - Giardini, Vilone, Conte - Consensus emerging from the bottom-up the role of cognitive variables in opinion dynamics.pdf:pdf},
issn = {2296-424X},
journal = {Frontiers in Physics},
keywords = {agent-based modeling,cognitive modeling,opinion dynamics,social influ,social influence,sociophysics},
month = {sep},
number = {September},
pages = {1--10},
title = {{Consensus emerging from the bottom-up: the role of cognitive variables in opinion dynamics}},
url = {http://journal.frontiersin.org/article/10.3389/fphy.2015.00064},
volume = {3},
year = {2015}
}
@article{Cowley2017,
abstract = {We propose a dimensionality reduction method to identify linear projections that capture interactions between two or more sets of variables. The method, distance covariance analysis (DCA), can detect both linear and nonlinear relationships, and can take dependent variables into account. On previous testbeds and a new testbed that systematically assesses the ability to detect both linear and nonlinear interactions, DCA performs better than or comparable to existing methods, while being one of the fastest methods. To showcase the versatility of DCA, we also applied it to three different neurophysiological datasets.},
author = {Cowley, Benjamin R. and Semedo, Joao and Zandvakili, Amin and Smith, Matthew and Kohn, Adam and Yu, Byron M.},
file = {:home/kaslu/Documents/Mendeley/2017 - Cowley et al. - Distance Covariance Analysis.pdf:pdf},
journal = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
pages = {242--251},
title = {{Distance Covariance Analysis}},
url = {http://proceedings.mlr.press/v54/cowley17a.html},
volume = {54},
year = {2017}
}
@article{Ganguli2012,
abstract = {Neurons in early sensory cortex show weak but systematic correlations with perceptual decisions when trained animals perform at psychophysical threshold. These correlations are observed across repeated presentations of identical stimuli and cannot be explained by variation in external factors. The relationship between the activity of individual sensory neurons and the animal's behavioral choice means that even neurons in early sensory cortex carry information about an upcoming decision. This relationship, termed choice probability, may reflect the effect of fluctuations in neuronal firing rate on the animal's decision, but it can also reflect modulation of sensory responses by cognitive factors, or network properties such as variability that is shared among populations of neurons. Here, we review recent work clarifying the relationship among fluctuations in the responses of individual neurons, correlated variability, and behavior in a variety of tasks and cortical areas. We also discuss the possibility that choice probability may in part reflect the influence of cognitive factors on sensory neurons and explore the situations in which choice probability can be used to make inferences about the role of particular sensory neurons in the decision-making process.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ganguli, Surya and Sompolinsky, Haim},
doi = {10.1146/annurev-neuro-062111},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2012 - Ganguli, Sompolinsky - Compressed Sensing, Sparsity and neural data.pdf:pdf},
isbn = {1545-4126 (Electronic)$\backslash$n0147-006X (Linking)},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {choice probability,decision making,noise correlation},
number = {1},
pages = {463--483},
pmid = {22483043},
title = {{Compressed Sensing, Sparsity and neural data}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-neuro-062111-150403},
volume = {35},
year = {2012}
}
@article{Minka2001,
abstract = {This paper presents a new deterministic approximation technique in Bayesian networks. This method, "Expectation Propagation", unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. All three algorithms try to recover an approximate distribution which is close in KL divergence to the true distribution. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expectation Propagation approximates the belief states by only retaining certain expectations, such as mean and variance, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Expectation Propagation also extends belief propagation in the opposite direction - it can propagate richer belief states that incorporate correlations between nodes. Experiments with Gaussian mixture models show Expectation Propagation to be convincingly better than methods with similar computational cost: Laplace's method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers.},
archivePrefix = {arXiv},
arxivId = {1301.2294},
author = {Minka, Tom},
eprint = {1301.2294},
file = {:home/kaslu/Documents/Mendeley/2001 - Minka - Expecatation Propagation for Approximate Bayesian Inference.pdf:pdf},
isbn = {1-55860-800-1},
journal = {Conference on Uncertainty in Artificial Intelligence},
pages = {362--369},
title = {{Expecatation Propagation for Approximate Bayesian Inference}},
url = {http://dl.acm.org/citation.cfm?id=2074067{\%}5Cnhttp://arxiv.org/pdf/1301.2294},
year = {2001}
}
@article{Wexler2013,
abstract = {When human observers are exposed to even slight motion signals followed by brief visual transients--stimuli containing no detectable coherent motion signals--they perceive large and salient illusory jumps. This visually striking effect, which we call "high phi," challenges well-entrenched assumptions about the perception of motion, namely the minimal-motion principle and the breakdown of coherent motion perception with steps above an upper limit called dmax. Our experiments with transients, such as texture randomization or contrast reversal, show that the magnitude of the jump depends on spatial frequency and transient duration--but not on the speed of the inducing motion signals--and the direction of the jump depends on the duration of the inducer. Jump magnitude is robust across jump directions and different types of transient. In addition, when a texture is actually displaced by a large step beyond the upper step size limit of dmax, a breakdown of coherent motion perception is expected; however, in the presence of an inducer, observers again perceive coherent displacements at or just above dmax. In summary, across a large variety of stimuli, we find that when incoherent motion noise is preceded by a small bias, instead of perceiving little or no motion--as suggested by the minimal-motion principle--observers perceive jumps whose amplitude closely follows their own dmax limits.},
author = {Wexler, Mark and Glennerster, Andrew and Cavanagh, Patrick and Ito, Hiroyuki and Seno, Takeharu},
doi = {10.1073/pnas.1213997110},
file = {:home/kaslu/Documents/Mendeley/2013 - Wexler et al. - Default perception of high-speed motion.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Humans,Motion Perception,Motion Perception: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Psychophysics,Sensory Thresholds,Time Factors},
month = {apr},
number = {17},
pages = {7080--5},
pmid = {23572578},
title = {{Default perception of high-speed motion.}},
url = {http://www.pnas.org/cgi/content/short/110/17/7080},
volume = {110},
year = {2013}
}
@article{Harrington2015,
abstract = {Throughout history and within numerous disciplines, there exists a perennial debate about how societies should best be organized. Should they emphasize individual freedom and autonomy or security and constraint? Contrary to proponents who tout the benefits of one over the other, we demonstrate across 32 nations that both freedom and constraint exhibit a curvilinear relationship with many indicators of societal well-being. Relative to moderate nations, very permissive and very constrained nations exhibit worse psychosocial outcomes (lower happiness, greater dysthymia, higher suicide rates), worse health outcomes (lower life expectancy, greater mortality rates from cardiovascular disease and diabetes) and poorer economic and political outcomes (lower gross domestic product per capita, greater risk for political instability). This supports the notion that a balance between freedom and constraint results in the best national outcomes. Accordingly, it is time to shift the debate away from either constraint or freedom and focus on both in moderation.},
author = {Harrington, Jesse R and Boski, Pawel and Gelfand, Michele J.},
doi = {10.1371/journal.pone.0127173},
editor = {Voracek, Martin},
file = {:home/kaslu/Documents/Mendeley/2015 - Harrington, Boski, Gelfand - Culture and National Well-Being Should Societies Emphasize Freedom or Constraint.PDF:PDF},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {Delivery of Health Care,Freedom,Happiness,Humans,Politics,Social Welfare,Societies,Socioeconomic Factors},
month = {jun},
number = {6},
pages = {e0127173},
pmid = {26046772},
title = {{Culture and National Well-Being: Should Societies Emphasize Freedom or Constraint?}},
url = {http://dx.doi.org/10.1371/journal.pone.0127173 http://dx.plos.org/10.1371/journal.pone.0127173},
volume = {10},
year = {2015}
}
@article{Lochmann2011,
abstract = {Perception is about making sense, that is, understanding what events in the outside world caused the sensory observations. Consistent with this intuition, many aspects of human behavior confronting noise and ambiguity are well explained by principles of causal inference. Extending these insights, recent studies have applied the same powerful set of tools to perceptual processing at the neural level. According to these approaches, microscopic neural structures solve elementary probabilistic tasks and can be combined to construct hierarchical predictive models of the sensory input. This framework suggests that variability in neural responses reflects the inherent uncertainty associated with sensory interpretations and that sensory neurons are active predictors rather than passive filters of their inputs. Causal inference can account parsimoniously and quantitatively for non-linear dynamical properties in single synapses, single neurons and sensory receptive fields. ?? 2011.},
author = {Lochmann, Timm and Den{\`{e}}ve, Sophie},
doi = {10.1016/j.conb.2011.05.018},
file = {:home/kaslu/Documents/Mendeley/2011 - Lochmann, Den{\`{e}}ve - Neural processing as causal inference.pdf:pdf},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {5},
pages = {774--781},
pmid = {21742484},
publisher = {Elsevier Ltd},
title = {{Neural processing as causal inference}},
url = {http://dx.doi.org/10.1016/j.conb.2011.05.018},
volume = {21},
year = {2011}
}
@article{Gershman2017,
abstract = {We routinely observe others' choices and use them to guide our own. Whose choices influence us more, and why? Prior work has focused on the effect of perceived similarity between two indi-viduals (self and others), such as the degree of overlap in past choices or explicitly recognizable group affiliations. In the real world, however, any dyadic relationship is part of a more complex social structure involving multiple social groups that are not directly observable. Here we suggest that human learners go beyond dyadic similarities in choice behaviors or explicit group member-ships; they infer the structure of social influence by grouping individuals (including themselves) based on choices, and they use these groups to decide whose choices to follow. We propose a com-putational model that formalizes this idea, and we test the model predictions in a series of behav-ioral experiments. In Experiment 1, we reproduce a well-established finding that people's choices are more likely to be influenced by someone whose past choices are more similar to their own past choices, as predicted by our model as well as dyadic similarity models. In Experiments 2–5, we test a set of unique predictions of our model by looking at cases where the degree of choice overlap between individuals is equated, but their choices indicate a latent group structure. We then apply our model to prior empirical results on infants' understanding of others' preferences, presenting an alternative account of developmental changes. Finally, we discuss how our model relates to classi-cal findings in the social influence literature and the theoretical implications of our model. Taken together, our findings demonstrate that structure learning is a powerful framework for explaining the influence of social information on decision making in a variety of contexts.},
author = {Gershman, Samuel J. and Pouncy, Hillard Thomas and Gweon, Hyowon},
doi = {10.1111/cogs.12480},
file = {:home/kaslu/Documents/Mendeley/2017 - Gershman, Pouncy, Gweon - Learning the Structure of Social Influence.pdf:pdf},
isbn = {0364-0213},
issn = {15516709},
journal = {Cognitive Science},
keywords = {Bayesian inference,Social cognition,Structure learning},
month = {mar},
pages = {545--575},
pmid = {28294384},
title = {{Learning the Structure of Social Influence}},
url = {http://doi.wiley.com/10.1111/cogs.12480},
volume = {41},
year = {2017}
}
@article{Zhou2017,
abstract = {In this paper, we propose gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks. In contrast to deep neural networks which require great effort in hyper-parameter tuning, gcForest is much easier to train. Actually, even when gcForest is applied to different data from different domains, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient and scalable. In our experiments its training time running on a PC is comparable to that of deep neural networks running with GPU facilities, and the efficiency advantage may be more apparent because gcForest is naturally apt to parallel implementation. Furthermore, in contrast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data. Moreover, as a tree-based approach, gcForest should be easier for theoretical analysis than deep neural networks.},
archivePrefix = {arXiv},
arxivId = {1702.08835},
author = {Zhou, Zhi-Hua and Feng, Ji},
eprint = {1702.08835},
month = {feb},
title = {{Deep Forest: Towards An Alternative to Deep Neural Networks}},
url = {http://arxiv.org/abs/1702.08835},
year = {2017}
}
@article{Churchland2007,
abstract = {The relationship between neural activity in motor cortex and movement is highly debated. Although many studies have examined the spatial tuning (e.g., for direction) of cortical responses, less attention has been paid to the temporal properties of individual neuron responses. We developed a novel task, employing two instructed speeds, that allows meaningful averaging of neural responses across reaches with nearly identical velocity profiles. Doing so preserves fine temporal structure and reveals considerable complexity and heterogeneity of response patterns in primary motor and premotor cortex. Tuning for direction was prominent, but the preferred direction was frequently inconstant with respect to time, instructed-speed, and/or reach distance. Response patterns were often temporally complex and multiphasic, and varied with direction and instructed speed in idiosyncratic ways. A wide variety of patterns was observed, and it was not uncommon for a neuron to exhibit a pattern shared by no other neuron in our dataset. Response patterns of individual neurons rarely, if ever, matched those of individual muscles. Indeed, the set of recorded responses spanned a much higher dimensional space than would be expected for a model in which neural responses relate to a moderate number of factors-dynamic, kinematic, or otherwise. Complex responses may provide a basis-set representing many parameters. Alternately, it may be necessary to discard the notion that responses exist to "represent" movement parameters. It has been argued that complex and heterogeneous responses are expected of a recurrent network that produces temporally patterned outputs, and the present results would seem to support this view.},
author = {Churchland, Mark M. and Shenoy, Krishna V.},
doi = {00095.2007 [pii]\r10.1152/jn.00095.2007},
file = {:home/kaslu/Documents/Mendeley/2007 - Churchland, Shenoy - Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex.pdf:pdf},
isbn = {0022-3077 (Print)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {J Neurophysiol},
keywords = {Action Potentials/*physiology,Animals,Brain Mapping,Computer Simulation,Electromyography,Evoked Potentials,Macaca mulatta,Male,Models,Motor Cortex/*cytology,Motor/*physiology,Movement/*physiology,Neural Networks (Computer),Neurological,Neurons/classification/*physiology,Psychomotor Performance/physiology,Reaction Time/physiology},
number = {6},
pages = {4235--4257},
pmid = {17376854},
title = {{Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve{\&}db=PubMed{\&}dopt=Citation{\&}list{\_}uids=17376854{\%}5Cnhttp://jn.physiology.org/content/97/6/4235.full.pdf},
volume = {97},
year = {2007}
}
@article{DeOliveira2010,
abstract = {A novel learning algorithm is proposed for non- linear modelling and identification using radial basis function neural networks. The proposed method simplifies neural network training through the use of an adaptive computation algorithm (ACA). In addition, the convergence of the ACA is analyzed by the Lyapunov criterion. The proposed algorithm offers two important advantages. First, the model performance can be significantly improved through ACA, and the modelling error is uniformly ultimately bounded. Secondly, the proposed ACA can reduce computational cost and accelerate the training speed. The proposed method is then employed to model classical nonlinear system with limit cycle and to identify nonlinear dynamic system, exhibiting the effectiveness of the proposed algorithm. Compu- tational complexity analysis and simulation results demonstrate its effectiveness.},
author = {de Oliveira, Evaldo Araujo and Caticha, Nestor},
doi = {10.1109/TNN.2010.2046422},
issn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
month = {jun},
number = {6},
pages = {1015--1020},
title = {{Inference From Aging Information}},
url = {http://ieeexplore.ieee.org/document/5453021/},
volume = {21},
year = {2010}
}
@article{Kremkow2016,
abstract = {The primary visual cortex contains a detailed map of the visual scene, which is represented according to multiple stimulus dimensions including spatial location, ocular dominance and stimulus orientation. The maps for spatial location and ocular dominance arise from the spatial arrangement of thalamic afferent axons in the cortex. However, the origins of the other maps remain unclear. Here we show that the cortical maps for orientation, direction and retinal disparity in the cat (Felis catus) are all strongly related to the organization of the map for spatial location of light (ON) and dark (OFF) stimuli, an organization that we show is OFF-dominated, OFF-centric and runs orthogonal to ocular dominance columns. Because this ON-OFF organization originates from the clustering of ON and OFF thalamic afferents in the visual cortex, we conclude that all main features of visual cortical topography, including orientation, direction and retinal disparity, follow a common organizing principle that arranges thalamic axons with similar retinotopy and ON-OFF polarity in neighbouring cortical regions.},
author = {Kremkow, Jens and Jin, Jianzhong and Wang, Yushi and Alonso, Jose M.},
doi = {10.1038/nature17936},
file = {:home/kaslu/Documents/Mendeley/2016 - Kremkow et al. - Principles underlying sensory map topography in primary visual cortex.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
month = {apr},
number = {7601},
pages = {52--57},
pmid = {27120164},
publisher = {Nature Publishing Group},
title = {{Principles underlying sensory map topography in primary visual cortex.}},
url = {http://www.nature.com/doifinder/10.1038/nature17936 http://www.nature.com.gate1.inist.fr/nature/journal/v533/n7601/full/nature17936.html},
volume = {533},
year = {2016}
}
@article{Jaynes1957,
abstract = {Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum-entropy estimate. it is the least biased estimate possible on the given information; i.e., it is maximally noncommital with regard to the missing information. If one considers statistical mechanics as a form of statistical inference rather than as a physical theory, it is found that the usual computational rules, starting with the determination of the partition function, are an immediate consequence of the maximum-entropy principle. In the resulting "subjective statistical mechanics", the usual rules are thus justified independently of any physical argument, and in particular independently of experimental verification; whether or not the results agree with experiment, they still represent the best estimates that cound have been made on the basis of the information available. It is concluded that statistical mechancis need not be regarded as a physical theory dependent for its validity on the truth of additional assumptions not contained in the laws of mechanics (such as ergodicity, metric transitivity, equal a priori probabilities, etc.). Furthermore, it is possible to maintain a sharp distinction between its physical and statistical aspects. The former consists only of the correct enumeration of the states of a system and their properties; the latter is a straightforward example of statistical inference.},
author = {Jaynes, Edwin T.},
doi = {10.1103/PhysRev.108.171},
file = {:home/kaslu/Documents/Mendeley/1957 - Jaynes - Information Theory and Statistical Mechanics.pdf:pdf},
isbn = {1536-6065},
issn = {{\textless}null{\textgreater}},
journal = {Physical Review},
keywords = {information theory,statistical mechanics},
number = {4},
pages = {620--630},
pmid = {17798674},
title = {{Information Theory and Statistical Mechanics}},
volume = {106},
year = {1957}
}
@article{Goris2015,
abstract = {Neurons in visual cortex vary in their orientation selectivity. We measured responses of V1 and V2 cells to orientation mixtures and fit them with a model whose stimulus selectivity arises from the combined effects of filtering, suppression, and response nonlinearity. The model explains the diversity of orientation selectivity with neuron-to-neuron variability in all three mechanisms, of which variability in the orientation bandwidth of linear filtering is the most important. The model also accounts for the cells' diversity of spatial frequency selectivity. Tuning diversity is matched to the needs of visual encoding. The orientation content found in natural scenes is diverse, and neurons with different selectivities are adapted to different stimulus configurations. Single orientations are better encoded by highly selective neurons, while orientation mixtures are better encoded by less selective neurons. A diverse population of neurons therefore provides better overall discrimination capabilities for natural images than any homogeneous population.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Goris, Robbe L T and Simoncelli, Eero P. and Movshon, J. Anthony},
doi = {10.1016/j.neuron.2015.10.009},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2015 - Goris, Simoncelli, Movshon - Origin and Function of Tuning Diversity in Macaque Visual Cortex.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {10974199},
journal = {Neuron},
number = {4},
pages = {819--831},
pmid = {26549331},
publisher = {Elsevier Inc.},
title = {{Origin and Function of Tuning Diversity in Macaque Visual Cortex}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.10.009},
volume = {88},
year = {2015}
}
@inproceedings{Caticha2009,
abstract = {Some criticisms that have been raised against the Cox approach to probability theory are addressed. Should we use a single real number to measure a degree of rational belief? Can beliefs be compared? Are the Cox axioms obvious? Are there counterexamples to Cox? Rather than justifying Cox's choice of axioms we follow a different path and derive the sum and product rules of probability theory as the unique (up to regraduations) consistent representations of the Boolean AND and OR operations.},
archivePrefix = {arXiv},
arxivId = {0908.3212},
author = {Caticha, Ariel},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.3275647},
eprint = {0908.3212},
file = {:home/kaslu/Documents/Mendeley/2009 - Caticha - Quantifying rational belief.pdf:pdf},
isbn = {9780735407299},
issn = {0094243X},
keywords = {Bayesian inference,Degrees of rational belief,Probability},
month = {aug},
pages = {60--68},
title = {{Quantifying rational belief}},
url = {http://scitation.aip.org/content/aip/proceeding/aipcp/10.1063/1.3275647 http://arxiv.org/abs/0908.3212 http://arxiv.org/pdf/0908.3212v2.pdf},
volume = {1193},
year = {2009}
}
@article{Yu2009b,
abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
author = {Yu, Byron M. and Cunningham, John P. and Santhanam, G. and Ryu, S. I. and Shenoy, Krishna V. and Sahani, Maneesh},
doi = {10.1152/jn.90941.2008},
file = {:home/kaslu/Documents/Mendeley/2009 - Yu et al. - Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity.pdf:pdf},
isbn = {9781605609492},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {1},
pages = {614--635},
pmid = {19357332},
title = {{Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.90941.2008},
volume = {102},
year = {2009}
}
@article{Fehr2003,
author = {Fehr, Ernst and Fischbacher, Urs},
doi = {10.1038/nature02043},
file = {:home/kaslu/Documents/Mendeley/2003 - Fehr, Fischbacher - The nature of human altruism.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {oct},
number = {6960},
pages = {785--791},
title = {{The nature of human altruism}},
url = {http://www.nature.com/articles/nature02043},
volume = {425},
year = {2003}
}
@article{Iyer2012,
abstract = {Libertarians are an increasingly prominent ideological group in U.S. politics, yet they have been largely unstudied. Across 16 measures in a large web-based sample that included 11,994 self-identified libertarians, we sought to understand the moral and psychological characteristics of self-described libertarians. Based on an intuitionist view of moral judgment, we focused on the underlying affective and cognitive dispositions that accompany this unique worldview. Compared to self-identified liberals and conservatives, libertarians showed 1) stronger endorsement of individual liberty as their foremost guiding principle, and weaker endorsement of all other moral principles; 2) a relatively cerebral as opposed to emotional cognitive style; and 3) lower interdependence and social relatedness. As predicted by intuitionist theories concerning the origins of moral reasoning, libertarian values showed convergent relationships with libertarian emotional dispositions and social preferences. Our findings add to a growing recognition of the role of personality differences in the organization of political attitudes.},
author = {Iyer, Ravi and Koleva, Spassena and Graham, Jesse and Ditto, Peter and Haidt, Jonathan},
doi = {10.1371/journal.pone.0042366},
file = {:home/kaslu/Documents/Mendeley/2012 - Iyer et al. - Understanding libertarian morality the psychological dispositions of self-identified libertarians.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Adult,Cluster Analysis,Cognition,Empathy,Female,Freedom,Humans,Individuality,Male,Morals,Principal Component Analysis,Psychology,Social Values,Surveys and Questionnaires},
month = {jan},
number = {8},
pages = {e42366},
pmid = {22927928},
publisher = {Public Library of Science},
title = {{Understanding libertarian morality: the psychological dispositions of self-identified libertarians.}},
url = {http://dx.doi.org/10.1371/journal.pone.0042366},
volume = {7},
year = {2012}
}
@article{Pouget2016,
abstract = {When facing uncertainty, adaptive behavioral strategies demand that the brain performs probabilistic computations. In this probabilistic framework, the notion of certainty and confidence would appear to be closely related, so much so that it is tempting to conclude that these two concepts are one and the same. We argue that there are computational reasons to distinguish between these two concepts. Specifically, we propose that confidence should be defined as the probability that a decision or a proposition, overt or covert, is correct given the evidence, a critical quantity in complex sequential decisions. We suggest that the term certainty should be reserved to refer to the encoding of all other probability distributions over sensory and cognitive variables. We also discuss strategies for studying the neural codes for confidence and certainty and argue that clear definitions of neural codes are essential to understanding the relative contributions of various cortical areas to decision making.},
author = {Pouget, Alexandre and Drugowitsch, Jan and Kepecs, Adam},
doi = {10.1038/nn.4240},
file = {:home/kaslu/Documents/Mendeley/2016 - Pouget, Drugowitsch, Kepecs - Confidence and certainty distinct probabilistic quantities for different goals.pdf:pdf},
isbn = {1546-1726 (Electronic) 1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {366--374},
pmid = {26906503},
title = {{Confidence and certainty: distinct probabilistic quantities for different goals}},
url = {http://www.nature.com/doifinder/10.1038/nn.4240},
volume = {19},
year = {2016}
}
@article{Meyer2017,
abstract = {Rich, dynamic, and dense sensory stimuli are encoded within the nervous system by the time-varying activity of many individual neurons. A fundamental approach to understanding the nature of the encoded representation is to characterise the function that relates the moment-by-moment firing of a neuron to the recent history of a complex sensory input. This review provides a unifying and critical survey of the techniques that have been brought to bear on this effort thus far --- ranging from the classical linear receptive field model to modern approaches incorporating normalisation and other nonlinearities. We address separately the structure of the models; the criteria and algorithms used to identify the model parameters; and the role of regularising terms or ``priors''. In each case we consider benefits or drawbacks of various proposals, providing examples for when these methods work and when they may fail. Emphasis is placed on key concepts rather than mathematical details, so as to make the discussion accessible to readers from outside the field. Finally, we review ways in which the agreement between an assumed model and the neuron's response may be quantified.},
author = {Meyer, Arne F. and Williamson, Ross S. and Linden, Jennifer F. and Sahani, Maneesh},
doi = {10.3389/fnsys.2016.00109},
file = {:home/kaslu/Documents/Mendeley/2017 - Meyer et al. - Models of Neuronal Stimulus-Response Functions Elaboration, Estimation, and Evaluation.pdf:pdf},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
keywords = {neural coding,receptive field,receptive field, sensory system, neural coding,sensory system},
number = {January},
pages = {1--25},
pmid = {28127278},
title = {{Models of Neuronal Stimulus-Response Functions: Elaboration, Estimation, and Evaluation}},
url = {http://journal.frontiersin.org/article/10.3389/fnsys.2016.00109/full},
volume = {10},
year = {2017}
}
@article{Zhou2015,
abstract = {Pairs of active neurons frequently fire action potentials or “spikes” nearly synchronously (i.e., within 5ms of each other). This spike synchrony may occur by chance, based solely on the neurons' fluctuating firing patterns, or it may occur too frequently to be explicable by chance alone. When spike synchrony above chances levels is present, it may subserve computation for a specific cognitive process, or it could be an irrelevant byproduct of such computation. Either way, spike synchrony is a feature of neural data that should be explained. A point process regression framework has been developed previously for this purpose, using generalized linear models (GLMs). In this framework, the observed number of synchronous spikes is compared to the number predicted by chance under varying assumptions about the factors that affect each of the individual neuron's firing-rate func- tions. An important possible source of spike synchrony is network-wide oscillations, which may provide an essential mechanism of network information flow. To establish the statistical link between spike synchrony and network-wide oscillations, we have integrated oscillatory field potentials into our point process regression framework. Wefirst extended a previously-published model of spike-field association and showed that we could recover phase relationships between oscillatory field potentials and firing rates. We then used this new framework to demonstrate the statistical relationship between oscillatory field potentials and spike synchrony in: 1) simulated neurons, 2) in vitro recordings of hippocampal CA1 pyramidal cells, and 3) in vivo recordings of neocortical V4 neurons. Our results provide a rigorous method for establishing a statistical link between network oscillations and neural synchrony.},
author = {Zhou, Pengcheng and Burton, Shawn D. and Snyder, Adam C. and Smith, Matthew A. and Urban, Nathaniel N. and Kass, Robert E.},
doi = {10.1371/journal.pcbi.1004549},
file = {:home/kaslu/Documents/Mendeley/2015 - Zhou et al. - Establishing a Statistical Link between Network Oscillations and Neural Synchrony.PDF:PDF},
isbn = {10.1371/journal.pcbi.1004549},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {10},
pages = {1--25},
pmid = {26465621},
title = {{Establishing a Statistical Link between Network Oscillations and Neural Synchrony}},
volume = {11},
year = {2015}
}
@article{Barrett2016,
abstract = {The brain has an impressive ability to withstand neural damage. Diseases that kill neurons can go unnoticed for years, and incomplete brain lesions or silencing of neurons often fail to produce any behavioral effect. How does the brain compensate for such damage, and what are the limits of this compensation? We propose that neural circuits immediately compensate for neuron loss, thereby preserving their function as much as possible. We show that this compensation can explain changes in tuning curves induced by neuron silencing across a variety of systems, including the primary visual cortex. We find that compensatory mechanisms can be implemented through the dynamics of networks with a tight balance of excitation and inhibition, without requiring synaptic plasticity. The limits of this compensatory mechanism are reached when excitation and inhibition become unbalanced, thereby demarcating a recovery boundary, where signal representation fails and where diseases may become symptomatic.},
author = {Barrett, David TG and Den{\`{e}}ve, Sophie and Machens, Christian K},
doi = {10.7554/eLife.12454},
file = {:home/kaslu/Documents/Mendeley/2016 - Barrett, Den{\`{e}}ve, Machens - Optimal compensation for neuron loss.pdf:pdf},
issn = {2050-084X},
journal = {eLife},
pages = {1--36},
pmid = {27935480},
title = {{Optimal compensation for neuron loss}},
url = {http://elifesciences.org/lookup/doi/10.7554/eLife.12454},
volume = {5},
year = {2016}
}
@article{Cain2013,
abstract = {Stimulus from the environment that guides behavior and informs decisions is encoded in the firing rates of neural populations. Neurons in the populations, however, do not spike independently: spike events are correlated from cell to cell. To what degree does this apparent redundancy have an impact on the accuracy with which decisions can be made and the computations required to optimally decide? We explore these questions for two illustrative models of correlation among cells. Each model is statistically identical at the level of pairwise correlations but differs in higher-order statistics that describe the simultaneous activity of larger cell groups. We find that the presence of correlations can diminish the performance attained by an ideal decision maker to either a small or large extent, depending on the nature of the higher-order correlations. Moreover, although this optimal performance can in some cases be obtained using the standard integration-to-bound operation, in others it requires a nonlinear computation on incoming spikes. Overall, we conclude that a given level of pairwise correlations, even when restricted to identical neural populations, may not always indicate redundancies that diminish decision-making performance.},
archivePrefix = {arXiv},
arxivId = {arXiv:1207.5159v1},
author = {Cain, Nicholas and Shea-Brown, Eric},
doi = {10.1162/NECO_a_00398},
eprint = {arXiv:1207.5159v1},
file = {:home/kaslu/Documents/Mendeley/2013 - Cain, Shea-Brown - Impact of Correlated Neural Activity on Decision-Making Performance.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
number = {2},
pages = {289--327},
pmid = {23148409},
title = {{Impact of Correlated Neural Activity on Decision-Making Performance}},
url = {http://www.mitpressjournals.org/doi/10.1162/NECO{\_}a{\_}00398},
volume = {25},
year = {2013}
}
@article{Harrington2014,
abstract = {This research demonstrates wide variation in tightness-looseness (the strength of punishment and degree of latitude/permissiveness) at the state level in the United States, as well as its association with a variety of ecological and historical factors, psychological characteristics, and state-level outcomes. Consistent with theory and past research, ecological and man-made threats-such as a higher incidence of natural disasters, greater disease prevalence, fewer natural resources, and greater degree of external threat-predicted increased tightness at the state level. Tightness is also associated with higher trait conscientiousness and lower trait openness, as well as a wide array of outcomes at the state level. Compared with loose states, tight states have higher levels of social stability, including lowered drug and alcohol use, lower rates of homelessness, and lower social disorganization. However, tight states also have higher incarceration rates, greater discrimination and inequality, lower creativity, and lower happiness relative to loose states. In all, tightness-looseness provides a parsimonious explanation of the wide variation we see across the 50 states of the United States of America.},
author = {Harrington, Jesse R and Gelfand, Michele J.},
doi = {10.1073/pnas.1317937111},
file = {:home/kaslu/Documents/Mendeley/2014 - Harrington, Gelfand - Tightness-looseness across the 50 united states.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jun},
number = {22},
pages = {7990--7995},
pmid = {24843116},
title = {{Tightness-looseness across the 50 united states}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24843116 http://www.pnas.org/cgi/doi/10.1073/pnas.1317937111},
volume = {111},
year = {2014}
}
@article{Itthipuripat2015,
abstract = {Normative theories posit that value-based decision-making is context independent. However, decisions between two high-value options can be suboptimally biased by the introduction of a third low-value option. This context-dependent modulation is consistent with the divisive normalization of the value of each stimulus by the total value of all stimuli. In addition, an independent line of research demonstrates that pairing a stimulus with a high-value outcome can lead to attentional capture that can mediate the efficiency of visual information processing. Here we tested the hypothesis that value-based attentional capture interacts with value-based normalization to influence the optimality of decision-making. We used a binary-choice paradigm in which observers selected between two targets and the color of each target indicated the magnitude of their reward potential. Observers also had to simultaneously ignore a task-irrelevant distractor rendered in a color that was previously associated with a specific reward magnitude. When the color of the task-irrelevant distractor was previously associated with a high reward, observers responded more slowly and less optimally. Moreover, as the learned value of the distractor increased, electrophysiological data revealed an attenuation of the lateralized N1 and N2Pc responses evoked by the relevant choice stimuli and an attenuation of the late positive deflection (LPD). Collectively, these behavioral and electrophysiological data suggest that value-based attentional capture and value-based normalization jointly mediate the influence of context on free-choice decision-making.},
author = {Itthipuripat, Sirawaj and Cha, Kexin and Rangsipat, N and Serences, John T.},
doi = {10.1152/jn.00343.2015},
file = {:home/kaslu/Documents/Mendeley/2015 - Itthipuripat et al. - Value-based attentional capture influences context-dependent decision-making.pdf:pdf},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {J Neurophysiol},
keywords = {Eeg,attention,decision-making,reward,value normalization},
number = {1},
pages = {560--569},
pmid = {25995350},
title = {{Value-based attentional capture influences context-dependent decision-making}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25995350},
volume = {114},
year = {2015}
}
@article{Rodriguez-Sickert2015,
annote = {tentar repoduzir com entropia?},
author = {Rodriguez-Sickert, Carlos and Cosmelli, Diego and Claro, Francisco and Fuentes, Miguel Angel},
doi = {10.1371/journal.pone.0138172},
editor = {Amblard, Frederic},
issn = {1932-6203},
journal = {PLOS ONE},
month = {sep},
number = {9},
pages = {e0138172},
title = {{The Underlying Social Dynamics of Paradigm Shifts}},
url = {http://dx.plos.org/10.1371/journal.pone.0138172},
volume = {10},
year = {2015}
}
@article{Takahashi2011,
abstract = {Nature Neuroscience 14, 1590 (2011). doi:10.1038/nn.2957},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Takahashi, Yuji K and Roesch, Matthew R and Wilson, Robert C and Toreson, Kathy and O'Donnell, Patricio and Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1038/nn.2957},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2011 - Takahashi et al. - Expectancy-related changes in firing of dopamine neurons depend on orbitofrontal cortex.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {12},
pages = {1590--1597},
pmid = {22037501},
publisher = {Nature Publishing Group},
title = {{Expectancy-related changes in firing of dopamine neurons depend on orbitofrontal cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.2957},
volume = {14},
year = {2011}
}
@incollection{Haidt2009,
abstract = {Most academic efforts to understand morality and ideology come from theorists who limit the domain of morality to issues related to harm and fairness. For such theorists, conservative beliefs are puzzles requiring non-moral explanations. In contrast, we present moral foundations theory, which broadens the moral do- main to match the anthropological literature on morality. We extend the theory by integrating it with a review of the sociological constructs of community, authority, and sacredness, as formulated by Emile Durkheim and others. We present data supporting the theory, which also shows that liberals misunderstand the explicit moral concerns of conservatives more than conservatives misunderstand liber- als. We suggest that what liberals see as a non-moral motivation for system justification may be better described as a moral motivation to protect society, groups, and the structures and constraints that are often (although not always) beneficial for individuals. Finally, we outline the possible benefits of a moral foun- dations perspective for system justification theory (SJT), including better un- derstandings of (a) why the system-justifying motive is palliative despite some harmful effects, (b) possible evolutionary origins of the motive, and (c) the values and worldviews of conservatives in general.},
author = {Haidt, Jonathan and Graham, Jesse},
booktitle = {Social and Psychological Bases of Ideology and System Justification},
doi = {10.1093/acprof:oso/9780195320916.003.015},
file = {:home/kaslu/Documents/Mendeley/2009 - Haidt, Graham - Planet of the Durkheimians, Where Community, Authority, and Sacredness Are Foundations of Morality.pdf:pdf},
isbn = {9780199869541},
issn = {0162895X},
keywords = {Authority,Community,Durkheim,Durkheimians,Hypothetical societies,Moral foundations theory,Sacredness,Social evolution,conservative,liberal,metaethics,moral,moral foundation},
month = {aug},
pages = {371--401},
publisher = {Oxford University Press},
title = {{Planet of the Durkheimians, Where Community, Authority, and Sacredness Are Foundations of Morality}},
url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195320916.001.0001/acprof-9780195320916-chapter-15},
year = {2009}
}
@article{Giffin2016,
abstract = {It is known that the Maximum relative Entropy (MrE) method can be used to both update and approximate probability distributions functions in statistical inference problems. In this manuscript, we apply the MrE method to infer magnetic properties of ferromagnetic materials. In addition to comparing our approach to more traditional methodologies based upon the Ising model and Mean Field Theory, we also test the effectiveness of the MrE method on conventionally unexplored ferromagnetic materials with defects.},
archivePrefix = {arXiv},
arxivId = {1603.00068},
author = {Giffin, Adom and Cafaro, Carlo and Ali, Sean Alan},
eprint = {1603.00068},
file = {:home/kaslu/Documents/Mendeley/2016 - Giffin, Cafaro, Ali - Application of the Maximum relative Entropy method to the physics of ferromagnetic materials.pdf:pdf},
month = {feb},
pages = {27},
title = {{Application of the Maximum relative Entropy method to the physics of ferromagnetic materials}},
url = {http://arxiv.org/abs/1603.00068},
year = {2016}
}
@article{Caticha2015,
abstract = {Within an agent-based model where moral classifications are socially learned, we ask if a population of agents behaves in a way that may be compared with conservative or liberal positions in the real political spectrum. We assume that agents first experience a formative period, in which they adjust their learning style acting as supervised Bayesian adaptive learners. The formative phase is followed by a period of social influence by reinforcement learning. By comparing data generated by the agents with data from a sample of 15,000 Moral Foundation questionnaires we found the following. (1) The number of information exchanges in the formative phase correlates positively with statistics identifying liberals in the social influence phase. This is consistent with recent evidence that connects the dopamine receptor D4-7R gene, political orientation and early age social clique size. (2) The learning algorithms that result from the formative phase vary in the way they treat novelty and corroborative information with more conservative-like agents treating it more equally than liberal-like agents. This is consistent with the correlation between political affiliation and the Openness personality trait reported in the literature. (3) Under the increase of a model parameter interpreted as an external pressure, the statistics of liberal agents resemble more those of conservative agents, consistent with reports on the consequences of external threats on measures of conservatism. We also show that in the social influence phase liberal-like agents readapt much faster than conservative-like agents when subjected to changes on the relevant set of moral issues. This suggests a verifiable dynamical criterium for attaching liberal or conservative labels to groups.},
archivePrefix = {arXiv},
arxivId = {1502.03394},
author = {Caticha, Nestor and Cesar, Jonatas and Vicente, Renato},
doi = {10.3389/fphy.2015.00025},
eprint = {1502.03394},
file = {:home/kaslu/Documents/Mendeley/2015 - Caticha, Cesar, Vicente - For whom will the Bayesian agents vote.pdf:pdf},
issn = {2296-424X},
journal = {Frontiers in Physics},
keywords = {Bayesian learning,agent-based model,bayesian learning,moral foundations,opinion dynamics,sociophysics},
month = {apr},
number = {25},
pages = {1--14},
title = {{For whom will the Bayesian agents vote?}},
url = {http://www.frontiersin.org/interdisciplinary{\_}physics/10.3389/fphy.2015.00025/abstract http://journal.frontiersin.org/article/10.3389/fphy.2015.00025/abstract},
volume = {3},
year = {2015}
}
@inproceedings{Caticha2006a,
author = {Caticha, Nestor and Neirotti, Juan Pablo},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.2423276},
file = {:home/kaslu/Documents/Mendeley/2006 - Caticha, Neirotti - The evolution of learning systems to Bayes or not to be.pdf:pdf},
issn = {0094243X},
pages = {203--210},
publisher = {AIP},
title = {{The evolution of learning systems: to Bayes or not to be}},
url = {http://scitation.aip.org/content/aip/proceeding/aipcp/10.1063/1.2423276},
volume = {872},
year = {2006}
}
@article{Manning2015,
abstract = {This article focuses on intimate partner killings to address the question of why some killers subsequently commit suicide whereas others do not. Utilizing Blackian theories of conflict management and Manning's theory of suicide, it advances hypotheses about when intimate partner conflict will result in homicide-suicide rather than homicide alone. These hypotheses propose that differing amounts of status superiority and relational distance predict and explain different patterns of lethal violence. The hypotheses are illustrated and supported with data taken from a study of intimate partner homicides in the state of West Virginia. The article concludes by arguing for a micro-structural model that addresses suicide, homicide, and homicide-suicide.},
author = {Manning, Jason},
doi = {10.1177/1088767914547819},
issn = {1088-7679},
journal = {Homicide Studies},
keywords = {commits suicide shortly after,homicide-suicide is an event,in which a perpetrator,intimate partner,methodology,multitrait-multimethod,offender relationship,structural causes,subtypes,victim},
number = {4},
pages = {350--369},
title = {{The Social Structure of Homicide-Suicide}},
url = {http://hsx.sagepub.com/content/19/4/350.abstract},
volume = {19},
year = {2015}
}
@article{Kiani2014a,
abstract = {Decision making is a complex process in which different sources of information are combined into a decision variable (DV) that guides action [1, 2]. Neurophysiological studies have typically sought insight into the dynamics of the decision-making process and its neural mechanisms through statistical analysis of large numbers of trials from sequentially recorded single neurons or small groups of neurons [3-6]. However, detecting and analyzing the DV on individual trials has been challenging [7]. Here we show that by recording simultaneously from hundreds of units in prearcuate gyrus of macaque monkeys performing a direction discrimination task, we can predict the monkey's choices with high accuracy and decode DV dynamically as the decision unfolds on individual trials. This advance enabled us to study changes of mind (CoMs) that occasionally happen before the final commitment to a decision [8-10]. On individual trials, the decoded DV varied significantly over time and occasionally changed its sign, identifying a potential CoM. Interrogating the system by random stopping of the decision-making process during the delay period after stimulus presentation confirmed the validity of identified CoMs. Importantly, the properties of the candidate CoMs also conformed to expectations based on prior theoretical and behavioral studies [8]: they were more likely to go from an incorrect to a correct choice, they were more likely for weak and intermediate stimuli than for strong stimuli, and they were more likely earlier in the trial. We suggest that simultaneous recording of large neural populations provides a good estimate of DV and explains idiosyncratic aspects of the decision-making process that were inaccessible before. {\textcopyright} 2014 Elsevier Ltd.},
author = {Kiani, Roozbeh and Cueva, Christopher J. and Reppas, John B. and Newsome, William T.},
doi = {10.1016/j.cub.2014.05.049},
isbn = {1879-0445 (Electronic)$\backslash$n0960-9822 (Linking)},
issn = {09609822},
journal = {Current Biology},
month = {jul},
number = {13},
pages = {1542--1547},
pmid = {24954050},
title = {{Dynamics of neural population responses in prefrontal cortex indicate changes of mind on single trials}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982214006149},
volume = {24},
year = {2014}
}
@article{Scott2016,
author = {Scott, Steven L. and Blocker, Alexander W. and Bonassi, Fernando V. and Chipman, Hugh A. and George, Edward I. and McCulloch, Robert E.},
doi = {10.1080/17509653.2016.1142191},
file = {:home/kaslu/Documents/Mendeley/2016 - Scott et al. - Bayes and big data the consensus Monte Carlo algorithm.pdf:pdf},
issn = {1750-9653},
journal = {International Journal of Management Science and Engineering Management},
month = {apr},
number = {2},
pages = {78--88},
title = {{Bayes and big data: the consensus Monte Carlo algorithm}},
url = {https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/41849.pdf http://www.tandfonline.com/doi/full/10.1080/17509653.2016.1142191},
volume = {11},
year = {2016}
}
@article{Whalen2017,
author = {Whalen, Andrew and Griffiths, Thomas L. and Buchsbaum, Daphna},
doi = {10.1111/cogs.12485},
file = {:home/kaslu/Documents/Mendeley/2017 - Whalen, Griffiths, Buchsbaum - Sensitivity to shared information in social learning.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Bayesian modeling,Culture,Human experimentation,Mathematical modeling,Psychology},
month = {jun},
pages = {1--30},
title = {{Sensitivity to shared information in social learning}},
url = {http://doi.wiley.com/10.1111/cogs.12485},
year = {2017}
}
@article{Zylberberg2017,
abstract = {Sensory neurons give highly variable responses to stimulation, which can limit the amount of stimulus information available to downstream circuits. Much work has investigated the factors that affect the amount of information encoded in these population responses, leading to insights about the role of covariability among neurons, tuning curve shape, etc. However, the informativeness of neural responses is not the only relevant feature of population codes; of potentially equal importance is how robustly that information propagates to downstream structures. For instance, to quantify the retina's performance, one must consider not only the informativeness of the optic nerve responses, but also the amount of information that survives the spike-generating nonlinearity and noise corruption in the next stage of processing, the lateral geniculate nucleus. Our study identifies the set of covariance structures for the upstream cells that optimize the ability of information to propagate through noisy, nonlinear circuits. Within this optimal family are covariances with "differential correlations", which are known to reduce the information encoded in neural population activities. Thus, covariance structures that maximize information in neural population codes, and those that maximize the ability of this information to propagate, can be very different.},
archivePrefix = {arXiv},
arxivId = {1608.05706},
author = {Zylberberg, Joel and Pouget, Alexandre and Latham, Peter E. and Shea-Brown, Eric},
doi = {10.1371/journal.pcbi.1005497},
eprint = {1608.05706},
file = {:home/kaslu/Documents/Mendeley/2017 - Zylberberg et al. - Robust information propagation through noisy neural circuits.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {4},
pages = {1--35},
pmid = {28419098},
title = {{Robust information propagation through noisy neural circuits}},
volume = {13},
year = {2017}
}
@article{Mathys2011,
abstract = {Computational learning models are critical for understanding mechanisms of adaptive behavior. However, the two major current frameworks, reinforcement learning (RL) and Bayesian learning, both have certain limitations. For example, many Bayesian models are agnostic of inter-individual variability and involve complicated integrals, making online learning difficult. Here, we introduce a generic hierarchical Bayesian framework for individual learning under multiple forms of uncertainty (e.g., environmental volatility and perceptual uncertainty). The model assumes Gaussian random walks of states at all but the first level, with the step size determined by the next highest level. The coupling between levels is controlled by parameters that shape the influence of uncertainty on learning in a subject-specific fashion. Using variational Bayes under a mean-field approximation and a novel approximation to the posterior energy function, we derive trial-by-trial update equations which (i) are analytical and extremely efficient, enabling real-time learning, (ii) have a natural interpretation in terms of RL, and (iii) contain parameters representing processes which play a key role in current theories of learning, e.g., precision-weighting of prediction error. These parameters allow for the expression of individual differences in learning and may relate to specific neuromodulatory mechanisms in the brain. Our model is very general: it can deal with both discrete and continuous states and equally accounts for deterministic and probabilistic relations between environmental events and perceptual states (i.e., situations with and without perceptual uncertainty). These properties are illustrated by simulations and analyses of empirical time series. Overall, our framework provides a novel foundation for understanding normal and pathological learning that contextualizes RL within a generic Bayesian scheme and thus connects it to principles of optimality from probability theory.},
author = {Mathys, Christoph and Daunizeau, Jean and Friston, Karl and Stephan, Klaas E},
doi = {10.3389/fnhum.2011.00039},
file = {:home/kaslu/Documents/Mendeley/2011 - Mathys et al. - A bayesian foundation for individual learning under uncertainty.pdf:pdf},
isbn = {1662-5161 (Electronic){\$}\backslash{\$}n1662-5161 (Linking)},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {acetylcholine,decision-,decisionmaking,dopamine,hierarchical models,neuromodulation,serotonin,variational bayes,volatility},
month = {jan},
number = {May},
pages = {39},
pmid = {21629826},
title = {{A bayesian foundation for individual learning under uncertainty.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3096853{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Finnila1994,
abstract = {Quantum annealing is a new method for finding extrema of multidimensional functions. Based on an extension of classical, simulated annealing, this approach appears robust with respect to avoiding local minima. Further, unlike some of its predecessors, it does not require an approximation to a wavefunction. We apply the technique to the problem of finding the lowest energy configurations of Lennard-Jones clusters of up to 19 particles (roughly 105 local minima). This early success suggests that this method may complement the widely implemented technique of simulated annealing.},
author = {Finnila, A.B. and Gomez, M.A. and Sebenik, C. and Stenson, C. and Doll, J.D.},
doi = {10.1016/0009-2614(94)00117-0},
file = {:home/kaslu/Documents/Mendeley/1994 - Finnila et al. - Quantum annealing A new method for minimizing multidimensional functions.pdf:pdf},
issn = {00092614},
journal = {Chemical Physics Letters},
month = {mar},
number = {5-6},
pages = {343--348},
title = {{Quantum annealing: A new method for minimizing multidimensional functions}},
url = {http://www.sciencedirect.com/science/article/pii/0009261494001170},
volume = {219},
year = {1994}
}
@article{DouglasFields2008,
author = {{Douglas Fields}, R.},
doi = {10.1038/scientificamerican0308-54},
file = {:home/kaslu/Documents/Mendeley/2008 - Douglas Fields - White Matter Matters.pdf:pdf},
isbn = {00368733},
issn = {0036-8733},
journal = {Scientific American},
month = {mar},
number = {3},
pages = {54--61},
title = {{White Matter Matters}},
url = {http://www.nature.com/doifinder/10.1038/scientificamerican0308-54},
volume = {298},
year = {2008}
}
@article{Talhelm,
author = {Talhelm, Thomas and Haidt, Jonathan and Oishi, Shigehiro and Zhang, Xuemin and Miao, Felicity F and Chen, Shimin},
doi = {10.1177/0146167214563672},
file = {:home/kaslu/Documents/Mendeley/2015 - Talhelm et al. - Liberals Think More Analytically (More WEIRD) Than Conservatives.pdf:pdf},
issn = {0146-1672},
journal = {Personality and Social Psychology Bulletin},
month = {feb},
number = {2},
pages = {250--267},
title = {{Liberals Think More Analytically (More "WEIRD") Than Conservatives}},
url = {http://psp.sagepub.com/cgi/doi/10.1177/0146167214563672},
volume = {41},
year = {2015}
}
@article{Kiani2014,
abstract = {"Degree of certainty" refers to the subjective belief, prior to feedback, that a decision is correct. A reliable estimate of certainty is essential for prediction, learning from mistakes, and planning subsequent actions when outcomes are not immediate. It is generally thought that certainty is informed by a neural representation of evidence at the time of a decision. Here we show that certainty is also informed by the time taken to form the decision. Human subjects reported simultaneously their choice and confidence about the direction of a noisy display of moving dots. Certainty was inversely correlated with reaction times and directly correlated with motion strength. Moreover, these correlations were preserved even for error responses, a finding that contradicts existing explanations of certainty based on signal detection theory. We also contrived a stimulus manipulation that led to longer decision times without affecting choice accuracy, thus demonstrating that deliberation time itself informs the estimate of certainty. We suggest that elapsed decision time informs certainty because it serves as a proxy for task difficulty.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Kiani, Roozbeh and Corthell, Leah and Shadlen, Michael N.},
doi = {10.1016/j.neuron.2014.12.015},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2014 - Kiani, Corthell, Shadlen - Choice certainty is informed by both evidence and decision time.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
number = {6},
pages = {1329--1342},
pmid = {25521381},
publisher = {Elsevier Inc.},
title = {{Choice certainty is informed by both evidence and decision time}},
url = {http://dx.doi.org/10.1016/j.neuron.2014.12.015},
volume = {84},
year = {2014}
}
@article{Toulouse2015,
abstract = {We provide a pedagogical introduction to the two main variants of real-space quantum Monte Carlo methods for electronic-structure calculations: variational Monte Carlo (VMC) and diffusion Monte Carlo (DMC). Assuming no prior knowledge on the subject, we review in depth the Metropolis-Hastings algorithm used in VMC for sampling the square of an approximate wave function, discussing details important for applications to electronic systems. We also review in detail the more sophisticated DMC algorithm within the fixed-node approximation, introduced to avoid the infamous Fermionic sign problem, which allows one to sample a more accurate approximation to the ground-state wave function. Throughout this review, we discuss the statistical methods used for evaluating expectation values and statistical uncertainties. In particular, we show how to estimate nonlinear functions of expectation values and their statistical uncertainties.},
archivePrefix = {arXiv},
arxivId = {1508.02989},
author = {Toulouse, Julien and Assaraf, Roland and Umrigar, C. J.},
eprint = {1508.02989},
file = {:home/kaslu/Documents/Mendeley/2015 - Toulouse, Assaraf, Umrigar - Introduction to the variational and diffusion Monte Carlo methods.pdf:pdf},
month = {aug},
title = {{Introduction to the variational and diffusion Monte Carlo methods}},
url = {http://arxiv.org/abs/1508.02989},
year = {2015}
}
@inproceedings{Mimno,
abstract = {The four-level pachinko allocation model (PAM) (Li {\&} McCallum, 2006) represents correlations among topics using a DAG struc-ture. It does not, however, represent a nested hierarchy of topics, with some top-ical word distributions representing the vo-cabulary that is shared among several more specific topics. This paper presents hierar-chical PAM —an enhancement that explic-itly represents a topic hierarchy. This model can be seen as combining the advantages of hLDA's topical hierarchy representation with PAM's ability to mix multiple leaves of the topic hierarchy. Experimental results show improvements in likelihood of held-out docu-ments, as well as mutual information between automatically-discovered topics and human-generated categories such as journals.},
address = {New York, New York, USA},
author = {Mimno, David and Li, Wei and McCallum, Andrew},
booktitle = {Proceedings of the 24th international conference on Machine learning - ICML '07},
doi = {10.1145/1273496.1273576},
file = {:home/kaslu/Documents/Mendeley/2007 - Mimno, Li, McCallum - Mixtures of hierarchical topics with Pachinko allocation.pdf:pdf},
isbn = {9781595937933},
pages = {633--640},
publisher = {ACM Press},
title = {{Mixtures of hierarchical topics with Pachinko allocation}},
url = {http://portal.acm.org/citation.cfm?doid=1273496.1273576},
year = {2007}
}
@article{Trust2016,
author = {Trust, Biometrika},
file = {:home/kaslu/Documents/Mendeley/2016 - Trust - Biometrika Trust Statistical Analysis for the Angular Central Gaussian Distribution on the Sphere Author ( s ) David E ..pdf:pdf},
number = {3},
pages = {579--589},
title = {{Biometrika Trust Statistical Analysis for the Angular Central Gaussian Distribution on the Sphere Author ( s ): David E . Tyler Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : http://www.jstor.org/stable/2336697 REFERENCE}},
volume = {74},
year = {2016}
}
@article{Wilson2013,
abstract = {The most exciting hypothesis in cognitive science right now is the theory that cognition is embodied. Like all good ideas in cognitive science, however, embodiment immediately came to mean six different things. The most common definitions involve the straight-forward claim that "states of the body modify states of the mind." However, the implications of embodiment are actually much more radical than this. If cognition can span the brain, body, and the environment, then the "states of mind" of disembodied cognitive science won't exist to be modified. Cognition will instead be an extended system assembled from a broad array of resources. Taking embodiment seriously therefore requires both new methods and theory. Here we outline four key steps that research programs should follow in order to fully engage with the implications of embodiment. The first step is to conduct a task analysis, which characterizes from a first person perspective the specific task that a perceiving-acting cognitive agent is faced with. The second step is to identify the task-relevant resources the agent has access to in order to solve the task. These resources can span brain, body, and environment. The third step is to identify how the agent can assemble these resources into a system capable of solving the problem at hand. The last step is to test the agent's performance to confirm that agent is actually using the solution identified in step 3. We explore these steps in more detail with reference to two useful examples (the outfielder problem and the A-not-B error), and introduce how to apply this analysis to the thorny question of language use. Embodied cognition is more than we think it is, and we have the tools we need to realize its full potential.},
author = {Wilson, Andrew D. and Golonka, Sabrina},
doi = {10.3389/fpsyg.2013.00058},
file = {:home/kaslu/Documents/Mendeley/2013 - Wilson, Golonka - Embodied Cognition is Not What you Think it is.pdf:pdf},
isbn = {1664-1078 (Electronic)},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {a-not-b,dynamical systems,embodied cognition,outfielder problem,replacement,replacement hypothesis,robotics},
number = {Article 58},
pages = {1--13},
pmid = {23408669},
publisher = {Frontiers},
title = {{Embodied Cognition is Not What you Think it is}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00058/abstract http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3569617{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2013}
}
@article{Henrich2010,
abstract = {Behavioral scientists routinely publish broad claims about human psychology and behavior in the world's top journals based on samples drawn entirely from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) societies. Researchers – often implicitly – assume that either there is little variation across human populations, or that these " standard subjects " are as representative of the species as any other population. Are these assumptions justified? Here, our review of the comparative database from across the behavioral sciences suggests both that there is substantial variability in experimental results across populations and that WEIRD subjects are particularly unusual compared with the rest of the species – frequent outliers. The domains reviewed include visual perception, fairness, cooperation, spatial reasoning, categorization and inferential induction, moral reasoning, reasoning styles, self-concepts and related motivations, and the heritability of IQ. The findings suggest that members of WEIRD societies, including young children, are among the least representative populations one could find for generalizing about humans. Many of these findings involve domains that are associated with fundamental aspects of psychology, motivation, and behavior – hence, there are no obvious a priori grounds for claiming that a particular behavioral phenomenon is universal based on sampling from a single subpopulation. Overall, these empirical patterns suggests that we need to be less cavalier in addressing questions of human nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity. We close by proposing ways to structurally re-organize the behavioral sciences to best tackle these challenges.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Henrich, Joseph and Heine, Steven J and Norenzayan, Ara},
doi = {10.1017/S0140525X0999152X},
eprint = {arXiv:1011.1669v3},
isbn = {0140-525X},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {behavioral economics,cross-cultural research,cultural psychology,culture,evolutionary psychology,experiments,external validity,generalizability,human universals,population variability},
pages = {61--135},
pmid = {20550733},
title = {{The weirdest people in the world?}},
url = {http://www.psych.ubc.ca/henrich/home.html},
volume = {33},
year = {2010}
}
@article{Johnson2016,
abstract = {We propose a general modeling and inference framework that composes probabilistic graphical models with deep learning methods and combines their respective strengths. Our model family augments graphical structure in latent variables with neural network observation models. For inference, we extend variational autoencoders to use graphical model approximating distributions with recognition networks that output conjugate potentials. All components of these models are learned simultaneously with a single objective, giving a scalable algorithm that leverages stochastic variational inference, natural gradients, graphical model message passing, and the reparameterization trick. We illustrate this framework with several example models and an application to mouse behavioral phenotyping.},
archivePrefix = {arXiv},
arxivId = {1603.06277},
author = {Johnson, Matthew J. and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan Prescott},
eprint = {1603.06277},
file = {:home/kaslu/Documents/Mendeley/2016 - Johnson et al. - Composing graphical models with neural networks for structured representations and fast inference.pdf:pdf},
month = {mar},
title = {{Composing graphical models with neural networks for structured representations and fast inference}},
url = {http://arxiv.org/abs/1603.06277},
year = {2016}
}
@article{Crockett2013,
abstract = {Moral dilemmas engender conflicts between two traditions: consequentialism, which evaluates actions based on their outcomes, and deontology, which evaluates actions themselves. These strikingly resemble two distinct decision-making architectures: a model-based system that selects actions based on inferences about their consequences; and a model-free system that selects actions based on their reinforcement history. Here, I consider how these systems, along with a Pavlovian system that responds reflexively to rewards and punishments, can illuminate puzzles in moral psychology. {\textcopyright} 2013 Elsevier Ltd.},
author = {Crockett, Molly J.},
doi = {10.1016/j.tics.2013.06.005},
file = {:home/kaslu/Documents/Mendeley/2013 - Crockett - Models of morality.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {8},
pages = {363--366},
pmid = {23845564},
publisher = {Elsevier Ltd},
title = {{Models of morality}},
url = {http://dx.doi.org/10.1016/j.tics.2013.06.005},
volume = {17},
year = {2013}
}
@article{Clauset2018,
abstract = {Since 1945, there have been relatively few large interstate wars, especially compared to the preceding 30 years, which included both World Wars. This pattern, sometimes called the long peace, is highly controversial. Does it represent an enduring trend caused by a genuine change in the underlying conflict-generating processes? Or is it consistent with a highly variable but otherwise stable system of conflict? Using the empirical distributions of interstate war sizes and onset times from 1823 to 2003, we parameterize stationary models of conflict generation that can distinguish trends from statistical fluctuations in the statistics of war. These models indicate that both the long peace and the period of great violence that preceded it are not statistically uncommon patterns in realistic but stationary conflict time series. This fact does not detract from the importance of the long peace or the proposed mechanisms that explain it. However, the models indicate that the postwar pattern of peace would need to endure at least another 100 to 140 years to become a statistically significant trend. This fact places an implicit upper bound on the magnitude of any change in the true likelihood of a large war after the end of the Second World War. The historical patterns of war thus seem to imply that the long peace may be substantially more fragile than proponents believe, despite recent efforts to identify mechanisms that reduce the likelihood of interstate wars.},
author = {Clauset, Aaron},
doi = {10.1126/sciadv.aao3580},
file = {:home/kaslu/Documents/Mendeley/2018 - Clauset - Trends and fluctuations in the severity of interstate wars.pdf:pdf},
issn = {2375-2548},
journal = {Science Advances},
month = {feb},
number = {2},
pages = {eaao3580},
publisher = {American Association for the Advancement of Science},
title = {{Trends and fluctuations in the severity of interstate wars}},
url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.aao3580},
volume = {4},
year = {2018}
}
@article{Meyniel2015,
abstract = {Research on confidence spreads across several sub-fields of psychology and neuroscience. Here, we explore how a definition of confidence as Bayesian probability can unify these viewpoints. This computational view entails that there are distinct forms in which confidence is represented and used in the brain, including distributional confidence, pertaining to neural representations of probability distributions, and summary confidence, pertaining to scalar summaries of those distributions. Summary confidence is, normatively, derived or "read out" from distributional confidence. Neural implementations of readout will trade off optimality versus flexibility of routing across brain systems, allowing confidence to serve diverse cognitive functions.},
author = {Meyniel, Florent and Sigman, Mariano and Mainen, Zachary F.},
doi = {10.1016/j.neuron.2015.09.039},
file = {:home/kaslu/Documents/Mendeley/2015 - Meyniel, Sigman, Mainen - Confidence as Bayesian Probability From Neural Origins to Behavior.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = {oct},
number = {1},
pages = {78--92},
pmid = {26447574},
publisher = {Elsevier Inc.},
title = {{Confidence as Bayesian Probability: From Neural Origins to Behavior}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.09.039 http://linkinghub.elsevier.com/retrieve/pii/S0896627315008284},
volume = {88},
year = {2015}
}
@article{Gallistel2014,
author = {Gallistel, C. R. and Krishan, Monika and Liu, Ye and Miller, Reilly and Latham, Peter E.},
doi = {10.1037/a0035232},
file = {:home/kaslu/Documents/Mendeley/2014 - Gallistel et al. - The perception of probability.pdf:pdf},
isbn = {0033-295X},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {10,1037,a0035232,adequacy trade-off,bayesian model comparison,change-point representation,compact coding,dis-,doi,dx,http,org,processes,retrospective revision,simplicity,supp,supplemental materials,we live in a,world of nonstationary stochastic},
number = {1},
pages = {96--123},
pmid = {24490790},
title = {{The perception of probability.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0035232},
volume = {121},
year = {2014}
}
@article{Horowitz2014,
author = {Horowitz, Jordan M. and Esposito, Massimiliano},
doi = {10.1103/PhysRevX.4.031015},
file = {:home/kaslu/Documents/Mendeley/2014 - Horowitz, Esposito - Thermodynamics with Continuous Information Flow.pdf:pdf},
issn = {2160-3308},
journal = {Physical Review X},
month = {jul},
number = {3},
pages = {031015},
title = {{Thermodynamics with Continuous Information Flow}},
url = {http://link.aps.org/doi/10.1103/PhysRevX.4.031015},
volume = {4},
year = {2014}
}
@article{Nienborg2012,
abstract = {Neurons in early sensory cortex show weak but systematic correlations with perceptual decisions when trained animals perform at psychophysical threshold. These correlations are observed across repeated presentations of identical stimuli and cannot be explained by variation in external factors. The relationship between the activity of individual sensory neurons and the animal's behavioral choice means that even neurons in early sensory cortex carry information about an upcoming decision. This relationship, termed choice probability, may reflect the effect of fluctuations in neuronal firing rate on the animal's decision, but it can also reflect modulation of sensory responses by cognitive factors, or network properties such as variability that is shared among populations of neurons. Here, we review recent work clarifying the relationship among fluctuations in the responses of individual neurons, correlated variability, and behavior in a variety of tasks and cortical areas. We also discuss the possibility that choice probability may in part reflect the influence of cognitive factors on sensory neurons and explore the situations in which choice probability can be used to make inferences about the role of particular sensory neurons in the decision-making process.},
author = {Nienborg, Hendrikje and {R. Cohen}, Marlene and Cumming, Bruce G.},
doi = {10.1146/annurev-neuro-062111-150403},
file = {:home/kaslu/Documents/Mendeley/2012 - Nienborg, R. Cohen, Cumming - Decision-Related Activity in Sensory Neurons Correlations Among Neurons and with Behavior.pdf:pdf},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
month = {jul},
number = {1},
pages = {463--483},
title = {{Decision-Related Activity in Sensory Neurons: Correlations Among Neurons and with Behavior}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-062111-150403},
volume = {35},
year = {2012}
}
@article{Nicholson2016,
abstract = {We show that music is represented by fluctuations away from the minimum path through statistical space. Our key idea is to envision music as the evolution of a non-equilibrium system and to construct probability distribution functions (PDFs) from musical instrument digital interface (MIDI) files of classical compositions. Classical music is then viewed through the lens of generalized position and velocity, based on the Fisher metric. Through these statistical tools we discuss a way to quantitatively discriminate between music and noise.},
author = {Nicholson, Schuyler and Kim, Eun-jin},
doi = {10.3390/e18070258},
issn = {1099-4300},
journal = {Entropy},
keywords = {fisher information,information geometry,non-equilibrium},
language = {en},
month = {jul},
number = {7},
pages = {258},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Structures in Sound: Analysis of Classical Music Using the Information Length}},
url = {http://www.mdpi.com/1099-4300/18/7/258/htm http://www.mdpi.com/1099-4300/18/7/258},
volume = {18},
year = {2016}
}
@article{Miller2017,
abstract = {The lack of a formal link between neural network structure and its emergent function has hampered our understanding of how the brain processes information. We have now come closer to describing such a link by taking the direction of synaptic transmission into account, constructing graphs of a network that reflect the direction of information flow, and analyzing these directed graphs using algebraic topology. Applying this approach to a local network of neurons in the neocortex revealed a remarkably intricate and previously unseen topology of synaptic connectivity. The synaptic network contains an abundance of cliques of neurons bound into cavities that guide the emergence of correlated activity. In response to stimuli, correlated activity binds synaptically connected neurons into functional cliques and cavities that evolve in a stereotypical sequence toward peak complexity. We propose that the brain processes stimuli by forming increasingly complex functional cliques and cavities.},
author = {Reimann, Michael W and Nolte, Max and Scolamiero, Martina and Turner, Katharine and Perin, Rodrigo and Chindemi, Giuseppe and Dlotko, Pawel and Levi, Ran and Hess, Kathryn and Markram, Henry},
doi = {10.3389/fncom.2017.00048},
file = {:home/kaslu/Documents/Mendeley/2017 - Reimann et al. - Cliques of Neurons Bound into Cavities Provide a Missing Link between Structure and Function.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Betti numbers,connectomics,correlations,directed networks,structure-function,topology},
month = {jun},
number = {June},
title = {{Cliques of Neurons Bound into Cavities Provide a Missing Link between Structure and Function}},
url = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00048/full},
volume = {11},
year = {2017}
}
@article{Grabska-Barwinska2016,
abstract = {The olfactory system faces a hard problem: on the basis of noisy information from olfactory receptor neurons (the neurons that transduce chemicals to neural activity), it must figure out which odors are present in the world. Odors almost never occur in isolation, and different odors excite overlapping populations of olfactory receptor neurons, so the central challenge of the olfactory system is to demix its input. Because of noise and the large number of possible odors, demixing is fundamentally a probabilistic inference task. We propose that the early olfactory system uses approximate Bayesian inference to solve it. The computations involve a dynamical loop between the olfactory bulb and the piriform cortex, with cortex explaining incoming activity from the olfactory receptor neurons in terms of a mixture of odors. The model is compatible with known anatomy and physiology, including pattern decorrelation, and it performs better than other models at demixing odors.},
author = {Grabska-Barwi{\'{n}}ska, Agnieszka and Barthelm{\'{e}}, Simon and Beck, Jeffrey M. and Mainen, Zachary and Pouget, Alexandre and Latham, Peter E.},
doi = {10.1038/nn.4444},
file = {:home/kaslu/Documents/Mendeley/2016 - Grabska-Barwi{\'{n}}ska et al. - A probabilistic approach to demixing odors.pdf:pdf},
isbn = {1546-1726 (Electronic) 1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {December},
pages = {6--8},
pmid = {27918530},
title = {{A probabilistic approach to demixing odors}},
url = {http://www.nature.com/doifinder/10.1038/nn.4444},
year = {2016}
}
@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
eprint = {1406.2661},
file = {:home/kaslu/Documents/Mendeley/2014 - Goodfellow et al. - Generative Adversarial Networks.pdf:pdf},
month = {jun},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}
@article{Pusey2011,
abstract = {Quantum states are the key mathematical objects in quantum theory. It is therefore surprising that physicists have been unable to agree on what a quantum state truly represents. One possibility is that a pure quantum state corresponds directly to reality. However, there is a long history of suggestions that a quantum state (even a pure state) represents only knowledge or information about some aspect of reality. Here we show that any model in which a quantum state represents mere information about an underlying physical state of the system, and in which systems that are prepared independently have independent physical states, must make predictions which contradict those of quantum theory.},
archivePrefix = {arXiv},
arxivId = {1111.3328},
author = {Pusey, Matthew F. and Barrett, Jonathan and Rudolph, Terry},
doi = {10.1038/nphys2309},
eprint = {1111.3328},
file = {:home/kaslu/Documents/Mendeley/2012 - Pusey, Barrett, Rudolph - On the reality of the quantum state.pdf:pdf;:home/kaslu/Documents/Mendeley/2012 - Pusey, Barrett, Rudolph - On the reality of the quantum state(2).pdf:pdf},
isbn = {1745-2481},
issn = {1745-2473},
journal = {Nature Physics},
month = {may},
number = {6},
pages = {476--479},
title = {{On the reality of the quantum state}},
url = {http://arxiv.org/abs/1111.3328 http://dx.doi.org/10.1038/nphys2309 http://www.nature.com/doifinder/10.1038/nphys2309},
volume = {8},
year = {2012}
}
@article{McDonnell2011,
abstract = {This article introduces several fundamental concepts in information theory from the perspective of their origins in engineering. Understanding such concepts is important in neuroscience for two reasons. Simply applying formulae from information theory without understanding the assumptions behind their definitions can lead to erroneous results and conclusions. Furthermore, this century will see a convergence of information theory and neuroscience; information theory will expand its foundations to incorporate more comprehensively biological processes thereby helping reveal how neuronal networks achieve their remarkable information processing abilities.},
archivePrefix = {arXiv},
arxivId = {1107.2984},
author = {McDonnell, Mark D. and Ikeda, Shiro and Manton, Jonathan H.},
doi = {10.1007/s00422-011-0451-9},
eprint = {1107.2984},
file = {:home/kaslu/Documents/Mendeley/2011 - McDonnell, Ikeda, Manton - An introductory review of information theory in the context of computational neuroscience.pdf:pdf;:home/kaslu/Documents/Mendeley/2011 - McDonnell, Ikeda, Manton - An introductory review of information theory in the context of computational neuroscience(2).pdf:pdf},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Brain,Brain: physiology,Cognition,Cognition: physiology,Communication,Humans,Information Theory,Mathematics,Neurons,Neurons: physiology,Neurosciences},
month = {jul},
number = {1},
pages = {55--70},
pmid = {21792610},
title = {{An introductory review of information theory in the context of computational neuroscience.}},
url = {http://arxiv.org/abs/1107.2984 http://www.ncbi.nlm.nih.gov/pubmed/21792610},
volume = {105},
year = {2011}
}
@inproceedings{Enßlin2013,
abstract = {Non-linear image reconstruction and signal analysis deal with complex inverse problems. To tackle such problems in a systematic way, I present information field theory (IFT) as a means of Bayesian, data based inference on spatially distributed signal fields. IFT is a statistical field theory, which permits the construction of optimal signal recovery algorithms even for non-linear and non-Gaussian signal inference problems. IFT algorithms exploit spatial correlations of the signal fields and benefit from techniques developed to investigate quantum and statistical field theories, such as Feynman diagrams, re-normalisation calculations, and thermodynamic potentials. The theory can be used in many areas, and applications in cosmology and numerics are presented.},
archivePrefix = {arXiv},
arxivId = {1301.2556},
author = {En{\ss}lin, Torsten},
doi = {10.1063/1.4819999},
eprint = {1301.2556},
file = {:home/kaslu/Documents/Mendeley/2013 - En{\ss}lin - Information field theory.pdf:pdf},
month = {jan},
pages = {184--191},
title = {{Information field theory}},
url = {http://arxiv.org/abs/1301.2556},
year = {2013}
}
@article{Solway2015a,
author = {Solway, Alec and Botvinick, Matthew M.},
doi = {10.1073/pnas.1505483112},
file = {:home/kaslu/Documents/Mendeley/2015 - Solway, Botvinick - Evidence integration in model-based tree search.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {sep},
number = {37},
pages = {11708--11713},
title = {{Evidence integration in model-based tree search}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1505483112},
volume = {112},
year = {2015}
}
@article{Tkacik2010,
abstract = {In retina and in cortical slice the collective response of spiking neural populations is well described by "maximum-entropy" models in which only pairs of neurons interact. We asked, how should such interactions be organized to maximize the amount of information represented in population responses? To this end, we extended the linear-nonlinear-Poisson model of single neural response to include pairwise interactions, yielding a stimulus-dependent, pairwise maximum-entropy model. We found that as we varied the noise level in single neurons and the distribution of network inputs, the optimal pairwise interactions smoothly interpolated to achieve network functions that are usually regarded as discrete--stimulus decorrelation, error correction, and independent encoding. These functions reflected a trade-off between efficient consumption of finite neural bandwidth and the use of redundancy to mitigate noise. Spontaneous activity in the optimal network reflected stimulus-induced activity patterns, and single-neuron response variability overestimated network noise. Our analysis suggests that rather than having a single coding principle hardwired in their architecture, networks in the brain should adapt their function to changing noise and stimulus correlations.},
author = {Tkacik, Gasper and Prentice, J. S. and Balasubramanian, Vijay and Schneidman, Elad},
doi = {10.1073/pnas.1004906107},
file = {:home/kaslu/Documents/Mendeley/2010 - Tkacik et al. - Optimal population coding by noisy spiking neurons.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {aug},
number = {32},
pages = {14419--14424},
pmid = {20660781},
title = {{Optimal population coding by noisy spiking neurons}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1004906107},
volume = {107},
year = {2010}
}
@article{Kirkpatrick1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
doi = {10.1126/science.220.4598.671},
file = {:home/kaslu/Documents/Mendeley/1983 - Kirkpatrick, Gelatt, Vecchi - Optimization by Simulated Annealing.pdf:pdf},
isbn = {1095-9203 (Electronic)$\backslash$r0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
number = {4598},
pages = {pp. 671--680},
pmid = {17813860},
title = {{Optimization by Simulated Annealing}},
url = {http://www.jstor.org/stable/1690046},
volume = {220},
year = {1983}
}
@article{Norman2003,
abstract = {The authors present a computational neural-network model of how the hippocampus and medial temporal lobe cortex (MTLC) contribute to recognition memory. The hippocampal component contributes by recalling studied details. The MTLC component cannot support recall, but one can extract a scalar familiarity signal from MTLC that tracks how well a test item matches studied items. The authors present simulations that establish key differences in the operating characteristics of the hippocampal-recall and MTLC-familiarity signals and identify several manipulations (e.g., target-lure similarity, interference) that differentially affect the 2 signals. They also use the model to address the stochastic relationship between recall and familiarity and the effects of partial versus complete hippocampal lesions on recognition.},
author = {Norman, Kenneth A. and O'Reilly, Randall C.},
doi = {10.1037/0033-295X.110.4.611},
file = {:home/kaslu/Documents/Mendeley/2003 - Norman, O'Reilly - Modeling hippocampal and neocortical contributions to recognition memory A complementary-learning-systems appr.pdf:pdf},
isbn = {0033-295X (Print)$\backslash$r0033-295X (Linking)},
issn = {1939-1471},
journal = {Psychological Review},
number = {4},
pages = {611--646},
pmid = {14599236},
title = {{Modeling hippocampal and neocortical contributions to recognition memory: A complementary-learning-systems approach.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.4.611},
volume = {110},
year = {2003}
}
@article{Dvali2018,
abstract = {Motivated by the potential similarities between the underlying mechanisms of the enhanced memory storage capacity in black holes and in brain networks, we construct an artificial quantum neural network based on gravity-like synaptic connections and a symmetry structure that allows to describe the network in terms of geometry of a d-dimensional space. We show that the network possesses a critical state in which the gapless neurons emerge that appear to inhabit a (d-1)-dimensional surface, with their number given by the surface area. In the excitations of these neurons, the network can store and retrieve an exponentially large number of patterns within an arbitrarily narrow energy gap. The corresponding micro-state entropy of the brain network exhibits an area law. The neural network can be described in terms of a quantum field, via identifying the different neurons with the different momentum modes of the field, while identifying the synaptic connections among the neurons with the interactions among the corresponding momentum modes. Such a mapping allows to attribute a well-defined sense of geometry to an intrinsically non-local system, such as the neural network, and vice versa, it allows to represent the quantum field model as a neural network.},
archivePrefix = {arXiv},
arxivId = {1801.03918},
author = {Dvali, Gia},
eprint = {1801.03918},
file = {:home/kaslu/Documents/Mendeley/2018 - Dvali - Black Holes as Brains Neural Networks with Area Law Entropy.pdf:pdf},
journal = {arXiv},
month = {jan},
title = {{Black Holes as Brains: Neural Networks with Area Law Entropy}},
url = {http://arxiv.org/abs/1801.03918},
year = {2018}
}
@article{Haidt2001,
abstract = {Research on moral judgment has been dominated by rationalist models, in which moral judgment is thought to be caused by moral reasoning. The author gives 4 reasons for considering the hypothesis that moral reasoning does not cause moral judgment; rather, moral reasoning is usually a post hoc construction, generated after a judgment has been reached. The social intuitionist model is presented as an alternative to rationalist models. The model is a social model in that it deemphasizes the private reasoning done by individuals and emphasizes instead the importance of social and cultural influences. The model is an intuitionist model in that it states that moral judgment is generally the result of quick, automatic evaluations (intuitions). The model is more consistent that rationalist models with recent findings in social, cultural, evolutionary, and biological psychology, as well as in anthropology and primatology.},
author = {Haidt, Jonathan},
doi = {10.1037/0033-295X.108.4.814},
file = {:home/kaslu/Documents/Mendeley/2001 - Haidt - The emotional dog and its rational tail a social intuitionist approach to moral judgment.pdf:pdf},
isbn = {0033-295X (Print)$\backslash$r0033-295X (Linking)},
issn = {0033-295X},
journal = {Psychological review},
number = {4},
pages = {814--834},
pmid = {11699120},
title = {{The emotional dog and its rational tail: a social intuitionist approach to moral judgment.}},
volume = {108},
year = {2001}
}
@article{Gelfand1999,
abstract = {This research incorporates the theory of individualism-collectivism into research on accountability in intergroup negotiations. Given that accountability is fundamentally a norm enforcement mechanism and that norms and standards for behavior vary for individualists and collectivists ( H. R. Markus {\&} S. Kitayama, 1991 ; H. C. Triandis, 1995 ) it was predicted that accountability would differentially affect individualists and collectivists in intergroup negotiations. In support of this, results from a laboratory study (with Caucasians and Asian Americans) and from a judgment study (in the United States and Estonia) found that collectivism moderated the effects of accountability on negotiators' psychological states, behaviors, and outcomes. In contrast to previous research, the results illustrate that accountability does not necessarily produce competitive behavior, but rather produces the behavior most normative for individuals in their sociocultural experience.},
author = {Gelfand, Michele J. and Realo, Anu},
doi = {10.1037/0021-9010.84.5.721},
isbn = {1939-1854},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
number = {5},
pages = {721--736},
pmid = {8365},
title = {{Individualism-collectivism and accountability in intergroup negotiations.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0021-9010.84.5.721},
volume = {84},
year = {1999}
}
@article{Deneve2012,
abstract = {To make fast and accurate behavioral choices, we need to integrate noisy sensory input, take prior knowledge into account, and adjust our decision criteria. It was shown previously that in two-alternative-forced-choice tasks, optimal decision making can be formalized in the framework of a sequential probability ratio test and is then equivalent to a diffusion model. However, this analogy hides a "chicken and egg" problem: to know how quickly we should integrate the sensory input and set the optimal decision threshold, the reliability of the sensory observations must be known in advance. Most of the time, we cannot know this reliability without first observing the decision outcome. We consider here a Bayesian decision model that simultaneously infers the probability of two different choices and at the same time estimates the reliability of the sensory information on which this choice is based. We show that this can be achieved within a single trial, based on the noisy responses of sensory spiking neurons. The resulting model is a non-linear diffusion to bound where the weight of the sensory inputs and the decision threshold are both dynamically changing over time. In difficult decision trials, early sensory inputs have a stronger impact on the decision, and the threshold collapses such that choices are made faster but with low accuracy. The reverse is true in easy trials: the sensory weight and the threshold increase over time, leading to slower decisions but at much higher accuracy. In contrast to standard diffusion models, adaptive sensory weights construct an accurate representation for the probability of each choice. This information can then be combined appropriately with other unreliable cues, such as priors. We show that this model can account for recent findings in a motion discrimination task, and can be implemented in a neural architecture using fast Hebbian learning.},
author = {Den{\`{e}}ve, Sophie},
doi = {10.3389/fnins.2012.00075},
file = {:home/kaslu/Documents/Mendeley/2012 - Den{\`{e}}ve - Making decisions with unknown sensory reliability.pdf:pdf},
isbn = {1662-453X},
issn = {16624548},
journal = {Frontiers in Neuroscience},
keywords = {Adaptation,Bayesian,Decision making,Decision threshold,Evidence,Expectation-maximization,Prior,Uncertainty},
number = {JUN},
pmid = {22679418},
title = {{Making decisions with unknown sensory reliability}},
year = {2012}
}
@article{Howard2016,
abstract = {The Weber-Fechner law describes the form of psychological space in many behavioral experiments involving perception of one-dimensional physical quantities. If the physical quantity is expressed using multiple neural receptors, then placing receptive fields evenly along a logarithmic scale naturally leads to the psychological Weber-Fechner law. In the visual system, the spacing and width of extrafoveal receptive fields are consistent with logarithmic scaling. Other sets of neural "receptors" appear to show the same qualitative properties, suggesting that this form of neural scaling reflects a solution to a very general problem. This paper argues that these neural scaling laws enable the brain to represent information about the world efficiently without making any assumptions about the statistics of the world. This analysis suggests that the organization of neural scales to represent one-dimensional quantities, including more abstract quantities such as numerosity, time, and allocentric space, should have a universal form. The ratio of adjacent receptor spacings should be locally constant almost everywhere. Globally, for certain values of the ratio there should be a region of constant spacing---analogous to the fovea in vision---for small values of the scale transitioning abruptly to a logarithmic scale at larger values. The generality of these arguments suggest they should apply to a range of neural systems and taken into consideration in the design of artificial neural systems.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1607.04886},
author = {Howard, Marc W. and Shankar, Karthik H.},
eprint = {1607.04886},
file = {:home/kaslu/Documents/Mendeley/2016 - Howard, Shankar - Neural scaling laws for an uncertain world.pdf:pdf},
month = {jul},
title = {{Neural scaling laws for an uncertain world}},
url = {http://arxiv.org/abs/1607.04886},
year = {2016}
}
@article{Manoel2013,
abstract = {Reputation systems seek to infer which members of a community can be trusted based on ratings they issue about each other. We construct a Bayesian inference model and simulate approximate estimates using belief propagation (BP). The model is then mapped onto computing equilibrium properties of a spin glass in a random field and analyzed by employing the replica symmetric cavity approach. Having the fraction of trustful nodes and environment noise level as control parameters, we evaluate the theoretical performance in terms of estimation error and the robustness of the BP approximation in different scenarios. Regions of degraded performance are then explained by the convergence properties of the BP algorithm and by the emergence of a glassy phase.},
archivePrefix = {arXiv},
arxivId = {1211.6462},
author = {Manoel, Andre and Vicente, Renato},
doi = {10.1088/1742-5468/2013/08/P08002},
eprint = {1211.6462},
file = {:home/kaslu/Documents/Mendeley/2013 - Manoel, Vicente - Statistical mechanics of reputation systems in autonomous networks.pdf:pdf},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {rv,social},
mendeley-tags = {rv,social},
month = {aug},
number = {08},
pages = {P08002},
title = {{Statistical mechanics of reputation systems in autonomous networks}},
url = {http://arxiv.org/abs/1211.6462 http://stacks.iop.org/1742-5468/2013/i=08/a=P08002?key=crossref.63cd02c34d7fae74db4c250003349c28},
volume = {2013},
year = {2013}
}
@article{A.L.Berger1996,
abstract = {The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper, we describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in natural language processing.},
author = {Berger, Adam L and {Della Pietra}, Vincent J and {Della Pietra}, Stephen A},
doi = {10.3115/1075812.1075844},
file = {:home/kaslu/Documents/Mendeley/1996 - Berger, Della Pietra, Della Pietra - A maximum entropy approach to natural language processing.pdf:pdf},
isbn = {1558603573},
issn = {08912017},
journal = {Computational linguistics},
number = {1},
pages = {39--71},
title = {{A maximum entropy approach to natural language processing}},
url = {http://portal.acm.org/citation.cfm?id=234285.234289},
volume = {22},
year = {1996}
}
@article{Castellana2014a,
abstract = {If we have a system of binary variables and we measure the pairwise correlations among these variables, then the least structured or maximum entropy model for their joint distribution is an Ising model with pairwise interactions among the spins. Here we consider inhomogeneous systems in which we constrain, for example, not the full matrix of correlations, but only the distribution from which these correlations are drawn. In this sense, what we have constructed is an inverse spin glass: rather than choosing coupling constants at random from a distribution and calculating correlations, we choose the correlations from a distribution and infer the coupling constants. We argue that such models generate a block structure in the space of couplings, which provides an explicit solution of the inverse problem. This allows us to generate a phase diagram in the space of (measurable) moments of the distribution of correlations. We expect that these ideas will be most useful in building models for systems that are nonequilibrium statistical mechanics problems, such as networks of real neurons.},
archivePrefix = {arXiv},
arxivId = {1312.0886},
author = {Castellana, Michele and Bialek, William},
doi = {10.1103/PhysRevLett.113.117204},
eprint = {1312.0886},
file = {:home/kaslu/Documents/Mendeley/2014 - Castellana, Bialek - Inverse spin glass and related maximum entropy problems.pdf:pdf},
issn = {1079-7114},
journal = {Physical Review Letters},
month = {sep},
number = {11},
pages = {117204},
pmid = {25260004},
title = {{Inverse spin glass and related maximum entropy problems.}},
url = {http://arxiv.org/abs/1312.0886 http://link.aps.org/doi/10.1103/PhysRevLett.113.117204},
volume = {113},
year = {2014}
}
@article{Schneidman2006,
author = {Schneidman, Elad and Berry, Michael J. and Segev, Ronen and Bialek, William},
doi = {10.1038/nature04701},
file = {:home/kaslu/Documents/Mendeley/2006 - Schneidman et al. - Weak pairwise correlations imply strongly correlated network states in a neural population.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {apr},
number = {7087},
pages = {1007--1012},
publisher = {Nature Publishing Group},
title = {{Weak pairwise correlations imply strongly correlated network states in a neural population}},
url = {http://www.nature.com/doifinder/10.1038/nature04701},
volume = {440},
year = {2006}
}
@article{Erren2007,
abstract = {Posters are a key component of communicating your science and an important element in a successful scientific career. Posters, while delivering the same high-quality science, offer a different medium from either oral presentations 1 or published papers 2, and should be treated accordingly. Posters should be considered a snapshot of your work intended to engage colleagues in a dialog about the work, or, if you are not present, to be a summary that will encourage the reader to want to learn more. Many a lifelong collaboration 3 has begun in front of a poster board. Here are ten simple rules for maximizing the return on the time-consuming process of preparing and presenting an effective poster.},
author = {Erren, Thomas C. and Bourne, Philip E.},
doi = {10.1371/journal.pcbi.0030102},
file = {:home/kaslu/Documents/Mendeley/2007 - Erren, Bourne - Ten simple rules for a good poster presentation.pdf:pdf},
isbn = {1553-7358},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {5},
pages = {0777--0778},
pmid = {17530921},
title = {{Ten simple rules for a good poster presentation}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1876493/},
volume = {3},
year = {2007}
}
@article{Szegedy2013,
abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.   First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.   Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
eprint = {1312.6199},
file = {:home/kaslu/Documents/Mendeley/2013 - Szegedy et al. - Intriguing properties of neural networks.pdf:pdf},
month = {dec},
title = {{Intriguing properties of neural networks}},
url = {http://arxiv.org/abs/1312.6199},
year = {2013}
}
@article{Aktas2016,
abstract = {Previous research has investigated the relationship between cultural values and leadership. This research expands on this tradition and examines how the strength of social norms—or tightness–looseness—influences perceptions of effective leadership. Data from Gelfand, Raver, et al. were integrated with GLOBE's leadership research to examine the attributes of leaders seen as leading to effectiveness in tight and loose cultures. Analyses of data across 29 samples show that cultural tightness is positively related to the endorsement of autonomous leadership and negatively related to the endorsement of charismatic and team leadership, even controlling for in-group collectivism, power distance, and future orientation at the societal and organizational level of analysis. Theoretical and practical implications are discussed.},
author = {Aktas, Mert and Gelfand, Michele J. and Hanges, Paul J.},
doi = {10.1177/0022022115606802},
isbn = {0022-0221$\backslash$r1552-5422},
issn = {0022-0221},
journal = {Journal of Cross-Cultural Psychology},
keywords = {1990,1997,aditya,alike,bass,culture,group of individuals influences,has been,house,leadership,leadership attributes,leadership effectiveness,looseness,many,norms,of interest to social,one person or a,others,scientists and policy makers,the process by which,tightness},
month = {feb},
number = {2},
pages = {294--309},
title = {{Cultural Tightness-Looseness and Perceptions of Effective Leadership}},
url = {http://jcc.sagepub.com/content/47/2/294 http://jcc.sagepub.com/cgi/doi/10.1177/0022022115606802},
volume = {47},
year = {2016}
}
@article{Baldassi2016,
abstract = {In artificial neural networks, learning from data is a computationally demanding task in which a large number of connection weights are iteratively tuned through stochastic-gradient-based heuristic processes over a cost function. It is not well understood how learning occurs in these systems, in particular how they avoid getting trapped in configurations with poor computational performance. Here, we study the difficult case of networks with discrete weights, where the optimization landscape is very rough even for simple architectures, and provide theoretical and numerical evidence of the existence of rare-but extremely dense and accessible-regions of configurations in the network weight space. We define a measure, the robust ensemble (RE), which suppresses trapping by isolated configurations and amplifies the role of these dense regions. We analytically compute the RE in some exactly solvable models and also provide a general algorithmic scheme that is straightforward to implement: define a cost function given by a sum of a finite number of replicas of the original cost function, with a constraint centering the replicas around a driving assignment. To illustrate this, we derive several powerful algorithms, ranging from Markov Chains to message passing to gradient descent processes, where the algorithms target the robust dense states, resulting in substantial improvements in performance. The weak dependence on the number of precision bits of the weights leads us to conjecture that very similar reasoning applies to more conventional neural networks. Analogous algorithmic schemes can also be applied to other optimization problems.},
archivePrefix = {arXiv},
arxivId = {1605.06444},
author = {Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer T and Ingrosso, Alessandro and Lucibello, Carlo and Saglietti, Luca and Zecchina, Riccardo},
doi = {10.1073/pnas.1608103113},
eprint = {1605.06444},
file = {:home/kaslu/Documents/Mendeley/2016 - Baldassi et al. - Unreasonable effectiveness of learning neural networks From accessible states and robust ensembles to basic alg.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {machine learning,neural networks,optimization,statistical physics},
number = {48},
pages = {E7655--E7662},
pmid = {27856745},
title = {{Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27856745{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5137727},
volume = {113},
year = {2016}
}
@article{Chikuse1990,
abstract = {The Riemann space whose elements are m ?? k (m ??? k) matrices X such that X???X = Ik is called the Stiefel manifold and denoted by Vk,m. Some distributions on Vk,m, e.g., the matrix Langevin (or von Mises-Fisher) and Bingham distributions and the uniform distribution, have been defined and discussed in the literature. In this paper, we present methods to construct new kinds of distributions on Vk,m and discuss some properties of these distributions. We investigate distributions of the "orientation" HZ = Z(Z???Z)-1 2 (??{\{}lunate{\}}Vk,m) of an m ?? k random matrix Z. The general integral form of the density of HZ reduces to a simple mathematical form, when Z has the matrix-variate central normal distribution with parameter ??, an m ?? m positive definite matrix. We may call this distribution the matrix angular central Gaussian distribution with parameter ??, denoted by the MACG (??) distribution. The MACG distribution reduces to the angular central Gaussian distribution on the hypersphere for k = 1, which has been already known. Then, we are concerned with distributions of the orientation HY of a linear transformation Y = BZ of Z, where B is an m ?? m matrix such that ???B??? ??? 0. Utilizing properties of these distributions, we propose a general family of distributions of Z such that HZ has the MACG (??) distribution. ?? 1990.},
author = {Chikuse, Yasuko},
doi = {10.1016/0047-259X(90)90050-R},
file = {:home/kaslu/Documents/Mendeley/1990 - Chikuse - The matrix angular central Gaussian distribution.pdf:pdf},
issn = {10957243},
journal = {Journal of Multivariate Analysis},
keywords = {Stiefel manifolds,matrix angular Gaussian distributions,matrix elliptically symmetric distributions,matrix-variate normal distributions,orientation of a random matrix},
number = {2},
pages = {265--274},
title = {{The matrix angular central Gaussian distribution}},
volume = {33},
year = {1990}
}
@article{Dewar2003,
author = {Dewar, Roderick},
file = {:home/kaslu/Documents/Mendeley/2003 - Dewar - Information theory explanation of the fluctuation theorem, maximum entropy production and self-organized criticality in n.pdf:pdf},
pages = {631--641},
title = {{Information theory explanation of the fluctuation theorem, maximum entropy production and self-organized criticality in non-equilibrium stationary states}},
volume = {36},
year = {2003}
}
@article{Jerico2016,
abstract = {Inequality and its consequences are the subject of intense recent debate. Using a simplified model of the economy, we address the relation between inequality and liquidity, the latter understood as the frequency of economic exchanges. Assuming a Pareto distribution of wealth for the agents, that is consistent with empirical findings, we find an inverse relation between wealth inequality and overall liquidity. We show that an increase in the inequality of wealth results in an even sharper concentration of the liquid financial resources. This leads to a congestion of the flow of goods and the arrest of the economy when the Pareto exponent reaches one.},
archivePrefix = {arXiv},
arxivId = {1602.07300},
author = {Jeric{\'{o}}, Jo{\~{a}}o Pedro and Landes, Fran{\c{c}}ois P and Marsili, Matteo and {P{\'{e}}rez Castillo}, Isaac and Volpati, Valerio},
doi = {10.1088/1742-5468/2016/07/073402},
eprint = {1602.07300},
file = {:home/kaslu/Documents/Mendeley/2016 - Jeric{\'{o}} et al. - When does inequality freeze an economy.pdf:pdf},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {critical phenomena of socio-economic,interacting agent,models,stochastic processes,systems},
month = {jul},
number = {7},
pages = {073402},
publisher = {IOP Publishing},
title = {{When does inequality freeze an economy?}},
url = {http://stacks.iop.org/1742-5468/2016/i=7/a=073402?key=crossref.7d1b867c253f1d2c07191fc22b37d22d http://arxiv.org/abs/1602.07300 http://dx.doi.org/10.1088/1742-5468/2016/07/073402},
volume = {2016},
year = {2016}
}
@article{Kinouchi2006,
abstract = {A recurrent idea in the study of complex systems is that optimal information processing is to be found near bifurcation points or phase transitions. However, this heuristic hypothesis has few (if any) concrete realizations where a standard and biologically relevant quantity is optimized at criticality. Here we give a clear example of such a phenomenon: a network of excitable elements has its sensitivity and dynamic range maximized at the critical point of a non-equilibrium phase transition. Our results are compatible with the essential role of gap junctions in olfactory glomeruli and retinal ganglionar cell output. Synchronization and global oscillations also appear in the network dynamics. We propose that the main functional role of electrical coupling is to provide an enhancement of dynamic range, therefore allowing the coding of information spanning several orders of magnitude. The mechanism could provide a microscopic neural basis for psychophysical laws.},
archivePrefix = {arXiv},
arxivId = {q-bio/0601037},
author = {Kinouchi, Osame and Copelli, Mauro},
doi = {10.1038/nphys289},
eprint = {0601037},
file = {:home/kaslu/Documents/Mendeley/2006 - Kinouchi, Copelli - Optimal dynamical range of excitable networks at criticality.pdf:pdf},
isbn = {1745-2473},
issn = {1745-2473},
journal = {Nature Physics},
number = {5},
pages = {348--351},
primaryClass = {q-bio},
title = {{Optimal dynamical range of excitable networks at criticality}},
url = {http://arxiv.org/abs/q-bio/0601037{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nphys289},
volume = {2},
year = {2006}
}
@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:home/kaslu/Documents/Mendeley/2009 - George, Hawkins - Towards a mathematical theory of cortical micro-circuits.pdf:pdf},
isbn = {1553-734X},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {10},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
volume = {5},
year = {2009}
}
@article{Rigotti2013,
abstract = {Nature (2013). doi:10.1038/nature12160},
author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao-Jing and Daw, Nathaniel D. and Miller, Earl K and Fusi, Stefano},
doi = {10.1038/nature12160},
file = {:home/kaslu/Documents/Mendeley/2013 - Rigotti et al. - The importance of mixed selectivity in complex cognitive tasks.pdf:pdf},
isbn = {doi:10.1038/nature12160},
issn = {1476-4687},
journal = {Nature},
number = {7451},
pages = {1--6},
pmid = {23685452},
publisher = {Nature Publishing Group},
title = {{The importance of mixed selectivity in complex cognitive tasks}},
url = {http://dx.doi.org/10.1038/nature12160{\%}5Cnpapers3://publication/doi/10.1038/nature12160},
volume = {497},
year = {2013}
}
@article{Biehl1994,
abstract = {We study on-line learning of a linearly separable rule with a simple perceptron. Training utilizes a sequence of uncorrelated, randomly drawn N -dimensional input examples. In the thermodynamic limit the generalization error after training such examples with P can be calculated exactly. For the standard perceptron algorithm it decrease like ( N/P ) 1/3 for large P/N , in contrast to the faster ( N/P ) 1/2 -behaviour of the so-called Hebbian learning. Furthermore, we show that a specific parameter-free on-line scheme, the AdaTron algorithm, gives an asymptotic ( N/P )-decay of the generalization error. This coincides (up to a constant factor) with the bound for any training process based on random examples, including off-line learning. Simulations confirm our results.},
author = {Biehl, Michael and Riegler, P},
doi = {10.1209/0295-5075/28/7/012},
file = {:home/kaslu/Documents/Mendeley/1994 - Biehl, Riegler - On-Line Learning with a Perceptron.pdf:pdf},
issn = {0295-5075},
journal = {Europhysics Letters (EPL)},
month = {dec},
number = {7},
pages = {525--530},
title = {{On-Line Learning with a Perceptron}},
url = {https://iopscience.iop.org/article/10.1209/0295-5075/28/7/012/},
volume = {28},
year = {1994}
}
@article{Fry2013,
abstract = {It has been argued that warfare evolved as a component of early human behavior within foraging band societies. We investigated lethal aggression in a sample of 21 mobile forager band societies (MFBS) derived systematically from the standard cross-cultural sample. We hypothesized, on the basis of mobile forager ethnography, that most lethal events would stem from personal disputes rather than coalitionary aggression against other groups (war). More than half of the lethal aggression events were perpetrated by lone individuals, and almost two-thirds resulted from accidents, interfamilial disputes, within-group executions, or interpersonal motives such as competition over a particular woman. Overall, the findings suggest that most incidents of lethal aggression among MFBS may be classified as homicides, a few others as feuds, and a minority as war.},
author = {Fry, Douglas P and Soderberg, P.},
doi = {10.1126/science.1235675},
issn = {0036-8075},
journal = {Science},
month = {jul},
number = {6143},
pages = {270--273},
pmid = {23869015},
title = {{Lethal Aggression in Mobile Forager Bands and Implications for the Origins of War}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23869015 http://www.sciencemag.org/cgi/doi/10.1126/science.1235675},
volume = {341},
year = {2013}
}
@article{Pillow2017,
abstract = {A study introduces innovative ways to test whether neural population activity exhibits structure above and beyond that of its basic components.},
author = {Pillow, Jonathan W. and Aoi, Mikio C.},
doi = {10.1038/nn.4627},
file = {:home/kaslu/Documents/Mendeley/2017 - Pillow, Aoi - Is population activity more than the sum of its parts(2).pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Dynamical systems,Network models},
month = {aug},
number = {9},
pages = {1196--1198},
publisher = {Nature Publishing Group},
title = {{Is population activity more than the sum of its parts?}},
url = {http://www.nature.com/doifinder/10.1038/nn.4627},
volume = {20},
year = {2017}
}
@article{Ma2014,
abstract = {Organisms must act in the face of sensory, motor, and reward uncertainty stemming from a pandemonium of stochasticity and missing information. In many tasks, organisms can make better decisions if they have at their disposal a representation of the uncertainty associated with task-relevant variables. We formalize this problem using Bayesian decision theory and review recent behavioral and neural evidence that the brain may use knowledge of uncertainty, confidence, and probability.},
author = {Ma, Wei Ji and Jazayeri, Mehrdad},
doi = {10.1146/annurev-neuro-071013-014017},
file = {:home/kaslu/Documents/Mendeley/2014 - Ma, Jazayeri - Neural Coding of Uncertainty and Probability.pdf:pdf},
isbn = {0147-006X},
issn = {1545-4126},
journal = {Annual review of neuroscience},
keywords = {Bayesian inference,decision making,perception,population encoding},
pages = {205--220},
pmid = {25032495},
title = {{Neural Coding of Uncertainty and Probability.}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-neuro-071013-014017},
volume = {37},
year = {2014}
}
@article{Shadlen2013,
abstract = {A decision is a commitment to a proposition or plan of action based on information and values associated with the possible outcomes. The process operates in a flexible timeframe that is free from the immediacy of evidence acquisition and the real time demands of action itself. Thus, it involves deliberation, planning, and strategizing. This Perspective focuses on perceptual decision making in nonhuman primates and the discovery of neural mechanisms that support accuracy, speed, and confidence in a decision. We suggest that these mechanisms expose principles of cognitive function in general, and we speculate about the challenges and directions before the field.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Shadlen, Michael N. and Kiani, Roozbeh},
doi = {10.1016/j.neuron.2013.10.047},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2013 - Shadlen, Kiani - Decision making as a window on cognition.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
number = {3},
pages = {791--806},
pmid = {24183028},
publisher = {Elsevier Inc.},
title = {{Decision making as a window on cognition}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.10.047},
volume = {80},
year = {2013}
}
@article{Krueger2008,
abstract = {Sleep is vital to cognitive performance, productivity, health and well-being. Earlier theories of sleep presumed that it occurred at the level of the whole organism and that it was governed by central control mechanisms. However, evidence now indicates that sleep might be regulated at a more local level in the brain: it seems to be a fundamental property of neuronal networks and is dependent on prior activity in each network. Such local-network sleep might be initiated by metabolically driven changes in the production of sleep-regulatory substances. We discuss a mathematical model which illustrates that the sleep-like states of individual cortical columns can be synchronized through humoral and electrical connections, and that whole-organism sleep occurs as an emergent property of local-network interactions.},
author = {Krueger, James M. and Rector, David M. and Roy, Sandip and {Van Dongen}, Hans P A and Belenky, Gregory and Panksepp, Jaak},
doi = {10.1038/nrn2521},
file = {:home/kaslu/Documents/Mendeley/2008 - Krueger et al. - Sleep as a fundamental property of neuronal assemblies.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
number = {12},
pages = {910--919},
pmid = {18985047},
title = {{Sleep as a fundamental property of neuronal assemblies}},
volume = {9},
year = {2008}
}
@article{Chambers2016,
author = {Chambers, Brendan and MacLean, Jason N.},
doi = {10.1371/journal.pcbi.1005078},
editor = {Triesch, Jochen},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {aug},
number = {8},
pages = {e1005078},
publisher = {Public Library of Science},
title = {{Higher-Order Synaptic Interactions Coordinate Dynamics in Recurrent Networks}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1005078},
volume = {12},
year = {2016}
}
@article{DeRuytervanSteveninck1997,
abstract = {To provide information about dynamic sensory stimuli, the pattern of action potentials in spiking neurons must be variable. To ensure reliability these variations must be related, reproducibly, to the stimulus. For H1, a motion-sensitive neuron in the fly's visual system, constant-velocity motion produces irregular spike firing patterns, and spike counts typically have a variance comparable to the mean, for cells in the mammalian cortex. But more natural, time-dependent input signals yield patterns of spikes that are much more reproducible, both in terms of timing and of counting precision. Variability and reproducibility are quantified with ideas from information theory, and measured spike sequences in H1 carry more than twice the amount of information they would if they followed the variance-mean relation seen with constant inputs. Thus, models that may accurately account for the neural response to static stimuli can significantly underestimate the reliability of signal transfer under more natural conditions.},
author = {{de Ruyter van Steveninck}, R. R.},
doi = {10.1126/science.275.5307.1805},
file = {:home/kaslu/Documents/Mendeley/1997 - de Ruyter van Steveninck - Reproducibility and Variability in Neural Spike Trains.pdf:pdf},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
month = {mar},
number = {5307},
pages = {1805--1808},
pmid = {9065407},
title = {{Reproducibility and Variability in Neural Spike Trains}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.275.5307.1805},
volume = {275},
year = {1997}
}
@article{Allen1966,
abstract = {Publisher Summary Conformity to the group is a complex phenomenon, which should be differentiated into several distinct psychological processes, and has often been contrasted with nonconformity or independence. This chapter describes the various aspects of conformity, public compliance and private change, conditions of responding, characteristics of the group, and nature of the task. Nonconformity consists of two conceptually distinct types of behavior, and may reflect independence, or it may actually be anticonformity. These three types of behavior—conformity, independence, and anticonformity—are related to each other as the apexes of a triangle. It makes a great deal of difference whether agreement with the group is public compliance, or true private change, or whether nonconformity represents independence or anticonformity. Although, there have been a few studies of generalization of conformity, little is known of the generality of conformity, and investigations have not been conducted on the generality of conformity across situations outside the laboratory. A subject in a conformity situation has information and beliefs about several important features of the situation: the task, other members of the group, and the experimenter. Theories of conformity, which have been advanced in recent years, include psychoanalytic, cognitive, reinforcement, and even mathematical models. Research should be directed toward understanding the variables that affect nonconformity, as well as conformity.},
author = {Allen, Vernon L.},
doi = {10.1016/S0065-2601(08)60105-7},
file = {:home/kaslu/Documents/Mendeley/1966 - Allen - Situational Factors In Conformity.pdf:pdf},
isbn = {0065-2601},
issn = {00652601},
journal = {Advances in Experimental Social Psychology},
number = {C},
pages = {133--175},
title = {{Situational Factors In Conformity}},
volume = {2},
year = {1966}
}
@inproceedings{Abdolmaleki2015,
author = {Abdolmaleki, Abbas and Lioutikov, Rudolf and Peters, Jan R. and Lau, Nuno and Reis, Luis Pualo and Neumann, Gerhard},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/kaslu/Documents/Mendeley/2015 - Abdolmaleki et al. - Model-Based Relative Entropy Stochastic Search.pdf:pdf},
pages = {3537--3545},
title = {{Model-Based Relative Entropy Stochastic Search}},
url = {https://papers.nips.cc/paper/5672-model-based-relative-entropy-stochastic-search},
year = {2015}
}
@article{Lim2013,
abstract = {Persistent neural activity in the absence of a stimulus has been identified as a neural correlate of working memory, but how such activity is maintained by neocortical circuits remains unknown. We used a computational approach to show that the inhibitory and excitatory microcircuitry of neocortical memory-storing regions is sufficient to implement a corrective feedback mechanism that enables persistent activity to be maintained stably for prolonged durations. When recurrent excitatory and inhibitory inputs to memory neurons were balanced in strength and offset in time, drifts in activity triggered a corrective signal that counteracted memory decay. Circuits containing this mechanism temporally integrated their inputs, generated the irregular neural firing observed during persistent activity and were robust against common perturbations that severely disrupted previous models of short-term memory storage. These results reveal a mechanism for the accumulation and storage of memories in neocortical circuits based on principles of corrective negative feedback that are widely used in engineering applications.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lim, Sukbin and Goldman, Mark S},
doi = {10.1038/nn.3492},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2013 - Lim, Goldman - Balanced cortical microcircuitry for maintaining information in working memory.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {9},
pages = {1306--1314},
pmid = {23955560},
title = {{Balanced cortical microcircuitry for maintaining information in working memory}},
url = {http://www.nature.com/doifinder/10.1038/nn.3492},
volume = {16},
year = {2013}
}
@article{Bialek1987,
abstract = {Annu. Rev. Biophys. Biophys. Chem. 1987.16:455-478},
author = {Bialek, William},
doi = {10.1146/annurev.bb.16.060187.002323},
file = {:home/kaslu/Documents/Mendeley/1987 - Bialek - Physical limits to sensation and perception.pdf:pdf},
isbn = {0883-9182 (Print)$\backslash$r0883-9182 (Linking)},
issn = {0883-9182},
journal = {Annual review of Biophysic Chem.},
month = {jun},
number = {1},
pages = {455--78},
pmid = {3297091},
title = {{Physical limits to sensation and perception}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.bb.16.060187.002323},
volume = {16},
year = {1987}
}
@article{Vicente1998,
abstract = {We review the application of Statistical Mechanics methods to the study of online learning of a drifting concept in the limit of large systems. The model where a feed-forward network learns from examples generated by a time dependent teacher of the same architecture is analyzed. The best possible generalization ability is determined exactly, through the use of a variational method. The constructive variational method also suggests a learning algorithm. It depends, however, on some unavailable quantities, such as the present performance of the student. The construction of estimators for these quantities permits the implementation of a very effective, highly adaptive algorithm. Several other algorithms are also studied for comparison with the optimal bound and the adaptive algorithm, for different types of time evolution of the rule.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9801297},
author = {Vicente, Renato and Kinouchi, Osame and Caticha, Nestor},
doi = {10.1023/A:1007428731714},
eprint = {9801297},
file = {:home/kaslu/Documents/Mendeley/1998 - Vicente, Kinouchi, Caticha - Statistical mechanics of online learning of drifting concepts A variational approach.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Concept learning,Neural networks,Online algorithms,Variational optimization},
language = {en},
month = {aug},
number = {2},
pages = {179--201},
primaryClass = {cond-mat},
publisher = {Kluwer Academic Publishers},
title = {{Statistical mechanics of online learning of drifting concepts: A variational approach}},
url = {http://link.springer.com/article/10.1023/A:1007428731714},
volume = {32},
year = {1998}
}
@article{Sliwa2017,
abstract = {Primate cognition requires interaction processing. Interactions can reveal otherwise hidden properties of intentional agents, such as thoughts and feelings, and of inanimate objects, such as mass and material. Where and how interaction analyses are implemented in the brain is unknown. Using whole-brain functional magnetic resonance imaging in macaque monkeys, we discovered a network centered in the medial and ventrolateral prefrontal cortex that is exclusively engaged in social interaction analysis. Exclusivity of specialization was found for no other function anywhere in the brain. Two additional networks, a parieto-premotor and a temporal one, exhibited both social and physical interaction preference, which, in the temporal lobe, mapped onto a fine-grain pattern of object, body, and face selectivity. Extent and location of a dedicated system for social interaction analysis suggest that this function is an evolutionary forerunner of human mind-reading capabilities.},
author = {Sliwa, J and Freiwald, W A},
doi = {10.1126/science.aam6383},
file = {:home/kaslu/Documents/Mendeley/2017 - Sliwa, Freiwald - A dedicated network for social interaction processing in the primate brain.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {may},
number = {6339},
pages = {745--749},
pmid = {28522533},
title = {{A dedicated network for social interaction processing in the primate brain}},
url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aam6383 http://www.ncbi.nlm.nih.gov/pubmed/28522533},
volume = {356},
year = {2017}
}
@article{Raftopoulos1999,
abstract = {In this paper I discuss Newton's first optical paper. My aim is to examine the type of argument which Newton uses in order to convince his readers of the truth of his theory of colors. My claim is that this argument is an induction by elimination, and that the Newtonian method of justification is a kind of "generative justification", a term due to T. Nickles. To achieve my aim I analyze in some detail the arguments in Newton's first optical paper, relating the paper with Newton's other writings in optics, and especially his early correspondence in defence of his theory of colors. {\textcopyright} 1999 Kluwer Academic Publishers.},
author = {Raftopoulos, Athanassios},
file = {:home/kaslu/Documents/Mendeley/1999 - Raftopoulos - Newton's experimental proofs as eliminative reasoning.pdf:pdf},
issn = {01650106},
journal = {Erkenntnis},
number = {1},
pages = {95--125},
title = {{Newton's experimental proofs as eliminative reasoning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0038443338{\&}partnerID=tZOtx3y1},
volume = {50},
year = {1999}
}
@article{Jonas2017,
abstract = {There is a popular belief in neuroscience that we are primarily data limited, that producing large, multimodal, and complex datasets will, enabled by data analysis algorithms, lead to fundamental insights into the way the brain processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. Here we take a simulated classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the processor. This suggests that current approaches in neuroscience may fall short of producing meaningful models of the brain.},
author = {Jonas, Eric and Kording, Konrad P.},
doi = {10.1371/journal.pcbi.1005268},
file = {:home/kaslu/Documents/Mendeley/2017 - Jonas, Kording - Could a Neuroscientist Understand a Microprocessor.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {1},
pages = {1--24},
pmid = {1000361415},
title = {{Could a Neuroscientist Understand a Microprocessor?}},
volume = {13},
year = {2017}
}
@article{Fallis2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
address = {Cambridge},
author = {Roweis, Sam and Ghahramani, Zoubin},
doi = {10.1162/089976699300016674},
file = {:home/kaslu/Documents/Mendeley/1999 - Roweis, Ghahramani - A Unifying Review of Linear Gaussian Models.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {icle},
month = {feb},
number = {2},
pages = {305--345},
title = {{A Unifying Review of Linear Gaussian Models}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976699300016674},
volume = {11},
year = {1999}
}
@article{Freire2012,
abstract = {O presente trabalho tem basicamente dois objetivos. O primeiro {\'{e}} apresentar o problema geral da mec{\^{a}}nica lagrangiana e o princ{\'{i}}pio de Hamilton utilizando, de uma maneira did{\'{a}}tica, defini{\c{c}}{\~{o}}es matem{\'{a}}ticas de derivadas "direcionais" funcionais e pontos cr{\'{i}}ticos ou estacion{\'{a}}rios de um funcional. O segundo {\'{e}} analisar, atrav{\'{e}}s da derivada funcional de segunda ordem, condi{\c{c}}{\~{o}}es em que as solu{\c{c}}{\~{o}}es de modelos unidimensionais representam "pontos cr{\'{i}}ticos"de m{\'{i}}nimo, de sela ou de m{\'{a}}ximo local do funcional a{\c{c}}{\~{a}}o e mostrar alguns exemplos.},
author = {Freire, Wilson Hugo C},
doi = {10.1590/S1806-11172012000100001},
issn = {1806-1117},
journal = {Revista Brasileira de Ensino de F{\'{i}}sica},
keywords = {euler-lagrange equation,func-,functional,functional directional derivative,order,stationary point of a,tional derivative of second},
month = {mar},
number = {1},
pages = {1--6},
title = {{A derivada funcional de segunda ordem da a{\c{c}}{\~{a}}o: investigando minimalidade, maximalidade e "ponto" sela}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S1806-11172012000100001{\&}lng=pt{\&}tlng=pt},
volume = {34},
year = {2012}
}
@article{Yoo2016,
abstract = {Information processing in the presence of noise has been a key challenge in multiple disciplines including computer science, communications, and neuroscience. Among such noise-reduction mechanisms, the shift-map code represents an analog variable by its residues with respect to distinct moduli (that are chosen as geometric scalings of an integer). Motivated by the multi-periodic neural code in the entorhinal cortex, i.e., the coding mechanism of grid cells, this work extends the shift-map code by generalizing the choices of moduli. In particular, it is shown that using similarly sized moduli (for instance, evenly and closely spaced integers, which tend to have large co-prime factors) results in a code whose codewords are separated in an interleaving way such that when the decoder has side information regarding the source, then error control is significantly improved (compared to the original shift map code). This novel structure allows the system to dynamically adapt to the side information at the decoder, even if the encoder is not privy to the side information. A geometrical interpretation of the proposed coding scheme and a method to find such codes are detailed. As an extension, it is shown that this novel code also adapts to scenarios when only a fraction of codeword symbols is available at the decoder.},
author = {Yoo, Yongseok and {Ozan Koyluoglu}, O. and Vishwanath, Sriram and Fiete, Ila R.},
doi = {10.1016/j.tcs.2016.02.026},
file = {:home/kaslu/Documents/Mendeley/2016 - Yoo et al. - Multi-periodic neural coding for adaptive information transfer.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Grid cells,Multi-periodic neural codes,Shift-map codes,Side information,The entorhinal cortex},
pages = {37--53},
publisher = {Elsevier B.V.},
title = {{Multi-periodic neural coding for adaptive information transfer}},
url = {http://dx.doi.org/10.1016/j.tcs.2016.02.026},
volume = {633},
year = {2016}
}
@article{Wheeler1989,
abstract = {This report reviews what quantum physics and information theory have to tell us about the age-old question, How come existence? No escape is evident from four conclusions: (1) The world cannot be a giant machine, ruled by any preestablished continuum physical law. (2) There is no such thing at the microscopic level as space or time or spacetime continuum. (3) the familiar probablity function or functional, and wave equation or functional wave equation, of standard quantum theory provide mere continuum idealizations and by reason of this circumstance coneal the information-theoretic source from which they derive. (4) No element in the description of physics shows itself as closer to primordial than the elementary quantum phenomenon, that is, the elementary device-intermediated act of posing a yes-no physical question and eliciting an answer or, in brief, the elementary act of observer-participancy. Otherwise stated, every physical quantity, every it, derives its ultimate significance from bits, binary yes-or-no indications, a conclusion which we epitomize in the phrase 'it from bit'.},
author = {Wheeler, John Archibald},
file = {:home/kaslu/Documents/Mendeley/1989 - Wheeler - Information, Physics, Quantum The Search for Links.pdf:pdf},
isbn = {0201515091},
journal = {3rd Int. Symp. Foundations of Quantum Mechanichs},
keywords = {information theory,physics of information},
pages = {3--28},
title = {{Information, Physics, Quantum: The Search for Links}},
year = {1989}
}
@article{Fonseca-Azevedo2012,
abstract = {Despite a general trend for larger mammals to have larger brains, humans are the primates with the largest brain and number of neurons, but not the largest body mass. Why are great apes, the largest primates, not also those endowed with the largest brains? Recently, we showed that the energetic cost of the brain is a linear function of its numbers of neurons. Here we show that metabolic limitations that result from the number of hours available for feeding and the low caloric yield of raw foods impose a tradeoff between body size and number of brain neurons, which explains the small brain size of great apes compared with their large body size. This limitation was probably overcome in Homo erectus with the shift to a cooked diet. Absent the requirement to spend most available hours of the day feeding, the combination of newly freed time and a large number of brain neurons affordable on a cooked diet may thus have been a major positive driving force to the rapid increased in brain size in human evolution.},
author = {Fonseca-Azevedo, Karina and Herculano-Houzel, Suzana},
doi = {10.1073/pnas.1206390109},
file = {:home/kaslu/Documents/Mendeley/2012 - Fonseca-Azevedo, Herculano-Houzel - Metabolic constraint imposes tradeoff between body size and number of brain neurons in human.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Biological Evolution,Body Size,Brain,Brain: anatomy {\&} histology,Brain: cytology,Brain: metabolism,Cell Count,Diet,Feeding Behavior,Humans,Neurons,Neurons: cytology,Neurons: metabolism,Organ Size,Primates,Species Specificity,Time Factors},
month = {nov},
number = {45},
pages = {18571--6},
pmid = {23090991},
title = {{Metabolic constraint imposes tradeoff between body size and number of brain neurons in human evolution.}},
url = {http://www.pnas.org/cgi/content/long/109/45/18571},
volume = {109},
year = {2012}
}
@article{Baumeister1995,
abstract = {A hypothesized need to form and maintain strong, stable interpersonal relationships is evaluated in light of the empirical literature. The need is for frequent, nonaversive interactions within an ongoing relational bond. Consistent with the belongingness hypothesis, people form social attachments readily under most conditions and resist the dissolution of existing bonds. Belongingness appears to have multiple and strong effects on emotional patterns and on cognitive processes. Lack of attachments is linked to a variety of ill effects on health, adjustment, and well-being. Other evidence, such as that concerning satiation, substitution, and behavioral consequences, is likewise consistent with the hypothesized motivation. Several seeming counterexamples turned out not to disconfirm the hypothesis. Existing evidence supports the hypothesis that the need to belong is a powerful, fundamental, and extremely pervasive motivation.},
author = {Baumeister, Roy F. and Leary, Mark R.},
doi = {10.1037/0033-2909.117.3.497},
file = {:home/kaslu/Documents/Mendeley/1995 - Baumeister, Leary - The need to belong desire for interpersonal attachments as a fundamental human motivation.pdf:pdf},
isbn = {1227401000838},
issn = {0033-2909},
journal = {Psychological bulletin},
month = {may},
number = {3},
pages = {497--529},
pmid = {7777651},
title = {{The need to belong: desire for interpersonal attachments as a fundamental human motivation.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.117.3.497 http://www.ncbi.nlm.nih.gov/pubmed/7777651},
volume = {117},
year = {1995}
}
@article{Lent2012,
abstract = {Owing to methodological shortcomings and a certain conservatism that consolidates wrong assumptions in the literature, some dogmas have become established and reproduced in papers and textbooks, derived from quantitative features of the brain. The first dogma states that the cerebral cortex is the pinnacle of brain evolution - based on the observations that its volume is greater in more 'intelligent' species, and that cortical surface area grows more than any other brain region, to reach the largest proportion in higher primates and humans. The second dogma claims that the human brain contains 100 billion neurons, plus 10-fold more glial cells. These round numbers have become widely adopted, although data provided by different authors have led to a broad range of 75-125 billion neurons in the whole brain. The third dogma derives from the second, and states that our brain is structurally special, an outlier as compared with other primates. Being so large and convoluted, it is a special construct of nature, unrelated to evolutionary scaling. Finally, the fourth dogma appeared as a tentative explanation for the considerable growth of the brain throughout development and evolution - being modular in structure, the brain (and particularly the cerebral cortex) grows by tangential addition of modules that are uniform in neuronal composition. In this review, we sought to examine and challenge these four dogmas, and propose other interpretations or simply their replacement with alternative views.},
author = {Lent, Roberto and Azevedo, Frederico a C and Andrade-Moraes, Carlos H and Pinto, Ana V O},
doi = {10.1111/j.1460-9568.2011.07923.x},
file = {:home/kaslu/Documents/Mendeley/2012 - Lent et al. - How many neurons do you have Some dogmas of quantitative neuroscience under revision.pdf:pdf},
issn = {1460-9568},
journal = {The European journal of neuroscience},
keywords = {Animals,Biological Evolution,Cerebellum,Cerebellum: cytology,Cerebral Cortex,Cerebral Cortex: cytology,Humans,Neuroglia,Neuroglia: cytology,Neurons,Neurons: cytology,Neurosciences,Primates},
month = {jan},
number = {1},
pages = {1--9},
pmid = {22151227},
title = {{How many neurons do you have? Some dogmas of quantitative neuroscience under revision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22151227},
volume = {35},
year = {2012}
}
@article{Piza2017,
annote = {NULL},
author = {Piza, A F R De Toledo},
doi = {10.1590/1806-9126-rbef-2016-0298},
issn = {18061117},
journal = {Revista Brasileira de Ensino de F{\'{i}}sica},
keywords = {experimental course,molecular science,multidisciplinarity},
title = {{Curso de Ci{\^{e}}ncias Moleculares: uma singularidade nas colmeias}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S1806-11172017000300301{\&}lng=pt{\&}nrm=iso{\&}tlng=pt},
volume = {39},
year = {2017}
}
@article{Shannon1948,
abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist and Hartley on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information. The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point. Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem. The significant aspect is that the actual message is one selected from a set of possible messages. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. If the number of messages in the set is finite then this number or any monotonic function of this number can be regarded as a measure of the information produced when one message is chosen from the set, all choices being equally likely. As was pointed out by Hartley the most natural choice is the logarithmic function. Although this definition must be generalized considerably when we consider the influence of the statistics of the message and when we have a continuous range of messages, we will in all cases use an essentially logarithmic measure.},
author = {Shannon, Claude E.},
doi = {10.1002/j.1538-7305.1948.tb01338.x},
isbn = {0252725484},
issn = {00058580},
journal = {Bell System Technical Journal},
month = {jul},
number = {3},
pages = {379--423},
pmid = {9230594},
title = {{A Mathematical Theory of Communication}},
url = {http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6773024},
volume = {27},
year = {1948}
}
@article{Jeffreys1946,
author = {Jeffreys, H.},
doi = {10.1098/rspa.1946.0056},
file = {:home/kaslu/Documents/Mendeley/1946 - Jeffreys - An Invariant Form for the Prior Probability in Estimation Problems.pdf:pdf},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = {sep},
number = {1007},
pages = {453--461},
title = {{An Invariant Form for the Prior Probability in Estimation Problems}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.1946.0056},
volume = {186},
year = {1946}
}
@article{Chaudhuri2016,
abstract = {Memories are stored, retained, and recollected through complex, coupled processes operating on multiple timescales. To understand the computational principles behind these intricate networks of interactions we construct a broad class of synaptic models that efficiently harnesses biological complexity to preserve numerous memories. The memory capacity scales almost linearly with the number of synapses, which is a substantial improvement over the square root scaling of previous models. This was achieved by combining multiple dynamical processes that initially store memories in fast variables and then progressively transfer them to slower variables. Importantly, the interactions between fast and slow variables are bidirectional. The proposed models are robust to parameter perturbations and can explain several properties of biological memory, including delayed expression of synaptic modifications, metaplasticity, and spacing effects.},
author = {Chaudhuri, Rishidev and Fiete, Ila R.},
doi = {10.1038/nn.4237},
file = {:home/kaslu/Documents/Mendeley/2016 - Chaudhuri, Fiete - Computational principles of memory.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {394--403},
pmid = {26906506},
title = {{Computational principles of memory}},
url = {http://arxiv.org/abs/1507.07580 http://www.nature.com/doifinder/10.1038/nn.4237},
volume = {19},
year = {2016}
}
@article{Daw2005,
abstract = {A broad range of neural and behavioral data suggests that the brain contains multiple systems for behavioral choice, including one associated with prefrontal cortex and another with dorsolateral striatum. However, such a surfeit of control raises an additional choice problem: how to arbitrate between the systems when they disagree. Here, we consider dual-action choice systems from a normative perspective, using the computational theory of reinforcement learning. We identify a key trade-off pitting computational simplicity against the flexible and statistically efficient use of experience. The trade-off is realized in a competition between the dorsolateral striatal and prefrontal systems. We suggest a Bayesian principle of arbitration between them according to uncertainty, so each controller is deployed when it should be most accurate. This provides a unifying account of a wealth of experimental evidence about the factors favoring dominance by either system.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Daw, Nathaniel D. and Niv, Yael and Dayan, Peter},
doi = {10.1038/nn1560},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2005 - Daw, Niv, Dayan - Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {12},
pages = {1704--1711},
pmid = {16286932},
title = {{Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control}},
url = {http://www.nature.com/doifinder/10.1038/nn1560},
volume = {8},
year = {2005}
}
@article{Kinouchi1992,
abstract = {A new learning algorithm for the one-layer perceptron is presented. It aims to maximize the$\backslash$n generalization gain per example. Analytical results are obtained for the case of single presentation$\backslash$n of each example. The weight attached to a Hebbian term is a function of the expected stability of$\backslash$n the example in the teacher perceptron. This leads to the obtention of upper bounds for the$\backslash$n generalization ability. This scheme can be iterated and the results of numerical simulations show$\backslash$n that it converges, within errors, to the theoretical optimal generalization ability of the Bayes$\backslash$n algorithm. Analytical and numerical results for an algorithm with maximized generalization in the$\backslash$n learning strategy with selection of examples are obtained and it is proved that, as expected,$\backslash$n orthogonal selection is optimal. Exponential decay of the generalization error is obtained for the$\backslash$n single presentation of selected examples.},
author = {Kinouchi, Osame and Caticha, Nestor},
doi = {10.1088/0305-4470/25/23/020},
file = {:home/kaslu/Documents/Mendeley/1992 - Kinouchi, Caticha - Optimal generalization in perceptions(2).pdf:pdf;:home/kaslu/Documents/Mendeley/1992 - Kinouchi, Caticha - Optimal generalization in perceptions.pdf:pdf},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
month = {dec},
number = {23},
pages = {6243--6250},
title = {{Optimal generalization in perceptions}},
url = {http://stacks.iop.org/0305-4470/25/i=23/a=020 http://stacks.iop.org/0305-4470/25/i=23/a=020?key=crossref.e3454a8494f54e330be3832cec186fa1},
volume = {25},
year = {1992}
}
@article{Sarma2015,
abstract = {Our ability to learn a wide range of behavioral tasks is essential for responding appropriately to sensory stimuli according to behavioral demands, but the underlying neural mechanism has been rarely examined by neurophysiological recordings in the same subjects across learning. To understand how learning new behavioral tasks affects neuronal representations, we recorded from posterior parietal cortex (PPC) before and after training on a visual motion categorization task. We found that categorization training influenced cognitive encoding in PPC, with a marked enhancement of memory-related delay-period encoding during the categorization task that was absent during a motion discrimination task before categorization training. In contrast, the prefrontal cortex (PFC) exhibited strong delay-period encoding during both discrimination and categorization tasks. This reveals a dissociation between PFC's and PPC's roles in working memory, with general engagement of PFC across multiple tasks, in contrast with more task-specific mnemonic encoding in PPC.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Sarma, Arup and Masse, Nicolas Y and Wang, Xiao-Jing and Freedman, David J},
doi = {10.1038/nn.4168},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2015 - Sarma et al. - Task-specific versus generalized mnemonic representations in parietal and prefrontal cortices.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {1},
pages = {143--149},
pmid = {26595652},
publisher = {Nature Publishing Group},
title = {{Task-specific versus generalized mnemonic representations in parietal and prefrontal cortices}},
url = {http://www.nature.com/doifinder/10.1038/nn.4168},
volume = {19},
year = {2015}
}
@misc{Olshausen1996,
abstract = {THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1–4 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7–12. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13–18, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
author = {Olshausen, Bruno A. and Field, David J.},
booktitle = {Nature},
doi = {10.1038/381607a0},
file = {:home/kaslu/Documents/Mendeley/1996 - Olshausen, Field - Emergence of simple-cell receptive field properties by learning a sparse code for natural images.pdf:pdf},
isbn = {9781612849379},
issn = {0028-0836},
number = {6583},
pages = {607--609},
pmid = {8637596},
title = {{Emergence of simple-cell receptive field properties by learning a sparse code for natural images}},
url = {http://www.nature.com/doifinder/10.1038/381607a0},
volume = {381},
year = {1996}
}
@article{Eykhoff1994,
abstract = {The design of a complex regulator often includes the making of a model of the system to be regulated. The making of such a model has hitherto been regarded as optional, as merely one of many possible ways. In this paper a theorem is presented which shows, under very broad conditions, that any regulator that is maximally both successful and simple must be isomorphic with the system being regulated. (The exact assumptions are given.) Making a model is thus necessary. The theorem has the interesting corollary that the living brain, so far as it is to be successful and efficient as a regulator for survival, must proceed, in learning, by the formation of a model (or models) of its environment.},
author = {Eykhoff, Pieter},
doi = {10.4173/mic.1994.3.2},
isbn = {03327353},
issn = {0332-7353},
journal = {Modeling, Identification and Control: A Norwegian Research Bulletin},
number = {3},
pages = {135--139},
title = {{Every good regulator of a system must be a model of that system}},
url = {http://www.mic-journal.no/ABS/MIC-1994-3-2.asp},
volume = {15},
year = {1994}
}
@article{Pouget2000,
abstract = {Information is encoded in the brain by populations or clusters of cells, rather than by single cells. This encoding strategy is known as population coding. Here we review the standard use of population codes for encoding and decoding information, and consider how population codes can be used to support neural computations such as noise removal and nonlinear mapping. More radical ideas about how population codes may directly represent information about stimulus uncertainty are also discussed.},
author = {Pouget, Alexandre and Dayan, Peter and Zemel, R},
doi = {10.1038/35039062},
file = {:home/kaslu/Documents/Mendeley/2000 - Pouget, Dayan, Zemel - Information processing with population codes.pdf:pdf},
isbn = {1471-003X (Print)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Likelihood Functions,Mental Processes,Mental Processes: physiology,Models,Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics},
number = {2},
pages = {125--32},
pmid = {11252775},
title = {{Information processing with population codes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11252775},
volume = {1},
year = {2000}
}
@inproceedings{Kappel2015,
author = {Kappel, David and Habenschuss, Stefan and Legenstein, Robert and Maass, Wolfgang},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/kaslu/Documents/Mendeley/2015 - Kappel et al. - Synaptic Sampling A Bayesian Approach to Neural Network Plasticity and Rewiring.pdf:pdf},
pages = {370--378},
title = {{Synaptic Sampling: A Bayesian Approach to Neural Network Plasticity and Rewiring}},
url = {https://papers.nips.cc/paper/5952-synaptic-sampling-a-bayesian-approach-to-neural-network-plasticity-and-rewiring},
year = {2015}
}
@article{Sadtler2014,
abstract = {Learning, whether motor, sensory or cognitive, requires networks of neurons to generate new activity patterns. As some behaviours are easier to learn than others, we asked if some neural activity patterns are easier to generate than others. Here we investigate whether an existing network constrains the patterns that a subset of its neurons is capable of exhibiting, and if so, what principles define this constraint. We employed a closed-loop intracortical brain-computer interface learning paradigm in which Rhesus macaques (Macaca mulatta) controlled a computer cursor by modulating neural activity patterns in the primary motor cortex. Using the brain-computer interface paradigm, we could specify and alter how neural activity mapped to cursor velocity. At the start of each session, we observed the characteristic activity patterns of the recorded neural population. The activity of a neural population can be represented in a high-dimensional space (termed the neural space), wherein each dimension corresponds to the activity of one neuron. These characteristic activity patterns comprise a low-dimensional subspace (termed the intrinsic manifold) within the neural space. The intrinsic manifold presumably reflects constraints imposed by the underlying neural circuitry. Here we show that the animals could readily learn to proficiently control the cursor using neural activity patterns that were within the intrinsic manifold. However, animals were less able to learn to proficiently control the cursor using activity patterns that were outside of the intrinsic manifold. These results suggest that the existing structure of a network can shape learning. On a timescale of hours, it seems to be difficult to learn to generate neural activity patterns that are not consistent with the existing network structure. These findings offer a network-level explanation for the observation that we are more readily able to learn new skills when they are related to the skills that we already possess.},
author = {Sadtler, Patrick T. and Quick, Kristin M. and Golub, Matthew D. and Chase, Steven M. and Ryu, Stephen I. and Tyler-Kabara, Elizabeth C. and Yu, Byron M. and Batista, Aaron P.},
doi = {10.1038/nature13665},
file = {:home/kaslu/Documents/Mendeley/2014 - Sadtler et al. - Neural constraints on learning.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
keywords = {Animals,Brain-Computer Interfaces,Computers,Learning,Learning: physiology,Macaca mulatta,Male,Models, Neurological,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,Motor Skills,Motor Skills: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: physiology},
number = {7515},
pages = {423--426},
pmid = {25164754},
publisher = {Nature Publishing Group},
title = {{Neural constraints on learning}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4393644{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {512},
year = {2014}
}
@article{Copelli1995,
abstract = {The dynamics of learning from examples in the k = 3 non- overlapping committee machine with single presentation of examples is studied. The optimal algorithm, in the sense of mean generalization, is obtained from a variational analysis of the differential equations which describe the dynamics. The agreement of the theoretical predictions and the results of numerical simulations is excellent. The optimized dynamics has the extra advantage with respect to the non-optimized cases in that it uncouples the differential equations which describe the evolution of the relevant parameters, i.e, the student-teacher overlap and the norm of the student synaptic vector. This, in turn, translates into the possibility of constructing useful practical optimized on-line algorithms. For the optimal algorithm the generalization error decays as similar to 0.88 alpha(-1), the same nominal error as for the simple perceptron with optimized dynamics.},
author = {Copelli, Mauro and Caticha, Nestor},
doi = {10.1088/0305-4470/28/6/016},
file = {:home/kaslu/Documents/Mendeley/1995 - Copelli, Caticha - On-line learning in the committee machine.pdf:pdf},
issn = {0305-4470},
journal = {Journal of Physics A: Mathematical and General},
keywords = {networks},
month = {mar},
number = {6},
pages = {1615--1625},
title = {{On-line learning in the committee machine}},
url = {http://stacks.iop.org/0305-4470/28/i=6/a=016?key=crossref.91e7066693ad37864bbe844a5563aa78},
volume = {28},
year = {1995}
}
@article{Reich2013,
abstract = {Conventional wisdom and past research suggest that contradicting oneself, or changing one's stated opinion, should undermine one's persuasiveness. In contrast to this view, we propose that under specifiable conditions contradicting oneself might offer a persuasive advantage. Across a series of experiments, we find evidence for this contradiction effect and explore its mechanism and boundaries. In particular, we show that contradictions can prompt attributional processing geared toward understanding why a shift in opinion has occurred. When strong arguments are provided, they foster favorable attributions (e.g., the source thought more about the issue and/or gathered new information), which result in increased persuasive impact. When weak arguments are provided, they induce less favorable attributions, which in turn dampen or even reverse the effect. Furthermore, consistent with an attributional perspective, we find that contradictions introduce a persuasive advantage only when they come from a single source and only when trust in that source is high. {\textcopyright} 2013 Elsevier Inc.},
author = {Reich, Taly and Tormala, Zakary L.},
doi = {10.1016/j.jesp.2013.01.004},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Attitude change,Persuasion,Social influence},
month = {may},
number = {3},
pages = {426--439},
title = {{When contradictions foster persuasion: An attributional perspective}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103113000218},
volume = {49},
year = {2013}
}
@article{Davis2001,
abstract = {On the basis of principles of balance theory and interdependence theory, this research examined a phenomenon termed attitude alignment, or the tendency of interacting partners to modify their attitudes in such a manner as to achieve attitudinal congruence. The results of three experiments generally were consistent with the proposed model. First, tendencies toward attitude alignment were greater to the extent that attitudinal discrepancies were salient. Second, alignment tendencies were greater to the extent that an issue was central to the partner; there was also evidence that the degree to which an issue was peripheral to the self affected alignment processes (e.g., for changes in centrality of issue, with regard to persuasion methods). Third, degree of alignment tended to be greater in dating-partner interactions than in stranger interactions and tended to be greater among couples with high adjustment than among those with low adjustment.},
author = {Davis, Jody L and Rusbult, Caryl E},
doi = {10.1037/0022-3514.81.1.65},
file = {:home/kaslu/Documents/Mendeley/2001 - Davis, Rusbult - Attitude alignment in close relationships.pdf:pdf},
isbn = {0022-3514},
issn = {0022-3514},
journal = {Journal of personality and social psychology},
number = {1},
pages = {65--84},
pmid = {11474727},
title = {{Attitude alignment in close relationships.}},
volume = {81},
year = {2001}
}
@article{Ho2017,
abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Many behavioral measures of visual perception fluctuate continually in a rhythmic manner, reflecting the influence of endogenous brain oscillations, particularly theta (∼4–7 Hz) and alpha (∼8–12 Hz) rhythms [1–3]. However, it is unclear whether these oscillations are unique to vision or whether auditory performance also oscillates [4, 5]. Several studies report no oscillatory modulation in audition [6, 7], while those with positive findings suffer from confounds relating to neural entrainment [8–10]. Here, we used a bilateral pitch-identification task to investigate rhythmic fluctuations in auditory performance separately for the two ears and applied signal detection theory (SDT) to test for oscillations of both sensitivity and criterion (changes in decision boundary) [11, 12]. Using uncorrelated dichotic white noise to induce a phase reset of oscillations, we demonstrate that, as with vision, both auditory sensitivity and criterion showed strong oscillations over time, at different frequencies: ∼6 Hz (theta range) for sensitivity and ∼8 Hz (low alpha range) for criterion, implying distinct underlying sampling mechanisms [13]. The modulation in sensitivity in left and right ears was in antiphase, suggestive of attention-like mechanisms sampling alternatively from the two ears.{\textless}/p{\textgreater}},
author = {Ho, Hao Tam and Leung, Johahn and Burr, David C. and Alais, David and Morrone, Maria Concetta},
doi = {10.1016/j.cub.2017.10.017},
issn = {0960-9822},
journal = {Current Biology},
number = {23},
pages = {3643--3649.e3},
pmid = {29153327},
title = {{Auditory Sensitivity and Decision Criteria Oscillate at Different Frequencies Separately for the Two Ears}},
url = {http://www.cell.com/current-biology/fulltext/S0960-9822(17)31320-9?{\_}returnURL=http{\%}3A{\%}2F{\%}2Flinkinghub.elsevier.com{\%}2Fretrieve{\%}2Fpii{\%}2FS0960982217313209{\%}3Fshowall{\%}3Dtrue},
volume = {27},
year = {2017}
}
@article{Tkacik2009,
abstract = {Ising models with pairwise interactions are the least structured, or maximum-entropy, probability distributions that exactly reproduce measured pairwise correlations between spins. Here we use this equivalence to construct Ising models that describe the correlated spiking activity of populations of 40 neurons in the salamander retina responding to natural movies. We show that pairwise interactions between neurons account for observed higher-order correlations, and that for groups of 10 or more neurons pairwise interactions can no longer be regarded as small perturbations in an independent system. We then construct network ensembles that generalize the network instances observed in the experiment, and study their thermodynamic behavior and coding capacity. Based on this construction, we can also create synthetic networks of 120 neurons, and find that with increasing size the networks operate closer to a critical point and start exhibiting collective behaviors reminiscent of spin glasses. We examine closely two such behaviors that could be relevant for neural code: tuning of the network to the critical point to maximize the ability to encode diverse stimuli, and using the metastable states of the Ising Hamiltonian as neural code words.},
archivePrefix = {arXiv},
arxivId = {0912.5409},
author = {Tkacik, Gasper and Schneidman, Elad and Berry, Michael J. and Bialek, William},
eprint = {0912.5409},
file = {:home/kaslu/Documents/Mendeley/2009 - Tkacik et al. - Spin glass models for a network of real neurons.pdf:pdf},
month = {dec},
title = {{Spin glass models for a network of real neurons}},
url = {http://arxiv.org/abs/0912.5409},
year = {2009}
}
@article{Chow2010,
abstract = {We give a pedagogical review of the application of field theoretic and path integral methods to calculate moments of the probability density function of stochastic differential equations perturbatively.},
archivePrefix = {arXiv},
arxivId = {1009.5966},
author = {Chow, Carson C. and Buice, Michael a.},
doi = {10.1186/s13408-015-0018-5},
eprint = {1009.5966},
file = {:home/kaslu/Documents/Mendeley/2010 - Chow, Buice - Path Integral Methods for Stochastic Differential Equations.pdf:pdf},
issn = {2190-8567},
journal = {arXiv preprint arXiv:1009.5966},
title = {{Path Integral Methods for Stochastic Differential Equations}},
url = {http://arxiv.org/abs/1009.5966},
volume = {20892},
year = {2010}
}
@article{Murray2014,
abstract = {Specialization and hierarchy are organizing principles for primate cortex, yet there is little direct evidence for how cortical areas are specialized in the temporal domain. We measured timescales of intrinsic fluctuations in spiking activity across areas and found a hierarchical ordering, with sensory and prefrontal areas exhibiting shorter and longer timescales, respectively. On the basis of our findings, we suggest that intrinsic timescales reflect areal specialization for task-relevant computations over multiple temporal ranges.},
author = {Murray, John D and Bernacchia, Alberto and Freedman, David J and Romo, Ranulfo and Wallis, Jonathan D and Cai, Xinying and Padoa-Schioppa, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
doi = {10.1038/nn.3862},
file = {:home/kaslu/Documents/Mendeley/2014 - Murray et al. - A hierarchy of intrinsic timescales across primate cortex.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {12},
pages = {1661--1663},
pmid = {25383900},
title = {{A hierarchy of intrinsic timescales across primate cortex}},
url = {http://www.nature.com/doifinder/10.1038/nn.3862},
volume = {17},
year = {2014}
}
@article{Huth2016,
author = {Huth, Alexander G. and de Heer, Wendy A. and Griffiths, Thomas L. and Theunissen, Fr{\'{e}}d{\'{e}}ric E. and Gallant, Jack L.},
doi = {10.1038/nature17637},
file = {:home/kaslu/Documents/Mendeley/2016 - Huth et al. - Natural speech reveals the semantic maps that tile human cerebral cortex.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {apr},
number = {7600},
pages = {453--458},
publisher = {Nature Publishing Group},
title = {{Natural speech reveals the semantic maps that tile human cerebral cortex}},
url = {http://www.nature.com/doifinder/10.1038/nature17637},
volume = {532},
year = {2016}
}
@article{Smaldino2014,
author = {Smaldino, Paul E.},
doi = {10.1017/S0140525X13001544},
file = {:home/kaslu/Documents/Mendeley/2014 - Smaldino - The cultural evolution of emergent group-level traits.pdf:pdf;:home/kaslu/Documents/Mendeley/2014 - Smaldino - The cultural evolution of emergent group-level traits(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2014 - Smaldino - The cultural evolution of emergent group-level traits(3).pdf:pdf},
journal = {Behavioral and Brain Sciences},
keywords = {altruism,cooperation,cultural group selection,inclusive fi tness,innovation,institutions,interdependence,multilevel,niche construction,selection},
number = {03},
pages = {243--295},
title = {{The cultural evolution of emergent group-level traits}},
url = {http://smaldino.com/wp/wp-content/uploads/2013/09/Smaldino-BBS-GroupLevelTraits-INPRESS.pdf},
volume = {37},
year = {2014}
}
@article{Harrigan2007,
abstract = {Studying the extent to which realism is compatible with quantum mechanics teaches us something about the quantum mechanical universe, regardless of the validity of such realistic assumptions. It has also recently been appreciated that these kinds of studies are fruitful for questions relating to quantum information and computation. Motivated by this, we extend the ontological model formalism for realistic theories to describe a set of theories emphasizing the role of measurement and preparation devices by introducing `hidden variables' to describe them. We illustrate both the ontological model formalism and our generalization of it through a series of example models taken from the literature. Our extension of the formalism allows us to quantitatively analyze the meaning contextuality (a constraint on successful realistic theories), finding that - taken at face-value - it can be realized as a natural interaction between the configurations of a system and measurement device. However, we also describe a property that we call deficiency, which follows from contextuality, but does not admit such a natural interpretation. Loosely speaking, deficiency breaks a symmetry between preparations and measurements in quantum mechanics. It is the property that the set of ontic states which a system prepared in quantum state psi may actually be in, is strictly smaller than the set of ontic states which would reveal the measurement outcome psi with certainty.},
archivePrefix = {arXiv},
arxivId = {0709.4266},
author = {Harrigan, Nicholas and Rudolph, Terry},
eprint = {0709.4266},
file = {:home/kaslu/Documents/Mendeley/2007 - Harrigan, Rudolph - Ontological models and the interpretation of contextuality.pdf:pdf},
month = {sep},
title = {{Ontological models and the interpretation of contextuality}},
url = {http://arxiv.org/abs/0709.4266},
year = {2007}
}
@article{Berman2016,
abstract = {Even the simplest of animals exhibit behavioral sequences with complex temporal dynamics. Prominent amongst the proposed organizing principles for these dynamics has been the idea of a hierarchy, wherein the movements an animal makes can be understood as a set of nested sub-clusters. Although this type of organization holds potential advantages in terms of motion control and neural circuitry, measurements demonstrating this for an animal's entire behavioral repertoire have been limited in scope and temporal complexity. Here, we use a recently developed unsupervised technique to discover and track the occurrence of all stereotyped behaviors performed by fruit flies moving in a shallow arena. Calculating the optimally predictive representation of the fly's future behaviors, we show that fly behavior exhibits multiple time scales and is organized into a hierarchical structure that is indicative of its underlying behavioral programs and its changing internal states.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1506.01997},
author = {Berman, Gordon J and Bialek, William and Shaevitz, Joshua W.},
doi = {10.1073/pnas.1607601113},
eprint = {1506.01997},
file = {:home/kaslu/Documents/Mendeley/2016 - Berman, Bialek, Shaevitz - Predictability and hierarchy in Drosophila behavior.pdf:pdf},
isbn = {1216578109},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {42},
pages = {11943--11948},
pmid = {23112202},
title = {{Predictability and hierarchy in Drosophila behavior}},
url = {http://biorxiv.org/lookup/doi/10.1101/052928 http://www.pnas.org/lookup/doi/10.1073/pnas.1607601113},
volume = {113},
year = {2016}
}
@article{Timme2016,
abstract = {Recent work has shown that functional connectivity among cortical neurons is highly varied, with a small percentage of neurons having many more connections than others. Also, recent theoretical developments now make it possible to quantify how neurons modify information from the connections they receive. Therefore, it is now possible to investigate how information modification, or computation, depends on the number of connections a neuron receives (in-degree) or sends out (out-degree). To do this, we recorded the simultaneous spiking activity of hundreds of neurons in cortico-hippocampal slice cultures using a high-density 512-electrode array. This preparation and recording method combination produced large numbers of neurons recorded at temporal and spatial resolutions that are not currently available in any in vivo recording system. We utilized transfer entropy (a well-established method for detecting linear and nonlinear interactions in time series) and the partial information decomposition (a powerful, recently developed tool for dissecting multivariate information processing into distinct parts) to quantify computation between neurons where information flows converged. We found that computations did not occur equally in all neurons throughout the networks. Surprisingly, neurons that computed large amounts of information tended to receive connections from high out-degree neurons. However, the in-degree of a neuron was not related to the amount of information it computed. To gain insight into these findings, we developed a simple feedforward network model. We found that a degree-modified Hebbian wiring rule best reproduced the pattern of computation and degree correlation results seen in the real data. Interestingly, this rule also maximized signal propagation in the presence of network-wide correlations, suggesting a mechanism by which cortex could deal with common random background input. These are the first results to show that the extent to which a neuron modifies incoming information streams depends on its topological location in the surrounding functional network.},
author = {Timme, Nicholas M. and Ito, Shinya and Myroshnychenko, Maxym and Nigam, Sunny and Shimono, Masanori and Yeh, Fang Chin and Hottowy, Pawel and Litke, Alan M. and Beggs, John M.},
doi = {10.1371/journal.pcbi.1004858},
file = {:home/kaslu/Documents/Mendeley/2016 - Timme et al. - High-Degree Neurons Feed Cortical Computations.pdf:pdf},
isbn = {1553-734x},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {5},
pages = {1--31},
pmid = {27159884},
title = {{High-Degree Neurons Feed Cortical Computations}},
volume = {12},
year = {2016}
}
@article{Chaudhuri2014,
abstract = {Neurons show diverse timescales, so that different parts of a network respond with disparate temporal dynamics. Such diversity is observed both when comparing timescales across brain areas and among cells within local populations; the underlying circuit mechanism remains unknown. We examine conditions under which spatially local connectivity can produce such diverse temporal behavior. In a linear network, timescales are segregated if the eigenvectors of the connectivity matrix are localized to different parts of the network. We develop a framework to predict the shapes of localized eigenvectors. Notably, local connectivity alone is insufficient for separate timescales. However, localization of timescales can be realized by heterogeneity in the connectivity profile, and we demonstrate two classes of network architecture that allow such localization. Our results suggest a framework to relate structural heterogeneity to functional diversity and, beyond neural dynamics, are generally applicable to the relationship between structure and dynamics in biological networks. DOI: http://dx.doi.org/10.7554/eLife.01239.001.},
author = {Chaudhuri, Rishidev and Bernacchia, Alberto and Wang, Xiao Jing},
doi = {10.7554/eLife.01239},
file = {:home/kaslu/Documents/Mendeley/2014 - Chaudhuri, Bernacchia, Wang - A diversity of localized timescales in network activity.pdf:pdf},
isbn = {2050-084X (Electronic)},
issn = {2050084X},
journal = {eLife},
keywords = {network dynamics,neural networks,timescales},
pages = {e01239},
pmid = {24448407},
title = {{A diversity of localized timescales in network activity}},
volume = {3},
year = {2014}
}
@article{Boareto2015,
author = {Boareto, Marcelo and Cesar, Jonatas and Leite, Vitor B. P. and Caticha, Nestor},
doi = {10.1109/TCBB.2014.2377750},
file = {:home/kaslu/Documents/Mendeley/2015 - Boareto et al. - Supervised Variational Relevance Learning, An Analytic Geometric Feature Selection with Applications to Omic Dat.pdf:pdf},
issn = {1545-5963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Analytic metric learning,Distance learning,Feature selection,Genomics,Metabolomics,Proteomics,Relevance Learning,Suvrel},
month = {may},
number = {3},
pages = {705--711},
title = {{Supervised Variational Relevance Learning, An Analytic Geometric Feature Selection with Applications to Omic Datasets}},
volume = {12},
year = {2015}
}
@article{Gelfand2012,
abstract = {Anecdotal evidence abounds that organizations have distinct conflict cultures, or socially shared norms for how conflict should be managed. However, research to date has largely focused on conflict management styles at the individual and small group level, and has yet to examine whether organizations create socially shared and normative ways to manage conflict. In a sample of leaders and members from 92 branches of a large bank, factor analysis and aggregation analyses show that 3 conflict cultures-collaborative, dominating, and avoidant-operate at the unit level of analysis. Building on Lewin, Lippitt, and White's (1939) classic work, we find that leaders' own conflict management behaviors are associated with distinct unit conflict cultures. The results also demonstrate that conflict cultures have implications for macro branch-level outcomes, including branch viability (i.e., cohesion, potency, and burnout) and branch performance (i.e., creativity and customer service). A conflict culture perspective moves beyond the individual level and provides new insight into the dynamics of conflict management in organizational contexts.},
author = {Gelfand, Michele J. and Leslie, Lisa M. and Keller, Kirsten and de Dreu, Carsten},
doi = {10.1037/a0029993},
file = {:home/kaslu/Documents/Mendeley/2012 - Gelfand et al. - Conflict Cultures in Organizations How Leaders Shape Conflict Cultures and Their Organizational-Level Consequenc.pdf:pdf},
isbn = {0021-9010},
issn = {0021-9010},
journal = {Journal of Applied Psychology},
keywords = {conflict,conflict management,culture,develop cultures in which,in which,is managed productively,leadership,members consistently work against,norms,one another,organizations,sabotaging each,whereas others have cultures,why do some organizations},
number = {6},
pages = {1131--1147},
pmid = {23025807},
title = {{Conflict Cultures in Organizations: How Leaders Shape Conflict Cultures and Their Organizational-Level Consequences.}},
volume = {97},
year = {2012}
}
@article{Fowler2008,
abstract = {In the past 50 years, biologists have learned a tremendous amount about human brain function and its genetic basis. At the same time, political scientists have been intensively studying the effect of the social and institutional environment on mass political attitudes and behaviors. However, these separate fields of inquiry are subject to inherent limitations that may only be resolved through collaboration across disciplines. We describe recent advances and argue that biologists and political scientists must work together to advance a new science of human nature},
author = {Fowler, Jh and Schreiber, Darren},
doi = {10.1126/science.1158188},
file = {:home/kaslu/Documents/Mendeley/2008 - Fowler, Schreiber - Biology, politics, and the emerging science of human nature.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
number = {November},
pages = {912--914},
pmid = {18988845},
title = {{Biology, politics, and the emerging science of human nature}},
url = {http://www.sciencemag.org/content/322/5903/912.short},
year = {2008}
}
@article{Navajas2017a,
abstract = {The aggregation of many independent estimates can outperform the most accurate individual judgment. This centenarian finding, popularly known as the wisdom of crowds, has been applied to problems ranging from the diagnosis of cancer to financial forecasting. It is widely believed that social influence undermines collective wisdom by reducing the diversity of opinions within the crowd. Here, we show that if a large crowd is structured in small independent groups, deliberation and social influence within groups improve the crowd's collective accuracy. We asked a live crowd (N=5180) to respond to general-knowledge questions (e.g., what is the height of the Eiffel Tower?). Participants first answered individually, then deliberated and made consensus decisions in groups of five, and finally provided revised individual estimates. We found that averaging consensus decisions was substantially more accurate than aggregating the initial independent opinions. Remarkably, combining as few as four consensus choices outperformed the wisdom of thousands of individuals.},
archivePrefix = {arXiv},
arxivId = {1703.00045},
author = {Navajas, Joaquin and Niella, Tamara and Garbulsky, Gerry and Bahrami, Bahador and Sigman, Mariano},
doi = {10.1038/s41562-017-0273-4},
eprint = {1703.00045},
file = {:home/kaslu/Documents/Mendeley/2017 - Navajas et al. - Aggregated knowledge from a small number of debates outperforms the wisdom of large crowds.pdf:pdf},
isbn = {4156201702734},
issn = {2397-3374},
journal = {Nature Human Behaviour},
publisher = {Springer US},
title = {{Aggregated knowledge from a small number of debates outperforms the wisdom of large crowds}},
url = {http://arxiv.org/abs/1703.00045},
year = {2017}
}
@article{Zurek2003,
abstract = {Decoherence is caused by the interaction with the environment. Environment monitors certain observables of the system, destroying interference between the pointer states corresponding to their eigenvalues. This leads to environment-induced superselection or einselection, a quantum process associated with selective loss of information. Einselected pointer states are stable. They can retain correlations with the rest of the Universe in spite of the environment. Einselection enforces classicality by imposing an effective ban on the vast majority of the Hilbert space, eliminating especially the flagrantly non-local "Schr$\backslash$"odinger cat" states. Classical structure of phase space emerges from the quantum Hilbert space in the appropriate macroscopic limit: Combination of einselection with dynamics leads to the idealizations of a point and of a classical trajectory. In measurements, einselection replaces quantum entanglement between the apparatus and the measured system with the classical correlation.},
archivePrefix = {arXiv},
arxivId = {quant-ph/0105127},
author = {Zurek, Wojciech Hubert},
doi = {10.1103/RevModPhys.75.715},
eprint = {0105127},
file = {:home/kaslu/Documents/Mendeley/2003 - Zurek - Decoherence, einselection, and the quantum origins of the classical.pdf:pdf},
issn = {0034-6861},
journal = {Reviews of Modern Physics},
month = {may},
number = {3},
pages = {715--775},
primaryClass = {quant-ph},
title = {{Decoherence, einselection, and the quantum origins of the classical}},
url = {http://arxiv.org/abs/quant-ph/0105127},
volume = {75},
year = {2003}
}
@article{Chaisangmongkon2017,
abstract = {Decision making involves dynamic interplay between internal judgements and external perception, which has been investigated in delayed match-to-category (DMC) experiments. Our analysis of neural recordings shows that, during DMC tasks, LIP and PFC neurons demonstrate mixed, time-varying, and heterogeneous selectivity, but previous theoretical work has not established the link between these neural characteristics and population-level computations. We trained a recurrent network model to perform DMC tasks and found that the model can remarkably reproduce key features of neuronal selectivity at the single-neuron and population levels. Analysis of the trained networks elucidates that robust transient trajectories of the neural population are the key driver of sequential categorical decisions. The directions of trajectories are governed by network self-organized connectivity, defining a “neural landscape” consisting of a task-tailored arrangement of slow states and dynamical tunnels. With this model, we can identify functionally relevant circuit motifs and generalize the framework to solve other categorization tasks.},
author = {Chaisangmongkon, Warasinee and Swaminathan, Sruthi K. and Freedman, David J. and Wang, Xiao Jing},
doi = {10.1016/j.neuron.2017.03.002},
file = {:home/kaslu/Documents/Mendeley/2017 - Chaisangmongkon et al. - Computing by Robust Transience How the Fronto-Parietal Network Performs Sequential, Category-Based Decis.pdf:pdf},
issn = {10974199},
journal = {Neuron},
keywords = {LIP,PFC,category learning,decision making,delayed match-to-category task,hessian-free algorithm,lateral intraparietal cortex,prefrontal cortex,recurrent neural network,working memory},
number = {6},
pages = {1504--1517.e4},
pmid = {28334612},
publisher = {Elsevier Inc.},
title = {{Computing by Robust Transience: How the Fronto-Parietal Network Performs Sequential, Category-Based Decisions}},
url = {http://dx.doi.org/10.1016/j.neuron.2017.03.002},
volume = {93},
year = {2017}
}
@article{Sardi2017,
author = {Sardi, Shira and Vardi, Roni and Sheinin, Anton and Goldental, Amir and Kanter, Ido},
doi = {10.1038/s41598-017-18363-1},
file = {:home/kaslu/Documents/Mendeley/2017 - Sardi et al. - New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units.pdf:pdf;:home/kaslu/Documents/Mendeley/2017 - Sardi et al. - New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units(2).pdf:pdf;:home/kaslu/Documents/Mendeley/2017 - Sardi et al. - New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units(3).pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {18036},
title = {{New Types of Experiments Reveal that a Neuron Functions as Multiple Independent Threshold Units}},
url = {http://www.nature.com/articles/s41598-017-18363-1},
volume = {7},
year = {2017}
}
@article{Viswanathan1999,
abstract = {We address the general question of what is the best statistical strategy to adapt in order to search efficiently for randomly located objects ('target sites'). It is often assumed in foraging theory that the flight lengths of a forager have a characteristic scale: from this assumption gaussian, Rayleigh and other classical distributions with well-defined variances have arisen. However, such theories cannot explain the long-tailed power-law distributions of flight lengths or flight times that are observed experimentally. Here we study how the search efficiency depends on the probability distribution of flight lengths taken by a forager that can detect target sites only in its limited vicinity. We show that, when the target sites are sparse and can be visited any number of times, an inverse square power-law distribution of flight lengths, corresponding to L{\'{e}}vy flight motion, is an optimal strategy. We test the theory by analysing experimental foraging data on selected insect, mammal and bird species, and find that they are consistent with the predicted inverse square power-law distributions.},
author = {Viswanathan, G M and Buldyrev, Sergey V and Havlin, Shlomo and da Luz, M G E and Raposo, E P and Stanley, H Eugene},
doi = {10.1038/44831},
file = {:home/kaslu/Documents/Mendeley/1999 - Viswanathan et al. - Optimizing the success of random searches.pdf:pdf},
isbn = {0028-0836},
issn = {00280836},
journal = {Nature},
month = {oct},
number = {6756},
pages = {911--914},
pmid = {10553906},
title = {{Optimizing the success of random searches}},
url = {http://www.nature.com/doifinder/10.1038/44831},
volume = {401},
year = {1999}
}
@article{QuianQuiroga,
abstract = {It takes a fraction of a second to recognize a person or an object even when seen under strikingly different conditions. How such a robust, high-level representation is achieved by neurons in the human brain is still unclear. In monkeys, neurons in the upper stages of the ventral visual pathway respond to complex images such as faces and objects and show some degree of invariance to metric properties such as the stimulus size, position and viewing angle. We have previously shown that neurons in the human medial temporal lobe (MTL) fire selectively to images of faces, animals, objects or scenes. Here we report on a remarkable subset of MTL neurons that are selectively activated by strikingly different pictures of given individuals, landmarks or objects and in some cases even by letter strings with their names. These results suggest an invariant, sparse and explicit code, which might be important in the transformation of complex visual percepts into long-term and more abstract memories.},
author = {Quiroga, R. Quian and Reddy, L. and Kreiman, G. and Koch, C. and Fried, I.},
doi = {10.1038/nature03687},
file = {:home/kaslu/Documents/Mendeley/2005 - Quiroga et al. - Invariant visual representation by single neurons in the human brain.pdf:pdf},
isbn = {0028-0836},
issn = {00280836},
journal = {Nature},
number = {7045},
pages = {1102--1107},
pmid = {15973409},
title = {{Invariant visual representation by single neurons in the human brain}},
volume = {435},
year = {2005}
}
@article{Smola2006,
author = {Smola, Alexander J and Gretton, Arthur and Sch{\"{o}}lkopf, Bernhard},
file = {:home/kaslu/Documents/Mendeley/2006 - Smola, Gretton, Sch{\"{o}}lkopf - Correcting Sample Selection Bias by Unlabeled Data.pdf:pdf},
journal = {Advances in neural information processing systems},
title = {{Correcting Sample Selection Bias by Unlabeled Data}},
year = {2006}
}
@article{Melo2015,
abstract = {Modularity is a central concept in modern biology, providing a powerful framework for the study of living organisms on many organizational levels. Two central and related questions can be posed in regard to modularity: How does modularity appear in the first place, and what forces are responsible for keeping and/or changing modular patterns? We approached these questions using a quantitative genetics simulation framework, building on previous results obtained with bivariate systems and extending them to multivariate systems. We developed an individual-based model capable of simulating many traits controlled by many loci with variable pleiotropic relations between them, expressed in populations subject to mutation, recombination, drift, and selection. We used this model to study the problem of the emergence of modularity, and hereby show that drift and stabilizing selection are inefficient at creating modular variational structures. We also demonstrate that directional selection can have marked effects on the modular structure between traits, actively promoting a restructuring of genetic variation in the selected population and potentially facilitating the response to selection. Furthermore, we give examples of complex covariation created by simple regimes of combined directional and stabilizing selection and show that stabilizing selection is important in the maintenance of established covariation patterns. Our results are in full agreement with previous results for two-trait systems and further extend them to include scenarios of greater complexity. Finally, we discuss the evolutionary consequences of modular patterns being molded by directional selection.},
annote = {10.1073/pnas.1322632112},
author = {Melo, Diogo and Marroig, Gabriel},
doi = {10.1073/pnas.1322632112},
file = {:home/kaslu/Documents/Mendeley/2015 - Melo, Marroig - Directional selection can drive the evolution of modularity in complex traits.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {jan},
number = {2},
pages = {470--475},
title = {{Directional selection can drive the evolution of modularity in complex traits}},
url = {http://www.pnas.org/content/112/2/470.abstract http://www.pnas.org/lookup/doi/10.1073/pnas.1322632112},
volume = {112},
year = {2015}
}
@article{Wayne2016,
abstract = {How does accountability impact political decisions? Though previous research on accountability has demonstrated its potential effects in the realms of business, elec-tions, and more, very little research has explored the effect of citizen accountability in highly ideological, intractable, and political conflicts. This article addresses this issue, looking at the unique interaction between accountability and ideology on Israeli citizens' political attitudes regarding the Israeli–Palestinian conflict. The results of two experimental studies in Israel reveal that accountable individuals behave in significantly more ideologically partisan ways than their nonaccountable counter-parts. Moreover, this polarization is dependent on the specific conflict context, with leftists more affected by the issue of negotiations and rightists by security concerns. This signals that ideological polarization under accountability may depend on the ''issue ownership'' each ideological group feels toward the specific conflict context and its corresponding social goal of projecting ideological con-sistency on these issues.},
author = {Wayne, Carly and Porat, Roni and Tamir, Maya and Halperin, Eran},
doi = {10.1177/0022002714564431},
issn = {0022-0027},
journal = {Journal of Conflict Resolution},
month = {dec},
number = {8},
pages = {1473--1502},
title = {{Rationalizing Conflict}},
url = {http://journals.sagepub.com/doi/10.1177/0022002714564431},
volume = {60},
year = {2016}
}
@article{Westheimer2008,
abstract = {Abstract. Modern developments in machine vision and object recognition have generated renewed interest in the proposal for drawing inferences put forward by the Rev. Thomas Bayes (1701 {\^{}} 1759). In this connection the epistemological studies by Hermann Helmholtz (1821 {\^{}} 1894) are often cited as laying the foundation of the currently popular move to regard perception as Bayesian inference. Helmholtz in his mature writings tried to reconcile the German idealist notions of reality-ashypothesis with scientists' quests for the laws of nature, and espoused the view that we ``attain knowledge of the lawful order in the realm of the real, but only in so far as it is represented in the tokens within the system of sensory impressions''. His propositions of inferring objects from internal sensory signals by what he called `unconscious inferences' have made Helmholtz be regarded as a proto-Bayesian. But juxtaposing Bayes's original writings, the modern formulation of Bayesian inference, and Helmholtz's views of perception reveals only a tenuous relationship},
author = {Westheimer, Gerald},
doi = {10.1068/p5973},
issn = {03010066},
journal = {Perception},
number = {5},
pages = {642--650},
pmid = {18605140},
title = {{Was Helmholtz a Bayesian?}},
volume = {37},
year = {2008}
}
@article{Ensslin2013,
abstract = {Information field dynamics (IFD) is introduced here as a framework to derive numerical schemes for the simulation of physical and other fields without assuming a particular subgrid structure as many schemes do. IFD constructs an ensemble of nonparametric subgrid field configurations from the combination of the data in computer memory, representing constraints on possible field configurations, and prior assumptions on the subgrid field statistics. Each of these field configurations can formally be evolved to a later moment since any differential operator of the dynamics can act on fields living in continuous space. However, these virtually evolved fields need again a representation by data in computer memory. The maximum entropy principle of information theory guides the construction of updated data sets via entropic matching, optimally representing these field configurations at the later time. The field dynamics thereby become represented by a finite set of evolution equations for the data that can be solved numerically. The subgrid dynamics is thereby treated within auxiliary analytic considerations. The resulting scheme acts solely on the data space. It should provide a more accurate description of the physical field dynamics than simulation schemes constructed ad hoc, due to the more rigorous accounting of subgrid physics and the space discretization process. Assimilation of measurement data into an IFD simulation is conceptually straightforward since measurement and simulation data can just be merged. The IFD approach is illustrated using the example of a coarsely discretized representation of a thermally excited classical Klein-Gordon field. This should pave the way towards the construction of schemes for more complex systems like turbulent hydrodynamics.},
archivePrefix = {arXiv},
arxivId = {1206.4229},
author = {En{\ss}lin, Torsten},
doi = {10.1103/PhysRevE.87.013308},
eprint = {1206.4229},
file = {:home/kaslu/Documents/Mendeley/2013 - En{\ss}lin - Information field dynamics for simulation scheme construction.pdf:pdf},
issn = {1550-2376},
journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},
keywords = {Algorithms,Computer Simulation,Computer-Assisted,Electromagnetic Fields,Models,Numerical Analysis,Theoretical},
month = {jan},
number = {1},
pages = {013308},
pmid = {23410461},
title = {{Information field dynamics for simulation scheme construction.}},
url = {http://arxiv.org/abs/1206.4229},
volume = {87},
year = {2013}
}
@article{Hoffman2012,
abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
archivePrefix = {arXiv},
arxivId = {1206.7051},
author = {Hoffman, Matt and Blei, David M. and Wang, Chong and Paisley, John},
eprint = {1206.7051},
file = {:home/kaslu/Documents/Mendeley/2012 - Hoffman et al. - Stochastic Variational Inference.pdf:pdf},
month = {jun},
title = {{Stochastic Variational Inference}},
url = {http://arxiv.org/abs/1206.7051},
year = {2012}
}
@article{Battiston2015,
author = {Battiston, Stefano and Farmer, J Doyne and Flache, Andreas and Garlaschelli, Diego and Haldane, A. G. and Heesterbeek, Hans and Hommes, Cars and Jaeger, Carlo and May, Robert and Scheffer, Marten},
doi = {10.1126/science.aad0299},
file = {:home/kaslu/Documents/Mendeley/2016 - Battiston et al. - Complexity theory and financial regulation.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {feb},
number = {6275},
pages = {818--819},
pmid = {26912882},
title = {{Complexity theory and financial regulation}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aad0299},
volume = {351},
year = {2016}
}
@article{Wang2013,
abstract = {The projected normal distribution is an under-utilized model for explaining directional data. In particular, the general version provides flexibility, e.g., asymmetry and possible bimodality along with convenient regression specification. Here, we clarify the properties of this general class. We also develop fully Bayesian hierarchical models for analyzing circular data using this class. We show how they can be fit using MCMC methods with suitable latent variables. We show how posterior inference for distributional features such as the angular mean direction and concentration can be implemented as well as how prediction within the regression setting can be handled. With regard to model comparison, we argue for an out-of-sample approach using both a predictive likelihood scoring loss criterion and a cumulative rank probability score criterion. ?? 2012 Elsevier B.V..},
author = {Wang, Fangpo and Gelfand, Alan E.},
doi = {10.1016/j.stamet.2012.07.005},
file = {:home/kaslu/Documents/Mendeley/2013 - Wang, Gelfand - Directional data analysis under the general projected normal distribution.pdf:pdf},
issn = {15723127},
journal = {Statistical Methodology},
keywords = {Bivariate normal distribution,Circular data,Concentration,Latent variables,Markov chain Monte Carlo,Mean direction},
number = {1},
pages = {113--127},
publisher = {Elsevier B.V.},
title = {{Directional data analysis under the general projected normal distribution}},
url = {http://dx.doi.org/10.1016/j.stamet.2012.07.005},
volume = {10},
year = {2013}
}
@article{Gao2015,
abstract = {Technological advances have dramatically expanded our ability to probe multi-neuronal dynamics and connectivity in the brain. However, our ability to extract a simple conceptual understanding from complex data is increasingly hampered by the lack of theoretically principled data analytic procedures, as well as theoretical frameworks for how circuit connectivity and dynamics can conspire to generate emergent behavioral and cognitive functions. We review and outline potential avenues for progress, including new theories of high dimensional data analysis, the need to analyze complex artificial networks, and methods for analyzing entire spaces of circuit models, rather than one model at a time. Such interplay between experiments, data analysis and theory will be indispensable in catalyzing conceptual advances in the age of large-scale neuroscience.},
archivePrefix = {arXiv},
arxivId = {1503.0877},
author = {Gao, Peiran and Ganguli, Surya},
doi = {10.1016/j.conb.2015.04.003},
eprint = {1503.0877},
file = {:home/kaslu/Documents/Mendeley/2015 - Gao, Ganguli - On simplicity and complexity in the brave new world of large-scale neuroscience.pdf:pdf},
isbn = {0959-4388},
issn = {18736882},
journal = {Current Opinion in Neurobiology},
pages = {148--155},
pmid = {25932978},
publisher = {Elsevier Ltd},
title = {{On simplicity and complexity in the brave new world of large-scale neuroscience}},
url = {http://dx.doi.org/10.1016/j.conb.2015.04.003},
volume = {32},
year = {2015}
}
@article{Merchan2016,
abstract = {Biological information processing networks consist of many components, which are coupled by an even larger number of complex multivariate interactions. However, analyses of data sets from fields as diverse as neuroscience, molecular biology, and behavior have reported that observed statistics of states of some biological networks can be approximated well by maximum entropy models with only pairwise interactions among the components. Based on simulations of random Ising spin networks with {\$}p{\$}-spin ({\$}p{\textgreater}2{\$}) interactions, here we argue that this reduction in complexity can be thought of as a natural property of densely interacting networks in certain regimes, and not necessarily as a special property of living systems. By connecting our analysis to the theory of random constraint satisfaction problems, we suggest a reason for why some biological systems may operate in this regime.},
archivePrefix = {arXiv},
arxivId = {1505.02831},
author = {Merchan, Lina and Nemenman, Ilya},
doi = {10.1007/s10955-016-1456-5},
eprint = {1505.02831},
file = {:home/kaslu/Documents/Mendeley/2016 - Merchan, Nemenman - On the Sufficiency of Pairwise Interactions in Maximum Entropy Models of Networks.pdf:pdf},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
month = {mar},
number = {5},
pages = {1294--1308},
title = {{On the Sufficiency of Pairwise Interactions in Maximum Entropy Models of Networks}},
url = {http://arxiv.org/abs/1505.02831 http://dx.doi.org/10.1007/s10955-016-1456-5 http://link.springer.com/10.1007/s10955-016-1456-5},
volume = {162},
year = {2016}
}
@article{Abbott2008,
abstract = {Theoretical neuroscience has experienced explosive growth over the past 20 years. In addition to bringing new researchers into the field with backgrounds in physics, mathematics, computer science, and engineering, theoretical approaches have helped to introduce new ideas and shape directions of neuroscience research. This review presents some of the developments that have occurred and the lessons they have taught us. ?? 2008 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0-262-04199-5},
author = {Abbott, Larry},
doi = {10.1016/j.neuron.2008.10.019},
eprint = {0-262-04199-5},
file = {:home/kaslu/Documents/Mendeley/2008 - Abbott - Theoretical Neuroscience Rising.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$n0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {3},
pages = {489--495},
pmid = {18995824},
publisher = {Elsevier Inc.},
title = {{Theoretical Neuroscience Rising}},
url = {http://dx.doi.org/10.1016/j.neuron.2008.10.019},
volume = {60},
year = {2008}
}
@article{Vicente2009a,
abstract = {We study opinion dynamics in a population of interacting adaptive agents voting on a set of complex multidimensional issues. We consider agents which can classify issues into for or against. The agents arrive at the opinions about each issue in question using an adaptive algorithm. Adaptation comes from learning and the information for the learning process comes from interacting with other neighboring agents and trying to change the internal state in order to concur with their opinions. The change in the internal state is driven by the information contained in the issue and in the opinion of the other agent. We present results in a simple yet rich context where each agent uses a Boolean Perceptron to state its opinion. If there is no internal clock, so the update occurs with asynchronously exchanged information among pairs of agents, then the typical case, if the number of issues is kept small, is the evolution into a society thorn by the emergence of factions with extreme opposite beliefs. This occurs even when seeking consensus with agents with opposite opinions. The curious result is that it is learning from those that hold the same opinions that drives the emergence of factions. This results follows from the fact that factions are prevented by not learning at all from those agents that hold the same opinion. If the number of issues is large, the dynamics becomes trapped and the society does not evolve into factions and a distribution of moderate opinions is observed. We also study the less realistic, but technically simpler synchronous case showing that global consensus is a fixed point. However, the approach to this consensus is glassy in the limit of large societies if agents adapt even in the case of agreement.},
archivePrefix = {arXiv},
arxivId = {0811.2099},
author = {Vicente, Renato and Martins, Andr{\'{e}} C. R. and Caticha, Nestor},
doi = {10.1088/1742-5468/2009/03/P03015},
eprint = {0811.2099},
file = {:home/kaslu/Documents/Mendeley/2009 - Vicente, Martins, Caticha - Opinion dynamics of learning agents does seeking consensus lead to disagreement.pdf:pdf},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {Physics and Society,caticha,rv,social},
mendeley-tags = {caticha,rv,social},
month = {mar},
number = {03},
pages = {P03015},
title = {{Opinion dynamics of learning agents: does seeking consensus lead to disagreement?}},
url = {http://stacks.iop.org/1742-5468/2009/i=03/a=P03015?key=crossref.abf913219606282210db115d1655d36b http://arxiv.org/abs/0811.2099 http://dx.doi.org/10.1088/1742-5468/2009/03/P03015},
year = {2009}
}
@article{FeherdaSilva2017,
abstract = {Research has not yet reached a consensus on why humans match probabilities instead of maximise in a probability learning task. The most influential explanation is that they search for patterns in the random sequence of outcomes. Other explanations, such as expectation matching, are plausible, but do not consider how reinforcement learning shapes people's choices. We aimed to quantify how human performance in a probability learning task is affected by pattern search and reinforcement learning. We collected behavioural data from 84 young adult participants who performed a probability learning task wherein the majority outcome was rewarded with 0.7 probability, and analysed the data using a reinforcement learning model that searches for patterns. Model simulations indicated that pattern search, exploration, recency (discounting early experiences), and forgetting may impair performance. Our analysis estimated that 85{\%} (95{\%} HDI [76, 94]) of participants searched for patterns and believed that each trial outcome depended on one or two previous ones. The estimated impact of pattern search on performance was, however, only 6{\%}, while those of exploration and recency were 19{\%} and 13{\%} respectively. This suggests that probability matching is caused by uncertainty about how outcomes are generated, which leads to pattern search, exploration, and recency.},
author = {{Feher da Silva}, Carolina and Victorino, Camila Gomes and Caticha, Nestor and Baldo, Marcus Vin{\'{i}}cius Chrys{\'{o}}stomo},
doi = {10.1038/s41598-017-15587-z},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Humanities and Social Sciences,Science,multidisciplinary},
month = {dec},
number = {1},
pages = {15326},
publisher = {Nature Publishing Group},
title = {{Exploration and recency as the main proximate causes of probability matching: a reinforcement learning analysis}},
url = {http://www.nature.com/articles/s41598-017-15587-z},
volume = {7},
year = {2017}
}
@article{Rothe2017,
abstract = {A hallmark of human intelligence is the ability to ask rich, creative, and revealing questions. Here we introduce a cognitive model capable of constructing human-like questions. Our approach treats questions as formal programs that, when executed on the state of the world, output an answer. The model specifies a probability distribution over a complex, compositional space of programs, favoring concise programs that help the agent learn in the current context. We evaluate our approach by modeling the types of open-ended questions generated by humans who were attempting to learn about an ambiguous situation in a game. We find that our model predicts what questions people will ask, and can creatively produce novel questions that were not present in the training set. In addition, we compare a number of model variants, finding that both question informativeness and complexity are important for producing human-like questions.},
archivePrefix = {arXiv},
arxivId = {1711.06351},
author = {Rothe, Anselm and Lake, Brenden M. and Gureckis, Todd M.},
eprint = {1711.06351},
file = {:home/kaslu/Documents/Mendeley/2017 - Rothe, Lake, Gureckis - Question Asking as Program Generation.pdf:pdf},
month = {nov},
title = {{Question Asking as Program Generation}},
url = {http://arxiv.org/abs/1711.06351},
year = {2017}
}
@article{DiTella2015,
abstract = {We present results from a “corruption game” (a dictator game modified so that recipients can take a side payment in exchange for accepting a reduction in the overall size of the pie). Dictators (silently) treated to be able to take more of the recipient's tokens, took more of them. They were also more likely to believe that recipi- ents had accepted side payments, even if there was a prize for accu- racy. The results favor the hypothesis that people avoid altruistic actions by distorting beliefs about others' altruism.},
author = {{Di Tella}, Rafael and Perez-Truglia, Ricardo and Babino, Andres and Sigman, Mariano},
doi = {10.1257/aer.20141409},
issn = {0002-8282},
journal = {American Economic Review},
month = {nov},
number = {11},
pages = {3416--3442},
title = {{Conveniently Upset: Avoiding Altruism by Distorting Beliefs about Others' Altruism}},
url = {http://pubs.aeaweb.org/doi/10.1257/aer.20141409},
volume = {105},
year = {2015}
}
@article{Dietze2008,
author = {F{\O}RLAND, TOR EGIL},
doi = {10.1111/j.1468-2303.2008.00435.x},
file = {:home/kaslu/Documents/Mendeley/2008 - F{\O}RLAND - MENTALITY AS A SOCIAL EMERGENT CAN THE ZEITGEIST HAVE EXPLANATORY POWER.pdf:pdf},
isbn = {1800444273},
issn = {0018-2656},
journal = {History and Theory},
month = {feb},
number = {1},
pages = {44--56},
title = {{MENTALITY AS A SOCIAL EMERGENT: CAN THE ZEITGEIST HAVE EXPLANATORY POWER?}},
url = {http://doi.wiley.com/10.1111/j.1468-2303.2008.00435.x},
volume = {47},
year = {2008}
}
@article{Mason2016,
abstract = {We used functional MRI (fMRI) to assess neural representations of physics concepts (momentum, energy, etc.) in juniors, seniors, and graduate students majoring in physics or engineering. Our goal was to identify the underlying neural dimensions of these representations. Using factor analysis to reduce the number of dimensions of activation, we obtained four physics-related factors that were mapped to sets of voxels. The four factors were interpretable as causal motion visualization, periodicity, algebraic form, and energy flow. The individual concepts were identifiable from their fMRI signatures with a mean rank accuracy of .75 using a machine-learning (multivoxel) classifier. Furthermore, there was commonality in participants' neural representation of physics; a classifier trained on data from all but one participant identified the concepts in the left-out participant (mean accuracy = .71 across all nine participant samples). The findings indicate that abstract scientific concepts acquired in an educational setting evoke activation patterns that are identifiable and common, indicating that science education builds abstract knowledge using inherent, repurposed brain systems.},
annote = {10.1177/0956797616641941},
author = {Mason, Robert A and Just, Marcel Adam},
doi = {10.1177/0956797616641941},
file = {:home/kaslu/Documents/Mendeley/2016 - Mason, Just - Neural Representations of Physics Concepts.pdf:pdf},
journal = {Psychological Science},
month = {jun},
number = {6},
pages = {904--913},
title = {{Neural Representations of Physics Concepts}},
url = {http://pss.sagepub.com/content/27/6/904.abstract},
volume = {27},
year = {2016}
}
@article{Knollmuller2017,
abstract = {We present a new method for the separation of superimposed, independent, auto-correlated components from noisy multi-channel measurement. The presented method simultaneously reconstructs and separates the components, taking all channels into account and thereby increases the effective signal-to-noise ratio considerably, allowing separations even in the high noise regime. Characteristics of the measurement instruments can be included, allowing for application in complex measurement situations. Independent posterior samples can be provided, permitting error estimates on all desired quantities. Using the concept of information field theory, the algorithm is not restricted to any dimensionality of the underlying space or discretization scheme thereof.},
archivePrefix = {arXiv},
arxivId = {1705.02344},
author = {Knollm{\"{u}}ller, Jakob and En{\ss}lin, Torsten A.},
doi = {10.1103/PhysRevE.96.042114},
eprint = {1705.02344},
file = {:home/kaslu/Documents/Mendeley/2017 - Knollm{\"{u}}ller, En{\ss}lin - Noisy independent component analysis of autocorrelated components.pdf:pdf},
issn = {2470-0045},
journal = {Physical Review E},
month = {oct},
number = {4},
pages = {042114},
title = {{Noisy independent component analysis of autocorrelated components}},
url = {http://arxiv.org/abs/1705.02344 https://link.aps.org/doi/10.1103/PhysRevE.96.042114},
volume = {96},
year = {2017}
}
@article{Pitkow2015,
abstract = {Single sensory neurons can be surprisingly predictive of behavior in discrimination tasks. We propose this is possible because sensory information extracted from neural populations is severely restricted, either by near-optimal decoding of a population with information-limiting correlations or by suboptimal decoding that is blind to correlations. These have different consequences for choice correlations, the correlations between neural responses and behavioral choices. In the vestibular and cerebellar nuclei and the dorsal medial superior temporal area, we found that choice correlations during heading discrimination are consistent with near-optimal decoding of neuronal responses corrupted by information-limiting correlations. In the ventral intraparietal area, the choice correlations are also consistent with the presence of information-limiting correlations, but this area does not appear to influence behavior, although the choice correlations are particularly large. These findings demonstrate how choice correlations can be used to assess the efficiency of the downstream readout and detect the presence of information-limiting correlations.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Pitkow, Xaq and Liu, Sheng and Angelaki, Dora E. and DeAngelis, Gregory C. and Pouget, Alexandre},
doi = {10.1016/j.neuron.2015.06.033},
eprint = {15334406},
file = {:home/kaslu/Documents/Mendeley/2015 - Pitkow et al. - How Can Single Sensory Neurons Predict Behavior.pdf:pdf},
isbn = {doi:10.1016/j.neuron.2015.06.033},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {411--423},
pmid = {26182422},
title = {{How Can Single Sensory Neurons Predict Behavior?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315005966},
volume = {87},
year = {2015}
}
@article{Botvinick2009,
abstract = {Research on human and animal behavior has long emphasized its hierarchical structure — the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
author = {Botvinick, Matthew M. and Niv, Yael and Barto, AC},
doi = {10.1016/j.cognition.2008.08.011.Hierarchically},
file = {:home/kaslu/Documents/Mendeley/2009 - Botvinick, Niv, Barto - Hierarchically organized behavior and its neural foundations A reinforcement learning perspective.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
number = {3},
pages = {262--280},
title = {{Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective}},
url = {http://www.sciencedirect.com/science/article/pii/S0010027708002059},
volume = {113},
year = {2009}
}
@article{Ribas-Fernandes2011,
author = {Ribas-Fernandes, Jos{\'{e}} J F and Solway, Alec and Diuk, Carlos and Mcguire, Joseph T. and Barto, Andrew G. and Niv, Yael and Botvinick, Matthew M.},
doi = {10.1016/j.neuron.2011.05.042},
file = {:home/kaslu/Documents/Mendeley/2011 - Ribas-Fernandes et al. - A Neural Signature of Hierarchical Reinforcement Learning.pdf:pdf},
title = {{A Neural Signature of Hierarchical Reinforcement Learning}},
year = {2011}
}
@article{Edwards1986,
abstract = {Jesus of Nazareth underwent Jewish and Roman trials, was flogged, and was sentenced to death by crucifixion. The scourging produced deep stripelike lacerations and appreciable blood loss, and it probably set the stage for hypovolemic shock, as evidenced by the fact that Jesus was too weakened to carry the crossbar (patibulum) to Golgotha. At the site of crucifixion, his wrists were nailed to the patibulum and, after the patibulum was lifted onto the upright post (stipes), his feet were nailed to the stipes. The major pathophysiologic effect of crucifixion was an interference with normal respirations. Accordingly, death resulted primarily from hypovolemic shock and exhaustion asphyxia. Jesus' death was ensured by the thrust of a soldier's spear into his side. Modern medical interpretation of the historical evidence indicates that Jesus was dead when taken down from the cross.},
author = {Edwards, William D. and Gabel, Wesley J. and Hosmer, Floyd E.},
doi = {10.1001/jama.1986.03370110077025},
file = {:home/kaslu/Documents/Mendeley/1986 - Edwards, Gabel, Hosmer - On the Physical Death of Jesus Christ.pdf:pdf},
isbn = {0098-7484 (Print)$\backslash$r0098-7484 (Linking)},
issn = {15383598},
journal = {JAMA: The Journal of the American Medical Association},
month = {mar},
number = {11},
pages = {1455--1463},
pmid = {3512867},
publisher = {American Medical Association},
title = {{On the Physical Death of Jesus Christ}},
url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.1986.03370110077025},
volume = {255},
year = {1986}
}
@article{Gonzalez2014,
abstract = {The foundations of Statistical Mechanics can be recovered almost in their entirety from the Principle of Maximum Entropy. In this work we show that its non-equilibrium generalization, the Principle of Maximum Caliber (Jaynes, 1980), when applied to the unknown trajectory followed by a particle, leads to Newton's second law under two quite intuitive assumptions (the expected square displacement in one step and the spatial probability distribution of the particle are known at all times). Our derivation explicitly highlights the role of mass as an emergent measure of the fluctuations in velocity (inertia) and the origin of potential energy as a manifestation of spatial correlations. According to our findings, the application of Newton's equations is not limited to mechanical systems, and therefore could be used in modelling ecological, financial and biological systems, among others.},
archivePrefix = {arXiv},
arxivId = {1310.1382},
author = {Gonz{\'{a}}lez, Diego and Davis, Sergio and Guti{\'{e}}rrez, Gonzalo},
doi = {10.1007/s10701-014-9819-8},
eprint = {1310.1382},
file = {:home/kaslu/Documents/Mendeley/2014 - Gonz{\'{a}}lez, Davis, Guti{\'{e}}rrez - Newtonian Dynamics from the Principle of Maximum Caliber.pdf:pdf},
issn = {0015-9018},
journal = {Foundations of Physics},
keywords = {Maximum caliber,Newtonian mechanics},
month = {sep},
number = {9},
pages = {923--931},
title = {{Newtonian Dynamics from the Principle of Maximum Caliber}},
url = {http://arxiv.org/abs/1310.1382 http://dx.doi.org/10.1007/s10701-014-9819-8 http://link.springer.com/10.1007/s10701-014-9819-8},
volume = {44},
year = {2014}
}
@article{Kappel2015a,
abstract = {General results from statistical learning theory suggest to understand not only brain computations, but also brain plasticity as probabilistic inference. But a model for that has been missing. We propose that inherently stochastic features of synaptic plasticity and spine motility enable cortical networks of neurons to carry out probabilistic inference by sampling from a posterior distribution of network configurations. This model provides a viable alternative to existing models that propose convergence of parameters to maximum likelihood values. It explains how priors on weight distributions and connection probabilities can be merged optimally with learned experience, how cortical networks can generalize learned information so well to novel experiences, and how they can compensate continuously for unforeseen disturbances of the network. The resulting new theory of network plasticity explains from a functional perspective a number of experimental data on stochastic aspects of synaptic plasticity that previously appeared to be quite puzzling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1504.05143v1},
author = {Kappel, David and Habenschuss, Stefan and Legenstein, Robert and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1004485},
eprint = {arXiv:1504.05143v1},
file = {:home/kaslu/Documents/Mendeley/2015 - Kappel et al. - Network Plasticity as Bayesian Inference.pdf:pdf},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {11},
pages = {1--31},
pmid = {26545099},
title = {{Network Plasticity as Bayesian Inference}},
volume = {11},
year = {2015}
}
@article{Zarkeshian2017,
abstract = {Despite great progress in neuroscience, there are still fundamental unanswered questions about the brain, including the origin of subjective experience and consciousness. Some answers might rely on new physical mechanisms. Given that biophotons have been discovered in the brain, it is interesting to explore if neurons use photonic communication in addition to the well-studied electro-chemical signals. Such photonic communication in the brain would require waveguides. Here we review recent work [S. Kumar, K. Boone, J. Tuszynski, P. Barclay, and C. Simon, Scientific Reports 6, 36508 (2016)] suggesting that myelinated axons could serve as photonic waveguides. The light transmission in the myelinated axon was modeled, taking into account its realistic imperfections, and experiments were proposed both in-vivo and in-vitro to test this hypothesis. Potential implications for quantum biology are discussed.},
archivePrefix = {arXiv},
arxivId = {1708.08887},
author = {Zarkeshian, Parisa and Kumar, Sourabh and Tuszynski, Jack and Barclay, Paul and Simon, Christoph},
eprint = {1708.08887},
file = {:home/kaslu/Documents/Mendeley/2017 - Zarkeshian et al. - Are there optical communication channels in the brain.pdf:pdf},
month = {aug},
title = {{Are there optical communication channels in the brain?}},
url = {http://arxiv.org/abs/1708.08887},
year = {2017}
}
@article{Azhar2010a,
abstract = {The inverse problem of statistical mechanics involves finding the minimal Hamiltonian that is consistent with some observed set of correlation functions. This problem has received renewed interest in the analysis of biological networks; in particular, several such networks have been described successfully by maximum entropy models consistent with pairwise correlations. These correlations are usually weak in an absolute sense (e.g., correlation coefficients {\~{}} 0.1 or less), and this is sometimes taken as evidence against the existence of interesting collective behavior in the network. If correlations are weak, it should be possible to capture their effects in perturbation theory, so we develop an expansion for the entropy of Ising systems in powers of the correlations, carrying this out to fourth order. We then consider recent work on networks of neurons [Schneidman et al., Nature 440, 1007 (2006); Tkacik et al., arXiv:0912.5409 [q-bio.NC] (2009)], and show that even though all pairwise correlations are weak, the fact that these correlations are widespread means that their impact on the network as a whole is not captured in the leading orders of perturbation theory. More positively, this means that recent successes of maximum entropy approaches are not simply the result of correlations being weak.},
archivePrefix = {arXiv},
arxivId = {1012.5987},
author = {Azhar, Feraz and Bialek, William},
eprint = {1012.5987},
file = {:home/kaslu/Documents/Mendeley/2010 - Azhar, Bialek - When are correlations strong.pdf:pdf},
journal = {arXiv},
month = {dec},
pages = {1--14},
title = {{When are correlations strong?}},
url = {http://arxiv.org/abs/1012.5987},
year = {2010}
}
@article{Miller1995,
author = {Miller, Ralph R. and Miller, Ralph R. and Barnet, Robert C. and Barnet, Robert C. and Grahame, Nicholas J. and Grahame, Nicholas J.},
doi = {10.1037/0033-2909.117.3.363},
file = {:home/kaslu/Documents/Mendeley/1995 - Miller et al. - Assessment of the Rescorla- Wagner Model.pdf:pdf},
isbn = {0033-2909 (Print)$\backslash$n0033-2909 (Linking)},
issn = {0033-2909},
journal = {Psychological Bulletin},
number = {3},
pages = {363--386},
pmid = {7777644},
title = {{Assessment of the Rescorla- Wagner Model}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.117.3.363},
volume = {117},
year = {1995}
}
@article{Yu2009a,
abstract = {In a variety of behavioral tasks, subjects exhibit an automatic and apparently suboptimal sequential effect: they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history, such as a string of repetitions or alternations, compared to when it violates such a pattern. This is often the case even if the local trends arise by chance in the context of a randomized design, such that stimulus history has no real predictive power. In this work, we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reflect the inadvertent engagement of mechanisms critical for adapting to a changing environment. We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm. The Bayesian algorithm is shown to be well approximated by linear-exponential filtering of past observations, a feature also apparent in the behavioral data. We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential filter. Since the latter is equivalent to a leaky-integration process, a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies, our model provides a principled account of why such dynamics are useful. We also show that parameter-tuning of the leaky-integration process is possible, using stochastic gradient descent based only on the noisy binary inputs. This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics, but that they can also learn to tune the processing parameters without explicitly representing probabilities.},
author = {Yu, Angela J. and Cohen, Jonathan D.},
file = {:home/kaslu/Documents/Mendeley/2009 - Yu, Cohen - Sequential effects Superstition or rational behavior.pdf:pdf},
isbn = {9781605609492},
issn = {1049-5258},
journal = {Advances in neural information processing systems},
pages = {1873--1880},
pmid = {26412953},
title = {{Sequential effects: Superstition or rational behavior?}},
url = {http://papers.nips.cc/paper/3519-sequential-effects-superstition-or-rational-behavior http://www.pni.princeton.edu/ncc/publications/2009/YuNIPS09.pdf http://www.ncbi.nlm.nih.gov/pubmed/26412953 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC},
volume = {21},
year = {2009}
}
@article{Mensh2017,
abstract = {Good scientific writing is essential to career development and to the progress of science. A well-structured manuscript allows readers and reviewers to get excited about the subject matter, to understand and verify the paper's contributions, and to integrate them into a broader context. However, many scientists struggle with producing high-quality manuscripts and are typically given little training in paper writing. Focusing on how readers consume information, we present a set of 10 simple rules to help you get across the main idea of your paper. These rules are designed to make your paper more influential and the process of writing more efficient and pleasurable.},
archivePrefix = {arXiv},
arxivId = {1511.07122},
author = {Mensh, Brett and Kording, Konrad},
doi = {10.1371/journal.pcbi.1005619},
eprint = {1511.07122},
file = {:home/kaslu/Documents/Mendeley/2017 - Mensh, Kording - Ten simple rules for structuring papers.pdf:pdf},
isbn = {0894-0282},
issn = {15537358},
journal = {PLoS Computational Biology},
pmid = {22352717},
title = {{Ten simple rules for structuring papers}},
year = {2017}
}
@article{Kinouchi1995,
abstract = {The spherical perceptron with N inputs and a linear output does not present optimal generalization if trained by minimization of the standard quadratic cost function E=1/2 J=1N (b-h)2, where b and h are the outputs from the rule (teacher) and hypothesis (student) networks for the example and there are N examples. We derive an optimal algorithm for on-line learning of examples which outperforms the iterative (off-line) standard algorithm for up to 0.71. The on-line optimized algorithm suggests a class of cost functions for off-line learning, which we then proceed to study using the replica method. The optimized cost function within that class has the suggestive form E=N[(1/N) J=1N [-lnP(bh)]- lnZ], where Z is a normalization constant, P(bh) is the conditional probability of the output data b given the hypothesis output h, and is a learning parameter analogous to a temperature which decreases in a well defined manner along the learning process. {\textcopyright} 1995 The American Physical Society.},
author = {Kinouchi, Osame and Caticha, Nestor},
doi = {10.1103/PhysRevE.52.2878},
issn = {1063-651X},
journal = {Physical Review E},
month = {sep},
number = {3},
pages = {2878--2886},
title = {{On-line versus off-line learning in the linear perceptron: A comparative study}},
url = {https://link.aps.org/doi/10.1103/PhysRevE.52.2878},
volume = {52},
year = {1995}
}
@article{Geller1968,
abstract = {Tabulation of definite and indefinite integrals of products of error function with elementary and transcendental functions},
author = {Geller, M. and Ng, E. W.},
doi = {10.6028/jres.073B.001},
file = {:home/kaslu/Documents/Mendeley/1968 - Geller, Ng - A table of integrals of the error functions.pdf:pdf},
issn = {0098-8979},
journal = {JOURNAL OF RESEARCH of the National Bureau of Standards},
keywords = {astrophysics,atomic physics,error functions,indefi nite integrals,special fun ctions,statistical analysis},
number = {1},
pages = {1--20},
title = {{A table of integrals of the error functions.}},
volume = {73B},
year = {1968}
}
@article{Greene2009,
abstract = {This article reviews recent advances in the cognitive neuroscience of moral judgment. The field began with studies of individuals who exhibit abnormal moral behavior, including neurological patients and psychopaths. Such studies continue to provide valuable insights, particularly concerning the role of emotion in moral decision-making. Recent functional neuroimaging studies of normal individuals have identified neural correlates of specific emotional processes relevant to moral judgment. A range of studies using diverse methods support a dual-process theory of moral judgment according to which utilitarian moral judgments (favoring the “greater good” over individual rights) are enabled by controlled cognitive processes, while deontological judgments (favoring individual rights) are driven by intuitive emotional responses. Several recent neuroimaging studies focus on the neural bases of mental state attribution in the context of moral judgment. Finally, research in the field of neuroeconomics has focused on neural processing related to cooperation, trust, and fairness.},
author = {Greene, Joshua D.},
file = {:home/kaslu/Documents/Mendeley/2009 - Greene - The cognitive neuroscience of moral judgment.pdf:pdf},
isbn = {9780262027779},
journal = {The cognitive neurosciences IV},
pages = {1013--1024},
title = {{The cognitive neuroscience of moral judgment}},
url = {http://xa.yimg.com/kq/groups/14661755/505292463/name/gazzaniga-greene+chap.68.pdf},
year = {2009}
}
@article{FRANK2009,
author = {FRANK, S. A.},
doi = {10.1111/j.1420-9101.2009.01775.x},
file = {:home/kaslu/Documents/Mendeley/2009 - FRANK - The common patterns of nature.pdf:pdf},
issn = {1010061X},
journal = {Journal of Evolutionary Biology},
keywords = {ecological pattern,maximum entropy,neutral theories,population genetics},
month = {aug},
number = {8},
pages = {1563--1585},
publisher = {Blackwell Publishing Ltd},
title = {{The common patterns of nature}},
url = {http://doi.wiley.com/10.1111/j.1420-9101.2009.01775.x},
volume = {22},
year = {2009}
}
@article{Caticha2015a,
abstract = {A systematic method of transferring information from coarser to finer resolution based on renormalization group (RG) transformations is introduced. It permits building informative priors in finer scales from posteriors in coarser scales since, under some conditions, RG transformations in the space of hyperparameters can be inverted. These priors are updated using renormalized data into posteriors by Maximum Entropy. The resulting inference method, backward RG (BRG) priors, is tested by doing simulations of a functional magnetic resonance imaging (fMRI) experiment. Its results are compared with a Bayesian approach working in the finest available resolution. Using BRG priors sources can be partially identified even when signal to noise ratio levels are up to {\~{}} -25dB improving vastly on the single step Bayesian approach. For low levels of noise the BRG prior is not an improvement over the single scale Bayesian method. Analysis of the histograms of hyperparameters can show how to distinguish if the method is failing, due to very high levels of noise, or if the identification of the sources is, at least partially possible.},
author = {Caticha, Nestor},
doi = {10.3390/e17052573},
file = {:home/kaslu/Documents/Mendeley/2015 - Caticha - Source Localization by Entropic Inference and Backward Renormalization Group Priors.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
keywords = {EEG,fMRI,inverse problems,maximum entropy,prior distribution,renormalization group},
language = {en},
month = {apr},
number = {5},
pages = {2573--2589},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Source Localization by Entropic Inference and Backward Renormalization Group Priors}},
url = {http://www.mdpi.com/1099-4300/17/5/2573/htm},
volume = {17},
year = {2015}
}
@article{Papamakarios2016,
abstract = {Many statistical models can be simulated forwards but have intractable likelihoods. Approximate Bayesian Computation (ABC) methods are used to infer properties of these models from data. Traditionally these methods approximate the posterior over parameters by conditioning on data being inside an {\$}\backslashepsilon{\$}-ball around the observed data, which is only correct in the limit {\$}\backslashepsilon\backslash!\backslashrightarrow\backslash!0{\$}. Monte Carlo methods can then draw samples from the approximate posterior to approximate predictions or error bars on parameters. These algorithms critically slow down as {\$}\backslashepsilon\backslash!\backslashrightarrow\backslash!0{\$}, and in practice draw samples from a broader distribution than the posterior. We propose a new approach to likelihood-free inference based on Bayesian conditional density estimation. Preliminary inferences based on limited simulation data are used to guide later simulations. In some cases, learning an accurate parametric representation of the entire true posterior distribution requires fewer model simulations than Monte Carlo ABC methods need to produce a single sample from an approximate posterior.},
archivePrefix = {arXiv},
arxivId = {1605.06376},
author = {Papamakarios, George and Murray, Iain},
eprint = {1605.06376},
file = {:home/kaslu/Documents/Mendeley/2016 - Papamakarios, Murray - Fast {\$}epsilon{\$}-free Inference of Simulation Models with Bayesian Conditional Density Estimation.pdf:pdf},
month = {may},
title = {{Fast {\$}\backslashepsilon{\$}-free Inference of Simulation Models with Bayesian Conditional Density Estimation}},
url = {http://arxiv.org/abs/1605.06376},
year = {2016}
}
@article{Clauset2015,
abstract = {The faculty job market plays a fundamental role in shaping research priorities, educational outcomes, and career trajectories among scientists and institutions. However, a quantitative understanding of faculty hiring as a system is lacking. Using a simple technique to extract the institutional prestige ranking that best explains an observed faculty hiring network—who hires whose graduates as faculty—we present and analyze comprehensive placement data on nearly 19,000 regular faculty in three disparate disciplines. Across disciplines, we find that faculty hiring follows a common and steeply hierarchical structure that reflects profound social inequality. Furthermore, doctoral prestige alone better predicts ultimate placement than a U.S. News {\&} World Report rank, women generally place worse than men, and increased institutional prestige leads to increased faculty production, better faculty placement, and a more influential position within the discipline. These results advance our ability to quantify the influence of prestige in academia and shed new light on the academic system.},
author = {Clauset, Aaron and Arbesman, S. and Larremore, Daniel B.},
doi = {10.1126/sciadv.1400005},
file = {:home/kaslu/Documents/Mendeley/2015 - Clauset, Arbesman, Larremore - Systematic inequality and hierarchy in faculty hiring networks.pdf:pdf},
isbn = {2375-2548},
issn = {2375-2548},
journal = {Science Advances},
month = {feb},
number = {1},
pages = {e1400005--e1400005},
pmid = {26601125},
publisher = {American Association for the Advancement of Science},
title = {{Systematic inequality and hierarchy in faculty hiring networks}},
url = {http://advances.sciencemag.org/cgi/doi/10.1126/sciadv.1400005},
volume = {1},
year = {2015}
}
@article{Tikochinsky1984,
abstract = {A consistent approach to the inference of a probability distribution given a limited number of expectation values of relevant variables is discussed. There are two key assumptions: that the experiment can be independently repeated a finite number (not necessarily large) of times and that the theoretical expectation values of the relevant observables are to be estimated from their measured sample averages. Three independent but complementary routes for deriving the form of the distribution from these two assumptions are reviewed. All three lead to a unique distribution which is identical with the one obtained by the maximum-entropy formalism. The present derivation thus provides an alternative approach to the inference problem which does not invoke Shannon's notion of missing information or entropy. The approach is more limited in scope than the one proposed by Jaynes, but has the advantage that it is objective and that the operational origin of the "given" expectation values is specified.},
author = {Tikochinsky, Y. and Tishby, N. Z. and Levine, R. D.},
doi = {10.1103/PhysRevA.30.2638},
file = {:home/kaslu/Documents/Mendeley/1984 - Tikochinsky, Tishby, Levine - Alternative approach to maximum-entropy inference.pdf:pdf},
issn = {0556-2791},
journal = {Physical Review A},
month = {nov},
number = {5},
pages = {2638--2644},
title = {{Alternative approach to maximum-entropy inference}},
url = {https://link.aps.org/doi/10.1103/PhysRevA.30.2638},
volume = {30},
year = {1984}
}
@article{Yu2009,
abstract = {We investigate the problem of using continuous features in the maximum entropy (MaxEnt) model. We explain why the MaxEnt model with the moment constraint (MaxEnt-MC) works well with binary features but not with the continuous features. We describe how to enhance constraints on the continuous features and show that the weights associated with the continuous features should be continuous functions instead of single values. We propose a spline-based solution to the MaxEnt model with non-linear continuous weighting functions and illustrate that the optimization problem can be converted into a standard log-linear model at a higher-dimensional space. The empirical results on two classification tasks that contain continuous features are reported. The results confirm our insight and show that our proposed solution consistently outperforms the MaxEnt-MC model and the bucketing approach with significant margins. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Yu, Dong and Deng, Li and Acero, Alex},
doi = {10.1016/j.patrec.2009.06.005},
file = {:home/kaslu/Documents/Mendeley/2009 - Yu, Deng, Acero - Using continuous features in the maximum entropy model.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Continuous feature,Distribution constraint,Maximum entropy model,Maximum entropy principle,Moment constraint,Spline interpolation},
number = {14},
pages = {1295--1300},
publisher = {Elsevier B.V.},
title = {{Using continuous features in the maximum entropy model}},
url = {http://dx.doi.org/10.1016/j.patrec.2009.06.005},
volume = {30},
year = {2009}
}
@article{Coombes2006,
abstract = {We review mathematical aspects of biophysical dynamics, signal transduction and network architecture that have been used to uncover functionally significant relations between the dynamics of single neurons and the networks they compose. We focus on examples that combine insights from these three areas to expand our understanding of systems neuroscience. These range from single neuron coding to models of decision making and electrosensory discrimination by networks and populations and also coincidence detection in pairs of dendrites and dynamics of large networks of excitable dendritic spines. We conclude by describing some of the challenges that lie ahead as the applied mathematics community seeks to provide the tools which will ultimately underpin systems neuroscience.},
author = {Coombes, S. and Doiron, Brent and Josic, K. and Shea-Brown, Eric},
doi = {10.1098/rsta.2006.1903},
file = {:home/kaslu/Documents/Mendeley/2006 - Coombes et al. - Towards blueprints for network architecture, biophysical dynamics and signal transduction.pdf:pdf},
isbn = {1364-503X (Print)},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {biological neural networks,coupled oscillators,information theory,neural signal processing,stochastic neuroscience},
number = {1849},
pages = {3301--3318},
pmid = {17090461},
title = {{Towards blueprints for network architecture, biophysical dynamics and signal transduction}},
url = {http://rsta.royalsocietypublishing.org/cgi/doi/10.1098/rsta.2006.1903},
volume = {364},
year = {2006}
}
@article{Peck2004,
abstract = {This study presents a mathematical model in which the fitness of an individual depends on the individual's genotype (individual effects) and on the genotypes of other members of the individual's local group (group effects). The findings suggest that, if phenotypes are a result of complex interactions between genes at different loci, then fitness-enhancing group effects may become common in sexual populations. The spread of fitness-enhancing group effects is facilitated when environmental conditions sometimes deteriorate temporarily. This is so even if the genotypes with the highest group effects also tend to have relatively low individual effects. In this sense, the process described here can lead to the evolution of altruism. By contrast, when populations are asexual it appears that group effects are much less important in determining the outcome of evolution. Thus, in nature, asexual populations may tend to be characterized by more antagonistic interactions than those that typically prevail when reproduction is sexual. This might help to explain why asexual lineages are prone to rapid extinction.},
author = {Peck, Joel R},
doi = {10.1098/rspb.2003.2650},
isbn = {0962-8452 (Print)$\backslash$n0962-8452 (Linking)},
issn = {0962-8452},
journal = {Proceedings. Biological sciences / The Royal Society},
keywords = {altruism,antagonistic interactions than those,epistasis,evolution of sex,group selection,population genetics,reproduction is sexual,that typically prevail when,this might help to},
number = {1543},
pages = {993--1000},
pmid = {15293851},
title = {{Sex causes altruism. Altruism causes sex. Maybe.}},
volume = {271},
year = {2004}
}
@article{Marvel2012,
abstract = {Some of the most pivotal moments in intellectual history occur when a new ideology sweeps through a society, supplanting an established system of beliefs in a rapid revolution of thought. Yet in many cases the new ideology is as extreme as the old. Why is it then that moderate positions so rarely prevail? Here, in the context of a simple model of opinion spreading, we test seven plausible strategies for deradicalizing a society and find that only one of them significantly expands the moderate subpopulation without risking its extinction in the process.},
archivePrefix = {arXiv},
arxivId = {1209.3546},
author = {Marvel, Seth A. and Hong, Hyunsuk and Papush, Anna and Strogatz, Steven H.},
doi = {10.1103/PhysRevLett.109.118702},
eprint = {1209.3546},
file = {:home/kaslu/Documents/Mendeley/2012 - Marvel et al. - Encouraging moderation Clues from a simple model of ideological conflict.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {11},
pages = {1--4},
pmid = {23005690},
title = {{Encouraging moderation: Clues from a simple model of ideological conflict}},
volume = {109},
year = {2012}
}
@article{Lake2015,
abstract = {People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation.We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches.We also present several “visual Turing tests” probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior.},
author = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
doi = {10.1126/science.aab3050},
file = {:home/kaslu/Documents/Mendeley/2015 - Lake, Salakhutdinov, Tenenbaum - Human-level concept learning through probabilistic program induction(2).pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {dec},
number = {6266},
pages = {1332--1338},
title = {{Human-level concept learning through probabilistic program induction}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aab3050 https://www.sciencemag.org/content/350/6266/1332.full.pdf},
volume = {350},
year = {2015}
}
@article{Tseng2008,
abstract = {We develop a maximum relative entropy formalism to generate optimal approximations to probability distributions. The central results consist of (a) justifying the use of relative entropy as the uniquely natural criterion to select a preferred approximation from within a family of trial parameterized distributions, and (b) to obtain the optimal approximation by marginalizing over parameters using the method of maximum entropy and information geometry. As an illustration we apply our method to simple fluids. The "exact" canonical distribution is approximated by that of a fluid of hard spheres. The proposed method first determines the preferred value of the hard-sphere diameter, and then obtains an optimal hard-sphere approximation by a suitably weighed average over different hard-sphere diameters. This leads to a considerable improvement in accounting for the soft-core nature of the interatomic potential. As a numerical demonstration, the radial distribution function and the equation of state for a Lennard-Jones fluid (argon) are compared with results from molecular dynamics simulations. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Tseng, Chih Yuan and Caticha, Ariel},
doi = {10.1016/j.physa.2008.08.035},
file = {:home/kaslu/Documents/Mendeley/2008 - Tseng, Caticha - Using relative entropy to find optimal approximations An application to simple fluids.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Approximation method,Hard sphere approximation,Marginalization,Maximum entropy,Simple fluids},
number = {27},
pages = {6759--6770},
publisher = {Elsevier B.V.},
title = {{Using relative entropy to find optimal approximations: An application to simple fluids}},
url = {http://dx.doi.org/10.1016/j.physa.2008.08.035},
volume = {387},
year = {2008}
}
@article{Curley2017,
author = {Curley, James P. and Ochsner, Kevin N.},
doi = {10.1038/s41562-017-0104},
issn = {2397-3374},
journal = {Nature Human Behaviour},
month = {apr},
number = {5},
pages = {0104},
publisher = {Macmillan Publishers Limited},
title = {{Neuroscience: Social networks in the brain}},
url = {http://www.nature.com/articles/s41562-017-0104},
volume = {1},
year = {2017}
}
@article{Shimazaki2015,
abstract = {We show that dynamical gain modulation of neurons' stimulus response is described as an information-theoretic cycle that generates entropy associated with the stimulus-related activity from entropy produced by the modulation. To articulate this theory, we describe stimulus-evoked activity of a neural population based on the maximum entropy principle with constraints on two types of overlapping activities, one that is controlled by stimulus conditions and the other, termed internal activity, that is regulated internally in an organism. We demonstrate that modulation of the internal activity realises gain control of stimulus response, and controls stimulus information. A cycle of neural dynamics is then introduced to model information processing by the neurons during which the stimulus information is dynamically enhanced by the internal gain-modulation mechanism. Based on the conservation law for entropy production, we demonstrate that the cycle generates entropy ascribed to the stimulus-related activity using entropy supplied by the internal mechanism, analogously to a heat engine that produces work from heat. We provide an efficient cycle that achieves the highest entropic efficiency to retain the stimulus information. The theory allows us to quantify efficiency of the internal computation and its theoretical limit.},
archivePrefix = {arXiv},
arxivId = {1512.07855},
author = {Shimazaki, Hideaki},
eprint = {1512.07855},
file = {:home/kaslu/Documents/Mendeley/2015 - Shimazaki - Neurons as an Information-theoretic Engine.pdf:pdf},
journal = {arXiv},
keywords = {()},
month = {dec},
pages = {1512.07855},
title = {{Neurons as an Information-theoretic Engine}},
url = {http://arxiv.org/abs/1512.07855},
year = {2015}
}
@article{Nogueira2017,
abstract = {The orbitofrontal cortex encodes outcomes, expected rewards and values, but it is unclear how this region uses this information to inform action selection. Here, the authors show that lateral orbitofrontal cortex anticipates upcoming choices and combines recent prior information with current sensory information.},
author = {Nogueira, Ramon and Abolafia, Juan M. and Drugowitsch, Jan and Balaguer-Ballester, Emili and Sanchez-Vives, Maria V. and Moreno-Bote, Rub{\'{e}}n},
doi = {10.1038/ncomms14823},
file = {:home/kaslu/Documents/Mendeley/2017 - Nogueira et al. - Lateral orbitofrontal cortex anticipates choices and integrates prior with current information.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
month = {mar},
pages = {14823},
pmid = {28337990},
title = {{Lateral orbitofrontal cortex anticipates choices and integrates prior with current information}},
url = {http://www.nature.com/doifinder/10.1038/ncomms14823},
volume = {8},
year = {2017}
}
@article{Anderson1972,
author = {Anderson, P. W.},
doi = {10.1126/science.177.4047.393},
file = {:home/kaslu/Documents/Mendeley/1972 - Anderson - More Is Different.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {aug},
number = {4047},
pages = {393--396},
title = {{More Is Different}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.177.4047.393},
volume = {177},
year = {1972}
}
@article{Holroyd2002,
abstract = {The authors present a unified account of 2 neural systems concerned with the development and expression of adaptive behaviors: a mesencephalic dopamine system for reinforcement learning and a "generic" error-processing system associated with the anterior cingulate cortex. The existence of the error-processing system has been inferred from the error-related negativity (ERN), a component of the event-related brain potential elicited when human participants commit errors in reaction-time tasks. The authors propose that the ERN is generated when a negative reinforcement learning signal is conveyed to the anterior cingulate cortex via the mesencephalic dopamine system and that this signal is used by the anterior cingulate cortex to modify performance on the task at hand. They provide support for this proposal using both computational modeling and psychophysiological experimentation.},
author = {Holroyd, C B and Coles, M G H},
doi = {10.1037//0033-295X.109.4.679},
file = {:home/kaslu/Documents/Mendeley/2002 - Holroyd, Coles - The Neural Basis of Human Error Processing Reinforcement Learning, Dopamine, and the Error-Related Negativity.pdf:pdf},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological Review},
number = {4},
pages = {679--709},
pmid = {12374324},
title = {{The Neural Basis of Human Error Processing: Reinforcement Learning, Dopamine, and the Error-Related Negativity}},
url = {http://www.sciencedirect.com/science/article/pii/S0033295X02005704},
volume = {109},
year = {2002}
}
@article{Vanslette2017,
abstract = {The problem of measurement in quantum mechanics is studied within the Entropic Dynamics framework. We discuss von Neumann and Weak measurements, wavefunction collapse, and Weak Values as examples of bayesian and entropic inference.},
archivePrefix = {arXiv},
arxivId = {1701.00781},
author = {Vanslette, Kevin and Caticha, Ariel},
eprint = {1701.00781},
file = {:home/kaslu/Documents/Mendeley/2017 - Vanslette, Caticha - Quantum Measurement and Weak Values in Entropic Dynamics.pdf:pdf},
month = {jan},
title = {{Quantum Measurement and Weak Values in Entropic Dynamics}},
url = {http://arxiv.org/abs/1701.00781},
year = {2017}
}
@article{Knuth2004,
abstract = {The effect of Richard T. Cox's contribution to probability theory was to generalize Boolean implication among logical statements to degrees of implication, which are manipulated using rules derived from consistency with Boolean algebra. These rules are known as the sum rule, the product rule and Bayes' Theorem, and the measure resulting from this generalization is probability. In this paper, I will describe how Cox's technique can be further generalized to include other algebras and hence other problems in science and mathematics. The result is a methodology that can be used to generalize an algebra to a calculus by relying on consistency with order theory to derive the laws of the calculus. My goals are to clear up the mysteries as to why the same basic structure found in probability theory appears in other contexts, to better understand the foundations of probability theory, and to extend these ideas to other areas by developing new mathematics and new physics. The relevance of this methodology will be demonstrated using examples from probability theory, number theory, geometry, information theory, and quantum mechanics.},
archivePrefix = {arXiv},
arxivId = {physics/0403031},
author = {Knuth, Kevin H.},
doi = {10.1063/1.1751368},
eprint = {0403031},
file = {:home/kaslu/Documents/Mendeley/2004 - Knuth - Deriving laws from ordering relations.pdf:pdf},
issn = {0094243X},
journal = {AIP Conference Proceedings},
month = {mar},
pages = {204--235},
primaryClass = {physics},
publisher = {AIP},
title = {{Deriving laws from ordering relations}},
url = {http://arxiv.org/abs/physics/0403031 http://dx.doi.org/10.1063/1.1751368 http://scitation.aip.org/content/aip/proceeding/aipcp/10.1063/1.1751368},
volume = {707},
year = {2004}
}
@article{Bohorquez2009,
abstract = {Many collective human activities, including violence, have been shown to exhibit universal patterns. The size distributions of casualties both in whole wars from 1816 to 1980 and terrorist attacks have separately been shown to follow approximate power-law distributions. However, the possibility of universal patterns ranging across wars in the size distribution or timing of within-conflict events has barely been explored. Here we show that the sizes and timing of violent events within different insurgent conflicts exhibit remarkable similarities. We propose a unified model of human insurgency that reproduces these commonalities, and explains conflict-specific variations quantitatively in terms of underlying rules of engagement. Our model treats each insurgent population as an ecology of dynamically evolving, self-organized groups following common decision-making processes. Our model is consistent with several recent hypotheses about modern insurgency, is robust to many generalizations, and establishes a quantitative connection between human insurgency, global terrorism and ecology. Its similarity to financial market models provides a surprising link between violent and non-violent forms of human behaviour.},
author = {Bohorquez, Juan Camilo and Gourley, Sean and Dixon, Alexander R and Spagat, Michael and Johnson, Neil F},
doi = {10.1038/nature08631},
file = {:home/kaslu/Documents/Mendeley/2009 - Bohorquez et al. - Common ecology quantifies human insurgency.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Afghanistan,Colombia,Conflict (Psychology),Decision Making,Ecology,Economic,Group Processes,Humans,Iraq,Models,Terrorism,Time Factors,Violence,War},
month = {dec},
number = {7275},
pages = {911--4},
pmid = {20016600},
publisher = {Macmillan Publishers Limited. All rights reserved},
shorttitle = {Nature},
title = {{Common ecology quantifies human insurgency.}},
url = {http://dx.doi.org/10.1038/nature08631},
volume = {462},
year = {2009}
}
@article{Dunlop2009,
abstract = {We present eco-genetic modeling as a flexible tool for exploring the course and rates of multi-trait life-history evolution in natural populations. We build on existing modeling approaches by combining features that facilitate studying the ecological and evolutionary dynamics of realistically structured populations. In particular, the joint consideration of age and size structure enables the analysis of phenotypically plastic populations with more than a single growth trajectory, and ecological feedback is readily included in the form of density dependence and frequency dependence. Stochasticity and life-history trade-offs can also be implemented. Critically, eco-genetic models permit the incorporation of salient genetic detail such as a population's genetic variances and covariances and the corresponding heritabilities, as well as the probabilistic inheritance and phenotypic expression of quantitative traits. These inclusions are crucial for predicting rates of evolutionary change on both contemporary and longer timescales. An eco-genetic model can be tightly coupled with empirical data and therefore may have considerable practical relevance, in terms of generating testable predictions and evaluating alternative management measures. To illustrate the utility of these models, we present as an example an eco-genetic model used to study harvest-induced evolution of multiple traits in Atlantic cod. The predictions of our model (most notably that harvesting induces a genetic reduction in age and size at maturation, an increase or decrease in growth capacity depending on the minimum-length limit, and an increase in reproductive investment) are corroborated by patterns observed in wild populations. The predicted genetic changes occur together with plastic changes that could phenotypically mask the former. Importantly, our analysis predicts that evolutionary changes show little signs of reversal following a harvest moratorium. This illustrates how predictions offered by eco-genetic models can enable and guide evolutionarily sustainable resource management.},
author = {Dunlop, Erin S. and Heino, Mikko and Dieckmann, Ulf L F},
doi = {10.1890/08-1404.1},
file = {:home/kaslu/Documents/Mendeley/2009 - Dunlop, Heino, Dieckmann - Eco-genetic modeling of contemporary life-history evolution.pdf:pdf},
isbn = {1051-0761},
issn = {10510761},
journal = {Ecological Applications},
keywords = {Atlantic cod,Density-dependent growth,Eco-evolutionary dynamics,Evolution,Fisheries-induced evolution,Fishing-induced adaptive change,Gadus morhua,Harvest,Phenotypic plasticity,Probabilistic maturation reaction norm,Quantitative genetics,Reproductive investment,life-history theory},
month = {oct},
number = {7},
pages = {1815--1834},
pmid = {19831072},
title = {{Eco-genetic modeling of contemporary life-history evolution}},
url = {http://doi.wiley.com/10.1890/08-1404.1},
volume = {19},
year = {2009}
}
@article{Powers2017,
abstract = {Some people hear voices that others do not, but only some of those people seek treatment. Using a Pavlovian learning task, we induced conditioned hallucinations in four groups of people who differed orthogonally in their voice-hearing and treatment-seeking statuses. People who hear voices were significantly more susceptible to the effect. Using functional neuroimaging and computational modeling of perception, we identified processes that differentiated voice-hearers from non–voice-hearers and treatment- seekers from non–treatment-seekers and characterized a brain circuit that mediated the conditioned hallucinations. These data demonstrate the profound and sometimes pathological impact of top-down cognitive processes on perception and may represent an objective means to discern people with a need for treatment from those without.},
author = {Powers, A. R. and Mathys, C. and Corlett, P. R.},
doi = {10.1126/science.aan3458},
file = {:home/kaslu/Documents/Mendeley/2017 - Powers, Mathys, Corlett - Pavlovian conditioning–induced hallucinations result from overweighting of perceptual priors.pdf:pdf},
isbn = {1095-9203 (Electronic) 0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science},
month = {aug},
number = {6351},
pages = {596--600},
pmid = {28798131},
title = {{Pavlovian conditioning–induced hallucinations result from overweighting of perceptual priors}},
url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aan3458},
volume = {357},
year = {2017}
}
@article{Schultz1998,
abstract = {The effects of lesions, receptor blocking, electrical self-stimulation, and drugs of abuse suggest that midbrain dopamine systems are involved in processing reward information and learning approach behavior. Most dopamine neurons show phasic activations after primary liquid and food rewards and conditioned, reward-predicting visual and auditory stimuli. They show biphasic, activation-depression responses after stimuli that resemble reward-predicting stimuli or are novel or particularly salient. However, only few phasic activations follow aversive stimuli. Thus dopamine neurons label environmental stimuli with appetitive value, predict and detect rewards and signal alerting and motivating events. By failing to discriminate between different rewards, dopamine neurons appear to emit an alerting message about the surprising presence or absence of rewards. All responses to rewards and reward-predicting stimuli depend on event predictability. Dopamine neurons are activated by rewarding events that are better than predicted, remain uninfluenced by events that are as good as predicted, and are depressed by events that are worse than predicted. By signaling rewards according to a prediction error, dopamine responses have the formal characteristics of a teaching signal postulated by reinforcement learning theories. Dopamine responses transfer during learning from primary rewards to reward-predicting stimuli. This may contribute to neuronal mechanisms underlying the retrograde action of rewards, one of the main puzzles in reinforcement learning. The impulse response releases a short pulse of dopamine onto many dendrites, thus broadcasting a rather global reinforcement signal to postsynaptic neurons. This signal may improve approach behavior by providing advance reward information before the behavior occurs, and may contribute to learning by modifying synaptic transmission. The dopamine reward signal is supplemented by activity in neurons in striatum, frontal cortex, and amygdala, which process specific reward information but do not emit a global reward prediction error signal. A cooperation between the different reward signals may assure the use of specific rewards for selectively reinforcing behaviors. Among the other projection systems, noradrenaline neurons predominantly serve attentional mechanisms and nucleus basalis neurons code rewards heterogeneously. Cerebellar climbing fibers signal errors in motor performance or errors in the prediction of aversive events to cerebellar Purkinje cells. Most deficits following dopamine-depleting lesions are not easily explained by a defective reward signal but may reflect the absence of a general enabling function of tonic levels of extracellular dopamine. Thus dopamine systems may have two functions, the phasic transmission of reward information and the tonic enabling of postsynaptic neurons.},
author = {Schultz, Wolfram},
file = {:home/kaslu/Documents/Mendeley/1998 - Schultz - Predictive reward signal of dopamine neurons.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
month = {jul},
number = {1},
pages = {1--27},
pmid = {9658025},
title = {{Predictive reward signal of dopamine neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9658025},
volume = {80},
year = {1998}
}
@article{Donnarumma2017,
abstract = {We present a novel computational model that describes action perception as an active inferential process that combines motor prediction (the reuse of our own motor system to predict perceived movements) and hypothesis testing (the use of eye movements to disambiguate amongst hypotheses). The system uses a generative model of how (arm and hand) actions are performed to generate hypothesis-specific visual predictions, and directs saccades to the most informative places of the visual scene to test these predictions – and underlying hypotheses. We test the model using eye movement data from a human action observation study. In both the human study and our model, saccades are proactive whenever context affords accurate action prediction; but uncertainty induces a more reactive gaze strategy, via tracking the observed movements. Our model offers a novel perspective on action observation that highlights its active nature based on prediction dynamics and hypothesis testing.},
author = {Donnarumma, Francesco and Costantini, Marcello and Ambrosini, Ettore and Friston, Karl and Pezzulo, Giovanni},
doi = {10.1016/j.cortex.2017.01.016},
file = {:home/kaslu/Documents/Mendeley/2017 - Donnarumma et al. - Action perception as hypothesis testing.pdf:pdf},
isbn = {3908122031},
issn = {00109452},
journal = {Cortex},
month = {apr},
pages = {45--60},
title = {{Action perception as hypothesis testing}},
url = {http://www.sciencedirect.com/science/article/pii/S0010945217300308 http://linkinghub.elsevier.com/retrieve/pii/S0010945217300308},
volume = {89},
year = {2017}
}
@article{Attanasi2014,
abstract = {Collective behaviour in biological systems is often accompanied by strong correlations. The question has therefore arisen of whether correlation is amplified by the vicinity to some critical point in the parameters space. Biological systems, though, are typically quite far from the thermodynamic limit, so that the value of the control parameter at which correlation and susceptibility peak depend on size. Hence, a system would need to readjust its control parameter according to its size in order to be maximally correlated. This readjustment, though, has never been observed experimentally. By gathering three-dimensional data on swarms of midges in the field we find that swarms tune their control parameter and size so as to maintain a scaling behaviour of the correlation function. As a consequence, correlation length and susceptibility scale with the system's size and swarms exhibit a near-maximal degree of correlation at all sizes.},
archivePrefix = {arXiv},
arxivId = {1412.6975},
author = {Attanasi, Alessandro and Cavagna, Andrea and {Del Castello}, Lorenzo and Giardina, Irene and Melillo, Stefania and Parisi, Leonardo and Pohl, Oliver and Rossaro, Bruno and Shen, Edward and Silvestri, Edmondo and Viale, Massimiliano},
doi = {10.1103/PhysRevLett.113.238102},
eprint = {1412.6975},
file = {:home/kaslu/Documents/Mendeley/2014 - Attanasi et al. - Finite-Size Scaling as a Way to Probe Near-Criticality in Natural Swarms.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {dec},
number = {23},
pages = {238102},
pmid = {25526161},
title = {{Finite-Size Scaling as a Way to Probe Near-Criticality in Natural Swarms}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.113.238102},
volume = {113},
year = {2014}
}
@article{Lake2016,
abstract = {Both scientists and children make important structural discoveries, yet their computational underpinnings are not well understood. Structure discovery has previously been formalized as probabilistic inference about the right structural form --- where form could be a tree, ring, chain, grid, etc. [Kemp {\&} Tenenbaum (2008). The discovery of structural form. PNAS, 105(3), 10687-10692]. While this approach can learn intuitive organizations, including a tree for animals and a ring for the color circle, it assumes a strong inductive bias that considers only these particular forms, and each form is explicitly provided as initial knowledge. Here we introduce a new computational model of how organizing structure can be discovered, utilizing a broad hypothesis space with a preference for sparse connectivity. Given that the inductive bias is more general, the model's initial knowledge shows little qualitative resemblance to some of the discoveries it supports. As a consequence, the model can also learn complex structures for domains that lack intuitive description, as well as predict human property induction judgments without explicit structural forms. By allowing form to emerge from sparsity, our approach clarifies how both the richness and flexibility of human conceptual organization can coexist.},
archivePrefix = {arXiv},
arxivId = {1611.09384},
author = {Lake, Brenden M. and Lawrence, Neil D. and Tenenbaum, Joshua B.},
eprint = {1611.09384},
file = {:home/kaslu/Documents/Mendeley/2016 - Lake, Lawrence, Tenenbaum - The Emergence of Organizing Structure in Conceptual Representation.pdf:pdf},
month = {nov},
pages = {1--36},
title = {{The Emergence of Organizing Structure in Conceptual Representation}},
url = {http://arxiv.org/abs/1611.09384},
year = {2016}
}
@article{Miyagawa2013,
abstract = {We propose a novel account for the emergence of human language syntax. Like many evolutionary innovations, language arose from the adventitious combination of two pre-existing, simpler systems that had been evolved for other functional tasks. The first system, Type E(xpression), is found in birdsong, where it marks territory, mating availability, and similar ‘expressive' functions. The second system, Type L(exical), has been suggestively found in non-human primate calls and in honeybee waggle dances, where it demarcates predicates with one or more ‘arguments,' such as combinations of calls in monkeys or compass headings set to sun position in honeybees. We show that human language syntax is composed of two layers that parallel these two independently evolved systems: an “E” layer resembling the Type E system of birdsong and an “L” layer providing words. The existence of the “E” and “L” layers can be confirmed using standard linguistic methodology. Each layer, E and L, when considered separately, are characterizable as finite state systems, as observed in several non-human species. When the two systems are put together they interact, yielding the unbounded, non-finite state, hierarchical structure that serves as the hallmark of ful},
author = {Miyagawa, Shigeru and Berwick, Robert C. and Okanoya, Kazuo},
doi = {10.3389/fpsyg.2013.00071},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Hierarchy,Honeybee,Social,birdsong,human language,monkey communication},
pages = {71},
publisher = {Frontiers},
title = {{The Emergence of Hierarchical Structure in Human Language}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00071/abstract},
volume = {4},
year = {2013}
}
@article{Gershman2015a,
abstract = {Effective reinforcement learning hinges on having an appropriate state representation. But where does this representation come from? We argue that the brain discovers state representations by trying to infer the latent causal structure of the task at hand, and assigning each latent cause to a separate state. In this paper, we review several implications of this latent cause framework, with a focus on Pavlovian conditioning. The framework suggests that conditioning is not the acquisition of associations between cues and outcomes, but rather the acquisition of associations between latent causes and observable stimuli. A latent cause interpretation of conditioning enables us to begin answering questions that have frustrated classical theories: Why do extinguished responses sometimes return? Why do stimuli presented in compound sometimes summate and sometimes do not? Beyond conditioning, the principles of latent causal inference may provide a general theory of structure learning across cognitive domains.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Gershman, Samuel J. and Norman, Kenneth A. and Niv, Yael},
doi = {10.1016/j.cobeha.2015.07.007},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2015 - Gershman, Norman, Niv - Discovering latent causes in reinforcement learning.pdf:pdf},
isbn = {23521546},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {43--50},
pmid = {26627312},
publisher = {Elsevier Ltd},
title = {{Discovering latent causes in reinforcement learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2352154615001059},
volume = {5},
year = {2015}
}
@article{Herculano-Houzel2009,
abstract = {The human brain has often been viewed as outstanding among mammalian brains: the most cognitively able, the largest-than-expected from body size, endowed with an overdeveloped cerebral cortex that represents over 80{\%} of brain mass, and purportedly containing 100 billion neurons and 10x more glial cells. Such uniqueness was seemingly necessary to justify the superior cognitive abilities of humans over larger-brained mammals such as elephants and whales. However, our recent studies using a novel method to determine the cellular composition of the brain of humans and other primates as well as of rodents and insectivores show that, since different cellular scaling rules apply to the brains within these orders, brain size can no longer be considered a proxy for the number of neurons in the brain. These studies also showed that the human brain is not exceptional in its cellular composition, as it was found to contain as many neuronal and non-neuronal cells as would be expected of a primate brain of its size. Additionally, the so-called overdeveloped human cerebral cortex holds only 19{\%} of all brain neurons, a fraction that is similar to that found in other mammals. In what regards absolute numbers of neurons, however, the human brain does have two advantages compared to other mammalian brains: compared to rodents, and probably to whales and elephants as well, it is built according to the very economical, space-saving scaling rules that apply to other primates; and, among economically built primate brains, it is the largest, hence containing the most neurons. These findings argue in favor of a view of cognitive abilities that is centered on absolute numbers of neurons, rather than on body size or encephalization, and call for a re-examination of several concepts related to the exceptionality of the human brain.},
author = {Herculano-Houzel, Suzana},
doi = {10.3389/neuro.09.031.2009},
file = {:home/kaslu/Documents/Mendeley/2009 - Herculano-Houzel - The human brain in numbers a linearly scaled-up primate brain.pdf:pdf},
isbn = {1662-5161 (Electronic)$\backslash$n1662-5161 (Linking)},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {brain scaling,encephalization,human,number of neurons},
number = {November},
pages = {31},
pmid = {19915731},
title = {{The human brain in numbers: a linearly scaled-up primate brain.}},
url = {http://journal.frontiersin.org/article/10.3389/neuro.09.031.2009/full},
volume = {3},
year = {2009}
}
@article{Zink2008,
abstract = {Social hierarchies guide behavior in many species, including humans, where status also has an enormous impact on motivation and health. However, little is known about the underlying neural representation of social hierarchies in humans. In the present study, we identify dissociable neural responses to perceived social rank using functional magnetic resonance imaging (fMRI) in an interactive, simulated social context. In both stable and unstable social hierarchies, viewing a superior individual differentially engaged perceptual-attentional, saliency, and cognitive systems, notably dorsolateral prefrontal cortex. In the unstable hierarchy setting, additional regions related to emotional processing (amygdala), social cognition (medial prefrontal cortex), and behavioral readiness were recruited. Furthermore, social hierarchical consequences of performance??were neurally dissociable and of comparable salience to monetary reward, providing a neural basis for the high motivational value of status. Our results identify neural mechanisms that may mediate the enormous influence of social status on human behavior and health. ?? 2008 Elsevier Inc. All rights reserved.},
author = {Zink, Caroline F. and Tong, Yunxia and Chen, Qiang and Bassett, Danielle S. and Stein, Jason L. and Meyer-Lindenberg, Andreas},
doi = {10.1016/j.neuron.2008.01.025},
file = {:home/kaslu/Documents/Mendeley/2008 - Zink et al. - Know Your Place Neural Processing of Social Hierarchy in Humans.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$n0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
month = {apr},
number = {2},
pages = {273--283},
pmid = {18439411},
title = {{Know Your Place: Neural Processing of Social Hierarchy in Humans}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627308001128},
volume = {58},
year = {2008}
}
@article{Wilson2014,
abstract = {Orbitofrontal cortex (OFC) has long been known to play an important role in decision making. However, the exact nature of that role has remained elusive. Here, we propose a unifying theory of OFC function. We hypothesize that OFC provides an abstraction of currently available information in the form of a labeling of the current task state, which is used for reinforcement learning (RL) elsewhere in the brain. This function is especially critical when task states include unobservable information, for instance, from working memory. We use this framework to explain classic findings in reversal learning, delayed alternation, extinction, and devaluation as well as more recent findings showing the effect of OFC lesions on the firing of dopaminergic neurons in ventral tegmental area (VTA) in rodents performing an RL task. In addition, we generate a number of testable experimental predictions that can distinguish our theory from other accounts of OFC function. ?? 2014 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Wilson, Robert C. and Takahashi, Yuji K. and Schoenbaum, Geoffrey and Niv, Yael},
doi = {10.1016/j.neuron.2013.11.005},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2014 - Wilson et al. - Orbitofrontal cortex as a cognitive map of task space.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {2},
pages = {267--278},
pmid = {24462094},
publisher = {Elsevier Inc.},
title = {{Orbitofrontal cortex as a cognitive map of task space}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.11.005},
volume = {81},
year = {2014}
}
@article{Yuste2015,
abstract = {For over a century, the neuron doctrine--which states that the neuron is the structural and functional unit of the nervous system--has provided a conceptual foundation for neuroscience. This viewpoint reflects its origins in a time when the use of single-neuron anatomical and physiological techniques was prominent. However, newer multineuronal recording methods have revealed that ensembles of neurons, rather than individual cells, can form physiological units and generate emergent functional properties and states. As a new paradigm for neuroscience, neural network models have the potential to incorporate knowledge acquired with single-neuron approaches to help us understand how emergent functional states generate behaviour, cognition and mental disease.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.05133v2},
author = {Yuste, Rafael},
doi = {10.1038/nrn3962},
eprint = {arXiv:1508.05133v2},
file = {:home/kaslu/Documents/Mendeley/2015 - Yuste - From the neuron doctrine to neural networks.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
number = {8},
pages = {487--97},
pmid = {26152865},
publisher = {Nature Publishing Group},
title = {{From the neuron doctrine to neural networks.}},
url = {http://www.nature.com/doifinder/10.1038/nrn3962{\%}5Cnhttp://dx.doi.org/10.1038/nrn3962{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26152865},
volume = {16},
year = {2015}
}
@article{Peterson1987,
abstract = {Based on t he Boltzmann Mac hine concept, we derive a lear ning algorith m in which time-consumi ng stochastic meas urements of correlations a re replaced by solutions to dete rminist ic mean field theory equ ations. T he method is applied to t he XOR (ex clusive-or), encoder, and line sym metry problem s wit h substanti al success. We observe speedup facto rs ranging from 10 to 30 for these ap plicat ions a nd a significan tly bet ter learning perform an ce in general. 1. Motivation and results 1.1 Background Neural Network models are present ly subject to int ense st ud ies [1,2,7,10]. Most attent ion is being paid to pattern complet ion pro blems . Net work arc hi-tect ures and learning algorit hms are here the dominat ing t hemes . Common ingredi ents of all models a re a set of bina ry valu ed neu ro ns S, = ±1 wh ich are int ercon nect ed wit h synaptic strengths Tij, whe re T ij rep resents t he st rength of the connection between th e outp ut of t he i t h neuron and t he inp ut of t he p hneuron and T i j = O. In ty pical app lications, a subset of t he neur ons are design ated as inputs a nd t he remainder are used to indicat e t he outpu t. By clampi ng t he neurons to certain pattern s, 5, = Sf' , the sy napt ic st re ngt hs adapt acco rding to different lear ning algorit hms . For patterns with first-order internal constraints, on e has the Hebb ru le [4], whe re for each pa t-tern a the sy napses are mo dified according to sr; ()((S,Sj) (1.1) whe re 0 denotes a time average. In the case in which one has higher-order cons traints, as in parity pat -terns, the situation is mor e complicated . Ex tra, so-called hidden units are t hen needed to ca pture or to build a n inter nal represent a t ion of the pat-tern . In t his case, equa t ion (1.1) is not ade quate; for t he different patterns, @ 1987 Complex Syste ms Pub licat ions, Inc. 996 Carsten Peterson and James R . Anderson t he hidden uni ts have no par tic ular values. For this reason , more elaborate lea rning algo rithms have been develop ed. Most popular and powerful are t he Back-propagation Scheme [10) and th e Bolt zm ann Mac1Jjne (BM) [IJ. T he latter determines Tjj for a given set of patter ns by a global sea rch over a large solut ion space. Wit h its sim ula ted annealing [8] relaxation t echn ique, BM is particularly well suite d for avoiding local minima. T his feature, on t he other hand, makes BM t ime consuming; Dot only does the stochast ic annealing a lgor ithm involve meas ur ement s at many successive t emperatures, but th e meas ur ement s t hemselves require many sweeps. Development s or approximat ions that would speed up t his algorit hm ar e in deman d.},
author = {Peterson, C and Anderson, J R},
file = {:home/kaslu/Documents/Mendeley/1987 - Peterson, Anderson - A Mean Field Theory Learning Algorithm for Neural Networks.pdf:pdf},
journal = {Complex Systems},
number = {5},
pages = {995--1019},
title = {{A Mean Field Theory Learning Algorithm for Neural Networks}},
volume = {1},
year = {1987}
}
@article{Strouse2016,
abstract = {Lossy compression and clustering fundamentally involve a decision about what features are relevant and which are not. The information bottleneck method (IB) by Tishby, Pereira, and Bialek formalized this notion as an information-theoretic optimization problem and proposed an optimal tradeoff between throwing away as many bits as possible, and selectively keeping those that are most important. In the IB, compression is measure my mutual information. Here, we introduce an alternative formulation that replaces mutual information with entropy, which we call the deterministic information bottleneck (DIB), that we argue better captures this notion of compression. As suggested by its name, the solution to the DIB problem turns out to be a deterministic encoder, or hard clustering, as opposed to the stochastic encoder, or soft clustering, that is optimal under the IB. We compare the IB and DIB on synthetic data, showing that the IB and DIB perform similarly in terms of the IB cost function, but that the DIB significantly outperforms the IB in terms of the DIB cost function. We also empirically find that the DIB offers a considerable gain in computational efficiency over the IB, over a range of convergence parameters. Our derivation of the DIB also suggests a method for continuously interpolating between the soft clustering of the IB and the hard clustering of the DIB.},
archivePrefix = {arXiv},
arxivId = {1604.00268},
author = {Strouse, DJ and Schwab, David J.},
eprint = {1604.00268},
file = {:home/kaslu/Documents/Mendeley/2016 - Strouse, Schwab - The deterministic information bottleneck.pdf:pdf},
isbn = {9781510827806},
month = {apr},
title = {{The deterministic information bottleneck}},
url = {http://arxiv.org/abs/1604.00268},
year = {2016}
}
@article{David-Barrett2014,
abstract = {Animal (and human) societies characterized by dominance hierarchies invariably suffer from inequality. The rise of inequality has 3 main prerequisites: 1) a group in which inequality can emerge, 2) the existence of differences in payoff, and 3) a mechanism that initiates, accumulates, and propagates the differences. Hitherto, 2 kinds of models have been used to study the processes involved. In winner-loser models of inequality (typical in zoology), the 3 elements are independent. In division-of-labor models of inequality, the first 2 elements are linked, whereas the third is independent. In this article, we propose a new model, that of synchronized group action, in which all 3 elements are linked. Under these conditions, agent-based simulations of communal action in multilayered communities naturally give rise to endogenous status, emergent social stratification, and the rise of elite cliques. We show that our 3 emergent social phenomena (status, stratification, and elite formation) react to natural variations in merit (the capacity to influence others' decisions). We also show that the group-level efficiency and inequality consequences of these emergent phenomena define a space for social institutions that optimize efficiency gain in some fitness-related respect, while controlling the loss of efficiency and equality in other respects.},
author = {D{\'{a}}vid-Barrett, Tam{\'{a}}s and Dunbar, R. I M},
doi = {10.1093/beheco/art085},
isbn = {1045-2249},
issn = {10452249},
journal = {Behavioral Ecology},
keywords = {Behavioral synchrony,Division of labor,Elite formation,Social hierarchy,Social stratification},
number = {1},
pages = {58--68},
title = {{Social elites can emerge naturally when interaction in networks is restricted}},
volume = {25},
year = {2014}
}
@incollection{Tetlock1992,
author = {Tetlock, Philip E},
booktitle = {Advances in Experimental Social Psychology},
doi = {10.1016/S0065-2601(08)60287-7},
isbn = {0120152258},
issn = {00652601},
pages = {331--376},
title = {{The Impact of Accountability on Judgment and Choice: Toward A Social Contingency Model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0065260108602877},
volume = {25},
year = {1992}
}
@article{Kinzel1990,
abstract = {We show that the generalization ability of simple Perceptron-like$\backslash$ndevices is strongly enhanced by allowing the network itself to select$\backslash$nthe training examples. Analytic and numerical results are obtained$\backslash$nfor the Hebb and for the optimal Perceptron learning rule, respectively.},
author = {Kinzel, Wolfgang and Rujan, P},
doi = {10.1209/0295-5075/13/5/016},
file = {:home/kaslu/Documents/Mendeley/1990 - Kinzel, Rujan - Improving a network generalization ability by selecting examples.pdf:pdf},
issn = {12864854},
journal = {EPL (Europhysics Letters)},
number = {5},
pages = {473--477},
title = {{Improving a network generalization ability by selecting examples}},
url = {http://iopscience.iop.org/0295-5075/13/5/016},
volume = {13},
year = {1990}
}
@article{Yu2008,
abstract = {To date, the neural decoding of time-evolving physical state for example, the path of a foraging rat or arm movements - has been largely carried out using linear trajectory models, primarily due to their computational efficiency. The possibility of better capturing the statistics of the movements using nonlinear trajectory models, thereby yielding more accurate decoded trajectories, is enticing. However, nonlinear decoding usually carries a higher computational cost, which is an important consideration in real-time settings. In this paper, we present techniques for nonlinear decoding employing modal Gaussian approximations, expectatation propagation, and Gaussian quadrature. We compare their decoding accuracy versus computation time tradeoffs based on high-dimensional simulated neural spike counts.},
author = {Yu, Byron M. and Cunningham, John P. and Shenoy, Krishna V. and Sahani, Maneesh},
doi = {10.1007/978-3-540-69158-7_61},
file = {:home/kaslu/Documents/Mendeley/2008 - Yu et al. - Neural decoding of movements From linear to nonlinear trajectory models.pdf:pdf},
isbn = {3540691545},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Expectation-propagation,Gaussian quadrature,Neural decoding,Neural prosthetics,Nonlinear dynamical models,Nonlinear state estimation},
number = {PART 1},
pages = {586--595},
title = {{Neural decoding of movements: From linear to nonlinear trajectory models}},
volume = {4984 LNCS},
year = {2008}
}
@article{Watson2016,
abstract = {The theory of evolution links random variation and selection to incremental adaptation. In a different intellectual domain, learning theory links incremental adaptation (e.g., from positive and/or negative reinforcement) to intelligent behaviour. Specifically, learning theory explains how incremental adaptation can acquire knowledge from past experience and use it to direct future behaviours toward favourable outcomes. Until recently such cognitive learning seemed irrelevant to the 'uninformed' process of evolution. In our opinion, however, new results formally linking evolutionary processes to the principles of learning might provide solutions to several evolutionary puzzles - the evolution of evolvability, the evolution of ecological organisation, and evolutionary transitions in individuality. If so, the ability for evolution to learn might explain how it produces such apparently intelligent designs.},
author = {Watson, Richard A. and Szathm{\'{a}}ry, E{\"{o}}rs},
doi = {10.1016/j.tree.2015.11.009},
isbn = {0169-5347},
issn = {01695347},
journal = {Trends in Ecology {\&} Evolution},
month = {feb},
number = {2},
pages = {147--157},
pmid = {26705684},
title = {{How Can Evolution Learn?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169534715002931},
volume = {31},
year = {2016}
}
@article{Naumann2010,
abstract = {Existing techniques for monitoring neural activity in awake, freely behaving vertebrates are invasive and difficult to target to genetically identified neurons. We used bioluminescence to non-invasively monitor the activity of genetically specified neurons in freely behaving zebrafish. Transgenic fish with the Ca2+-sensitive photoprotein green fluorescent protein (GFP)-Aequorin in most neurons generated large and fast bioluminescent signals that were related to neural activity, neuroluminescence, which could be recorded continuously for many days. To test the limits of this technique, we specifically targeted GFP-Aequorin to the hypocretin-positive neurons of the hypothalamus. We found that neuroluminescence generated by this group of {\~{}}20 neurons was associated with periods of increased locomotor activity and identified two classes of neural activity corresponding to distinct swim latencies. Our neuroluminescence assay can report, with high temporal resolution and sensitivity, the activity of small subsets of neurons during unrestrained behavior.},
author = {Naumann, Eva A. and Kampff, Adam R. and Prober, David A. and Schier, Alexander F. and Engert, Florian},
doi = {10.1038/nn.2518},
file = {:home/kaslu/Documents/Mendeley/2010 - Naumann et al. - Monitoring neural activity with bioluminescence during natural behavior.pdf:pdf},
isbn = {6174954382},
issn = {10976256},
journal = {Nature Neuroscience},
number = {4},
pages = {513--520},
pmid = {20305645},
publisher = {Nature Publishing Group},
title = {{Monitoring neural activity with bioluminescence during natural behavior}},
url = {http://dx.doi.org/10.1038/nn.2518},
volume = {13},
year = {2010}
}
@article{Hyvarinen2000,
abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject. Copyright (C) 2000.},
archivePrefix = {arXiv},
arxivId = {1504.05070},
author = {Hyv{\"{a}}rinen, Aapo and Oja, Erkki},
doi = {10.1016/S0893-6080(00)00026-5},
eprint = {1504.05070},
file = {:home/kaslu/Documents/Mendeley/2000 - Hyv{\"{a}}rinen, Oja - Independent component analysis Algorithms and applications.pdf:pdf},
isbn = {3589451327},
issn = {08936080},
journal = {Neural Networks},
keywords = {Blind signal separation,Factor analysis,Independent component analysis,Projection pursuit,Representation,Source separation},
number = {4-5},
pages = {411--430},
pmid = {10946390},
title = {{Independent component analysis: Algorithms and applications}},
volume = {13},
year = {2000}
}
@article{Clauset2009,
abstract = {Power-law distributions occur in many situations of scientific interest and have significant consequences for our understanding of natural and man-made phenomena. Unfortunately, the detection and characterization of power laws is complicated by the large fluctuations that occur in the tail of the distribution—the part of the distribution representing large but rare events— and by the difficulty of identifying the range over which power-law behavior holds. Commonly used methods for analyzing power-law data, such as least-squares fitting, can produce substantially inaccurate estimates of parameters for power-law distributions, and even in cases where such methods return accurate answers they are still unsatisfactory because they give no indication of whether the data obey a power law at all. Here we present a principled statistical framework for discerning and quantifying power-law behavior in empirical data. Our approach combines maximum-likelihood fitting methods with goodness-of-fit tests based on the Kolmogorov-Smirnov statistic and likelihood ratios. We evaluate the effectiveness of the approach with tests on synthetic data and give critical comparisons to previous approaches. We also apply the proposed methods to twenty-four real-world data sets from a range of different disciplines, each of which has been conjectured to follow a power-law distribution. In some cases we find these conjectures to be consistent with the data while in others the power law is ruled out.},
author = {Virkar, Yogesh and Clauset, Aaron},
doi = {10.1214/13-AOAS710},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {()},
month = {mar},
number = {1},
pages = {89--119},
title = {{Power-law distributions in binned empirical data}},
url = {http://projecteuclid.org/euclid.aoas/1396966280},
volume = {8},
year = {2014}
}
@article{Gershman2015b,
abstract = {Two important ideas about associative learning have emerged in recent decades: (1) Animals are Bayesian learners, tracking their uncertainty about associations; and (2) animals acquire long-term reward predictions through reinforcement learning. Both of these ideas are normative, in the sense that they are derived from rational design principles. They are also descriptive, capturing a wide range of empirical phenomena that troubled earlier theories. This article describes a unifying framework encompassing Bayesian and reinforcement learning theories of associative learning. Each perspective captures a different aspect of associative learning, and their synthesis offers insight into phenomena that neither perspective can explain on its own.},
author = {Gershman, Samuel J.},
doi = {10.1371/journal.pcbi.1004567},
file = {:home/kaslu/Documents/Mendeley/2015 - Gershman - A Unifying Probabilistic View of Associative Learning.PDF:PDF},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {11},
pages = {1--20},
pmid = {26535896},
title = {{A Unifying Probabilistic View of Associative Learning}},
volume = {11},
year = {2015}
}
@article{Pouget2013,
abstract = {There is strong behavioral and physiological evidence that the brain both represents probability distributions and performs probabilistic inference. Computational neuroscientists have started to shed light on how these probabilistic representations and computations might be implemented in neural circuits. One particularly appealing aspect of these theories is their generality: they can be used to model a wide range of tasks, from sensory processing to high-level cognition. To date, however, these theories have only been applied to very simple tasks. Here we discuss the challenges that will emerge as researchers start focusing their efforts on real-life computations, with a focus on probabilistic learning, structural learning and approximate inference.},
author = {Pouget, Alexandre and Beck, Jeffrey M. and Ma, Wei Ji and Latham, Peter E.},
doi = {10.1038/nn.3495},
file = {:home/kaslu/Documents/Mendeley/2013 - Pouget et al. - Probabilistic brains knowns and unknowns.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Brain,Brain: cytology,Brain: physiology,Humans,Learning,Models,Neurological,Neurons,Neurons: physiology,Perception,Probability,Sensation},
month = {aug},
number = {9},
pages = {1170--1178},
title = {{Probabilistic brains: knowns and unknowns}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23955561 http://www.nature.com/doifinder/10.1038/nn.3495},
volume = {16},
year = {2013}
}
@article{Sutherland2017,
abstract = {We propose a fast method with statistical guarantees for learning an exponential family density model where the natural parameter is in a reproducing kernel Hilbert space, and may be infinite-dimensional. The model is learned by fitting the derivative of the log density, the score, thus avoiding the need to compute a normalization constant. Our approach improves the computational efficiency of an earlier solution by using a low-rank, Nystr$\backslash$"om-like solution. The new solution retains the consistency and convergence rates of the full-rank solution (exactly in Fisher distance, and nearly in other distances), with guarantees on the degree of cost and storage reduction. We evaluate the method in experiments on density estimation and in the construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an existing score learning approach using a denoising autoencoder, our estimator is empirically more data-efficient when estimating the score, runs faster, and has fewer parameters (which can be tuned in a principled and interpretable way), in addition to providing statistical guarantees.},
archivePrefix = {arXiv},
arxivId = {1705.08360},
author = {Sutherland, Dougal J. and Strathmann, Heiko and Arbel, Michael and Gretton, Arthur},
eprint = {1705.08360},
file = {:home/kaslu/Documents/Mendeley/2017 - Sutherland et al. - Efficient and principled score estimation with Nystrom kernel exponential families.pdf:pdf},
month = {may},
number = {Brown 1986},
title = {{Efficient and principled score estimation with Nystr$\backslash$"om kernel exponential families}},
url = {http://arxiv.org/abs/1705.08360},
year = {2017}
}
@article{DoyeonKim2017,
abstract = {Much of what we know about how the brain forms decisions comes from studies of saccadic eye movements. However, saccadic decisions are often studied in isolation, which limits the insights that they can provide about real-world decisions with complex interdependencies. Here, we used a serial reaction time (RT) task to show that prior expectations affect RTs via interdependent, normative decision processes that operate within and across saccades. We found that human subjects performing the task generated saccades that were governed by a rise-to-threshold decision process with a starting point that reflected expected state-dependent transition probabilities. These probabilities depended on decisions about the current state (the correct target) that, under some conditions, required the accumulation of information across saccades. Without additional feedback, this information was provided by each saccadic decision threshold, which represented the total evidence in favor of the chosen target. Therefore, the output of the within-saccade process was used, not only to generate the saccade, but also to provide input to the across-saccade process. This across-saccade process, in turn, helped to set the starting point of the next within-saccade process. These results imply a novel role for functional information-processing loops in optimizing saccade generation in dynamic environments.SIGNIFICANCE STATEMENT Saccades are the rapid, ballistic eye movements that we make approximately three times every second to scan the visual scene for interesting things to look at. The apparent ease with which we produce saccades belies their computational sophistication, which can be studied quantitatively in the laboratory to provide insights into how our brain manages the interplay between sensory input and motor output. The present work is important because we show for the first time how this interplay operates both within and across saccades to ensure that these eye movements are guided effectively by learned expectations in dynamic environments. More generally, this study shows how sensory-motor decision processes, typically studied in isolation, interact via functional information-processing loops in the brain to produce complex, adaptive behaviors.},
author = {{Doyeon Kim}, Timothy and Kabir, Mohammad and Gold, Joshua I.},
doi = {10.1523/JNEUROSCI.3078-16.2017},
file = {:home/kaslu/Documents/Mendeley/2017 - Doyeon Kim, Kabir, Gold - Coupled decision processes update and maintain saccadic priors in a dynamic environment.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
keywords = {at,ballistic eye movements that,belies their computational sophistication,decision-making,eye movement,for,interesting things to look,response times,saccade,saccades are the rapid,scan the visual scene,significance statement,the apparent ease with,times every second to,we make approximately three,which,which we produce saccades},
number = {13},
pages = {3078--16},
pmid = {28242793},
title = {{Coupled decision processes update and maintain saccadic priors in a dynamic environment}},
url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3078-16.2017},
volume = {37},
year = {2017}
}
@article{Kording2004a,
abstract = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities-the prior-with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
author = {K{\"{o}}rding, Konrad P. and Wolpert, Daniel M.},
doi = {10.1038/nature02169},
file = {:home/kaslu/Documents/Mendeley/2004 - K{\"{o}}rding, Wolpert - Bayesian integration in sensorimotor learning.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {6971},
pages = {244--247},
pmid = {14724638},
title = {{Bayesian integration in sensorimotor learning}},
url = {http://www.nature.com/doifinder/10.1038/nature02169},
volume = {427},
year = {2004}
}
@article{Mattar2017,
abstract = {To make decisions, animals must evaluate outcomes of candidate choices by accessing memories of relevant experiences. Recent theories suggest that phenomena of habits and compulsion can be reinterpreted as selectively omitting such computations. Yet little is known about the more granular question of which specific experiences are considered or ignored during deliberation, which ultimately governs decisions. Here, we propose a normative theory to predict not just whether but which memories should be accessed at each time to enable the most rewarding future decisions. Using nonlocal "replay" of spatial locations in hippocampus as a window into memory access, we simulate a spatial navigation task where an agent accesses memories of locations sequentially, in order of the expected utility of the computation: how much more reward would be earned due to better choices. We show that our theory offers a unifying account of a large range of hitherto disconnected findings in the place cell literature such as the balance of forward and reverse replay, biases in the replayed content, and effects of experience. We suggest that the various types of nonlocal events during behavior and rest reflect different instances of a single choice evaluation operation, unifying seemingly disparate proposed functions of replay including planning, learning and consolidation, and whose dysfunction may explain issues like rumination and craving.},
author = {Mattar, Marcelo Gomes and Daw, Nathaniel D},
doi = {10.1101/225664},
file = {:home/kaslu/Documents/Mendeley/2017 - Mattar, Daw - Prioritized memory access explains planning and hippocampal replay.pdf:pdf},
journal = {bioRxiv},
pages = {225664},
title = {{Prioritized memory access explains planning and hippocampal replay}},
url = {https://www.biorxiv.org/content/early/2017/11/27/225664},
year = {2017}
}
@article{Harris2015,
abstract = {Similarities in neocortical circuit organization across areas and species suggest a common strategy to process diverse types of information, including sensation from diverse modalities, motor control and higher cognitive processes. Cortical neurons belong to a small number of main classes. The properties of these classes, including their local and long-range connectivity, developmental history, gene expression, intrinsic physiology and in vivo activity patterns, are remarkably similar across areas. Each class contains subclasses; for a rapidly growing number of these, conserved patterns of input and output connections are also becoming evident. The ensemble of circuit connections constitutes a basic circuit pattern that appears to be repeated across neocortical areas, with area- and species-specific modifications. Such 'serially homologous' organization may adapt individual neocortical regions to the type of information each must process.},
author = {Harris, Kenneth D. and Shepherd, Gordon M G},
doi = {10.1038/nn.3917},
file = {:home/kaslu/Documents/Mendeley/2015 - Harris, Shepherd - The neocortical circuit themes and variations.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {2},
pages = {170--181},
pmid = {25622573},
title = {{The neocortical circuit: themes and variations}},
url = {http://www.nature.com/articles/nn.3917},
volume = {18},
year = {2015}
}
@article{Axelrod1997,
abstract = {Despite tendencies toward convergence, differences between individuals and groups continue to exist in beliefs, attitudes, and behavior. An agent-based adaptive model reveals the effects of a mechanism of convergent social influence. The actors are placed at fixed sites. The basic premise is that the more similar an actor is to a neighbor, the more likely that that actor will adopt one of the neighbor's traits. Unlike previous models of social influence or cultural change that treat features one at a time, the proposed model takes into account the interaction between different features. The model illustrates how local convergence can generate global polarization. Simulations show that the number of stable homogeneous regions decreases with the number of features, increases with the number of alternative traits per feature, decreases with the range of interaction, and (most surprisingly) decreases when the geographic territory grows beyond a certain size.},
archivePrefix = {arXiv},
arxivId = {0803973233},
author = {Axelrod, Robert},
doi = {10.1177/0022002797041002001},
eprint = {0803973233},
file = {:home/kaslu/Documents/Mendeley/1997 - Axelrod - The Dissemination of Culture.pdf:pdf},
isbn = {00220027},
issn = {00220027},
journal = {The Journal of Conflict Resolution},
number = {2},
pages = {203--226},
pmid = {803973233},
title = {{The Dissemination of Culture}},
url = {http://www.jstor.org/stable/174371},
volume = {41},
year = {1997}
}
@article{Garibotti2009,
abstract = {Choosing good problems is essential for being a good scientist. But what is a good problem, and how do you choose one? The subject is not usually discussed explicitly within our profession. Scientists are expected to be smart enough to figure it out on their own and through the observation of their teachers. This lack of explicit discussion leaves a vacuum that can lead to approaches such as choosing problems that can give results that merit publication in valued journals, resulting in a job and tenure.},
author = {Alon, Uri},
doi = {10.1016/j.molcel.2009.09.013},
file = {:home/kaslu/Documents/Mendeley/2009 - Alon - How To Choose a Good Scientific Problem.pdf:pdf},
issn = {10972765},
journal = {Molecular Cell},
keywords = {Argentina,Lagoons,Physical-chemical parameters,Zooplankton},
month = {sep},
number = {6},
pages = {726--728},
publisher = {Elsevier Inc.},
title = {{How To Choose a Good Scientific Problem}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1097276509006418},
volume = {35},
year = {2009}
}
@article{Louie2013,
abstract = {Understanding the neural code is critical to linking brain and behavior. In sensory systems, divisive normalization seems to be a canonical neural computation, observed in areas ranging from retina to cortex and mediating processes including contrast adaptation, surround suppression, visual attention, and multisensory integration. Recent electrophysiological studies have extended these insights beyond the sensory domain, demonstrating an analogous algorithm for the value signals that guide decision making, but the effects of normalization on choice behavior are unknown. Here, we show that choice models using normalization generate significant (and classically irrational) choice phenomena driven by either the value or number of alternative options. In value-guided choice experiments, both monkey and human choosers show novel context-dependent behavior consistent with normalization. These findings suggest that the neural mechanism of value coding critically influences stochastic choice behavior and provide a generalizable quantitative framework for examining context effects in decision making.},
author = {Louie, K. and Khaw, M. W. and Glimcher, P. W.},
doi = {10.1073/pnas.1217854110},
file = {:home/kaslu/Documents/Mendeley/2013 - Louie, Khaw, Glimcher - Normalization is a general neural mechanism for context-dependent decision making.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {apr},
number = {15},
pages = {6139--6144},
pmid = {23530203},
title = {{Normalization is a general neural mechanism for context-dependent decision making}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1217854110},
volume = {110},
year = {2013}
}
@article{Neirotti2016,
author = {Neirotti, Juan Pablo},
doi = {10.1103/PhysRevE.94.012309},
file = {:home/kaslu/Documents/Mendeley/2016 - Neirotti - Anisotropic opinion dynamics.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {1},
pages = {1--9},
title = {{Anisotropic opinion dynamics}},
volume = {94},
year = {2016}
}
@article{Lake2016b,
abstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
doi = {10.1017/S0140525X16001837},
eprint = {1604.00289},
file = {:home/kaslu/Documents/Mendeley/2016 - Lake et al. - Building Machines That Learn and Think Like People.pdf:pdf;:home/kaslu/Documents/Mendeley/2016 - Lake et al. - Building Machines That Learn and Think Like People(2).pdf:pdf},
isbn = {9781577357384},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
month = {nov},
number = {2012},
pages = {1--101},
pmid = {1000303116},
title = {{Building Machines That Learn and Think Like People}},
url = {http://arxiv.org/abs/1604.00289 http://www.journals.cambridge.org/abstract{\_}S0140525X16001837},
year = {2016}
}
@book{Itthipuripat2017,
abstract = {Selective attention supports the prioritized processing of relevant sensory information to facilitate goal-directed behavior. Studies in human subjects demonstrate that attentional gain of cortical responses can sufficiently account for attention-related improvements in behavior. On the other hand, studies using highly trained nonhuman primates suggest that reductions in neural noise can better explain attentional facilitation of behavior. Given the importance of selective information processing in nearly all domains of cognition, we sought to reconcile these competing accounts by testing the hypothesis that extensive behavioral training alters the neural mechanisms that support selective attention. We tested this hypothesis using electroencephalography (EEG) to measure stimulus-evoked visual responses from human subjects while they performed a selective spatial attention task over the course of {\~{}}1 month. Early in training, spatial attention led to an increase in the gain of stimulus- evoked visual responses. Gain was apparent within {\~{}}100 ms of stimulus onset, and a quan- titative model based on signal detection theory (SDT) successfully linked the magnitude of this gain modulation to attention-related improvements in behavior. However, after extensive training, this early attentional gain was eliminated even though there were still substantial attention-related improvements in behavior. Accordingly, the SDT-based model required noise reduction to account for the link between the stimulus-evoked visual responses and attentional modulations of behavior. These findings suggest that training can lead to fundamental changes in the way attention alters the early cortical responses that support selective information processing. Moreover, these data facilitate the translation of results across different species and across experimental procedures that employ different behavioral training regimes.},
author = {Itthipuripat, Sirawaj and Cha, Kexin and Byers, Anna and Serences, John T},
booktitle = {PLoS biology},
doi = {10.1371/journal.pbio.2001724},
file = {:home/kaslu/Documents/Mendeley/2017 - Itthipuripat et al. - Two different mechanisms support selective attention at different phases of training.pdf:pdf},
isbn = {1111111111},
issn = {1545-7885},
number = {6},
pages = {e2001724},
pmid = {28654635},
title = {{Two different mechanisms support selective attention at different phases of training}},
url = {http://dx.plos.org/10.1371/journal.pbio.2001724},
volume = {15},
year = {2017}
}
@article{Dayan1995,
abstract = {Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.},
author = {Dayan, Peter and Hinton, Geoffrey E and Neal, Radford M and Zemel, Richard S},
doi = {10.1162/neco.1995.7.5.889},
file = {:home/kaslu/Documents/Mendeley/1995 - Dayan et al. - The Helmholtz Machine.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Algorithms,Automated,Feedback,Humans,Models,Pattern Recognition,Perception,Perception: physiology,Psychological,Stochastic Processes,Visual},
month = {sep},
number = {5},
pages = {889--904},
pmid = {7584891},
title = {{The Helmholtz Machine}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7584891{\%}5Cnhttp://www.mitpressjournals.org/doi/pdf/10.1162/neco.1995.7.5.889 http://www.mitpressjournals.org/doi/10.1162/neco.1995.7.5.889},
volume = {7},
year = {1995}
}
@article{Knuth2014,
abstract = {It is generally believed that physical laws, reflecting an inherent order in the universe, are ordained by nature. However, in modern physics the observer plays a central role raising questions about how an observer-centric physics can result in laws apparently worthy of a universal nature-centric physics. Over the last decade, we have found that the consistent apt quantification of algebraic and order-theoretic structures results in calculi that possess constraint equations taking the form of what are often considered to be physical laws. I review recent derivations of the formal relations among relevant variables central to special relativity, probability theory and quantum mechanics in this context by considering a problem where two observers form consistent descriptions of and make optimal inferences about a free particle that simply influences them. I show that this approach to describing such a particle based only on available information leads to the mathematics of relativistic quantum mechanics as well as a description of a free particle that reproduces many of the basic properties of a fermion. The result is an approach to foundational physics where laws derive from both consistent descriptions and optimal information-based inferences made by embedded observers.},
archivePrefix = {arXiv},
arxivId = {1310.1667},
author = {Knuth, Kevin H.},
doi = {10.1080/00107514.2013.853426},
eprint = {1310.1667},
issn = {0010-7514},
journal = {Contemporary Physics},
month = {jan},
number = {1},
pages = {12--32},
title = {{Information-based physics: an observer-centric foundation}},
url = {http://arxiv.org/abs/1310.1667 http://www.tandfonline.com/doi/abs/10.1080/00107514.2013.853426},
volume = {55},
year = {2014}
}
@article{Opper1996,
author = {Opper, Manfred},
doi = {10.1103/PhysRevLett.77.4671},
file = {:home/kaslu/Documents/Mendeley/1996 - Opper - On-line versus Off-line Learning from Random Examples General Results.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {nov},
number = {22},
pages = {4671--4674},
pmid = {10062597},
title = {{On-line versus Off-line Learning from Random Examples: General Results}},
url = {https://link.aps.org/doi/10.1103/PhysRevLett.77.4671},
volume = {77},
year = {1996}
}
@article{Gleiser2017,
abstract = {Science is a constructed narrative of the natural world based on information gathering and its subsequent analysis. In this essay, we develop a novel approach to the epistemic foundations of the scientific narrative, as based on our experiential interactions with the natural world. We first review some of the basic aspects of both Bayesian statistics and Shannon's information theory as applied to the construction of meaningful conceptualization of the natural world. This conceptualization is rendered through the maps we construct of the world based on our limited knowledge of reality. We propose a path from experience to information and physics based on the notion that information is experience that induces change in an Epistemic Agent (EA): the change may be local and focused to a minor aspect of reality or it may be broad and worldview-changing. We illustrate our approach through an analysis of a measure of spatial complexity proposed by one of us called Configuration Entropy (CE), and establish a link between experience at the cognitive level and information content, showing that the CE is a quantitative measure of how much information in spatial-complexity the external world hides from an EA.},
archivePrefix = {arXiv},
arxivId = {1710.09944},
author = {Gleiser, Marcelo and Sowinski, Damian},
eprint = {1710.09944},
file = {:home/kaslu/Documents/Mendeley/2017 - Gleiser, Sowinski - How We Make Sense of the World Information, Map-Making, and The Scientific Narrative.pdf:pdf},
month = {oct},
title = {{How We Make Sense of the World: Information, Map-Making, and The Scientific Narrative}},
url = {http://arxiv.org/abs/1710.09944},
year = {2017}
}
@article{Mutch2010,
abstract = {T his article relates Archer's morphogenetic approach, derived from the philosophical tradition of critical realism, to the use of information and communication technology in organizations. Three gains are seen to accrue from this approach: greater clarity about the material properties of technology, links to broader structural conditions arising from the concep- tualization of the relationship between agency and structure, and the potential to explore the importance of reflexivity in contemporary organizations, especially in conditions of the widespread use of information and communication technology. The importance of disaggregating the artifacts of this technology into levels and features is stressed to enable analysis to explore the specific impacts of particular combinations. This is developed through a discussion of data warehousing in connection with the attention being given to the importance of analytics in organizational strategies. Key features are in wider aspects of the cultural and structural context, demonstrating the fruitfulness of a morphogenetic approach.},
author = {Mutch, Alistair},
doi = {10.1287/orsc.1090.0441},
file = {:home/kaslu/Documents/Mendeley/2010 - Mutch - Technology, Organization, and Structure—A Morphogenetic Approach.pdf:pdf},
isbn = {1047-7039},
issn = {1047-7039},
journal = {Organization Science},
keywords = {2009,agency and structure,critical realism,data warehouses,history,in advance july 28,information,information systems,information technology,organizations and,published online in articles,reflexivity},
number = {2},
pages = {507--520},
title = {{Technology, Organization, and Structure—A Morphogenetic Approach}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/orsc.1090.0441},
volume = {21},
year = {2010}
}
@article{Pollard2016,
abstract = {In recent work, Baez, Fong and the author introduced a framework for describing Markov processes equipped with a detailed balanced equilibrium as open systems of a certain type. These " open Markov processes " serve as the building blocks for more complicated processes. In this paper, we describe the potential application of this framework in the modeling of biological systems as open systems maintained away from equilibrium. We show that non-equilibrium steady states emerge in open systems of this type, even when the rates of the underlying process are such that a detailed balanced equilibrium is permitted. It is shown that these non-equilibrium steady states minimize a quadratic form which we call " dissipation " . In some circumstances, the dissipation is approximately equal to the rate of change of relative entropy plus a correction term. On the other hand, Prigogine's principle of minimum entropy production generally fails for non-equilibrium steady states. We use a simple model of membrane transport to illustrate these concepts.},
author = {Pollard, Blake},
doi = {10.3390/e18040140},
issn = {1099-4300},
journal = {Entropy},
month = {apr},
number = {4},
pages = {140},
title = {{Open Markov Processes: A Compositional Perspective on Non-Equilibrium Steady States in Biology}},
url = {http://www.mdpi.com/1099-4300/18/4/140},
volume = {18},
year = {2016}
}
@article{Kanitscheider2017,
author = {Kanitscheider, Ingmar and Fiete, Ila R.},
doi = {10.1016/j.coisb.2017.04.008},
file = {:home/kaslu/Documents/Mendeley/2017 - Kanitscheider, Fiete - Making our way through the world Towards a functional understanding of the brain's spatial circuits.pdf:pdf},
issn = {24523100},
journal = {Current Opinion in Systems Biology},
keywords = {computational modelling,entorhinal cortex,hippocampus,keeping track of one,navigation,probabilistic inference,s location in space,simultaneous localization and mapping,while navigating},
pages = {186--194},
publisher = {Elsevier Ltd},
title = {{Making our way through the world: Towards a functional understanding of the brain's spatial circuits}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2452310017300549},
volume = {3},
year = {2017}
}
@article{Abrams1990,
abstract = {We contrast two theoretical approaches to social influence, one stressing interpersonal dependence, conceptualized as normative and informational influence (Deutsch {\&} Gerard, 1955), and the other stressing group membership, conceptualized as self-categorization and referent informational influence (Turner, Hogg, Oakes, Reicher {\&} Wetherell, 1987). We argue that both social comparisons to reduce uncertainty and the existence of normative pressure to comply depend on perceiving the source of influence as belonging to one's own category. This study tested these two approaches using three influence paradigms. First we demonstrate that, in Sherif's (1936) autokinetic effect paradigm, the impact of confederates on the formation of a norm decreases as their membership of a different category is made more salient to subjects. Second, in the Asch (1956) conformity paradigm, surveillance effectively exerts normative pressure if done by an in-group but not by an out-group. In-group influence decreases and out-group influence increases when subjects respond privately. Self-report data indicate that in-group confederates create more subjective uncertainty than out-group confederates and public responding seems to increase cohesiveness with in-group - but decrease it with out-group - sources of influence. In our third experiment we use the group polarization paradigm (e.g. Burnstein {\&} Vinokur, 1973) to demonstrate that, when categorical differences between two subgroups within a discussion group are made salient, convergence of opinion between the subgroups is inhibited. Taken together the experiments show that self-categorization can be a crucial determining factor in social influence.},
author = {Abrams, Dominic and Wetherell, Margaret and Cochrane, Sandra and Hogg, Michael A. and Turner, John C.},
doi = {10.1111/j.2044-8309.1990.tb00892.x},
file = {:home/kaslu/Documents/Mendeley/1990 - Abrams et al. - Knowing what to think by knowing who you are Self-categorization and the nature of norm formation, conformity and.pdf:pdf},
isbn = {0144-6665},
issn = {01446665},
journal = {British Journal of Social Psychology},
month = {jun},
number = {2},
pages = {97--119},
pmid = {2372667},
title = {{Knowing what to think by knowing who you are: Self-categorization and the nature of norm formation, conformity and group polarization}},
url = {http://doi.wiley.com/10.1111/j.2044-8309.1990.tb00892.x},
volume = {29},
year = {1990}
}
@article{Sasaki2014,
abstract = {Mean shift clustering finds the modes of the data probability density by identifying the zero points of the density gradient. Since it does not require to fix the number of clusters in advance, the mean shift has been a popular clustering algorithm in various application fields. A typical implementation of the mean shift is to first estimate the density by kernel density estimation and then compute its gradient. However, since good density estimation does not necessarily imply accurate estimation of the density gradient, such an indirect two-step approach is not reliable. In this paper, we propose a method to directly estimate the gradient of the log-density without going through density estimation. The proposed method gives the global solution analytically and thus is computationally efficient. We then develop a mean-shift-like fixed-point algorithm to find the modes of the density for clustering. As in the mean shift, one does not need to set the number of clusters in advance. We empirically show that the proposed clustering method works much better than the mean shift especially for high-dimensional data. Experimental results further indicate that the proposed method outperforms existing clustering methods.},
archivePrefix = {arXiv},
arxivId = {1404.5028},
author = {Sasaki, Hiroaki and Hyv{\"{a}}rinen, Aapo and Sugiyama, Masashi},
doi = {10.1007/978-3-662-44845-8_2},
eprint = {1404.5028},
file = {:home/kaslu/Documents/Mendeley/2014 - Sasaki, Hyv{\"{a}}rinen, Sugiyama - Clustering via mode seeking by direct estimation of the gradient of a log-density.pdf:pdf},
isbn = {9783662448441},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Clustering,High-Dimensional Data,Log-Density Gradient Estimation,Mean Shift},
number = {PART 3},
pages = {19--34},
title = {{Clustering via mode seeking by direct estimation of the gradient of a log-density}},
volume = {8726 LNAI},
year = {2014}
}
@article{Richters2010,
abstract = {Non-centralized recommendation-based decision making is a central feature of several social and technological processes, such as market dynamics, peer-to-peer file-sharing and the web of trust of digital certification. We investigate the properties of trust propagation on networks, based on a simple metric of trust transitivity. We investigate analytically the percolation properties of trust transitivity in random networks with arbitrary degree distribution, and compare with numerical realizations. We find that the existence of a non-zero fraction of absolute trust (i.e. entirely confident trust) is a requirement for the viability of global trust propagation in large systems: The average pair-wise trust is marked by a discontinuous transition at a specific fraction of absolute trust, below which it vanishes. Furthermore, we perform an extensive analysis of the Pretty Good Privacy (PGP) web of trust, in view of the concepts introduced. We compare different scenarios of trust distribution: community- and authority-centered. We find that these scenarios lead to sharply different patterns of trust propagation, due to the segregation of authority hubs and densely-connected communities. While the authority-centered scenario is more efficient, and leads to higher average trust values, it favours weakly-connected "fringe" nodes, which are directly trusted by authorities. The community-centered scheme, on the other hand, favours nodes with intermediate degrees, in detriment of the authorities and its "fringe" peers.},
archivePrefix = {arXiv},
arxivId = {1012.1358},
author = {Richters, Oliver and Peixoto, Tiago P.},
doi = {10.1371/journal.pone.0018384},
editor = {Perc, Matjaz},
eprint = {1012.1358},
file = {:home/kaslu/Documents/Mendeley/2010 - Richters, Peixoto - Trust transitivity in social networks.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = {dec},
number = {4},
pages = {e18384},
pmid = {21483683},
publisher = {Public Library of Science},
title = {{Trust transitivity in social networks}},
url = {http://dx.plos.org/10.1371/journal.pone.0018384 http://arxiv.org/abs/1012.1358 http://dx.doi.org/10.1371/journal.pone.0018384},
volume = {6},
year = {2010}
}
@article{Weinstein2017,
abstract = {We construct a hidden variable model for the EPR correlations using a Restricted Boltzmann Machine. The model reproduces the expected correlations and thus violates the Bell inequality, as required by Bell's theorem. Unlike most hidden-variable models, this model does not violate the {\$}locality{\$} assumption in Bell's argument. Rather, it violates {\$}measurement{\$} {\$}independence{\$}, albeit in a decidedly non-conspiratorial way.},
archivePrefix = {arXiv},
arxivId = {1707.03114},
author = {Weinstein, Steven},
eprint = {1707.03114},
file = {:home/kaslu/Documents/Mendeley/2017 - Weinstein - Learning the Einstein-Podolsky-Rosen correlations on a Restricted Boltzmann Machine.pdf:pdf},
month = {jul},
title = {{Learning the Einstein-Podolsky-Rosen correlations on a Restricted Boltzmann Machine}},
url = {http://arxiv.org/abs/1707.03114},
year = {2017}
}
@article{Hartig2014,
abstract = {If two species exhibit different nonlinear responses to a single shared resource, and if each species modifies the resource dynamics such that this favors its competitor, they may stably coexist. This coexistence mechanism, known as relative nonlinearity of competition, is well understood theoretically, but less is known about its evolutionary properties and its prevalence in real communities. We address this challenge by using adaptive dynamics theory and individual-based simulations to compare community stabilization and evolutionary stability of species that coexist by relative nonlinearity. In our analysis, evolution operates on the species' density-compensation strategies, and we consider a trade-off between population growth rates at high and low resource availability. We confirm previous findings that, irrespective of the particular model of density dependence, there are many combinations of overcompensating and undercompensating density-compensation strategies that allow stable coexistence by relative nonlinearity. However, our analysis also shows that most of these strategy combinations are not evolutionarily stable and will be outcompeted by an intermediate density-compensation strategy. Only very specific trade-offs lead to evolutionarily stable coexistence by relative nonlinearity. As we find no reason why these particular trade-offs should be common in nature, we conclude that the sympatric evolution and evolutionary stability of relative nonlinearity, while possible in principle, seems rather unlikely. We speculate that this may, at least in part, explain why empirical demonstrations of this coexistence mechanism are rare, noting, however, that the difficulty to detect relative nonlinearity in the field is an equally likely explanation for the current lack of empirical observations, and that our results are limited to communities with non-overlapping generations and constant resource supply. Our study highlights the need for combining ecological and evolutionary perspectives for gaining a better understanding of community assembly and biogeographic patterns.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.3114v1},
author = {Hartig, Florian and M{\"{u}}nkem{\"{u}}ller, Tamara and Johst, Karin and Dieckmann, Ulf},
doi = {10.1371/journal.pone.0094454},
editor = {Mouquet, Nicolas},
eprint = {arXiv:1308.3114v1},
file = {:home/kaslu/Documents/Mendeley/2014 - Hartig et al. - On the Sympatric Evolution and Evolutionary Stability of Coexistence by Relative Nonlinearity of Competition.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = {sep},
number = {9},
pages = {e94454},
pmid = {25184813},
title = {{On the Sympatric Evolution and Evolutionary Stability of Coexistence by Relative Nonlinearity of Competition}},
url = {http://dx.plos.org/10.1371/journal.pone.0094454},
volume = {9},
year = {2014}
}
@article{Everett2016,
abstract = {Moral judgments play a critical role in motivating and enforcing human cooperation, and research on the proximate mechanisms of moral judgments highlights the importance of intuitive, automatic processes in forming such judgments. Intuitive moral judgments often share characteristics with deontological theories in normative ethics, which argue that certain acts (such as killing) are absolutely wrong, regardless of their consequences. Why do moral intuitions typically follow deontological prescriptions, as opposed to those of other ethical theories? Here, we test a functional explanation for this phenomenon by investigating whether agents who express deontological moral judgments are more valued as social partners. Across 5 studies, we show that people who make characteristically deontological judgments are preferred as social partners, perceived as more moral and trustworthy, and are trusted more in economic games. These findings provide empirical support for a partner choice account of moral intuitions whereby typically deontological judgments confer an adaptive function by increasing a person's likelihood of being chosen as a cooperation partner. Therefore, deontological moral intuitions may represent an evolutionarily prescribed prior that was selected for through partner choice mechanisms.},
author = {Everett, Jim and Pizarro, David and Crockett, Molly J.},
doi = {10.1037/xge0000165},
file = {:home/kaslu/Documents/Mendeley/2016 - Everett, Pizarro, Crockett - Inference of Trustworthiness From Intuitive Moral Judgments.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
keywords = {deontological,intuition,morality,partner choice,utilitarian},
title = {{Inference of Trustworthiness From Intuitive Moral Judgments}},
url = {http://dx.doi.org/10.1037/xge0000165},
year = {2016}
}
@article{Rao2010,
abstract = {A fundamental problem faced by animals is learning to select actions based on noisy sensory information and incomplete knowledge of the world. It has been suggested that the brain engages in Bayesian inference during perception but how such probabilistic representations are used to select actions has remained unclear. Here we propose a neural model of action selection and decision making based on the theory of partially observable Markov decision processes (POMDPs). Actions are selected based not on a single "optimal" estimate of state but on the posterior distribution over states (the "belief" state). We show how such a model provides a unified framework for explaining experimental results in decision making that involve both information gathering and overt actions. The model utilizes temporal difference (TD) learning for maximizing expected reward. The resulting neural architecture posits an active role for the neocortex in belief computation while ascribing a role to the basal ganglia in belief representation, value computation, and action selection. When applied to the random dots motion discrimination task, model neurons representing belief exhibit responses similar to those of LIP neurons in primate neocortex. The appropriate threshold for switching from information gathering to overt actions emerges naturally during reward maximization. Additionally, the time course of reward prediction error in the model shares similarities with dopaminergic responses in the basal ganglia during the random dots task. For tasks with a deadline, the model learns a decision making strategy that changes with elapsed time, predicting a collapsing decision threshold consistent with some experimental studies. The model provides a new framework for understanding neural decision making and suggests an important role for interactions between the neocortex and the basal ganglia in learning the mapping between probabilistic sensory representations and actions that maximize rewards.},
author = {Rao, Rajesh P. N.},
doi = {10.3389/fncom.2010.00146},
file = {:home/kaslu/Documents/Mendeley/2010 - Rao - Decision Making Under Uncertainty A Neural Model Based on Partially Observable Markov Decision Processes.pdf:pdf},
isbn = {1662-5188 (Electronic)$\backslash$n1662-5188 (Linking)},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {basal ganglia,bayesian inference,decision theory,dopamine,parietal cortex,probabilistic models,reinforcement learning,temporal difference learning},
number = {November},
pages = {1--18},
pmid = {21152255},
title = {{Decision Making Under Uncertainty: A Neural Model Based on Partially Observable Markov Decision Processes}},
url = {http://journal.frontiersin.org/article/10.3389/fncom.2010.00146/abstract},
volume = {4},
year = {2010}
}
@article{Hangya2016,
abstract = {We have calculated the intrinsic dimensionality of visual object representations in anterior inferotemporal (AIT) cortex, based on responses of a large sample of cells stimulated with photographs of diverse objects. As dimensionality was dependent on data set size, we determined asymptotic dimensionality as both the number of neurons and number of stimulus image approached infinity. Our final dimensionality estimate was 93 (SD: ± 11), indicating that there is basis set of approximately a hundred independent features that characterize the dimensions of neural object space. We believe this is the first estimate of the dimensionality of neural visual representations based on single-cell neurophysiological data. The dimensionality of AIT object representations was much lower than the dimensionality of the stimuli. We suggest that there may be a gradual reduction in the dimensionality of object representations in neural populations going from retina to inferotemporal cortex, as receptive fields become increasingly complex. Introduction},
author = {Hangya, Bal{\'{a}}zs and Sanders, Joshua I. and Kepecs, Adam},
doi = {10.1162/NECO_a_00864},
file = {:home/kaslu/Documents/Mendeley/2016 - Hangya, Sanders, Kepecs - A Mathematical Framework for Statistical Decision Confidence.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {sep},
number = {9},
pages = {1840--1858},
title = {{A Mathematical Framework for Statistical Decision Confidence}},
url = {http://www.mitpressjournals.org/doi/10.1162/NECO{\_}a{\_}00864},
volume = {28},
year = {2016}
}
@article{Scargle2013,
abstract = {This paper addresses the problem of detecting and characterizing local variability in time series and other forms of sequential data. The goal is to identify and characterize statistically significant variations, at the same time suppressing the inevitable corrupting observational errors. We present a simple nonparametric modeling technique and an algorithm implementing it—an improved and generalized version of Bayesian Blocks—that finds the optimal segmentation of the data in the observation interval. The structure of the algorithm allows it to be used in either a real-time trigger mode, or a retrospective mode. Maximum likelihood or marginal posterior functions to measure model fitness are presented for events, binned counts, and measurements at arbitrary times with known error distributions. Problems addressed include those connected with data gaps, variable exposure, extension to piecewise linear and piecewise exponential representations, multivariate time series data, analysis of variance, data on the circle, other data modes, and dispersed data. Simulations provide evidence that the detection efficiency for weak signals is close to a theoretical asymptotic limit derived by Arias-Castro et al. In the spirit of Reproducible Research all of the code and data necessary to reproduce all of the figures in this paper are included as supplementary material.},
author = {Scargle, Jeffrey D and Norris, Jay P and Jackson, Brad and Chiang, James and Hansen, W W},
doi = {10.1088/0004-637X/764/2/167},
file = {:home/kaslu/Documents/Mendeley/2013 - Scargle et al. - STUDIES IN ASTRONOMICAL TIME SERIES ANALYSIS. VI. BAYESIAN BLOCK REPRESENTATIONS.pdf:pdf},
journal = {The Astrophysical Journal},
number = {26pp},
title = {{STUDIES IN ASTRONOMICAL TIME SERIES ANALYSIS. VI. BAYESIAN BLOCK REPRESENTATIONS}},
volume = {764},
year = {2013}
}
@article{Law2009,
abstract = {We recently showed that improved perceptual performance on a visual motion direction-discrimination task corresponds to changes in how an unmodified sensory representation in the brain is interpreted to form a decision that guides behavior. Here we found that these changes can be accounted for using a reinforcement-learning rule to shape functional connectivity between the sensory and decision neurons. We modeled performance on the basis of the readout of simulated responses of direction-selective sensory neurons in the middle temporal area (MT) of monkey cortex. A reward prediction error guided changes in connections between these sensory neurons and the decision process, first establishing the association between motion direction and response direction, and then gradually improving perceptual sensitivity by selectively strengthening the connections from the most sensitive neurons in the sensory population. The results suggest a common, feedback-driven mechanism for some forms of associative and perceptual learning.},
author = {Law, Chi-Tat and Gold, Joshua I.},
doi = {10.1038/nn.2304},
file = {:home/kaslu/Documents/Mendeley/2009 - Law, Gold - Reinforcement learning can account for associative and perceptual learning on a visual-decision task.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {5},
pages = {655--663},
pmid = {19377473},
title = {{Reinforcement learning can account for associative and perceptual learning on a visual-decision task.}},
volume = {12},
year = {2009}
}
@article{Yamada2017,
author = {Yamada, Yoshiyuki and Bhaukaurally, Khaleel and Madar{\'{a}}sz, Tam{\'{a}}s J. and Pouget, Alexandre and Rodriguez, Ivan and Carleton, Alan},
doi = {10.1016/j.neuron.2017.02.006},
issn = {08966273},
journal = {Neuron},
pages = {1198--1212},
pmid = {28238548},
title = {{Context- and Output Layer-Dependent Long-Term Ensemble Plasticity in a Sensory Circuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627317300909},
year = {2017}
}
@article{Buice2013a,
abstract = {Mean field theories have been a stalwart for studying the dynamics of networks of coupled neurons. They are convenient because they are relatively simple and possible to analyze. However, classical mean field theory neglects the effects of fluctuations and correlations due to single neuron effects. Here, we consider various possible approaches for going beyond mean field theory and incorporating correlation effects. Statistical field theory methods, in particular the Doi–Peliti–Janssen formalism, are particularly useful in this regard.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Buice, Michael a. and Chow, Carson C.},
doi = {10.1088/1742-5468/2013/03/P03003},
eprint = {NIHMS150003},
file = {:home/kaslu/Documents/Mendeley/2013 - Buice, Chow - Beyond mean field theory statistical field theory for neural networks.pdf:pdf},
isbn = {2122633255},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
month = {mar},
number = {03},
pages = {P03003},
pmid = {25243014},
publisher = {NIH Public Access},
title = {{Beyond mean field theory: statistical field theory for neural networks}},
url = {http://iopscience.iop.org/1742-5468/2013/03/P03003{\%}5Cnhttp://iopscience.iop.org/1742-5468/2013/03/P03003/pdf/1742-5468{\_}2013{\_}03{\_}P03003.pdf http://stacks.iop.org/1742-5468/2013/i=03/a=P03003?key=crossref.4da3fbb7f936711791c5dffabaad12ae},
volume = {2013},
year = {2013}
}
@article{Haidt2007,
abstract = {People are selfish, yet morally motivated. Morality is universal, yet culturally variable. Such apparent contradictions are dissolving as research from many disciplines converges on a few shared principles, including the importance of moral intuitions, the socially functional (rather than truth-seeking) nature of moral thinking, and the coevolution of moral minds with cultural practices and institutions that create diverse moral communities. I propose a fourth principle to guide future research: Morality is about more than harm and fairness. More research is needed on the collective and religious parts of the moral domain, such as loyalty, authority, and spiritual purity.},
author = {Haidt, Jonathan},
doi = {10.1126/science.1137651},
file = {:home/kaslu/Documents/Mendeley/2007 - Haidt - The new synthesis in moral psychology.pdf:pdf;:home/kaslu/Documents/Mendeley/2007 - Haidt - The new synthesis in moral psychology(2).pdf:pdf},
isbn = {0036-8075, 1095-9203},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Affect,Altruism,Brain,Brain: physiology,Cognition,Cooperative Behavior,Culture,Emotions,Group Processes,Humans,Intuition,Models,Morals,Psychological,Psychology,Social,Thinking},
month = {may},
number = {5827},
pages = {998--1002},
pmid = {17510357},
title = {{The new synthesis in moral psychology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17510357},
volume = {316},
year = {2007}
}
@article{Wrangham2012,
abstract = {Chimpanzee and hunter-gatherer intergroup aggression differ in important ways, including humans having the ability to form peaceful relationships and alliances among groups. This paper nevertheless evaluates the hypothesis that intergroup aggression evolved according to the same functional principles in the two species-selection favoring a tendency to kill members of neighboring groups when killing could be carried out safely. According to this idea chimpanzees and humans are equally risk-averse when fighting. When self-sacrificial war practices are found in humans, therefore, they result from cultural systems of reward, punishment, and coercion rather than evolved adaptations to greater risk-taking. To test this "chimpanzee model," we review intergroup fighting in chimpanzees and nomadic hunter-gatherers living with other nomadic hunter-gatherers as neighbors. Whether humans have evolved specific psychological adaptations for war is unknown, but current evidence suggests that the chimpanzee model is an appropriate starting point for analyzing the biological and cultural evolution of warfare.},
author = {Wrangham, Richard W and Glowacki, Luke},
doi = {10.1007/s12110-012-9132-1},
issn = {1045-6767},
journal = {Human Nature},
month = {mar},
number = {1},
pages = {5--29},
pmid = {22388773},
title = {{Intergroup Aggression in Chimpanzees and War in Nomadic Hunter-Gatherers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22388773 http://link.springer.com/10.1007/s12110-012-9132-1},
volume = {23},
year = {2012}
}
@article{Sriperumbudur2017,
abstract = {In this paper, we consider an infinite dimensional exponential family P of probability den-sities, which are parametrized by functions in a reproducing kernel Hilbert space H, and show it to be quite rich in the sense that a broad class of densities on R d can be approxi-mated arbitrarily well in Kullback-Leibler (KL) divergence by elements in P. Motivated by this approximation property, the paper addresses the question of estimating an unknown density p 0 through an element in P. Standard techniques like maximum likelihood estima-tion (MLE) or pseudo MLE (based on the method of sieves), which are based on minimizing the KL divergence between p 0 and P, do not yield practically useful estimators because of their inability to efficiently handle the log-partition function. We propose an estimato p n based on minimizing the Fisher divergence, J(p 0 p) between p 0 and p ∈ P, which involves solving a simple finite-dimensional linear system. When p 0 ∈ P, we show that the pro-posed estimator is consistent, and provide a convergence rate of n − min{\{} 2 3 , 2$\beta$+1 2$\beta$+2 {\}} in Fisher divergence under the smoothness assumption that log p 0 ∈ R(C $\beta$) for some $\beta$ ≥ 0, where C is a certain Hilbert-Schmidt operator on H and R(C $\beta$) denotes the image of C $\beta$ . We also investigate the misspecified case of p 0 / ∈ P and show that J(p p n) → inf p∈P J(p 0 p) as n → ∞, and provide a rate for this convergence under a similar smoothness condition as above. Through numerical simulations we demonstrate that the proposed estimator outperforms the non-parametric kernel density estimator, and that the advantage of the proposed estimator grows as d increases.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.3516v3},
author = {Sriperumbudur, Bharath and Fukumizu, Kenji and Gretton, Arthur and Hyv{\"{a}}rinen, Aapo and Kumar, Revant},
eprint = {arXiv:1312.3516v3},
file = {:home/kaslu/Documents/Mendeley/2017 - Sriperumbudur et al. - Density Estimation in Infinite Dimensional Exponential Families.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Fisher divergence,Tikhonov regularization,density estimation,exponential family,interpolation space,inverse problem,kernel density estimator,maximum likelihood,reproducing kernel Hilbert space,score matching},
pages = {1--59},
title = {{Density Estimation in Infinite Dimensional Exponential Families}},
url = {http://jmlr.org/papers/v18/16-011.html.},
volume = {18},
year = {2017}
}
@article{Rand2012,
abstract = {Cooperation is central to human social behaviour. However, choosing to cooperate requires individuals to incur a personal cost to benefit others. Here we explore the cognitive basis of cooperative decision-making in humans using a dual-process framework. We ask whether people are predisposed towards selfishness, behaving cooperatively only through active self-control; or whether they are intuitively cooperative, with reflection and prospective reasoning favouring 'rational' self-interest. To investigate this issue, we perform ten studies using economic games. We find that across a range of experimental designs, subjects who reach their decisions more quickly are more cooperative. Furthermore, forcing subjects to decide quickly increases contributions, whereas instructing them to reflect and forcing them to decide slowly decreases contributions. Finally, an induction that primes subjects to trust their intuitions increases contributions compared with an induction that promotes greater reflection. To explain these results, we propose that cooperation is intuitive because cooperative heuristics are developed in daily life where cooperation is typically advantageous. We then validate predictions generated by this proposed mechanism. Our results provide convergent evidence that intuition supports cooperation in social dilemmas, and that reflection can undermine these cooperative impulses.},
author = {Rand, David G. and Greene, Joshua D. and Nowak, Martin A.},
doi = {10.1038/nature11467},
file = {:home/kaslu/Documents/Mendeley/2012 - Rand, Greene, Nowak - Spontaneous giving and calculated greed.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {7416},
pages = {427--430},
pmid = {22996558},
title = {{Spontaneous giving and calculated greed}},
url = {http://www.nature.com/doifinder/10.1038/nature11467},
volume = {489},
year = {2012}
}
@article{Nessler2013,
abstract = {The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex. Funding: This work was written under partial support by project {\#}FP7-216593 (SECO), project {\#}FP7-506778 (PASCAL2), project {\#}FP7-243914 (BRAIN-I-NETS) and project {\#}FP7-269921 (BrainScaleS) of the European Union.},
author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003037},
file = {:home/kaslu/Documents/Mendeley/2013 - Nessler et al. - Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity.pdf:pdf},
journal = {PLoS Comput Biol},
number = {4},
title = {{Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity}},
volume = {9},
year = {2013}
}
@article{Shore1980,
abstract = {Jaynes's principle of maximum entropy and Kullbacks principle of minimum cross-entropy (minimum directed divergence) are shown to be uniquely correct methods for inductive inference when new information is given in the form of expected values. Previous justifications use intuitive arguments and rely on the properties of entropy and cross-entropy as information measures. The approach here assumes that reasonable methods of inductive inference should lead to consistent results when there are different ways of taking the same information into account (for example, in different coordinate system). This requirement is formalized as four consistency axioms. These are stated in terms of an abstract information operator and make no reference to information measures. It is proved that the principle of maximum entropy is correct in the following sense: maximizing any function but entropy will lead to inconsistency unless that function and entropy have identical maxima. In other words given information in the form of constraints on expected values, there is only one (distribution satisfying the constraints that can be chosen by a procedure that satisfies the consistency axioms; this unique distribution can be obtained by maximizing entropy. This result is established both directly and as a special case (uniform priors) of an analogous result for the principle of minimum cross-entropy. Results are obtained both for continuous probability densities and for discrete distributions.},
author = {Shore, J. and Johnson, R.},
doi = {10.1109/TIT.1980.1056144},
file = {:home/kaslu/Documents/Mendeley/1980 - Shore, Johnson - Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy.pdf:pdf},
isbn = {0018-9448},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {jan},
number = {1},
pages = {26--37},
pmid = {1056144},
title = {{Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy}},
url = {http://ieeexplore.ieee.org/document/1056144/},
volume = {26},
year = {1980}
}
@article{Aguilera2017,
abstract = {Many biological and cognitive systems do not operate deep into one or other regime of activity. Instead, they exploit critical surfaces poised at transitions in their parameter space. The pervasiveness of criticality in natural systems suggests that there may be general principles inducing this behaviour. However, there is a lack of conceptual models explaining how embodied agents propel themselves towards these critical points. In this paper, we present a learning model driving an embodied Boltzmann Machine towards critical behaviour by maximizing the heat capacity of the network. We test and corroborate the model implementing an embodied agent in the mountain car benchmark, controlled by a Boltzmann Machine that adjust its weights according to the model. We find that the neural controller reaches a point of criticality, which coincides with a transition point of the behaviour of the agent between two regimes of behaviour, maximizing the synergistic information between its sensors and the hidden and motor neurons. Finally, we discuss the potential of our learning model to study the contribution of criticality to the behaviour of embodied living systems in scenarios not necessarily constrained by biological restrictions of the examples of criticality we find in nature.},
archivePrefix = {arXiv},
arxivId = {1702.00614},
author = {Aguilera, Miguel and Bedia, Manuel G.},
eprint = {1702.00614},
month = {feb},
title = {{Learning Criticality in an Embodied Boltzmann Machine}},
url = {http://arxiv.org/abs/1702.00614},
year = {2017}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
author = {Ma, Wei Ji and Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
doi = {10.1038/nn1790},
file = {:home/kaslu/Documents/Mendeley/2006 - Ma et al. - Bayesian inference with probabilistic population codes.pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {11},
pages = {1432--1438},
pmid = {17057707},
title = {{Bayesian inference with probabilistic population codes}},
url = {http://www.nature.com/doifinder/10.1038/nn1790},
volume = {9},
year = {2006}
}
@incollection{Biehl2009,
abstract = {We introduce and discuss the application of statistical physics concepts in the context of on-line machine learning processes. The consideration of typical properties of very large systems allows to perfom averages over the randomness contained in the sequence of training data. It yields an exact mathematical description of the training dynamics in model scenarios. We present the basic concepts and results of the approach in terms of several examples, including the learning of linear separable rules, the training of multilayer neural networks, and Learning Vector Quantization.},
author = {Biehl, Michael and Caticha, Nestor and Riegler, Peter},
doi = {10.1007/978-3-642-01805-3_1},
file = {:home/kaslu/Documents/Mendeley/2009 - Biehl, Caticha, Riegler - Statistical Mechanics of On-line Learning.pdf:pdf},
pages = {1--22},
title = {{Statistical Mechanics of On-line Learning}},
url = {http://link.springer.com/10.1007/978-3-642-01805-3{\_}1},
year = {2009}
}
@article{Feynman1982,
abstract = {A digital computer is generally believed to be an efficient universal computing device; that is, it is believed able to simulate any physical computing device with an increase in computation time of at most a polynomial factor. This may not be true when quantum mechanics is taken into consideration. This paper considers factoring integers and finding discrete logarithms, two problems which are generally thought to be hard on a classical computer and have been used as the basis of several proposed cryptosystems. Efficient randomized algorithms are given for these two problems on a hypothetical quantum computer. These algorithms take a number of steps polynomial in the input size, e.g., the number of digits of the integer to be factored.},
author = {Feynman, Richard P.},
doi = {10.1007/BF02650179},
issn = {0020-7748},
journal = {International Journal of Theoretical Physics},
month = {jun},
number = {6-7},
pages = {467--488},
title = {{Simulating physics with computers}},
url = {http://link.springer.com/10.1007/BF02650179},
volume = {21},
year = {1982}
}
@article{Touboul2017,
abstract = {Critical states are usually identified experimentally through power-law statistics or universal scaling functions. We show here that such features naturally emerge from networks in self-sustained irregular regimes away from criticality. Power-law statistics are also seen when the units are replaced by independent stochastic surrogates, and thus are not sufficient to establish criticality. We rather suggest that these are universal features of large-scale networks when considered macroscopically. These results put caution on the interpretation of scaling laws found in nature.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.08033v1},
author = {Touboul, Jonathan and Destexhe, Alain},
doi = {10.1103/PhysRevE.95.012413},
eprint = {arXiv:1503.08033v1},
issn = {2470-0045},
journal = {Physical Review E},
month = {jan},
number = {1},
pages = {012413},
title = {{Power-law statistics and universal scaling in the absence of criticality}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.95.012413},
volume = {95},
year = {2017}
}
@article{Jaynes1957a,
author = {Jaynes, Edwin T.},
file = {:home/kaslu/Documents/Mendeley/1957 - Jaynes - Information Theory and Statistical Mechanics. II.pdf:pdf},
journal = {Phys. Rev. E},
number = {2},
pages = {171--190},
title = {{Information Theory and Statistical Mechanics. II}},
volume = {108},
year = {1957}
}
@article{Deneve2016,
abstract = {Memories are stored, retained, and recollected through complex, coupled processes operating on multiple timescales. To understand the computational principles behind these intricate networks of interactions we construct a broad class of synaptic models that efficiently harnesses biological complexity to preserve numerous memories. The memory capacity scales almost linearly with the number of synapses, which is a substantial improvement over the square root scaling of previous models. This was achieved by combining multiple dynamical processes that initially store memories in fast variables and then progressively transfer them to slower variables. Importantly, the interactions between fast and slow variables are bidirectional. The proposed models are robust to parameter perturbations and can explain several properties of biological memory, including delayed expression of synaptic modifications, metaplasticity, and spacing effects.},
author = {Den{\`{e}}ve, Sophie and Machens, Christian K},
doi = {10.1038/nn.4243},
file = {:home/kaslu/Documents/Mendeley/2016 - Den{\`{e}}ve, Machens - Efficient codes and balanced networks.pdf:pdf},
isbn = {1097-6256},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {feb},
number = {3},
pages = {375--382},
pmid = {26906504},
title = {{Efficient codes and balanced networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26906504 http://www.nature.com/doifinder/10.1038/nn.4243},
volume = {19},
year = {2016}
}
@article{Latimer2016a,
abstract = {Latimeret al (Reports, 10 July 2015, p. 184) claim that during perceptual decision formation, parietal neurons undergo one-time, discrete steps in firing rate instead of gradual changes that represent the accumulation of evidence. However, that conclusion rests on unsubstantiated assumptions about the time window of evidence accumulation, and their stepping model cannot explain existing data as effectively as evidence-accumulation models.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.7245v1},
author = {Latimer, K. W. and Yates, J. L. and Meister, M. L. R. and Huk, Alexander C. and Pillow, Jonathan W. and Ditterich, Jochen},
doi = {10.1126/science.aad3596},
eprint = {arXiv:1402.7245v1},
file = {:home/kaslu/Documents/Mendeley/2016 - Latimer et al. - Response to Comment on Single-trial spike trains in parietal cortex reveal discrete steps during decision-mak(2).pdf:pdf},
isbn = {10.1126/science.aaa4056},
issn = {0036-8075},
journal = {Science},
number = {6280},
pages = {1406--1406},
pmid = {27013723},
title = {{Response to Comment on "Single-trial spike trains in parietal cortex reveal discrete steps during decision-making"}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aad3596},
volume = {351},
year = {2016}
}
@article{Sahani2012,
author = {Sahani, Maneesh and Whiteley, Louise},
doi = {10.1093/acprof:oso/9780195387247.003.0005},
file = {:home/kaslu/Documents/Mendeley/2012 - Sahani, Whiteley - Modeling Cue Integration in Cluttered Environments.pdf:pdf},
isbn = {9780199918379},
journal = {Sensory Cue Integration},
keywords = {Attribute maps,Cue integration,Cue maps,Modeling,Perceptual inference,Single-valued cues,Spatial representation},
pages = {1--24},
title = {{Modeling Cue Integration in Cluttered Environments}},
year = {2012}
}
@article{Hellmann2016,
abstract = {Quantum information theory is built upon the realisation that quantum resources like coherence and entanglement can be exploited for novel or enhanced ways of transmitting and manipulating information, such as quantum cryptography, teleportation, and quantum computing. We now know that there is potentially much more than entanglement behind the power of quantum information processing. There exist more general forms of non-classical correlations, stemming from fundamental principles such as the necessary disturbance induced by a local measurement, or the persistence of quantum coherence in all possible local bases. These signatures can be identified and are resilient in almost all quantum states, and have been linked to the enhanced performance of certain quantum protocols over classical ones in noisy conditions. Their presence represents, among other things, one of the most essential manifestations of quantumness in cooperative systems, from the subatomic to the macroscopic domain. In this work we give an overview of the current quest for a proper understanding and characterisation of the frontier between classical and quantum correlations in composite states. We focus on various approaches to define and quantify general quantum correlations, based on different yet interlinked physical perspectives, and comment on the operational significance of the ensuing measures for quantum technology tasks such as information encoding, distribution, discrimination and metrology. We then provide a broader outlook of a few applications in which quantumness beyond entanglement looks fit to play a key role.},
author = {Hellmann, Frank and Kami{\'{n}}ski, Wojciech and Kostecki, Ryszard Pawe{\l}},
doi = {10.1088/1367-2630/18/1/013022},
file = {:home/kaslu/Documents/Mendeley/2016 - Hellmann, Kami{\'{n}}ski, Kostecki - Quantum collapse rules from the maximum relative entropy principle.pdf:pdf},
issn = {1367-2630},
journal = {New Journal of Physics},
month = {jan},
number = {1},
pages = {013022},
title = {{Quantum collapse rules from the maximum relative entropy principle}},
url = {http://stacks.iop.org/1367-2630/18/i=1/a=013022?key=crossref.2ebb61f65cf0bf28c7bae131324ed83a},
volume = {18},
year = {2016}
}
@article{Steele2015,
abstract = {For some ambiguous scenes perceptual conflict arises between integration and segregation. Initially, all stimulus features seem integrated. Then abruptly, perhaps after a few seconds, a segregated perceptual organization emerges. For example, segregation of acoustic features into streams may require several seconds. In behavioral experiments, when a subject's reports of stream segregation are averaged over repeated trials, one obtains a buildup function, a smooth time course for segregation probability. The buildup function has been said to reflect an underlying mechanism of evidence accumulation or adaptation. During long duration stimuli perception may alternate between integration and segregation. We present a statistical model based on an alternating renewal process that generates buildup functions without an accumulative process. In our model, perception alternates during a trial between different groupings, as in perceptual bistability, with random and independent dominance durations sampled from different percept-specific probability distributions. Using this theory, we describe the short-term dynamics of buildup observed on short trials in terms of the long-term statistics of percept durations for the two alternating perceptual organizations. Our statistical-dynamics model describes well the buildup functions and alternations in simulations of pseudo-mechanistic neuronal network models with percept-selective populations competing through mutual inhibition. Even though the competition model can show history dependence through slow adaptation, our statistical switching model, that neglects history, predicts well the buildup function. We propose that accumulation is not a necessary feature to produce buildup. Generally, if alternations between two states exhibit independent durations with stationary statistics then the associated buildup function can be described by the statistical dynamics of an alternating renewal process.},
author = {Steele, Sara A. and Tranchina, Daniel and Rinzel, John},
doi = {10.3389/fncom.2014.00166},
file = {:home/kaslu/Documents/Mendeley/2015 - Steele, Tranchina, Rinzel - An alternating renewal process describes the buildup of perceptual segregation.pdf:pdf},
isbn = {1662-5188},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
keywords = {alternating renewal process,bistable perception,buildup,perceptual dynamics,perceptual organization,stream segregation},
month = {jan},
pages = {166},
publisher = {Frontiers},
title = {{An alternating renewal process describes the buildup of perceptual segregation}},
url = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00166/abstract},
volume = {8},
year = {2015}
}
@article{Baldo2005,
abstract = {In the flash-lag effect (FLE) a moving object is perceived ahead of a stationary stimulus flashed in spatial alignment. Several explanations have been proposed to account for the FLE and its dependence on a variety of psychophysical attributes. Here, we show that a simple feed-forward network reproduces the standard FLE and several related manifestations, such as its modulation by stimulus luminance, trajectory, priming, and spatial predictability. A minimal set of elements, based on plausible neuronal mechanisms, yields a unified account of these visual illusions and possibly other perceptual phenomena. ?? 2005 Elsevier Ltd. All rights reserved.},
author = {Baldo, Marcus V. C. and Caticha, Nestor},
doi = {10.1016/j.visres.2005.04.014},
file = {:home/kaslu/Documents/Mendeley/2005 - Baldo, Caticha - Computational neurobiology of the flash-lag effect.pdf:pdf},
isbn = {0042-6989 (Print)$\backslash$r0042-6989 (Linking)},
issn = {00426989},
journal = {Vision Research},
keywords = {Flash-lag effect,Fr??hlich effect,Modeling,Neural network},
month = {sep},
number = {20},
pages = {2620--2630},
pmid = {15993457},
title = {{Computational neurobiology of the flash-lag effect}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698905002324 http://linkinghub.elsevier.com/retrieve/pii/S0042698905002324},
volume = {45},
year = {2005}
}
@article{Venkatasubramanian2015,
abstract = {The increasing inequality in income and wealth in recent years, and the associated excessive pay packages of CEOs in the US and elsewhere, is of growing concern among policy makers as well as the common person. However, there seems to be no satisfactory answer, in conventional economic theories and models, to the fundamental questions of what kind of income distribution we ought to see, at least under ideal conditions, in a free market environment, and whether this distribution is fair. We propose a novel microeconomic game theoretic framework that addresses these questions and proves that the lognormal distribution is the fairest inequality of pay in an organization comprising of homogeneous agents, under ideal free market conditions at equilibrium. We also show that for a population of two different classes of agents, the equilibrium distribution is a combination of two different lognormal distributions where one of them, corresponding to the top ∼3–5{\%} of the population, can be misidentified as a Pareto distribution. We compare our predictions with empirical data on global income inequality trends provided by Piketty and others. Our analysis suggests that the Scandinavian countries, and to a lesser extent Switzerland, Netherlands and Australia, have managed to get close to the ideal distribution for the bottom ∼99{\%} of the population, while the US and UK remain less fair at the other extreme. Other European countries such as France and Germany, and Japan and Canada, are in the middle. Our theory also shows the deep and direct connection between potential game theory and statistical mechanics through entropy, which we identify as a measure of fairness in a distribution. This leads us to propose the fair market hypothesis, that the self-organizing dynamics of the ideal free market, i.e., Adam Smith's “invisible hand”, not only promotes efficiency but also maximizes fairness under the given constraints.},
author = {Venkatasubramanian, Venkat and Luo, Yu and Sethuraman, Jay},
doi = {10.1016/j.physa.2015.04.014},
file = {:home/kaslu/Documents/Mendeley/2015 - Venkatasubramanian, Luo, Sethuraman - How much inequality in income is fair A microeconomic game theoretic perspective.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {CEO pay,Fairness,Game theory,Income inequality,Maximum entropy},
month = {oct},
pages = {120--138},
title = {{How much inequality in income is fair? A microeconomic game theoretic perspective}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437115003738},
volume = {435},
year = {2015}
}
@article{Caticha2007,
abstract = {Newtonian dynamics is derived from prior information codified into an appropriate statistical model. The basic assumption is that there is an irreducible uncertainty in the location of particles so that the state of a particle is defined by a probability distribution. The corresponding configuration space is a statistical manifold the geometry of which is defined by the information metric. The trajectory follows from a principle of inference, the method of Maximum Entropy. No additional "physical" postulates such as an equation of motion, or an action principle, nor the concepts of momentum and of phase space, not even the notion of time, need to be postulated. The resulting entropic dynamics reproduces the Newtonian dynamics of any number of particles interacting among themselves and with external fields. Both the mass of the particles and their interactions are explained as a consequence of the underlying statistical manifold.},
archivePrefix = {arXiv},
arxivId = {0710.1071},
author = {Caticha, Ariel and Cafaro, Carlo},
doi = {10.1063/1.2821259},
eprint = {0710.1071},
file = {:home/kaslu/Documents/Mendeley/2007 - Caticha, Cafaro - From Information Geometry to Newtonian Dynamics.pdf:pdf},
isbn = {9780735404687},
issn = {0094243X},
journal = {AIP Conference Proceedings},
month = {oct},
title = {{From Information Geometry to Newtonian Dynamics}},
url = {http://arxiv.org/abs/0710.1071 http://dx.doi.org/10.1063/1.2821259},
year = {2007}
}
@article{Barndorff-Nielsen1982,
author = {Barndorff-Nielsen, O. and Blaesild, P. and Jensen, J. L. and Jorgensen, B.},
doi = {10.1098/rspa.1982.0004},
file = {:home/kaslu/Documents/Mendeley/1982 - Barndorff-Nielsen et al. - Exponential Transformation Models.pdf:pdf},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
month = {jan},
number = {1776},
pages = {41--65},
title = {{Exponential Transformation Models}},
url = {http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.1983.0054 http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.1982.0004},
volume = {379},
year = {1982}
}
@inproceedings{Caticha2004,
abstract = {The method of Maximum (relative) Entropy (ME) is used to translate the information contained in the known form of the likelihood into a prior distribution for Bayesian inference. The argument is guided by intuition gained from the successful use of ME methods in statistical mechanics. For experiments that cannot be repeated the resulting "entropic prior" is formally identical with the Einstein fluctuation formula. For repeatable experiments, however, the expected value of the entropy of the likelihood turns out to be relevant information that must be included in the analysis. As an example the entropic prior for a Gaussian likelihood is calculated.},
archivePrefix = {arXiv},
arxivId = {physics/0312131},
author = {Caticha, Ariel and Preuss, Roland},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.1751380},
eprint = {0312131},
file = {:home/kaslu/Documents/Mendeley/2004 - Caticha, Preuss - Entropic Priors.pdf:pdf},
isbn = {0735401829},
issn = {0094243X},
month = {dec},
pages = {371--380},
primaryClass = {physics},
publisher = {AIP},
title = {{Entropic Priors}},
url = {http://arxiv.org/abs/physics/0312131 http://dx.doi.org/10.1063/1.1751380 http://aip.scitation.org/doi/abs/10.1063/1.1751380},
volume = {707},
year = {2004}
}
@article{Koren2017,
abstract = {Spontaneous activity is commonly observed in a variety of cortical states. Experimental evidence suggested that neural assemblies undergo slow oscillations with Up ad Down states even when the network is isolated from the rest of the brain. Here we show that these spontaneous events can be generated by the recurrent connections within the network and understood as signatures of neural circuits that are correcting their internal representation. A noiseless spiking neural network can represent its input signals most accurately when excitatory and inhibitory currents are as strong and as tightly balanced as possible. However, in the presence of realistic neural noise and synaptic delays, this may result in prohibitively large spike counts. An optimal working regime can be found by considering terms that control firing rates in the objective function from which the network is derived and then minimizing simultaneously the coding error and the cost of neural activity. In biological terms, this is equivalent to tuning neural thresholds and after-spike hyperpolarization. In suboptimal working regimes, we observe spontaneous activity even in the absence of feed-forward inputs. In an all-to-all randomly connected network, the entire population is involved in Up states. In spatially organized networks with local connectivity, Up states spread through local connections between neurons of similar selectivity and take the form of a traveling wave. Up states are observed for a wide range of parameters and have similar statistical properties in both active and quiescent state. In the optimal working regime, Up states are vanishing, leaving place to asynchronous activity, suggesting that this working regime is a signature of maximally efficient coding. Although they result in a massive increase in the firing activity, the read-out of spontaneous Up states is in fact orthogonal to the stimulus representation, therefore interfering minimally with the network function.},
author = {Koren, Veronika and Den{\`{e}}ve, Sophie},
doi = {10.1371/journal.pcbi.1005355},
editor = {Blackwell, Kim T.},
file = {:home/kaslu/Documents/Mendeley/2017 - Koren, Den{\`{e}}ve - Computational Account of Spontaneous Activity as a Signature of Predictive Coding.pdf:pdf},
isbn = {1111111111},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {jan},
number = {1},
pages = {e1005355},
pmid = {28114353},
title = {{Computational Account of Spontaneous Activity as a Signature of Predictive Coding}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1005355},
volume = {13},
year = {2017}
}
@article{Wilson1975,
abstract = {This review covers several topics involving renormalization group ideas. The solution of the s-wave Kondo Hamiltonian, describing a single magnetic impurity in a nonmagnetic metal, is explained in detail. See Secs. VII-IX. "Block spin" methods, applied to the two dimensional Ising model, are explained in Sec. VI. The first three sections give a relatively short review of basic renormalization group ideas, mainly in the context of critical phenomena. The relationship of the modern renormalization group to the older problems of divergences in statistical mechanics and field theory and field theoretic renormalization is discussed in Sec. IV. In Sec. V the special case of "marginal variables" is discussed in detail, along with the relationship of the modern renormalization group to its original formulation by Gell-Mann and Low and others.},
author = {Wilson, Kenneth G.},
doi = {10.1103/RevModPhys.47.773},
file = {:home/kaslu/Documents/Mendeley/1975 - Wilson - The renormalization group Critical phenomena and the Kondo problem.pdf:pdf},
isbn = {0034-6861},
issn = {00346861},
journal = {Reviews of Modern Physics},
number = {4},
pages = {773--840},
pmid = {4360451778447627413},
title = {{The renormalization group: Critical phenomena and the Kondo problem}},
volume = {47},
year = {1975}
}
@article{Makowsky2016,
abstract = {We consider a model of multilevel selection and the evolution of institutions that distribute power in the form of influence in a group's collective interactions with other groups. In the absence of direct group-level interactions, groups with the most cooperative members will outcompete less cooperative groups, while within any group the least cooperative members will be the most successful. Introducing group-level interactions, however, such as raiding or warfare, changes the selective landscape for groups. Our model suggests that as the global population becomes more integrated and the rate of intergroup conflict increases, selection increasingly favors unequally distributed power structures, where individual influence is weighted by acquired resources. The advantage to less democratic groups rests in their ability to facilitate selection for cooperative strategies - involving cooperation both among themselves and with outsiders - in order to produce the resources necessary to fuel their success in inter-group conflicts, while simultaneously selecting for leaders (and corresponding collective behavior) who are unburdened with those same prosocial norms. The coevolution of cooperative social norms and institutions of power facilitates the emergence of a leadership class of the selfish and has implications for theories of inequality, structures of governance, non-cooperative personality traits, and hierarchy. Our findings suggest an amendment to the well-known doctrine of multilevel selection that "Selfishness beats altruism within groups. Altruistic groups beat selfish groups." In an interconnected world, altruistic groups led by selfish individuals can beat them both.},
author = {Makowsky, Michael D. and Smaldino, Paul E.},
doi = {10.1016/j.jebo.2015.09.002},
isbn = {0167-2681},
issn = {01672681},
journal = {Journal of Economic Behavior and Organization},
keywords = {Agent-based modeling,Conflict,Cultural evolution,Cultural group selection,Institutions,Leadership,Multilevel selection},
pages = {75--88},
publisher = {Elsevier B.V.},
title = {{The evolution of power and the divergence of cooperative norms}},
url = {http://dx.doi.org/10.1016/j.jebo.2015.09.002},
volume = {126},
year = {2016}
}
@article{Mora2011,
abstract = {Many of life's most fascinating phenomena emerge from interactions among many elements--many amino acids determine the structure of a single protein, many genes determine the fate of a cell, many neurons are involved in shaping our thoughts and memories. Physicists have long hoped that these collective behaviors could be described using the ideas and methods of statistical mechanics. In the past few years, new, larger scale experiments have made it possible to construct statistical mechanics models of biological systems directly from real data. We review the surprising successes of this "inverse" approach, using examples form families of proteins, networks of neurons, and flocks of birds. Remarkably, in all these cases the models that emerge from the data are poised at a very special point in their parameter space--a critical point. This suggests there may be some deeper theoretical principle behind the behavior of these diverse systems.},
archivePrefix = {arXiv},
arxivId = {1012.2242},
author = {Mora, Thierry and Bialek, William},
doi = {10.1007/s10955-011-0229-4},
eprint = {1012.2242},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
month = {jun},
number = {2},
pages = {268--302},
title = {{Are Biological Systems Poised at Criticality?}},
url = {http://arxiv.org/abs/1012.2242},
volume = {144},
year = {2011}
}
@article{Kawai2015,
abstract = {Motor cortex is widely believed to underlie the acquisition and execution of motor skills, but its contributions to these processes are not fully understood. One reason is that studies on motor skills often conflate motor cortex's established role in dexterous control with roles in learning and producing task-specific motor sequences. To dissociate these aspects, we developed a motor task for rats that trains spatiotemporally precise movement patterns without requirements for dexterity. Remarkably, motor cortex lesions had no discernible effect on the acquired skills, which were expressed in their distinct pre-lesion forms on the very first day of post-lesion training. Motor cortex lesions prior to training, however, rendered rats unable to acquire the stereotyped motor sequences required for the task. These results suggest a remarkable capacity of subcortical motor circuits to execute learned skills and a previously unappreciated role for motor cortex in "tutoring" these circuits during learning. Motor cortex is widely credited with expanding the behavioral repertoire of mammals by enabling the acquisition and execution of new motor skills, but its specific contributions have been difficult to pin down. Using a novel motor skill learning paradigm, Kawai etal. show that motor cortex contributes to learning skills even when it is not required to execute them. This demonstrates a previously unappreciated role for motor cortex in "tutoring" subcortical circuits during skill learning.},
author = {Kawai, Risa and Markman, Timothy and Poddar, Rajesh and Ko, Raymond and Fantana, Antoniu L. and Dhawale, Ashesh K. and Kampff, Adam R. and {\"{O}}lveczky, Bence P.},
doi = {10.1016/j.neuron.2015.03.024},
file = {:home/kaslu/Documents/Mendeley/2015 - Kawai et al. - Motor Cortex Is Required for Learning but Not for Executing a Motor Skill.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
number = {3},
pages = {800--812},
pmid = {25892304},
title = {{Motor Cortex Is Required for Learning but Not for Executing a Motor Skill}},
volume = {86},
year = {2015}
}
@article{Martins2016,
abstract = {We believe in many different ways. One very common one is by supporting ideas we like. We label them correct and we act to dismiss doubts about them. We take sides about ideas and theories as if that was the right thing to do. And yet, from a rational point of view, this type of support and belief is not justifiable. The best we can hope when describing the real world, as far as we know today, is to have probabilistic knowledge. In practice, estimating a real probability can be too hard to achieve but that just means we have more uncertainty, not less. There are ideas we defend that define, in our minds, our own identity. And recent experiments have been showing that we stop being able to analyze competently those propositions we hold so dearly. In this paper, I gather the evidence we have about taking sides and present the obvious but unseen conclusion that these facts combined mean that we should actually never believe in anything about the real world, except in a probabilistic way. We must actually never take sides since taking sides compromise our abilities to seek for the most correct description of the world. That means we need to start reformulating the way we debate ideas, from our teaching to our political debates. Here, I will show the logical and experimental basis of this conclusion. I will also show, by presenting new models for the evolution of opinions, that our desire to have something to believe is probably behind the emergence of extremism in debates. And we will see how this problem can even have an impact in the reliability of whole scientific fields. The crisis around {\$}p{\$}-values is discussed and much better understood under the light of this paper results. Finally, I will debate possible consequences and ideas on how to deal with this problem.},
author = {Martins, Andr{\'{e}} C. R.},
doi = {10.3389/fphy.2016.00007},
file = {:home/kaslu/Documents/Mendeley/2016 - Martins - Thou Shalt Not Take Sides Cognition, Logic and the Need for Changing How We Believe.pdf:pdf},
issn = {2296-424X},
journal = {Frontiers in Physics},
keywords = {Cognition,belief system,epistemology,individual and group reasoning,logic,opinion dynamics},
month = {mar},
pages = {7},
publisher = {Frontiers},
title = {{Thou Shalt Not Take Sides: Cognition, Logic and the Need for Changing How We Believe}},
url = {http://journal.frontiersin.org/Article/10.3389/fphy.2016.00007/abstract},
volume = {4},
year = {2016}
}
@article{Heeger2017,
abstract = {Most models of sensory processing in the brain have a feedforward architecture in which each stage comprises simple linear filtering operations and nonlinearities. Models of this form have been used to explain a wide range of neurophysiological and psychophysical data, and many recent successes in artificial intelligence (with deep convolutional neural nets) are based on this architecture. However, neocortex is not a feedforward architecture. This paper proposes a first step toward an alternative computational framework in which neural activity in each brain area depends on a combination of feedforward drive (bottom-up from the previous processing stage), feedback drive (top-down context from the next stage), and prior drive (expectation). The relative contributions of feedforward drive, feedback drive, and prior drive are controlled by a handful of state parameters, which I hypothesize correspond to neuromodulators and oscillatory activity. In some states, neural responses are dominated by the feedforward drive and the theory is identical to a conventional feedforward model, thereby preserving all of the desirable features of those models. In other states, the theory is a generative model that constructs a sensory representation from an abstract representation, like memory recall. In still other states, the theory combines prior expectation with sensory input, explores different possible perceptual interpretations of ambiguous sensory inputs, and predicts forward in time. The theory, therefore, offers an empirically testable framework for understanding how the cortex accomplishes inference, exploration, and prediction. computational neuroscience | neural net | inference | prediction | vision},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Heeger, David J.},
doi = {10.1073/pnas.1619788114},
eprint = {arXiv:1408.1149},
file = {:home/kaslu/Documents/Mendeley/2017 - Heeger - Theory of cortical function.pdf:pdf},
isbn = {1091-6490},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {8},
pages = {1773--1782},
pmid = {28167793},
title = {{Theory of cortical function}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1619788114},
volume = {114},
year = {2017}
}
@article{Pillow2008,
abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20{\%} more information about the visual scene than decoding under the assumption of independence, and preserves 40{\%} more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
author = {Pillow, Jonathan W. and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M. and Chichilnisky, E. J. and Simoncelli, Eero P.},
doi = {10.1038/nature07140},
file = {:home/kaslu/Documents/Mendeley/2008 - Pillow et al. - Spatio-temporal correlations and visual signalling in a complete neuronal population.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
month = {aug},
number = {7207},
pages = {995--999},
pmid = {18650810},
title = {{Spatio-temporal correlations and visual signalling in a complete neuronal population}},
url = {http://www.nature.com/doifinder/10.1038/nature07140},
volume = {454},
year = {2008}
}
@article{Reagan2016,
abstract = {Advances in computing power, natural language processing, and digitization of text now make it possible to study our a culture's evolution through its texts using a "big data" lens. Our ability to communicate relies in part upon a shared emotional experience, with stories often following distinct emotional trajectories, forming patterns that are meaningful to us. Here, by classifying the emotional arcs for a filtered subset of 1,737 stories from Project Gutenberg's fiction collection, we find a set of six core trajectories which form the building blocks of complex narratives. We strengthen our findings by separately applying optimization, linear decomposition, supervised learning, and unsupervised learning. For each of these six core emotional arcs, we examine the closest characteristic stories in publication today and find that particular emotional arcs enjoy greater success, as measured by downloads.},
archivePrefix = {arXiv},
arxivId = {1606.07772},
author = {Reagan, Andrew J. and Mitchell, Lewis and Kiley, Dilan and Danforth, Christopher M. and Dodds, Peter Sheridan},
doi = {10.1140/epjds/s13688-016-0093-1},
eprint = {1606.07772},
issn = {2193-1127},
journal = {EPJ Data Science},
month = {dec},
number = {1},
pages = {31},
title = {{The emotional arcs of stories are dominated by six basic shapes}},
url = {http://arxiv.org/abs/1606.07772 http://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0093-1},
volume = {5},
year = {2016}
}
@article{Eddy2005,
author = {Eddy, Sean R},
doi = {10.1371/journal.pcbi.0010006},
file = {:home/kaslu/Documents/Mendeley/2005 - Eddy - Antedisciplinary science.pdf:pdf},
issn = {1553-734X},
journal = {PLoS computational biology},
month = {jun},
number = {1},
pages = {e6},
pmid = {16103907},
publisher = {Public Library of Science},
title = {{"Antedisciplinary" science.}},
url = {http://dx.doi.org/10.1371/journal.pcbi.0010006},
volume = {1},
year = {2005}
}
@article{Steckline1983,
author = {Steckline, Vincent S.},
doi = {10.1119/1.13373},
file = {:home/kaslu/Documents/Mendeley/1983 - Steckline - Zermelo, Boltzmann, and the recurrence paradox.pdf:pdf},
issn = {00029505},
journal = {American Journal of Physics},
number = {10},
pages = {894},
title = {{Zermelo, Boltzmann, and the recurrence paradox}},
url = {http://link.aip.org/link/?AJP/51/894/1{\&}Agg=doi},
volume = {51},
year = {1983}
}
@article{Smith2014,
abstract = {Increasingly-large datasets (for example, the resting-state fMRI data from the Human Connectome Project) are demanding analyses that are problematic because of the sheer scale of the aggregate data. We present two approaches for applying group-level PCA; both give a close approximation to the output of PCA applied to full concatenation of all individual datasets, while having very low memory requirements regardless of the number of datasets being combined. Across a range of realistic simulations, we find that in most situations, both methods are more accurate than current popular approaches for analysis of multi-subject resting-state fMRI studies. The group-PCA output can be used to feed into a range of further analyses that are then rendered practical, such as the estimation of group-averaged voxelwise connectivity, group-level parcellation, and group-ICA.},
author = {Smith, Stephen M. and Hyv{\"{a}}rinen, Aapo and Varoquaux, Ga{\"{e}}l and Miller, Karla L. and Beckmann, Christian F.},
doi = {10.1016/j.neuroimage.2014.07.051},
file = {:home/kaslu/Documents/Mendeley/2014 - Smith et al. - Group-PCA for very large fMRI datasets.pdf:pdf},
isbn = {1053-8119},
issn = {10959572},
journal = {NeuroImage},
keywords = {Big data,FMRI,ICA,PCA},
pages = {738--749},
pmid = {25094018},
publisher = {Elsevier Inc.},
title = {{Group-PCA for very large fMRI datasets}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2014.07.051},
volume = {101},
year = {2014}
}
@article{Fisher2015,
abstract = {The possibility that quantum processing with nuclear spins might be operative in the brain is proposed and then explored. Phosphorus is identified as the unique biological element with a nuclear spin that can serve as a qubit for such putative quantum processing - a neural qubit - while the phosphate ion is the only possible qubit-transporter. We identify the "Posner molecule", {\$}\backslashtext{\{}Ca{\}}{\_}9 (\backslashtext{\{}PO{\}}{\_}4){\_}6{\$}, as the unique molecule that can protect the neural qubits on very long times and thereby serve as a (working) quantum-memory. A central requirement for quantum-processing is quantum entanglement. It is argued that the enzyme catalyzed chemical reaction which breaks a pyrophosphate ion into two phosphate ions can quantum entangle pairs of qubits. Posner molecules, formed by binding such phosphate pairs with extracellular calcium ions, will inherit the nuclear spin entanglement. A mechanism for transporting Posner molecules into presynaptic neurons during a "kiss and run" exocytosis, which releases neurotransmitters into the synaptic cleft, is proposed. Quantum measurements can occur when a pair of Posner molecules chemically bind and subsequently melt, releasing a shower of intra-cellular calcium ions that can trigger further neurotransmitter release and enhance the probability of post-synaptic neuron firing. Multiple entangled Posner molecules, triggering non-local quantum correlations of neuron firing rates, would provide the key mechanism for neural quantum processing. Implications, both in vitro and in vivo, are briefly mentioned.},
archivePrefix = {arXiv},
arxivId = {1508.05929},
author = {Fisher, Matthew P. A.},
doi = {10.1016/j.aop.2015.08.020},
eprint = {1508.05929},
file = {:home/kaslu/Documents/Mendeley/2015 - Fisher - Quantum Cognition The possibility of processing with nuclear spins in the brain.pdf:pdf},
isbn = {00034916},
issn = {00034916},
journal = {Annals of Physics},
month = {aug},
pages = {593--602},
title = {{Quantum Cognition: The possibility of processing with nuclear spins in the brain}},
url = {http://arxiv.org/abs/1508.05929 http://linkinghub.elsevier.com/retrieve/pii/S0003491615003243},
volume = {362},
year = {2015}
}
@article{Aljadeff2016,
abstract = {As information flows through the brain, neuronal firing progresses from encoding the world as sensed by the animal to driving the motor output of subsequent behavior. One of the more tractable goals of quantitative neuroscience is to develop predictive models that relate the sensory or motor streams with neuronal firing. Here we review and contrast analytical tools used to accomplish this task. We focus on classes of models in which the external variable is compared with one or more feature vectors to extract a low-dimensional representation, the history of spiking and other variables are potentially incorporated, and these factors are nonlinearly transformed to predict the occurrences of spikes. We illustrate these techniques in application to datasets of different degrees of complexity. In particular, we address the fitting of models in the presence of strong correlations in the external variable, as occurs in natural sensory stimuli and in movement. Spectral correlation between predicted and measured spike trains is introduced to contrast the relative success of different methods.},
author = {Aljadeff, Johnatan and Lansdell, Benjamin J. and Fairhall, Adrienne L. and Kleinfeld, David},
doi = {10.1016/j.neuron.2016.05.039},
file = {:home/kaslu/Documents/Mendeley/2016 - Aljadeff et al. - Analysis of Neuronal Spike Trains, Deconstructed.pdf:pdf},
isbn = {0896-6273},
issn = {10974199},
journal = {Neuron},
keywords = {dimensional reduction,feature vector,neuroinformatics,predictive modeling,reverse correlation,systems identification,time series},
number = {2},
pages = {221--259},
pmid = {27477016},
publisher = {Elsevier Inc.},
title = {{Analysis of Neuronal Spike Trains, Deconstructed}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.05.039},
volume = {91},
year = {2016}
}
@article{Jazayeri2015,
abstract = {Timing plays a crucial role in sensorimotor function. However, the neural mechanisms that enable the brain to flexibly measure and reproduce time intervals are not known. We recorded neural activity in parietal cortex of monkeys in a time reproduction task. Monkeys were trained to measure and immediately afterward reproduce different sample intervals. While measuring an interval, neural responses had a nonlinear profile that increased with the duration of the sample interval. Activity was reset during the transition from measurement to production and was followed by a ramping activity whose slope encoded the previously measured sample interval. We found that firing rates at the end of the measurement epoch were correlated with both the slope of the ramp and the monkey's corresponding production interval on a trial-by-trial basis. Analysis of response dynamics further linked the rate of change of firing rates in the measurement epoch to the slope of the ramp in the production epoch. These observations suggest that, during time reproduction, an interval is measured prospectively in relation to the desired motor plan to reproduce that interval.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Jazayeri, Mehrdad and Shadlen, Michael N.},
doi = {10.1016/j.cub.2015.08.038},
eprint = {arXiv:1011.1669v3},
file = {:home/kaslu/Documents/Mendeley/2015 - Jazayeri, Shadlen - A Neural Mechanism for Sensing and Reproducing a Time Interval.pdf:pdf},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
number = {20},
pages = {2599--2609},
pmid = {26455307},
publisher = {Elsevier Ltd},
title = {{A Neural Mechanism for Sensing and Reproducing a Time Interval}},
url = {http://dx.doi.org/10.1016/j.cub.2015.08.038},
volume = {25},
year = {2015}
}
@inproceedings{Khalvati2015,
author = {Khalvati, Koosha and Rao, Rajesh P. N.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/kaslu/Documents/Mendeley/2015 - Khalvati, Rao - A Bayesian Framework for Modeling Confidence in Perceptual Decision Making.pdf:pdf},
pages = {2413--2421},
title = {{A Bayesian Framework for Modeling Confidence in Perceptual Decision Making}},
url = {https://papers.nips.cc/paper/5659-a-bayesian-framework-for-modeling-confidence-in-perceptual-decision-making},
year = {2015}
}
@article{Knill2004a,
abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are 'Bayes' optimal'. This leads to the 'Bayesian coding hypothesis': that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
author = {Knill, David C. and Pouget, Alexandre},
doi = {10.1016/j.tins.2004.10.007},
file = {:home/kaslu/Documents/Mendeley/2004 - Knill, Pouget - The Bayesian brain The role of uncertainty in neural coding and computation.pdf:pdf},
isbn = {0166-2236 (Print)$\backslash$n0166-2236 (Linking)},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {12},
pages = {712--719},
pmid = {15541511},
title = {{The Bayesian brain: The role of uncertainty in neural coding and computation}},
volume = {27},
year = {2004}
}
@article{Yeung2004,
abstract = {According to a recent theory, anterior cingulate cortex is sensitive to response conflict, the coactivation of mutually incompatible responses. The present research develops this theory to provide a new account of the error-related negativity (ERN), a scalp potential observed following errors. Connectionist simulations of response conflict in an attentional task demonstrated that the ERN--its timing and sensitivity to task parameters--can be explained in terms of the conflict theory. A new experiment confirmed predictions of this theory regarding the ERN and a second scalp potential, the N2, that is proposed to reflect conflict monitoring on correct response trials. Further analysis of the simulation data indicated that errors can be detected reliably on the basis of post-error conflict. It is concluded that the ERN can be explained in terms of response conflict and that monitoring for conflict may provide a simple mechanism for detecting errors.},
author = {Yeung, Nick and Botvinick, Matthew M. and Cohen, Jonathan D.},
doi = {10.1037/0033-295X.111.4.939},
file = {:home/kaslu/Documents/Mendeley/2004 - Yeung, Botvinick, Cohen - The Neural Basis of Error Detection Conflict Monitoring and the Error-Related Negativity.pdf:pdf},
isbn = {0033-295X$\backslash$r1939-1471},
issn = {0033-295X},
journal = {Psychological Review},
number = {4},
pages = {931--959},
pmid = {15482068},
title = {{The Neural Basis of Error Detection: Conflict Monitoring and the Error-Related Negativity.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.111.4.939},
volume = {111},
year = {2004}
}
@article{Elsayed2017,
abstract = {Neuroscientists increasingly analyze the joint activity of multineuron recordings to identify population-level structures believed to be significant and scientifically novel. Claims of significant population structure support hypotheses in many brain areas. However, these claims require first investigating the possibility that the population structure in question is an expected byproduct of simpler features known to exist in data. Classically, this critical examination can be either intuited or addressed with conventional controls. However, these approaches fail when considering population data, raising concerns about the scientific merit of population-level studies. Here we develop a framework to test the novelty of population-level findings against simpler features such as correlations across times, neurons and conditions. We apply this framework to test two recent population findings in prefrontal and motor cortices, providing essential context to those studies. More broadly, the methodologies we introduce provide a general neural population control for many population-level hypotheses.},
author = {Elsayed, Gamaleldin F. and Cunningham, John P.},
doi = {10.1038/nn.4617},
file = {:home/kaslu/Documents/Mendeley/2017 - Elsayed, Cunningham - Structure in neural population recordings an expected byproduct of simpler phenomena.pdf:pdf},
isbn = {1546-1726 (Electronic) 1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = {aug},
number = {9},
pages = {1310--1318},
pmid = {28783140},
title = {{Structure in neural population recordings: an expected byproduct of simpler phenomena?}},
url = {http://www.nature.com/doifinder/10.1038/nn.4617},
volume = {20},
year = {2017}
}
@article{Pesaran2002,
abstract = {Many cortical structures have elevated firing rates during working memory, but it is not known how the activity is maintained. To investigate whether reverberating activity is important, we studied the temporal structure of local field potential (LFP) activity and spiking from area LIP in two awake macaques during a memory-saccade task. Using spectral analysis, we found spatially tuned elevated power in the gamma band (25-90 Hz) in LFP and spiking activity during the memory period. Spiking and LFP activity were also coherent in the gamma band but not at lower frequencies. Finally, we decoded LFP activity on a single-trial basis and found that LFP activity in parietal cortex discriminated between preferred and anti-preferred direction with approximately the same accuracy as the spike rate and predicted the time of a planned movement with better accuracy than the spike rate. This finding could accelerate the development of a cortical neural prosthesis.},
archivePrefix = {arXiv},
arxivId = {q-bio/0309034},
author = {Pesaran, Bijan and Pezaris, John S. and Sahani, Maneesh and Mitra, Partha P. and Andersen, Richard A.},
doi = {10.1038/nn890},
eprint = {0309034},
file = {:home/kaslu/Documents/Mendeley/2002 - Pesaran et al. - Temporal structure in neuronal activity during working memory in macaque parietal cortex.pdf:pdf},
isbn = {1097-6256},
issn = {10976256},
journal = {Nature Neuroscience},
number = {8},
pages = {805--811},
pmid = {12134152},
primaryClass = {q-bio},
title = {{Temporal structure in neuronal activity during working memory in macaque parietal cortex}},
volume = {5},
year = {2002}
}
@article{Rosenbaum2017,
abstract = {Shared neural variability is ubiquitous in cortical populations. While this variability is presumed to arise from overlapping synaptic input, its precise relationship to local circuit architecture remains unclear. We combine computational models and in vivo recordings to study the relationship between the spatial structure of connectivity and correlated variability in neural circuits. Extending the theory of networks with balanced excitation and inhibition, we find that spatially localized lateral projections promote weakly correlated spiking, but broader lateral projections produce a distinctive spatial correlation structure: nearby neuron pairs are positively correlated, pairs at intermediate distances are negatively correlated and distant pairs are weakly correlated. This non-monotonic dependence of correlation on distance is revealed in a new analysis of recordings from superficial layers of macaque primary visual cortex. Our findings show that incorporating distance-dependent connectivity improves the extent to which balanced network theory can explain correlated neural variability.},
author = {Rosenbaum, Robert and Smith, Matthew A and Kohn, Adam and Rubin, Jonathan E and Doiron, Brent},
doi = {10.1038/nn.4433},
file = {:home/kaslu/Documents/Mendeley/2017 - Rosenbaum et al. - The spatial structure of correlated neuronal variability.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
keywords = {Network models,Neural circuits},
month = {oct},
number = {1},
pages = {107--114},
pmid = {27798630},
publisher = {Nature Publishing Group},
title = {{The spatial structure of correlated neuronal variability}},
url = {http://www.nature.com/doifinder/10.1038/nn.4433},
volume = {20},
year = {2017}
}
@article{Sahani2003,
abstract = {Perceptual inference fundamentally involves uncertainty, arising from noise in sensation and the ill-posed nature of many perceptual problems. Accurate perception requires that this uncertainty be correctly represented, manipulated, and learned about. The choicessubjects makein various psychophysical experiments suggest that they do indeed take such uncertainty into account when making perceptual inferences, posing the question as to how uncertainty is represented in the activities of neuronal populations. Most theoretical investigations of population coding have ignored this issue altogether; the few existing proposals that address it do so in such a way that it is fatally conflated with another facet of perceptual problems that also needs correct handling: multiplicity (that is, the simultaneous presence of multiple distinct stimuli). We present and validate a more powerful proposal for the way that population activity may encode uncertainty, both distinctly from and simultaneously with multiplicity.},
author = {Sahani, Maneesh and Dayan, Peter},
doi = {10.1162/089976603322362356},
file = {:home/kaslu/Documents/Mendeley/2003 - Sahani, Dayan - Doubly Distributional Population Codes Simultaneous Representation of Uncertainty and Multiplicity.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
number = {10},
pages = {2255--2279},
pmid = {14511521},
title = {{Doubly Distributional Population Codes: Simultaneous Representation of Uncertainty and Multiplicity}},
url = {http://www.mitpressjournals.org/doi/10.1162/089976603322362356},
volume = {15},
year = {2003}
}
@article{Koch2000,
author = {Koch, Christof and Segev, Idan},
doi = {10.1038/81444},
file = {:home/kaslu/Documents/Mendeley/2000 - Koch, Segev - The role of single neurons in information processing.pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
month = {nov},
number = {Supp},
pages = {1171--1177},
title = {{The role of single neurons in information processing}},
url = {http://oac.hsc.uth.tmc.edu/uth{\_}orgs/ngs/journalclub/files/KochSegev.pdf http://www.nature.com/doifinder/10.1038/81444},
volume = {3},
year = {2000}
}
@article{Solla1998,
abstract = {The recently proposed Bayesian approach to online learning is ap-plied to learning a rule deened as a noisy single layer perceptron with either continuous or binary weights. In the Bayesian online approach the exact posterior distribution is approximated by a simpler paramet-ric posterior that is updated online as new examples are incorporated to the dataset. In the case of continuous weights, the approximate pos-terior is chosen to be Gaussian. The computational complexity of the resulting online algorithm is found to be at least as high as that of the Bayesian ooine approach, making the online approach less attractive. A Hebbian approximation based on casting the full covariance matrix into an isotropic diagonal form signiicantly reduces the computational complexity and yields a previously identiied optimal Hebbian algo-rithm. In the case of binary weights, the approximate posterior is cho-sen to be a biased binary distribution. The resulting online algorithm is derived and shown to outperform several other online approaches to this problem.},
author = {Solla, SA and Winther, Ole},
file = {:home/kaslu/Documents/Mendeley/1998 - Solla, Winther - Optimal perceptron learning an online Bayesian approach.pdf:pdf},
isbn = {0-521-65263-4},
journal = {On-Line Learning in Neural Networks (Cambridge {\ldots}},
title = {{Optimal perceptron learning: an online Bayesian approach}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Optimal+Perceptron+Learning:+an+Online+Bayesian+Approach{\#}0},
year = {1998}
}
@article{Nowak2006,
abstract = {Cooperation is needed for evolution to construct new levels of organization. Genomes, cells, multicellular organisms, social insects, and human society are all based on cooperation. Cooperation means that selfish replicators forgo some of their reproductive potential to help one another. But natural selection implies competition and therefore opposes cooperation unless a specific mechanism is at work. Here I discuss five mechanisms for the evolution of cooperation: kin selection, direct reciprocity, indirect reciprocity, network reciprocity, and group selection. For each mechanism, a simple rule is derived that specifies whether natural selection can lead to cooperation.},
author = {Nowak, Martin},
doi = {10.1126/science.1133755},
isbn = {doi:10.1126/science.1133755},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
number = {5805},
pages = {1560--1563},
pmid = {17158317},
title = {{Five rules for the evolution of cooperation.}},
volume = {314},
year = {2006}
}
@article{MALONEY2009,
abstract = {Bayesian decision theory (BDT) is a mathematical framework that allows the experimenter to model ideal performance in a wide variety of visuomotor tasks. The experimenter can use BDT to compute benchmarks for ideal performance in such tasks and compare human performance to ideal. Recently, researchers have asked whether BDT can also be treated as a process model of visuomotor processing. It is unclear what sorts of experiments are appropriate to testing such claims and whether such claims are even meaningful. Any such claim presupposes that observers' performance is close to ideal, and typical experimental tests involve comparison of human performance to ideal. We argue that this experimental criterion, while necessary, is weak. We illustrate how to achieve near-optimal performance in combining perceptual cues with a process model bearing little resemblance to BDT. We then propose experimental criteria termed transfer criteria that constitute more powerful tests of BDT as a model of perception and action. We describe how recent work in motor control can be viewed as tests of transfer properties of BDT. The transfer properties discussed here comprise the beginning of an operationalization (Bridgman, 1927) of what it means to claim that perception is or is not Bayesian inference (Knill {\&} Richards, 1996). They are particularly relevant to research concerning natural scenes since they assess the ability of the organism to rapidly adapt to novel tasks in familiar environments or carry out familiar tasks in novel environments without learning.},
author = {MALONEY, LAURENCE T. and MAMASSIAN, PASCAL},
doi = {10.1017/S0952523808080905},
file = {:home/kaslu/Documents/Mendeley/2009 - MALONEY, MAMASSIAN - Bayesian decision theory as a model of human visual perception Testing Bayesian transfer.pdf:pdf},
isbn = {978-1-4020-8698-4},
issn = {0952-5238},
journal = {Visual Neuroscience},
keywords = {Bayesian decision theory,Bayesian transfer,Loss function,Perception,Statistical models,bayesian decision theory,bayesian transfer,loss function,perception,statistical models},
month = {jan},
number = {01},
pages = {147},
pmid = {19193251},
title = {{Bayesian decision theory as a model of human visual perception: Testing Bayesian transfer}},
url = {http://www.journals.cambridge.org/abstract{\_}S0952523808080905},
volume = {26},
year = {2009}
}
@article{Caticha1997,
abstract = {The ideas of optimization of learning algorithms in Artificial Neural Networks are reviewed emphasizing generic properties and the online implementations are interpreted from a biological perspective. A simple model of the relevant subsidiary variables needed to improve learning in artificial feedforward networks and the `time ordering' of the appearance of the respective information processing systems is proposed. We discuss the possibility that these results might be relevant in other contexts, not being restricted to the simple models from which they stem. The analysis of a few examples, which range from the lowest cellular scale to the macroscopic level, suggests that similar ideas could be applied to biological systems.},
archivePrefix = {arXiv},
arxivId = {cond-mat/9706112},
author = {Caticha, Nestor and Kinouchi, Osame},
doi = {10.1080/13642819808205049},
eprint = {9706112},
issn = {1364-2812},
journal = {Philosophical Magazine Part B},
month = {may},
number = {5},
pages = {1565--1574},
primaryClass = {cond-mat},
title = {{Time ordering in the evolution of information processing and modulation systems}},
url = {http://arxiv.org/abs/cond-mat/9706112 http://www.tandfonline.com/doi/abs/10.1080/13642819808205049 http://dx.doi.org/10.1080/13642819808205049},
volume = {77},
year = {1998}
}
@article{Neirotti2010,
abstract = {We explore the effects of over-specificity in learning algorithms by investigating the behavior of a student, suited to learn optimally from a teacher {\$}\backslashmathbf{\{}B{\}}{\$}, learning from a teacher {\$}\backslashmathbf{\{}B{\}}'\backslashneq\backslashmathbf{\{}B{\}}{\$}. We only considered the supervised, on-line learning scenario with teachers selected from a particular family. We found that, in the general case, the application of the optimal algorithm to the wrong teacher produces a residual generalization error, even if the right teacher is harder. By imposing mild conditions to the learning algorithm form we obtained an approximation for the residual generalization error. Simulations carried in finite networks validate the estimate found.},
archivePrefix = {arXiv},
arxivId = {0906.5461},
author = {Neirotti, Juan Pablo},
doi = {10.1088/1751-8113/43/1/015101},
eprint = {0906.5461},
file = {:home/kaslu/Documents/Mendeley/2010 - Neirotti - Can a student learn optimally from two different teachers.pdf:pdf},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and Theoretical},
month = {jan},
number = {1},
pages = {015101},
title = {{Can a student learn optimally from two different teachers?}},
url = {http://arxiv.org/abs/0906.5461 http://stacks.iop.org/1751-8121/43/i=1/a=015101?key=crossref.ecd42bdb7febe389178528beb18654c1},
volume = {43},
year = {2010}
}
@article{Starkweather2017a,
abstract = {A long-standing idea in modern neuroscience is that the brain computes inferences about the outside world rather than passively observing its environment. The authors record from midbrain dopamine neurons during tasks with different reward contingencies and show that responses are consistent with a learning rule that harnesses hidden-state inference.},
author = {Starkweather, Clara Kwon and Babayan, Benedicte M and Uchida, Naoshige and Gershman, Samuel J},
doi = {10.1038/nn.4520},
issn = {1097-6256},
journal = {Nature Neuroscience 2017 20:4},
number = {4},
pages = {581},
title = {{Dopamine reward prediction errors reflect hidden-state inference across time}},
url = {http://www.nature.com/articles/nn.4520 https://www.nature.com/articles/nn.4520},
volume = {20},
year = {2017}
}
@article{O'Reilly2006,
abstract = {Computer models based on the detailed biology of the brain can help us understand the myriad complexities of human cognition and intelligence. Here, we review models of the higher level aspects of human intelligence, which depend critically on the prefrontal cortex and associated subcortical areas. The picture emerging from a convergence of detailed mechanistic models and more abstract functional models represents a synthesis between analog and digital forms of computation. Specifically, the need for robust active maintenance and rapid updating of information in the prefrontal cortex appears to be satisfied by bistable activation states and dynamic gating mechanisms. These mechanisms are fundamental to digital computers and may be critical for the distinctive aspects of human intelligence.},
author = {O'Reilly, Randall C},
doi = {10.1126/science.1127242},
file = {:home/kaslu/Documents/Mendeley/2006 - O'Reilly - Biologically based computational models of high-level cognition.pdf:pdf},
isbn = {0036-8075},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Brain,Brain: physiology,Cognition,Computer Simulation,Humans,Intelligence,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology},
month = {oct},
number = {5796},
pages = {91--4},
pmid = {17023651},
title = {{Biologically based computational models of high-level cognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17023651},
volume = {314},
year = {2006}
}
@article{Churchland2016a,
abstract = {Recent years have seen a growing interest in understanding the neural mechanisms that support decision-making. The advent of new tools for measuring and manipulating neurons, alongside the inclusion of multiple new animal models and sensory systems has led to the generation of many novel datasets. The potential for these new approaches to constrain decision-making models is unprecedented. Here, we argue that to fully leverage these new approaches, three challenges must be met. First, experimenters must design well-controlled behavioral experiments that make it possible to distinguish competing behavioral strategies. Second, analyses of neural responses should think beyond single neurons, taking into account tradeoffs of single-trial versus trial-averaged approaches. Finally, quantitative model comparisons should be used, but must consider common obstacles.},
author = {Churchland, Anne K. and Kiani, Roozbeh},
doi = {10.1016/j.cobeha.2016.06.008},
file = {:home/kaslu/Documents/Mendeley/2016 - Churchland, Kiani - Three challenges for connecting model to mechanism in decision-making.pdf:pdf},
isbn = {2352-1546 (Linking)},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {74--80},
pmid = {27403450},
publisher = {Elsevier Ltd},
title = {{Three challenges for connecting model to mechanism in decision-making}},
url = {http://dx.doi.org/10.1016/j.cobeha.2016.06.008},
volume = {11},
year = {2016}
}
@article{Dieckmann1995,
abstract = {This paper describes the coevolution of phenotypes in a community comprising a population of predators and of prey. It is shown that evolutionary cycling is a likely outcome of the process. The dynamical systems on which this description is based are constructed from microscopic stochastic birth and death events, together with a process of random mutation. Births and deaths are caused in part by phenotype-dependent interactions between predator and prey individuals and therefore generate natural selection. Three outcomes of evolution are demonstrated. A community may evolve to a state at which the predator becomes extinct, or to one at which the species coexist with constant phenotypic values, or the species may coexist with cyclic changes in phenotypic values. The last outcome corresponds to a Red Queen dynamic, in which the selection pressures arising from the predator-prey interaction cause the species to evolve without ever reaching an equilibrium phenotypic state. The Red Queen dynamic requires an intermediate harvesting efficiency of the prey by the predator and sufficiently high evolutionary rate constant of the prey, and is robust when the model is made stochastic and phenotypically polymorphic. A cyclic outcome lies outside the contemporary focus on evolutionary equilibria, and argues for an extension to a dynamical framework for describing the asymptotic states of evolution.},
author = {Dieckmann, Ulf and Marrow, Paul and Law, Richard},
doi = {10.1006/jtbi.1995.0179},
file = {:home/kaslu/Documents/Mendeley/1995 - Dieckmann, Marrow, Law - Evolutionary cycling in predator-prey interactions population dynamics and the red queen.pdf:pdf},
isbn = {0022-5193 (Print)},
issn = {0022-5193},
journal = {Journal of theoretical biology},
month = {sep},
number = {1},
pages = {91--102},
pmid = {7475110},
title = {{Evolutionary cycling in predator-prey interactions: population dynamics and the red queen.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022519385701798},
volume = {176},
year = {1995}
}
@article{Mason2016Supp,
abstract = {We used functional MRI (fMRI) to assess neural representations of physics concepts (momentum, energy, etc.) in juniors, seniors, and graduate students majoring in physics or engineering. Our goal was to identify the underlying neural dimensions of these representations. Using factor analysis to reduce the number of dimensions of activation, we obtained four physics-related factors that were mapped to sets of voxels. The four factors were interpretable as causal motion visualization, periodicity, algebraic form, and energy flow. The individual concepts were identifiable from their fMRI signatures with a mean rank accuracy of .75 using a machine-learning (multivoxel) classifier. Furthermore, there was commonality in participants' neural representation of physics; a classifier trained on data from all but one participant identified the concepts in the left-out participant (mean accuracy = .71 across all nine participant samples). The findings indicate that abstract scientific concepts acquired in an educational setting evoke activation patterns that are identifiable and common, indicating that science education builds abstract knowledge using inherent, repurposed brain systems.},
author = {Mason, Robert A. and Just, Marcel Adam},
doi = {10.1177/0956797616641941},
file = {:home/kaslu/Documents/Mendeley/2016 - Mason, Just - Neural Representations of Physics Concepts SUPPLEMENTARY MATERIAL.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = {jun},
number = {6},
pages = {Supp},
title = {{Neural Representations of Physics Concepts SUPPLEMENTARY MATERIAL}},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797616641941},
volume = {27},
year = {2016}
}
