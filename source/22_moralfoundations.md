
## Moral Foundations Theory {#sec:moralfoundations}

How do people assess morality in everyday life? Recently this has been investigated extensively by Haidt and collaborators [a nice explanation can be found in @Haidt2007]. We outline some of their conclusions through several years and articles below.

In [@Haidt2001] was proposed that moral judgment is not a consequence of moral reasoning, but of "quick, automatic evaluations (_intuitions_)". According to this proposal moral reasoning "is an effortful process, engaged in after a moral judgment is made, in which a person searches for arguments that will support an already-made judgment" (pg. 818)

Although there are well-stated criticisms [@Pizarro2003] toward Haidt's _moral intuitionist_ model[^criticism], it is already clear that emotions and intuitions are primordial when humans make moral judgments [@Greene2009]. This is important to us because it is easier to model intuitive mechanisms of the brain than more elaborate ones. This also inform us that the human's action and reaction to moral assertions is prompt, immediate and mostly unconscious.

Also from this line of research, they found support for the idea that the human mind comes equipped with 5 "modules" [@Haidt2004][^mft4] to judge morality: Harm, Fairness (the ones agreed upon throughout academic community), Loyalty, Ingroup/Authority and Purity/Sanctity. This is now known as the ***Moral Foundations Theory*** [MFT @Graham2013].

This is a core pillar to our research because it is what guarantees that the assessment of morality happens within a finite set of dimensions, even if psychologists happen to find more foundations later. Morality does not happen in a non-comprehensible infinite space, nor is it an intermingle of "yes or no" output to one-case judgments.

Finally, [@Gilligan2012] developed a "reliable and theoretically-grounded measurement of the full range of moral concerns", the ***Moral Foundations Questionnaire*** (MFQ). It is set of responses people gave stating their opinions on 30 questions about morality. [^mfqonline] Those questions ranged through all of the moral foundations developed by the authors in previous works. Subjects also labeled themselves with what the researchers called  **political affiliations** (_pa_), which could one of the following entries: Very Liberal, Liberal, Slightly Liberal, Moderate, Slightly Conservative, Conservative, Very Conservative, Libertarian, Other and Don't know (we disregarded the last 3 categories in our analysis in [@sec:results:model2]).

This piece of their research culminated in discovering that people from different political affiliations tend to see moral assertions through different "lenses": people more inclined to be defined as Liberals tend to give more importance to features such as Harm and Care, whereas people self-labeled as Conservatives aggregate Ingroup, Loyalty and Purity dimensions to the first two (we reproduced this result from the MFQ's data in [@fig:4zeitgeists]).

This is an important piece of information for social psychology, a field which historically has focused much on Harm and Care, but has not had many accompanying developments on the study of the other foundations.

[^mfqonline]:

    One can take this same test and evaluate oneself at <https://www.yourmorals.org/>

[^mft4]:

    At the time they thought to be only 4. Now there is a discussion to propose a sixth one: maybe a Liberty dimension should be included to account for the libertarian movement [@Iyer2012]

[^criticism]:

    Namely, they argue for the relevance of some moral reasoning mechanism apart from the intuition circuitry. In their words, "there is considerable evidence from outside the laboratory that people actively engage in reasoning when faced with real-world moral dilemmas. Together, these facts limit the strong claims of the social intuitionist model concerning the irrelevance of conscious deliberation."
